[
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Map Azure DevOps Runtime Variables to Terraform Input Variables. This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790. opportunity to present our work you know we blog and you know there are a lot of people blogging there are a lot of people writing automations nowadays and if you see the Twitter and Linkedin it's like exploding like you know and every second somebody is posting something so these meetups you know gets opportunity People Like Us uh to showcase our work and uh thank you so much for that uh a little introduction about myself uh my name is Aranda Mitra and I have overall of 16 years of experience and in information technology I started uh as a data center uh specialist and I worked in data center in all Technologies being there and perhaps Cisco the next Windows you need it and I have worked on it um for close to 10 10 11 years and then I slowly moved into Cloud I started working with AWS for it for a year and then when I switched to Marshall so I'm now close to five years working in Azure I started with assessment and lift and shift and then I slowly moved into uh to Azure and then I slowly moved into infrastructure as a code devops and now currently I am working as a Azure Cloud solution a devops architect in Oxford Solutions um I normally block uh mostly about devops I in a way you can say that I love to automate things as much as possible wherever it is possible I I like to explore more so I normally specialize in Azure devops GitHub actions uh Powershell accli terraform so these are my core areas and uh with all the projects which I have worked I have right now worked on 50 or 52 Azure Services overall so so you can you can uh you can see that uh that you know I I normally put everything on my GitHub it's public so I I normally blog in in Dev dot two so this is where I blog and uh this is this is uh at the moment you know everything is here you can see you can have it and all this infrastructure as a code and I have like a lot of CDs out here I have a security started recently I have a terraform I have troubleshooting I have architecture detective actions there's also series called ops intervals so uh depending upon which category I'm writing or maybe when I'm working I find that you know something is really good enough to share that the world I know you do that so you can find uh you can you can have a look out here so for each of my topic uh what I do is I create a repository I'm sorry I normally create a repository out here and and after the repository you know I put my code for example like uh like catalog and access packages the other one so I spokes like you know this year I spoken um Azure spring clean so this is how I maintain so you can find the code out here the complete code so this is the whole code you will find out here um which ideally in your environment you have to just change few values and it should run and then I I put put I whatever I block that is also Version Control so whatever you see here you will also see it in my GitHub so I also document or uh the blog which I'm writing that is also Version Control so this is how I maintain it uh in my things so for everything you can have it for uh for any things you know which uh for example which is uh the sessions which I give and evidence to record it so that is also a part of a part of my tweet augmentations and everything so you can see that in anywhere which I have spoken wherever I had spoken that's all the YouTube videos are linked out here and it's a similar fashion you know which like you know today is my topic is there's there's no mapping of this adjective of runtime data booster terraform input field you will see that and I have already put it into that you know this is the this is what I'm presenting in first country so um so again going back to my GitHub repository so you can find me in uh in blog uh in dev.to you can find me in LinkedIn Twitter you can also find me such nice Facebook anything so this is my session next profile uh where I I normally apply for all the speaker sessions it has also uh deeply up to date wherever I do I have paid here as well so this is a little bit about my Twitter profile and of course this is my LinkedIn uh you know whenever I'm posting a blog or I'm speaking somewhere uh I normally put as much as detail as possible so that you know can benefit from that now the only thing you know so I'm basically blogging and basically speaking for close to like um like you know like five six years now uh with Azure I started blogging a year back and uh just to just for everybody to know"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:05:04",
        "seconds": 304,
        "text": "from that now the only thing you know so I'm basically blogging and basically speaking for close to like um like you know like five six years now uh with Azure I started blogging a year back and uh just to just for everybody to know that um I have recently applied for my MVP so I submitted my application eight for example I'm still waiting I don't know whether it's selected or not so this is about me and why I say about the citizen of the world is because you know I travel a lot a person with uh professionally so total like you know with my personal and professionally I have visited 22 countries till late and I have worked in I started working from Kuwait and then I worked in Dubai and after that I moved to hungari after from India in Zurich direct to New York New York to Baltimore Baltimore to Canada and then back to Switzerland so this is the because I was working in managed services and a lot of customer platforms so I traveled a lot and I learned a lot from that so uh this is a little bit about myself and uh now I will immediately jump into my topic uh which is like you know how uh mapping of the Azure devops runtime variables to telephone so a little background background about this that you know how I I came up with this topic it was mostly like you know if somebody has worked in terraform uh there is always like a variable uh there's a variable file and there is also a TF parse file the readable file is where you are defining that what is the type of the variable whether it's an array whether it's a string uh whether it's a Boolean whether it's a map so you define the variable out there but again you know uh in order to put the value so it's just like a key value pair so you define a variable and then you uh you put a value to that variable so that value is in tfrs and then all of a sudden you know I was reading one of the documentation that was uh I was reading this documentation of environmental variables and there they wrote that uh data from a hashicorp the group that you can you don't have to define the value um you don't have to define the value in the tfrs file but you can always use as an input variable from your yaml pipeline and that gave me the use case that okay what happens if like you know I'm I'm writing like for example I want to deploy a resource Group and I want to deploy a user assigned manager identity so this is about my blog of course so um then I have to give a name so I have to Define uh that okay there has to be a variable for my Resource Group and there has to be a variable for my user defined managed entity uh so uh for those you know I have to again have a value in my TF parse file what happens if I don't give it and you know I'm not hard coding those values but you know I am asking the user who is executing the pipeline to put the values and then you know that value I'm automatically passing without even refining in the TFS file so that is how I came up with this and this is what I'm going to explain you first a little bit and then I'm going to run a live demo so that you can see that you know what all things have happened so here so this is what I tried to explain as as what I'm going to demonstrate so I'm going to map the the runtime variables to the input variables and then you know we'll see that you know there is no need of defining the values of the variable and the quality of fast file so uh scrolling up a little bit you know of course you know for all these things you know I would be requiring a subscription I would be requiring a devops organization a project I would be requiring a SPI in the azure 80. that SBI I need to configure in my devops project as service connection because Azure devops is one entity Azure is another entity and you have to connect those that is how you know when you are going to run the infrastructure as a code that is how it gets deployed to your Azure portal so that is the magic which the SPI which is defined in in the Azure tenant Azure 80 and your directory services and that you know uh the object ID or the client ID and the secret then you use in this service connection Define and then of course uh we need the the terraform extension and the startup from extension has to be in the Microsoft because there are a lot of custom terraform extension as well available in the visual studio Marketplace so um so again you know from from my blog you can immediately from here you can jump to the GitHub repository and of course you know just to give a look uh that you know how my code plays with the looks because you know when I I read others blog and I see the problems which I face when I'm reading or I'm trying to follow somebody has written something and I'm trying to follow in my real life uh I see the problem and for me it's very important to see that anybody who has blocked or has written something you"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:10:07",
        "seconds": 607,
        "text": "I'm reading or I'm trying to follow somebody has written something and I'm trying to follow in my real life uh I see the problem and for me it's very important to see that anybody who has blocked or has written something you know how his local environment looks like because then that gives me an idea that gives me an inkling in my head I can map it out that okay so he developed the whole code like this so that is why I put the small screenshot showing the audiences that hey uh the way I did it is like I created a folder like you as a USR hyphen mid managed entity and then I have my yaml pipeline then I have my name dot EF and then I have the resource dot here then I had the tfrs where I'm defining the values and this is the variable that identifying people get an idea and kind of thing and then you know I'm I'm setting the uh setting the objective that okay what my automation is going to do so I'm going to Define so I'm going to deploy a small very small Resource Group and I'm going to define a user assigned manage identity inside that research Resource Group but I am not going to provide the value in my TF class the value is going to come from the runtime variables and this is this is my main entire code is here uh and uh and this is how it looks like so I will what I will do is I will immediately jump into my code so that I can extreme you better so um when when we are uh when we are doing this infrastructure as a code or devops uh it's very essential that you know we have to understand few things very important so your terraform is your scripting language where you're defining that how and what resources you want to deploy and your devops pipeline is a mechanism which is taking that infrastructure as a code and then helping you push it uh to to Azure to to build those resources so when we are doing this whole CI CD continuous integration continuous deployment it is basically like you know you are amalgamating two different languages one is the yaml another is a terraforms cutting language and then it starts becoming a little bit complex it's just like Azure you know when you're playing with one resource it's simple you add another resource on the top 10 percent complexity increases then you add another two three resources another twenty percent of complexity increases so it's just like that so that is why some terminologies has to be understood very very clearly the first thing about this whole automation is um I'm talking about the runtime variables what does this runtime variable means so this is the pipeline runtime variables I'm talking about so it means that these are the variables which I am asking the user who is running this pipeline to put those values so this is a user input value since there's a pipeline runtime variables then there is like my pipeline variables which is this part so these are the variables which I am defining so this is my key and this is my value so this is the key value pair and then you have the environmental variables the environmental variables are nothing but it's the uh the the variables which uh doesn't need so your entire uh pipeline which is running it needs a compute that compute is the build agent that build agent can be a Microsoft hosted agent it can be a self-hosted agent doesn't matter but it needs a compute it cannot run like a magic so when you are running that pipeline which is taking the terraform as your input so that whole thing is running basically on a VM which is which we are calling as a build agent and that VM can have a lot of environmental variables so that you know when they they want that value the build agent automatically knows that okay this is an environmental variable I don't have to look into terraform I don't have to look into Devo I mean like my yaml pipeline but I can use that as an environmental variables I can use that value automatically so so these are the three different concepts we have pipeline runtime variables we have the pipeline variables and then we have environmental variables so I'm actually using all the three in my automation so these are my pipeline runtime variable these are my pipeline variables and I very shortly I will come to the environmental units then I have like you know my building gym so I have I'm using the Microsoft hosted one you can see that you know I'm using this Windows latest which is my build agent variable so this is my value and this is what I'm passing out to you and then what I'm having is I'm having two different stages one is like plan so this is my plan that I'm I'm generating the terraform plan and after that I'm using the stage called deploy fair in the plan stage when I'm generating the plan that okay this is a resource of the script which will be getting deployed that plan I'm using in my"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:15:10",
        "seconds": 910,
        "text": "and after that I'm using the stage called deploy fair in the plan stage when I'm generating the plan that okay this is a resource of the script which will be getting deployed that plan I'm using in my deploy stage okay so what happens in my uh plan stage before I go here you can see that you know for all these things for all these things uh I know I have I have like lowercase only for my Resource Group name variable and for user assign manage identity see that I have in caps why so so what I'm doing with this is that you see that in my variable section I have the resource Group name which I have taken a string I have location which I've defined as string I have defined the user assign manage identity as a stream now you have defined the variables but if you go to the value I have only mentioned the location I have not mentioned the name of the resource Group I have not mentioned the name of the user assigned managed entity so how will terraform and by proxy my devops pipeline will know that by what name the resource Group should be deployed and by what name the user assigned manage identity should be deployed they don't know that because I have not specified yet this is just the location this is where this is coming in pictures so you see in the runtime variable I'm taking the user input so user is putting the name of the resource code and then I have a user is putting the name of the user assignment once they put it what I'm doing is I am taking that value and I'm putting it into this one so basically what I'm doing is I'm capturing the value from the runtime variable and then I am putting into pipeline variables but when I am putting into pipeline behaviors when I'm putting this whole value as the Caps according to the environmental variables documentation you see that here hashicorp had mentioned that if you are starting anything any any variable if you start with TF underscore VAR underscore the name of the variable in my case it is DF underscore bar underscore something like amrg then it automatically converts into the environmental variable that is why when it Maps into my uh environmental variable then I am using that environmental variable as the input to my terraform site that is how I'm converting it so this is the whole workflow and then what I'm doing here is and my plan stage I am running the terraform installer then I am initializing the terraform out here once I'm initializing the terraform then I'm validating the error form when I'm validating the data from then and generating the Terra function plan out here so you can see that the brand new institution plan then I am copying the files everything and then I'm just putting in my staging directory and publishing as an artifact why I am doing this because unless until because this these are two stages so whatever I'm doing in this stage somehow my my deploy stage has to consume what I have generated in my plan stage so the only way to consume is in pipelines is you have to publish us as an artifact there is no other way so you have to publish something then you can consume something it's just like you know if anybody has worked on the messaging services it's just like a pub sub model publish something then consume something subscribe something so then in the deploy stage what I'm doing is first I'm validating and putting a condition like succeeded which means that my previous stage which is my plan has to be successful otherwise they will just deploy the script if something goes wrong here and it doesn't execute my deploy stage will be skipped because I have put a condition like succeeded and then what I'm doing is the first is I'm downloading the artifacts so whatever I have published here I'm downloading it once I download it then I'm again initializing instead of from again because this is accepted stage and then what I'm doing is I'm applying uh this whole thing uh using the the terraform plan which is generated in the plan stage in which I have downloaded from the artifacts and that is how it is getting to uh that the whole thing is running and if I refer back to my documentation see that you know I have I have mentioned out here I have put a note about this one this thing which I extreme you so the user input values from the devops run times are referred to as a devops video so so all this this is a runtime variable and this is this has been reference to the pipeline"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "this thing which I extreme you so the user input values from the devops run times are referred to as a devops video so so all this this is a runtime variable and this is this has been reference to the pipeline variables and then I I explicitly mentioned that notice the variable that you know this is all caps where I try to explain that azure devops uh variable gets automatically mapped to the environment variables and the adjective of spirit agent and then you know automatically it it helps me to put it as a terraform in quickly represent this link which I'm talking about where if you can read you know you can you can understand this is also referencing my blog achievement okay so uh so this is the rest is the rest is all the same uh in your environment if you want to run my code uh the only thing uh which you have to change is always this section there's always like you know not this section because you know this is a user input but this is a section which you have to alter because you might be having different you might be having a different uh Resource Group names and the storage accounts so uh this is about the yaml pipeline now I come to the main file so the main.tf is the the main terraform file so the way I do it is like I always use the main TF for storing the backend State file uh this is a terraform stage file where I keep it so the first one is the resource Group at my storage account exist next is my storage account name then what is the container name inside my storage account and then uh what I do is since I I run a lot of use cases then what I do is whenever I'm running something I always prepare a folder inside the container just to keep it organized so this your umid is the folder name and this is my station then again you know uh the first one is the terraform version and this is my provider so I'm using Azure Autumn which is the Azure resource manager and I'm putting it in the version not here this is the the resource uh terraform file that I'm defining that okay Resource Group will be deployed and the user design management entity will be deployed uh I have used a depends on um uh a parameter out here it says that this piece of code will not start running unless the resource Group is created so this is what is called as the uh as the implicit dependency so I am creating depends on parameter which says that okay Azure RM underscore resource underscore group and the name of this one uh the module name and the and the name of the module I am putting it as it depends so unless oriented even if it is taking like for example one minute this piece of code Will Wait So once this gets executed Resource Group is ready then it will be here so that you know it doesn't happen because uh many a times when I'm running a code I see that uh Gerald form doesn't identify and it starts defining the user a user assigned managed entity but it fails because the resource Group doesn't exist so there is a lot of scenarios which I have seen in that view and this is the variable section which you are defining and then in the psrs where you're defining the value of the variables which I mean absolutely so this is this is all about the code now what I normally do you know when I'm running such pipeline is like you know I always as part of the best practices I always create a folder by the name so you see that I have a folder up to you so um because then it helps me understand the history of all the pipelines I'm running and if I go into this folder which is my current presentation like runtime variable terraform input variable if I click on this one then you see the history that how many times I've run I just ran like you know like before my presentation just to be sure that my code is running you know I ran it like you know so you can see it and this is how it looks like so you have a plan stage you have a deploy stage and that is how it do it the one thing I I always do is like uh if I go back to the code sorry uh if I go back to the repo and so one thing I would like to explain you one more is uh so I have one validation which is like uh uh the plan and the deploy stage so I have like you know the deploy will not work and doesn't plan is successful but there is also like a approval gate which I have put so I'm using this parameter environment so what it does in the in-depth for people who have used Azure devops you know earlier they started with classic pipeline the classic pipelines for something like a completely"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "which I have put so I'm using this parameter environment so what it does in the in-depth for people who have used Azure devops you know earlier they started with classic pipeline the classic pipelines for something like a completely a GUI base it's a it's a graphical user interface so used to define the whole thing which I'm defining in yaml uh you could you could do it graphically and in that graphically they had the option to add approval which means that you're running a pipeline and after a certain stage he cannot go further because there's an approval gate but when they switch from classic to yaml based pipeline uh primarily because then they wanted to do Microsoft wanted to do the Version Control of pipelines as well that is the main reason that is the main uh motivation to move from classic to yaml based uh then this was the piece which was missing and then Microsoft what they did is like you know they said that okay uh in case if you want to want to put an approval gate in your yaml based pipeline you have to use environment so that is why I have defined the environment and when you go to pipelines you see the environment section on the left if you click on the environment section you see that and I have defined a non prod if you click on non-prod and on the right hand side three dots PC approvals and checks if you click on approval you see that and I have created an approval so I have added my name this is approval so if you are including that in your yaml pipeline then it will it will automatically wait till the time it's improved so this was the last piece I wanted to say so I will go back to my folder again and what I will do is I will simply go here and I will just run I just ran from here because then I will just automatically get the values I don't have to think of some some name or something that is why I I meant for the otherwise you can always go here you go to the other one and then you can run the pipeline so then you know it will look a little bit different It'll ask you to specify the needs so here you see that you know I have used my subscription and my service connection depending upon your environment you can always change it and then I'm asking the user hey uh can you just provide me a resource Group name or can you provide me the user assign manage to entertain you just asking also when you're doing this you can always click on stages to run click on this this does a validation to to make you aware that your yaml syntax and everything which you have defined is perfectly okay so so there should not be any syntax problem when you are executing your pipeline but if there is an any other problem that would be something different but there is no syntax problem so this ensures that and so I will now fall back here so this is a pipeline which I previously run and if I run from here and just getting the value I'm little bit lazy out here just not to Define uh think of some some other names or something so what I would do is now I have my resource GroupMe so these are my pipeline runtime variations then I'm going to run it and now I will just wait uh please bear with me because you know I'm running on Microsoft host cities which means that you know it's a cold VM so whenever I'm executing uh then first it will just allocate me a VM from a pool then it will spin the VM up and then it will run so ideally it takes a minute or two so it was pretty much fast so um uh till the time this pipeline is running uh I will just pause for a moment and see if you guys have any questions and then I will resume uh what's the Pipelines I have a question I'm not sure if I caught had the back end set up for terraform but um not sure based on what I see this probably would would not work on terraform Club so uh so terraform cloud is a little bit different than the uh one which we are associating so terraform Cloud gives you the provision of of doing everything it's it's just like one front end so they have all the functionalities within their their own infrastructure but here we are using the terraform extension so it's it's it's basically um if I go here if I go to the organization settings and if you see the extension so I'm actually availing this extension so this is coming with the visual studio thing and then I"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "um if I go here if I go to the organization settings and if you see the extension so I'm actually availing this extension so this is coming with the visual studio thing and then I have to incorporate that when you are running the terraform init uh plan and apply without devops pipeline when you're running locally so there is always a state file which gets stored locally and then you also have a provision to uh to store the file remotely uh in terraform cloud of course there is there but uh when you are using terraform Cloud then there is no options of azure devops or GitHub action so terraform cloud is providing the whole CI CD as well as the hashicor as well as HCL as well as the terraform the whole package there often so it's the nomenclature or the way we are doing here where we are amalgamating uh Microsoft stack and a hashicot stack together to build the whole CI CD and the infrastructure as a code in terraform Cloud it is a little bit different terraform Cloud you know you're running the pipeline there you are you are using their own languages so it's it's basically like an of it's just like a one front end if that makes sense yeah thank you so if I go here um so this is what I was I was talking about uh and now you see that you know it's it's waiting uh this is the approval I was talking about so first thing first you see that um uh the best way of of doing is this like you know the way I have learned uh with my projects is that you know whenever you're writing a pipeline just Define what exactly things are doing so the first thing is you know they are installing the terraform versions and in each slides in the terraform validating then I'm generating the plan so this is the plan which I was talking so here in the plan you see that uh two resources we'll be getting added there is no modification done there is nothing to destroy zero to destroy zero to change and zero to uh two to add so this is what it gives me and this is the plan which I'm going to use in the deploy stage but in order to do that I have to copy the first files to the artifacts uh staging directory and then I have to publish the artifacts now before I proceed I will show you that where the artifacts is so you see here this is the artifact so basically my Pipeline and my terraform is running inside of VM which is somewhere in the Microsoft Data Center so all the files are there but how would I consume again so I have to publish so that is why I'm copying those things to a devops staging directory and from the devops staging directory and publishing as an artifact so all the code which you saw mean uh user uh the the resource file the dfrs the variable files everything it is putting it in the artifacts along with the plan file and this plan file is basically I'm consuming in my in my deploy stage so if I go here that would do is I'll just say okay I prove it and here you see that I have to put a check I have Google and you can see the name of the environment where the approval gate is attached to and then I approve it and now and now I'm going to deploy station so this got deployed uh so first thing first let's uh check in the portal um normally it will take some time to reflect but till the time it is getting reflected I will go to the part where which is the most important as a state file so this is my this is my uh storage account and then I have a container for TF pipeline essay and then I have a terraform container and here you see that I have created a folder inside the folder you see the stage file if you go here and if you edit it you can see the entire State file so the first section you know this old part this is the the resource Group State and the next part you will see is like this is the the user is saying manage it entity so this is like you know this is very important at the time you know if if"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "the next part you will see is like this is the the user is saying manage it entity so this is like you know this is very important at the time you know if if you have deployed the infrastructure using terraform and then you know you have manually deleted something then the next time if you try to deploy it will not allow you to deploy because because of the State Fair because the state uh the state file contents and your and their resource content this is a mismatch and then you have to first do the terraform surgery you have to remove those all contents and then you have to reapply the terraform that is that is why the the state file is so so important and if I go to the resource Group yep so this is my Resource Group and then I know this is my user design managed entity so the the whole the whole beauty of this is that I am I'm just asking my user or anybody uh to provide the appropriate names I'm not hard-coding any values in any of my code I'm just converting the whole uh pipeline variables into local variables local to environmental variables and from environmental variables Innovative and taking those as a terraform input variables passing those values and then then deploying those resources in in into Azure so this is this is this is what I I meant to say that that you know without even specifying the values for your variable you can still deploy and this is what I I I understood you know about what hashikov was trying to explain I'm sure but you know feel free to go through this documentation feel free to uh go to my blog and if you have any questions to to write to um so yeah this is this is all uh I had to present first day so you guys have any questions uh feel free to ask uh so feel free to come off of uh off of mute and uh pose any questions that you've got well sometimes uh sometimes uh demonstrations are so clear that people just know so uh so that uh don't be shocked um we'll give it one more minute and see if anybody has any uh questions feel free to type them in or come on mute and and ask away while we're waiting for that I'll uh I'll make a couple quick announcements uh this um recording will show up on the Boston Azure YouTube channel so you can find that at youtube.com Boston azure and also I mentioned at the beginning of this that there would be uh that we have a couple of uh we we still have some virtual events coming our whole pipeline coming so watch the either the North Boston Azure or the Boston Azure neither one uh meet up space for that and there are two in-person events coming to uh Boston Azure the one of them is the Boston Boston Edition uh Jason Veronica and I and uh We've are working on that and we've sent out a call for speakers just uh I think Veronica kicked it out um just uh in the last day or so and um that's Saturday May 13th at nerd in Cambridge and then we have one also tentatively scheduled in late April um for in person on a weekday night that so watch the space the usual spaces for those the Meetup sites and Twitter um and I will come back to uh has anybody anybody want to take advantage of the last movement to uh pop a question okay well that that's um that's cool um I I wish to I thank everybody for attending uh and it's the uh pretty late um uh in um Switzerland right you're in Switzerland yes what time what time is it right now it's one in the morning okay so uh uh Arundel Mitra thank you very much for being our speaker for staying up to one in the morning to entertain our uh our crew and uh we'll we'll see all the next uh event everybody uh Jason or Veronica did you have any uh any closing remarks or or uh our random do you have any uh any any uh closing remarks no thank you so much bill again uh for the opportunity uh uh I I wish you guys all the best and I hope that I would again get an opportunity to collaborate with you and uh Jason for you uh feel free to drop me an email for your podcast happy to happy to join that as well we'll do thanks man thanks everyone good night everybody take care yeah see you bye "
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Deploy Your GO API to Azure Functions. This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.. my name is susan abbasi i am a head of technology at a local company here called taiwan um i've been doing mostly a lot of mobile work so i'm mostly a mobile developer but i have been playing with back ends because a lot of times when i'm working on a front end i find myself needing a back end that doesn't exist and i haven't done backing in a very long time so i started doing a little bit of back-end work i started with typescript uh built some apis in typescript and built some in of course asp.net core or dot net core sorry uh then i built some in java i'm actually working on java one right now and then i came across go and i just loved it uh it was it was much lighter uh very fast it's much performant and i've talked about it before but in performance-wise it's it's more performant than your javascript stack so it's better than your node.js for instance uh in performance but it's not as good as rust just yet but it one of the main strengths it has is the dev experience and we'll see that in a second so um today uh thank you again for having me i know that the topic says deploy your go on on azure but i if we were in a room i would ask you know show of hands how many people have actually heard of golang or actually done any work in golang and you know get responses but since we are not in person and we are virtual uh feel free to raise your hand and then veronica or jason can tell me like to tell you how many people have actually dabbled in that uh go or not but my assumption is is not a lot so i have an hour what i would like to do is in the first half of the of this i just want to introduce you to the language what it is and the second half we'll talk about the actual api that i built and then we'll deploy it to azure function and then we will take q a at the end and i have a little surprise for you at the end uh hopefully you'll be able to do that so let me get started like i mentioned i work for a company called taiwan it's a digital consulting company so we do a lot of consultation for a fortune 500 companies we do mostly or not mostly we do anything industrial and startups and oil and gas and energy and we are we have a big plane energy transition right now that is going on so these are some of the logos that we've been working with our strategy is we don't just go in and get requirements and build we have a very mature experience group that does uh the user research and and works from bottom up to match the top-down approach and then we design solutions that actually work in the field and get adopted so we do a lot of strategy work with research our phd group does all the research design and then we have development of course then we have the data science piece to to help you go see after that we are hiring so if you are someone who is a a.net javascript stack project manager data scientist user research if you are in any of those domains and which would like to uh you know particularly fancy or like a change uh think of change reach out to me and we can talk afterwards that's enough about me and and taiwan let's get into it so i will not go through the whole stack i just wanted to have it here but i will go through some of the basics so we all know what this language is so when we actually look at the code it will make a lot of sense so what is golang or i should say go not golang so it's an open source programming language it was it was found in 2009 i think i should know but i believe it's 2009 and let me give you guys a full screen version because you guys have been seeing the non-full screen version um so it was built by the the founders of the the c language and b language as well and the founders of of the language want this to be a super simple uh you know no nonsense slim language that just works because they were working a lot with the existing languages for the back end and they realized that they needed something better so it's funded by it's backed by google the team that built it and is working on it is is in google is google team as well so what's the idea behind it well it's a journal per general purpose language so it can be used to build all sorts of applications it's it is compiled into your native code so when we compile it on windows where i mean x86 arm wasm you know it compiles to a machine code and then you can run it right on that platform and has a very light syntax so who who's using it the big names that you see here docker actually is built in go so if you guys are working in docker you know it's built uh in golang as well and cockroachdb as well so anyway like i mentioned is cross compiled so we take the the code and then based on how we compile it"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:05:05",
        "seconds": 305,
        "text": "actually is built in go so if you guys are working in docker you know it's built uh in golang as well and cockroachdb as well so anyway like i mentioned is cross compiled so we take the the code and then based on how we compile it uh it will give us that exe if we are in windows or or without the extension if we are on arm for instance um what is it good for web development not the front end i wouldn't go out and replace your javascript with your uh go just for the furnace just yet but for your apis and all the stack behind that it's great for that cloud and network services so devops a lot of the the devop workload is or it's great for uh handling that kind of workload uh developing sres right and command line so it's also good if you are building command line applications like tools tools whatever it's great for that as well we'll focus on the web part today though so really quickly what are the basics it has the primitive types that like you would expect it to have it has hints 8 16 32 signed and unsigned and only signed 64. it has float boolean string byte etc it one of the the the simplicity or the whole idea on keeping the syntax lightweight is that it doesn't have a ton and ton of data structures out of the out of the box available to us so it has arrays and slices a slice is our projection of an array we'll take a look at that it has a map so it's key value pair uh dictionary it has a struct so it doesn't have a it's not an object oriented based language so it doesn't have object and inheritance and all that stuff and we'll talk about that as well but it does have struct struct is your type so you can create all your types instruct right and then it has an interface which is a very powerful type as well that you can use to have behaviors defined for your types in go but also it could be used for a variety of open-ended return types for instance so logic control it has if like you you would expect it to have there is an if okay pattern um which we'll take a look at which is pretty cool it it kind of saves us a bit of typing it has for loop it has four range loop which is awesome you will see that in a second as well and then it has a switch now you don't see do while while and all those loops in here because you don't really need them the for loop is is pretty much good for for all those scenarios so let's take a look at a quick some of the quick code thing how do we declare a variable uh just basics we start with the keyword var then the name of the variable and then the type of the variable so in this case you know var name string we can also declare and initialize by doing this but a lot a lot of places in go you will see something like this which is declaring and initializing at the same time by using the colon equal sign so you will see this a whole lot in the code then the the top two you will see the var keyword when we are declaring items in the beginning of your code and initializing somewhere else down the line but if we are doing everything within a block of code or in this in a scope then you'll probably see them all like this and then there's a concept of the i don't know what the actual word is but i call it throwaway variable so imagine if you have a function that returns two two different types which we can do in go but you don't really care about one type for instance if you are looping over a range you don't really care about the index you only care about the value but you need to collect the index in some cases so you can collect it but since you're not going to use it you can just put a underscore and all it will do is it will accept the value but it won't give it you won't be able to access it right so it'll just be there but it will just get thrown away functions and method very simple the we start with funk keyword the name of the method and then the block we can also have anonymous functions so if you don't give it any name you can just leave it blank the return types so in this case you put the return type after your method declaration right so in this case it's just a single return type of end you can also return multiple types so in this case you are seeing that there is a person object and an error object being returned in that order right so when you call get person somewhere else you just need to know you will get these two values in that order and then there is this function where it can have a number of variables separated by comma so you can use that now we can tie a function to a type so for instance get full name if we put the type before that between the func and the method name then that method will only apply to that type so you will only be able to do person.getfull you won't be able to do that on any other type because this matches the the signature of that right so i know it's a little off if you're coming from network right where things are just different you will have this function within a class and it will be public or protected or something and then you will just use the"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "matches the the signature of that right so i know it's a little off if you're coming from network right where things are just different you will have this function within a class and it will be public or protected or something and then you will just use the dot notation you will still do that here but it won't be inside that code it'll live outside of that type but you will attach it to that type by doing that arrays and slices i know i'm going a little fast so just bear with me right and if you have questions feel free to ask but i want to show you the actual code and not spend a whole lot of time in the slides but i don't want to show you this in that code because it'll take longer so so a slice is just a projection on an array what that means is there's actually an underlying array that the slice is using but you don't you don't have to worry about it just let the slides do the work for you resizing and all that stuff for you so you don't have to resize the array yourself and what happens is for instance here i have an a slice or an array called integer as an array of integer with three values in it and if i pull out the length of this array using the built-in length function i get three back and if i wanted to turn this slice into an array all i have to do is just give it size in the in the brackets in the square brackets right so if i give it a size it becomes an array because now i'm dealing with the actual underlying array and if i do that you can see that i gave it a size of five but i only gave it three values it filled in the rest with the defaults of that type which is zeros and if i pull the length now i get the full five length for the array as opposed to the other one pretty stairs forward stuff map is as simple as it can get uh it's kind of weird but you know your you'll pick it up once you see it once you use it one time so for using the dictionary or the map key value pair you just have the word map the key is in the brackets and the values right next to it so if you see i'm initializing a map in m i'm telling it it's a map where the key is going to be string and the value is going to be an integer right and i knew up this by using those curly braces empty curly braces and then to write into that dictionary you just do like you would do in pretty much any other language you just have the m give it a key give it a value when you print that you get this representation of the key which is actually pretty nice so you don't have to worry about overriding the two string like you have to with some of the languages right it's pretty neat so i ran through some of that stuff i hope it made sense it wasn't uh it wasn't too uh out of the way if you are coming from c sharp background now this is where things change a little bit so we already know what struct is right from other languages which is fine in this case um i have a struct called vehicle that has two properties make and model they're of type string right so you see that there now what i don't have here is well let me just let me just go in here one nice thing about uh keeping it simple is that i can actually have nested structs so you can see here i added a category for that vehicle within that struct and i just nested it in there so now category is of type struct that has its own property called code which is of type integer and there is a concept of so there's a built-in support for json in the library or in the in the frame in the language we bring in this package called encoding.json and if we want if we're using this type for any serialization or deserialization with json we kind of just give it a what this is called a tag we just put a tag in front of the type by calling you json and then what the name needs to be in json so when now when you serialize or deserialize it will give it those values so you can see i have a make a model and for category i have the category json but that's after the last curly brace right okay now composition over inheritance like i mentioned there is no go is not based on oop so you you don't really have inheritance per se but you can compose your types so in here you have a type vehicle that is that has two properties and then you have a type car that is a vehicle right but instead of saying car struct you know extends or colon or whatever we just put the vehicle type within our car type so now that vehicle type becomes part of the car so now you have the make and model properties available in your car as well how do you initialize this it's pretty simple so now when you are creating a composing a car object you just create a new car object and then pass in the values for the vehicle by passing in a vehicle type and then the speed or if you simplify at the bottom just say car vehicle make model and then the speed right so it's it's a little different but once you play with it it will make a lot of sense and we will see an example of this in in the api called i'll show you now interface so interface defines a behavior for your code right so"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:15:11",
        "seconds": 911,
        "text": "right so it's it's a little different but once you play with it it will make a lot of sense and we will see an example of this in in the api called i'll show you now interface so interface defines a behavior for your code right so in this case when we use interface the way for us to have a type implement an interface is just mimic that behavior for instance if we have an interface called drivable that has an interface that has a method called drive then if we have any type any struct that has or implements that drive method we'll now implement that interface so then we can pass in that type for the interface wherever it needs to as long as it has the matching signature so in this case you can see i have a car and a truck they both have a drive method so they they are implementing the drivable interface but then i also have vehicle that has more than one interface implemented it has the drive and the fly the fly belongs to a whole different interface which is flyable and then let's just say plane is is just flying vehicle could be a car or a plane so it does both so it matches the behavior of your interface and not you know right click implement uh interface stuff that we are used to in it how does it look like a good a better example of that is think of a shape so if shape was an interface that had an area but then you wanted to get the area for a circle and an area for a square now how you compute those is completely different but you can pass the area or you can pass the circle or a square into it into a method that expects the shape interface and it will just be able to get the value for you so you can see the bottom half shows you how it's done we are passing in a circle with a radius and a square with an x and y and passing it into a method that is print area that takes in a shape and because circle and square also have an area method that is that is calculating the area they are able to pass into that shape interface right so it's again it's a little it's a little it seems a bit off once you work in it it'll make a lot of sense and if you're coming from other languages you know it'll probably be easier for you as well uh there is such a thing as empty interface empty interface if you're coming from javascript world it's like any so you can return an empty interface which means expect anything to come back from here and it'll still work next is just an example of what i was showing you right so here you can see actually let me show you the next one here let's say i have a um i have a car that has a drive method and i'm saying that car is driving then i have a vehicle that has a drive and fly that this is the the vehicle is is driving or flying and if i have a method that that said i i expect a drivable interface and then i'm i'm just going to call the drive a method on the interface and you pass in a car and pass that car into the start driving you will get the result as you would expect and same for flying right so pretty straight forward um nothing too crazy now i'll run through these as well any if there is no parenthesis no semicolons that you may have noticed but there the parentheses are uh sorry the curly braces are required so you cannot have an if a single line f without that you have to have curly brace so you know you win some you lose them whatever i did mention earlier you know where you can do things like get multiple return values what if can do you can actually have multiple statements on a single line but these are scoped what do i mean by this so you can do something like if val initialize the val object or val variable with whatever comes back from foo method and then right away some i call and check if val is null or not and if it is nil then you know don't do anything if it's not nil then go ahead and print it now this val actually scoped to this if so if you try to use val out after the f block you probably won't get to it so this makes sure that if you are initializing any variable in the if it stays scoped to the if block which is pretty neat easier to read if okay that's the pattern i mentioned earlier how does that help so imagine you have a full method that returns an actual value and an error and what you want to do is you only want to move on if the error was not nil and this is just like what we did before but instead of error you will do something like this where it comes in very handy so imagine if you're trying to get a value out of a dictionary and the value doesn't exist instead of crashing or throwing an exception you will just get a false right so here the pattern is if okay means if get me the value comma d okay which means if it exists or not out of this map for this key so that call to map will return false if that value doesn't exist and you can say oh do something with val if okay and you can see okay doesn't have if all k equals true and all this okay music price by itself means it's true so"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:20:14",
        "seconds": 1214,
        "text": "so that call to map will return false if that value doesn't exist and you can say oh do something with val if okay and you can see okay doesn't have if all k equals true and all this okay music price by itself means it's true so it's it's pretty neat for loop uh like i said it does a bunch of things uh it's one loop you know to to win them all so you have the traditional uh condition cursor loop uh you have infinite loop so it's like a while true so you can run as much as you want until you want to set your own break it has a conditional so you can have four condition and then continue going so after every block it will check the expression and if you want to get out of the loop you use your break or continue which is um sorry about that it's raining uh too many devices in my room right now uh okay so now let's talk about my favorite thing which is the four range uh loop so what four range does you can run that full range on any collection in go and the range the method will or the range operator will return different values to you based on the type you're running in a case of the collection so imagine we have an array of two strings hello and word if i run the four range i can get the index and the value at the same time so it's kind of like the four and the four each loop you know played together with the index and here we have so you can see i'm saying for the first variable is index the next one is value out of the range arr and i'm printing them out and it is giving me the index and the value and imagine if here we didn't want one of the two set like we don't care about the value we just care about the index or we don't care about the index we only care about the value we just use the underscore and it just kicks it out same thing goes for a map right when we run the range on a map we get the key and a value at the same time right so which is which is awesome we can check for values we can check for keys at the same time so four range is very powerful i mean i love it i use it for wherever i i need to check for one of the two switch so switch has a little um a little i don't know if it's neat trick or is not but so switch just like any other language works here but switch and go actually can do expression uh evaluation in as a case instead of only looking for constants or something like this so in this case you can see let's just say i have a state a switch on a state for a task if it's new i just say it's created if it's resolved or complete i just say it's resolved because if you are coming from your scrum background and every time you resolve it you want it to automatically close you know it's the same thing but you can also do things like this where you can switch on today and you can actually initialize it as a variable and then you can like i mentioned do evaluation expressions within your case which is pretty awesome right it's pretty strong now there is one more thing in sewage that that you should know which is again kind of crazy but as we as the control goes through switch right it goes through each case one by one but imagine if you were on a case for in this case let's just say if the state is new it'll come to task created and then it'll jump out we can do break we don't have to but it'll jump out of this switch statement and we'll move on if the task was resolved it'll say resolve and move on but there is a thing called fall through if we use fall through in a switch statement then the control will fall through to the next case without checking the expression so in this case for example if the state was resolved it will print the result it will say task resolved and then it will see oh you want me to follow through fine it will just next it will jump in next to or jump into the next case straight into the task closed print statement it will not evaluate the case at that point where is it useful i'm sure there are ways where if we have a reason to jump through cases and touch all of them if there's a if there's a case we can use that but this is the best i uh this is one of the things i could think of like maybe you want to resolve and close at the same time i don't know but it's pretty pretty cool uh moving on quickly to the structure itself so go structures is code and packages everything inside a package is scoped to that package so there is no private public internal keywords or accessories everything that is inside a package is available to that whole package now there is a difference between exported uh and and unexported right so for example what we saw earlier if the name of the variable or a method starts with a capital then it's considered to export out a package if it's lowercase then it's only scoped within the package so you will see when we go through some of the code that all the all the function method names for all the external libraries or even internal libraries start with a capital but internal methods are all lower case right so it's pretty it's it's"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "within the package so you will see when we go through some of the code that all the all the function method names for all the external libraries or even internal libraries start with a capital but internal methods are all lower case right so it's pretty it's it's pretty convenient so generics i'll run through this really quick so genetics is kind of new to the language i don't want to spend a lot of time on there but for generic you can see we can add a so you can see if we have an add function uh and we are if you are familiar with the generics in net for instance there is a you can pass in the values in this case i'm saying that the integer and float they're both um types that i want you to run this operation on and then i can call it with or without the with the the type and they will know how to handle that if i have more than one i can create an interface out of all the types i want for a single generic in this case i have a generic call number that has integer floor 32 and floor 64 and then i can say add the type number and then bring in uh you know the t from there and return that so pretty there so go routines are the the main or one of the main reasons you would want to use go language in the first place so what our goal routines go routines are user threads that execution threads that run uh in your application they're not os threads so they're not expensive we can have as many routines as we want they're all very cheap because they're running on the same user thread and then they come back to to the main thread when they're done um well they don't come back they're most like they're more like fire and forget but we can get information out of them right and then i'll show you how that is so what are go routines how do you actually do a go call a function as a go routine all we have to do is just add the word go before method and it will turn into a go routine now imagine you have a function like this one i'm doing two things here i am calling foo which is a method at the bottom you can see as a go routine or i'm just wrapping it within a function which is which is within an anonymous function to call it and i actually have to i would have to put parenthesis at the end of the last function for it to execute right otherwise it won't execute but what happens is with go if you have a method that has more than one goal routine as soon as the first go routine is done the method will jump out of it right so if you had more then you probably won't get the results back or you won't get those go routines completed in that scenario so if you want or if your code needs to wait for all those go routines to finish then we can use something called a weight group it's kind of like async await in.net but in here we control how many weight groups we should be waiting for so in this case you can see it's a bad example i'm only waiting on one but to show you how it works i have a function um that that i have an anonymous function that's a wrapper function i'm i'm doing something in there called foo and then i'm calling this thing called uh wait group dot done so you notice i said add one and i said done as soon as that number goes down to zero my weight group.weight method gets triggered and then i can move on in the execution so this is this is great you will see it makes sense when i show you the example now remember i said go routines were fire and forget well what if one go routine needs to talk to another go routine they can do that by using channels right so channels are in a single channel or buffer channel the way they work is you declare a channel using the make built and make function here we are saying make me a channel or make me a type oh sorry make me a channel of type integer because channel can only be singly typed so you cannot have a channel that can take more than one type in it and then if i want to set anything into that channel i just use that arrow dash so the arrow into the channel and of course if i don't take something out of the channel i just i don't switch the arrow as you would imagine because everything that gets the value should be on the left but in this case i put the c and that you can see when i'm reading from the channel the arrow is coming out of the channel and the value whatever value has sent which is one goes into i in this particular case right so again the reason i'm running through this is because i want to show you the actual code this is an example one of the examples of using a channel in my main function i initialize a channel and then i start a go routine and i pass this channel into that go routine and then inside that guru routine i'm passing in the value 10 to that channel and then outside back in my main function i'm waiting for a value as soon as that value gets sent to the channel i get the value out and i print that value onto the screen or whatever i'm doing now like i mentioned channels are only single typed so i can send information from one go routine to the other using channels it's"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "i get the value out and i print that value onto the screen or whatever i'm doing now like i mentioned channels are only single typed so i can send information from one go routine to the other using channels it's it's pretty fun now there is a whole uh it so the reason i call go routines and channels advanced functions because uh we can shoot ourselves in the foot with channels if you're not doing them right or we can write a lot of blocking code where we may have a we we may have a listener or receiver waiting on a channel and then a sender that never sends the information so now you have a blocking code but we also have we may have a receiver that send too many more than one data to the channel and the channel may you know panic and and the app will crash then we have to buffer when we buffer then we can send as many as if we want and then receivers will so it's it's a very powerful topic right and and i encourage you to look into that for for when you get to working on go routine channels i'll just breathe through this i also worked on making this work in the browser so i built a a fibonacci sequence or calculation calculator to run in the browser and i was able to do that by setting my operating system from my main go to javascript and then my architecture to wasm and this is how it looks like so in the brow i have a file main.go pretty simple i have a library called syscall slash js to communicate with javascript and there i map my javascript functions to my go functions by name and then when i compile it or cross compile it into wasm then i get a file called main.what that i can then load into my browser and read it using that wasmexact.js file and then my wasm code or sorry my go code runs directly in the browser without having to make any server call this is just how it works you can take a look at it later you can see it's just getting the the value from go from the browser from from whatever the ui is and this is how it looked so you can see i tried it on all three browsers i send in a limit i press the button it runs it creates the it calculates the value and then it just tells me how long it took to do that right not very efficient but it works this is what we've been waiting for so now i want to jump into code now you will find that most of the uh oops you will find that most of the world uses vs code uh i use vs code as well uh can you guys see my screen you probably cannot see my screen at this point but you are about to see my screen which is right here let me know if it's hard for you to read what's on the screen if not then i'm going to continue so all right cool well how do we actually cool how do we actually get started with the with go uh we can i mean i can do that late uh maybe at a different event where i can go through how to start go but i am using a different ide than vs code but it works perfectly fine in vs code i've done it vs code so here i wanted to show you my code structure first so what i have here is this is my project directory and i have three folders here i have a source code folder i have a build folder and then i have a az functions folder right so the reason i have it this way is because i want my code to be built separately and then whatever delivery mechanism or distribution mechanism i'm going to use or deployment i'll use that separately so if it is hazy function if it's docker if it's you know aws whatever the case is so in my source code i have a file called main.go and then i have handlers and that will take a look at we have services and then we have models and all that is in here so let's take a look so in here what i'm doing is i'm using a library called gin to create my it's a it's a framework to run your to write your rest apis in now there is a http package that's built into go it's an entire it's a first class package that also has a rest capability but i'm using gin just because it kind of takes some of some of that code and makes it easier to work with so we import and as you can see in the go code when you do import this is same as doing import fmt import log et cetera et cetera i can have multiple import statements or i can just have one import and group them in a in a parenthesis so you"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:35:23",
        "seconds": 2123,
        "text": "code when you do import this is same as doing import fmt import log et cetera et cetera i can have multiple import statements or i can just have one import and group them in a in a parenthesis so you can see that this is my main package so we always need a main package for our code in the main package i have a main function which is my starting point for this application and in this application what i'm doing is i'm just i'm calling i have a method called setup server and i have this thing called a router so this is coming from the gen library from the gen library uh i just call the default which gives me the router and then i want to set up some routing on my uh onto my my local server so what i have here is there are two ways for me to do it so what i'm going to do here is i will set up a get so i will say router.get i'll give it a path and then i can either have a function directly in here right so in this case i'm saying my handler is a function that takes in the context and returns so the context will turn a json where the status will be okay and the response will be this right but you don't really want to do this everywhere right so what you will have is something like this where you have a get and you'll probably have post put patch all these you have the end point with maybe some query paths in here which i do like city state and state and then you have i have a handlers package which is up here that has a get weather that it gets called and then this one has get alerts for state this is a weather api by the way that returns some other information and when i set up my routes right next thing i do is i say router dot run and i get the port so in this case because i'm deploying to azure function i'm just looking up my local environment to see if i have this variable set and you can see i'm using the if val okay if ok exists i'm going to go ahead and return that right i'm going to return that that port otherwise if this doesn't exist which means either i am not in azure or i am not anywhere else i may have more here to see if i'm in aws or whatever else but here i'm only checking for function if not then just go ahead and start it on 8080 right so to run that to run that i can uh i hope you can see this can you guys see this um read it pretty easily or yeah it looks good okay now it i hope you can see it now because it's pretty big okay so this is the same file i was showing earlier so we have a few files we have the goda mod which is just the module that i showed you earlier uh the sum is kind of like the packages file where once you run the mod it brings in all the dependencies then the blue are the folders handlers model services and then i have a main.go file right so this is the same file that we just saw right you can see i'm using this because you don't have to have an ide but you can just use your terminal and all i'm going to say is go build and main.go so when i run this right and now if i open up this folder you can see that there is a main file that's in red that just got created or generated because i run the go command which is how it compiled that code for me and because i'm on a mac it ran it for arm or in this case i don't know what it will be and if i want to run it all i have to say go run main.go and you can see now my server is running and it's telling me that it's running and these are the three endpoints i have the slash api slash weather and all that so what i can do is in here i can say actually let's switch to a browser so i will go to localhost 8080 and i'll just say api and you can see this is what the slash api returns and if i say i want to see alerts for for my state for instance you see i get the response i get the whatever whatever the object is and we'll take a look at this so i get 19 count and then these are all the weather alerts coming back for my for my state and it's running locally as you can see so i can come in here and it'll tell you that these two were called and you know all the time that it took 437 milliseconds right so pretty straightforward we run it you know it gets the state and it goes from there"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:40:24",
        "seconds": 2424,
        "text": "you can see so i can come in here and it'll tell you that these two were called and you know all the time that it took 437 milliseconds right so pretty straightforward we run it you know it gets the state and it goes from there now if i look at the source code i have handlers for instance i have the alert handler that we just saw it it takes in a context right and then it looks for a parameter called state so if you remember in here i said that look for there will be a query parameter called or a path parameter called state and that's what it's looking for here and if it gets if it doesn't get it it returns a bad request if it gets it it returns the alerts right and what is alerts uh i call the alerts or the other and i'm calling another hand another package called services and i'm passing in that value in there and all these packages if you notice at the top this is called package handler this is just me structuring my code right in the handlers and and services and whatnot and the alert service which is here it has two constants it has that get alert method and remember because i have this one as lowercase this is not exported so you can get to this one this is the only method that is uppercase so this is the only one you can get in the service and i get the url structured for my code i call the http response i don't have to do and there is no ceremony here right i just call if you notice i just call http get pass in the the url and i get the value back here i use something called defer so when you use a defer that code gets run at the end of the code block so this is really used so if you're about to like you know if you're reading something or you're opening a socket or a connection and you want to be able to close it and you don't want to forget you just do it right away so in this case as soon as i get a response that is not bad i close my function body and if this gives me an error i just log it i don't like do anything with it and then i'm saying okay if the status code is is not okay then return the editor otherwise you turn the body and the error will be nil right so and then i just do some uh serializing and deserializing so in this case remember i talked about keeping it simple keeping it very lightweight i have an alert response dto or dao or whatever you want to call it but this is a response object that's coming back from the from the response from the http call and here instead of creating another model and then just throwing it out there i just create an inline struct and i just use that to deserialize my incoming object which is pretty neat so i just said hey there's an alert response that'll have updated that'll have alerts um and in here when when my actual model alert is here i'm setting the values to my alert the count and then the actual array of all the alerts that come back and this service then goes back to my handler which gets the response here and and then i get c dot json status is okay and the response is alert right so that's what we saw there is a more complicated one which is the weather right i'm not going to go in all the detail but it works exactly the same way but this one has a few things right so this one does it makes two calls first of all to it to a server that it needs to wait on so i couldn't just spin off a i couldn't just spin off a go routine and then like not wait for it so here what i did is i said okay i'm going to get the city from the given text because i'm using rj arcgis for this and then i want to get the location i get the coordinates and once i get the coordinates this check this out this is the the main meet of this function so i'm calling in six core routines to go get different items for a weather response get me the alerts the observations the hourly forecast the daily forecast the rain forecast and some other product and then i tell this wait group to wait for all of them to finish and when they're finished return my response object and in go everything gets passed by value there is no passing by reference but you can pass in the address right so you can pass in the pointer so if you notice i have my weather object initialized up here in line 38 and i'm just passing in the address to that to all of these go routines because go routines don't return value and inside my go routine they're just making calls to different services they're getting the response set and they're just saying okay i'm done so every time a go routine says i'm done this weight group count goes down to zero when it goes down to zero it returns so this is like you know a bunch of code here this is all in github so you can see it um when this one runs how does this work let's take a look so i'm gonna go ahead and run it again right so it's running and then we go to the browser and instead"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:45:25",
        "seconds": 2725,
        "text": "see it um when this one runs how does this work let's take a look so i'm gonna go ahead and run it again right so it's running and then we go to the browser and instead of pulling for alerts we pull for weather and we say boston uh or not i think it's running let's try katie no it's not running oh it is not running because if i look at the code i should get a 400 back because i'm using the arcgis map api which i don't have it configured in my um i don't think i have it configured in my ide well i do have it yep i have it so let's see what does the 400 yeah it says unauthorized api key for service not found um let's take a look oh sorry i'm gonna run it through my ide because my id knows about it and not cli okay so now let's go here and run it again we go to localhost weather and let's just say boston and we still didn't do it why oh sorry i have to stop this one first let's start this again there you go now it's running on port 8080 so now if i go and run to boston if i run it there you go so what i get back is i get the update id all these values and you can see i get the hourly forecast i get the daily forecast the rain chances and all these good stuff now what you'd probably notice is something that is here let me actually see um localhost alerts let's see you guys don't have any alerts so i'm just going to say texas so you see what happens this this object that's getting back has a property called updated then it has a property called count that it has a property that's an alerts array and that is here so i have embedded the same object in my weather response so my weather response alert property looks exactly the same right i named it active alerts but it has update count and then the alert right in which in your case is empty so um that's just a quick little tour of the go apis itself now how do we actually publish it to azure so to do that let's switch over to azure this is my function app so in in my case i did the setup of the functions app in the browser and i'm in the portal and you can see that currently i have two apis in here i have an alerts and a weather api so if i go to go let's just pull texas why not so if i go to that you will see i get this i don't know why i don't have the the nice ui but you get the point so this one returns the update the alert count etc running on on azure so what i'm gonna do is i'm actually gonna delete these two um do i want to delete them let's just delete them oh i can't touch it in here okay so let's take a look at how we actually deploy no worries so for me to deploy i have to do a few things so let's just go back to my easy function folder so in my easy function folder as you would imagine for those of you who are this is the azure group so i'm sure you guys are familiar with with how we deploy to azure function normally we have the function bindings right so we have a function called alerts and we pass in a state then we have a function called weather we pass in the city state these are all http triggers and then i have the host.json and i made a few changes here so first of all i said that my execution path is going to be something called api so whatever my executable is going to be is going to be named api and i removed my route prefix right normally out of the box you get slash api as there are prefix i remove that because i don't want that and this is where my function configuration live in this folder called azfunc and if we look at that folder right now we will see that it has just a few files right it has alerts folder make file and all these things so what i'm going to do is we will go in to um we will go back into the source folder where we have"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:50:31",
        "seconds": 3031,
        "text": "right it has alerts folder make file and all these things so what i'm going to do is we will go in to um we will go back into the source folder where we have this and and i'm going to make some changes i'm going to say make my so now i'm going to cross compile this build for linux to run on my on my function so i'm going to say make my go os to be linux and make my architecture to be am d64 then i'm going to say go build main.go and output into az.functions uh actually i have to say where it needs to go and then the output is going to be going to call it api so or is it the other way go build uh let me make sure what the syntax looks like so go build i'll have to do the output then the folder and the file okay so i have to say go build the output will be complete main comes after that okay cool build output in this directory which is the azure function and my file will be main.go and the name comes okay so i'm going to say the name of my file will be api so if i run this it will take a second and okay more than a second and there you go so now if i go back to my az folder you see that there is a new api file that's the actual function that will get deployed so now within my i'm i can see my host.json within my azure folder where my function configuration is i can deploy but before i do that let me finish up with this really fast so nope that's not what i wanted but let's just run through it really quick all right here so now when we are ready to actually deploy this i'm going to show you two different ways of doing that right first is the actual cli that i'm going to show you now and then the github actions because i'm sure you will not be doing this manually in your code right so this all all this code is here and i'll show you in a second but this is the main function that we will call right so if i go back in here if i say func azure function app and then the name of the app was go w xp api so you have to say publish the app name and then because okay so if you if you know azure functions needs the runtime so if it's net if it's linux what it is uh if it's python whatever language it is and in our case it's custom because uh currently on azure go and rust fall under custom so when i run this it should connect to my i don't know if i'm logged in to this it may scream that i'm not um but i am logged in which is great so you see it's deploying to my function uh to the portal and it's going to sync both my alerts and weather and there you go so now if i go back to my portal i hit refresh they should still be there and they still are so if i run this now hey sometimes there's service okay there you go so it's still running right it normally takes a minute or two for it to finish deployment but in this case it actually went right away which is which is pretty good um let's run it one more time just to make sure it's not um cached we'll learn different one there you go so it's working right but how does actually how can we do this with github actions so in github actions at the directory that i'll share with you at the end where you can see all this all this code that you are seeing right now is on github of course so you can play with it yourself i have two workflows one is every time i do a pull request all it does it just all it does it just runs a a build just to make sure that it builds and runs the test and then when it's done it uploads artifact doesn't really need to do that either but it does that but the main one is publish so in this in"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:55:34",
        "seconds": 3334,
        "text": "a build just to make sure that it builds and runs the test and then when it's done it uploads artifact doesn't really need to do that either but it does that but the main one is publish so in this in this action or my workflow every time i push to my main branch i'm setting up my environment variable so i've set up my os architecture my build output path so you guys remember it's a z function and then my artifact name right so i set all this up up here and then of course i run the job so first i have to say i'm running in ubuntu then go ahead and and set up my setup go so i'm going to set up go at 1.18 version and then i'm going to go and build this and to build it i'm going to run this command where first i change directory into source and then i run the same command that rain in in in my command prompt which is go os go architecture go build verbose so i can see what's going on output and the output is going to be the build output path slash artifact name and then main.go so what this step does it creates that file and when it creates it it places it in that ac function folder that what i do next is i just upload it right so here i'm using the upload artifact get github action and i'm saying name it the artifact name and then put everything that is in the build output folder so remember this is important that i'm seeing everything in this folder upload it and name it this artifact and of course i don't have tests running right now i'm in test to run right now but this is how i run the test and the next main important thing is publish now there are two ways to publish and i'll show you both first is first things first i download the artifact with the same name that i uploaded them to and i log into azure using my secret credentials and for those of you not familiar if you go to your repository and if you go to settings on your left there is a secret folder i mean secret option menu and if you go to actions this is where you can put your secrets for your github actions and i have a few i have the function name i have the publish profile and the azure credentials um going back to code i log in using those two things and then i run this functions action step and this is actually pretty cool i i didn't like it at first i don't know if i like it still because it's too much of a abstraction in black box for me but all i have to do is just give it the actual of app name and it knows where it is right now and it has all the um it has downloaded the artifact so it will upload this artifact straight to my azure account using the credentials that i provided it if you don't want to do that you can also do it manually which is right here i left it here as company so you know what it is for that what i do is instead of using that action i set up the cli tool so i just do what you would do on your local machine because github actions is passwordless which means you can run sudo commands without having to get a prompt for password so in here i set up the repository i set up i pull down the package for linux i do have update and then i just install the cli tools and then here i run the same exact uh command that i ran locally which is function azure function i publish the name of the app and custom and it does the same thing right so if i was to show you this in action i will go back in here i will just update my readme file and let's just make a change and we will save it now i could go up to actions and just rerun the last action but i wanted to show you how it actually works so this is a you can see the version number on this particular one is 20. i'm not versioning my stuff right now but what will happen is in my code you will see it it is going to set up go environment it is going to build all it will bring in all the dependencies that my code needs it will build it and then it will upload it uh to upload my whole az function folder uh with the built-in with the build binary of the api and it's doing that right now it's going to test there's nothing to test so we'll just quickly pass all this and you can see on the left build pass if you go to publish it is going to publish this as well now what happens is if something goes wrong here for example if you passed in the wrong"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "01:00:38",
        "seconds": 3638,
        "text": "pass all this and you can see on the left build pass if you go to publish it is going to publish this as well now what happens is if something goes wrong here for example if you passed in the wrong location for your artifacts or if you didn't pass in the runtime properly it will actually remove your functions from the from the portal or from from azure because they will not know what to push and your functions will just disappear and then you have to just push a new one for them to go back and get synced and here you see i logged in successfully i'm publishing based on that using the function action step or github action step from the marketplace so this is all available i didn't do this one myself uh it is publishing once it's done publishing it will log off so in my case if you notice i'm logging in and logging out manually into azure just just to be on the safe side and it is publishing i think it's done publishing and now if i go back to my portal and i do refresh you can see my functions are here and if i run them let's run them from texas because we have some here and there you go right so in here if you come in here and don't know exactly where to go and see all the latest deployments that just happened on this anyone on the call if you can tell me really quick fine if not then it's okay but we can look at that to see all the deployment that just happened on this particular one i don't see any maybe activity log oh there you go yeah there you go you can see that eight minutes ago it synced successfully by eight minutes 13 minutes and it tells you which subscription i was using and who did it so this is all my company profile so it's all coming in here right so that that is that is pretty much it now i do want to finish up um we did this we did this and then when it's all said and done you should see it there so quick recap why use go i know that we went through a lot but i hope what you noticed was how simple the language itself is and how easy it looks like you can pick up and work with it right it's it's if you're coming from c sharp it shouldn't be very very different it's pretty easy to to pick up so i hope you will play with it like consider it for your apis if you have a need for really performant apis that could run anywhere definitely consider uh you know looking at go as well so it's perfect it's a it's great for cross-platform any use cases uh easy to learn dev experience is performant it is coming up in it's it actually picked up steam in 2021 when i guess everybody was back to their working from home and realized that they needed more their workload on their systems got pushed to the limit so they realized they need to look at some more performant technology so go came back in the picture a little bit more so it picked up a steam in in 21 and there are a lot of now go language oh sorry conversations are on go about people learning go where to go learn go uh you know people the the jobs posting are more and more asking for back end goal as well so and it's easier to learn than rest at this point so i think and it's pretty cool i pulled some stats so you can see it's number four most wanted from 22 stack overflow survey if you don't if you don't like that survey don't add me i don't really care about this airway but i do read it every year it comes out and it gives me a good indication of what's going on and then it is one of the the top paying jobs as well because of all the demand so resources how can you actually get started really quick if you go to go.dev today they have a playground where you can start coding without installing anything just go to the website um why don't i show you so if you go to go.dev it'll take you here and if you go to slash play you can run go directly in the browser so it's pretty cool you can do a lot of the use case you can learn the whole the whole you can learn a lot of the concepts directly in here if you wanted to i wouldn't because you know if you work a lot on recorder and save it and come back to it then you'll lose all that but it's really good place for you to go and play around with it if you want to go i just see some of the codes that i was showing you do during the presentation if you go to tinyurl.com go snippets it will bring you to my gist that"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "01:05:41",
        "seconds": 3941,
        "text": "if you want to go i just see some of the codes that i was showing you do during the presentation if you go to tinyurl.com go snippets it will bring you to my gist that i put together a while ago that talks to you about variables arrays map loop types generics i have a fibonacci calculator in there go routine channel and interface examples right so all this code is here uh just just look at it play with it i remember i was talking about circle radius and and square area and circle area et cetera so it's all in there if you want if you're interested if you're a javascript developer and you want to see how you can maybe use some of the go libraries within your uh browser and then my github repositories right there is called wasm samples and the one we just looked at is called go wx api wx usually stands for those of you who don't know wx stands for weather right so go by their api is there and for anything else you can find me on twitter that's my handle hussein and abbasi and my github and that's it thank you very much for uh coming along and and sticking it out for this long i will take any questions if you guys have at this point any questions how are we doing on time i guess i guess i would like to think that sure one of the promising things would go for me is the containers yes uh so if you notice uh even with net six we are in the dot net world we are coming to uh this new idea or the new way of doing this which is to minimal apis and minimize a lot of that boilerplate noise but go because it's built out of the gate has lightweight it still feels very light and yeah and yes if you noticed most of i shouldn't say this a lot of azure right nowadays runs on linux so i think we are we are in good hands we are not tied into a ecosystem at this point if no other questions um i would encourage you guys to just go go here copy paste this whole snippet into your vs code and once you install vs code copy paste it there and then just comment all these and then run one by one and see what's going on right how are the variables working how do the arrays work what happens in a map how does loop work struct vehicle we talked about all these things fibonacci number this is using a cache so it's super quick using my memoization this is a slower version where you know so you will see you know a lot of these examples are there how they work uh go routine this one has three go routines running you will learn running this code that they will always come back in different order but not always which tells you that there is no order to these whenever they finish they finish then channels you just play with that on your sending stuff to the channel receiving it back and then work with generics which is pretty fun which is right here i i'm really good at naming stuff so i call this edible you can add these things because you can also add a string right so if you pass in a string to edible two strings it will send send you by a concatenated string which is as useful as you can make it and there are some interface things and at the end uh yep that's all the interface work so a lot of stuff here just to get started and play with so yep that's it that's all going to go ahead and stop sharing all right well thank you for the presentation all right good job i actually see getting it getting it running and functions is something i just hadn't gotten to yet it's really cool thanks absolutely yeah that's that's one of the first things i did is how can i bring this to azure because most of my clients are in azure so if we are working with a more so we worked on a fire firefighter lms system that was that was being converted into go and they wanted performance and i was like how can i bring this to aws uh azure i mean and causing the war on aws and we are azure so that's why i started getting curious on go and azure and then there isn't a lot of documentation out there because go and rush kind of get lumped into the same support links but if you just play around with it long enough you'll get it awesome thanks and thanks everyone for coming thank you i'll get this posted up on the youtube channel probably tomorrow morning and put a link in the meetup as to where it's located great all right thanks everybody have a good night bye-bye bye goodnight thank you thanks susan all right "
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Pamela Fox: Building a RAG app to chat with your data. This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure. Json the data format thank you Jason for the introduction uh I do have the slides available for those who want to have a copy of the slides or follow along with them you should be able to get them from that speaker deck link so today we're going to talk about large language models briefly just to you know set the stage um for that terminology then go deep into rag which is retrieval augmented generation uh go and look at this open source rag chat app solution that can be deployed on as your talk about how to evaluate rag chat applications and talk about observability for rag chat applications on Azure so just to start off with talking about llms uh so llm stands for large language model it is a model that's so large that it achieves general purpose language understanding and generation so example I like to give is sentiment analysis which is you get a you know a sentence and you say whether it's positive or negative in the past what we would traditionally do is we' train a custom model with you know trained data that said here's a sentence it's positive here's a sentence it's negative and then what we would get is a model that could classify sentences as positive or negative and we would specifically use that Sate and now model when that's what we needed but with an llm we can just do this uh we don't have to specifically train the llm to know how to do it it just is able to do it because it's just seen so much data and been trained on such a large data set and one way you can think about the size of an llm is how how uh how many training operations it's had so the these graphs here are in turns of training flops which is floating operations per second I believe and what you see is that there's this jump when they've had 10 to the 24 training flops they suddenly achieve this ability to do really really well at these General purpose tasks and these are the classic ones that they do like modular arithmetic word in context Etc um so that this is observation they had is that if they threw enough data at it they threw enough compute at it then they you know achieve these general purpose models so you can there you can call them Universal models Foundation models large language models um but the point is that we can use them for a wide variety of tasks and that's really really exciting um and it's kind of like I don't know I feel like it's lowering the barrier for more folks to get involved with with uh Ai and using models because you know you think of a task you're like well maybe I can just use an llm to do it maybe I don't have to you know train one and learn how to do training well so there are lots of llms in used today ones that are both hosted on you know company infrastructure and also ones that are open source that you can even download to your computer and use uh so you know the hosted ones the big one of course uh are from open Ai and that's the GPT model like gp35 gbd4 whatever GPT is coming next uh Google is also in the game here you know it put out Palm was like a year ago and now it's put out Gemini and Gemini you know looks like it might be pretty impressive uh anthropic is a company I think they forked off of Open Ai and they recently put out the Claude 3 family which seems to be pretty powerful and then we've got the open model so there's a lot of open models coming from meta like uh the llama llama model uh and that one has kind of variety of sizes and then there's also this company mistro AI that's been putting out some models as well uh yeah I see a question from so yeah can you go back to the last slide and just want to understand when you say this um um like model scale training flops so what does it mean like mod AR arthamatic mod task nlu and word in context what does it mean these tasks that they get the models to do so mod arithmetic this is modular arithmetic so typically we wouldn't expect like a language model to be able to do modular arithmetic since it's not trained for math uh but you can see that its accuracy does jump to like 35% when it has been trained on a lat enough data just because it ends up seeing modular arithmetic a lot in the data um this one is multitask natural language understanding I don't remember exactly what that test test looks like um and then I don't remember what word into context looks like so I'd have to dig up the paper uh to remember what these what these tasks look like it's a good question thank you thank you so much uh yeah so and I see a good question about hallucinations so I'll certainly talk about that throughout it um so what we see is there's a variety of LMS so some of them are hosted and these are the like the most powerful ones you can really only use on someone else's infrastructure um unless you're willing to go through a lot of effort to figure out how to you know host one of these powerful and set up the GPU and all that stuff but you can totally get started running with these smaller models locally I recommend using olama"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:05:04",
        "seconds": 304,
        "text": "willing to go through a lot of effort to figure out how to you know host one of these powerful and set up the GPU and all that stuff but you can totally get started running with these smaller models locally I recommend using olama you can see I've got like a little llama up here uh and here I've got it running I typically have it running over here yeah so let's see emojis for Boston I always use it to generate emojis uh so this is with llama 2 so I just write a llama run llama 2 and what that does is that it pulls down the model if I don't have it already uh and then it lets me just chat with the model so here are some emojis to represent Boston so we get a building a park and a person walking they're pretty good ones I like to walk around Boston when I go there uh so I do recommend playing around with olama it's the easiest way to get started with these open models locally and it's just fun to have an llm in your terminal they're not as powerful as the models you'll definitely get more you know hallucinations um as you know Lucas was saying um but uh there's a lot you can do with it h you know especially if you just need a quick a quick Emoji quick poem that sort of thing so one thing that you might want to know about terminology wise is GPT what does that stand for it is generative pre-train Transformer that's what the open AI models are named after you'll also just generally people talk about he people talk about Transformer architecture so that architecture was actually first described in a research paper from the Google brain team so it's funny that you know open AI came up with the gvd models first but uh you know things happen uh so if you're interested in seeing how this architecture actually works and you like reading research papers uh do check out that paper that's where I got this diagram from um but basically this Transformer architecture m let uh was much better for language because of its ability to see multiple parts of the like kind of input the sentence at the same time so that's my very simp simplified and probably not quite correct uh you know understanding of the Transformer architecture there's more in the paper and there's also some great videos for f from folks that are actually machine learning experts that explain the attention architecture more there's also a fantastic videos from Andre karpathy who is a machine learning expert and he was just uh he was previously at open aai and at Tesla Ai and he's got a great talk state of GPT and then also he has a series where he builds GPT from scratch in code using python notebooks so that is a really cool Theory I still haven't made it through the whole series because it's a little intimidating to build entire tvt it takes quite a few hours but every time I watch his videos I I just learn so much so if you want to dig into how these you know how these GPT this transform architecture actually works that is what I recommend so how do we actually use these uh these GPT models from open AI uh one way you can do it is an Azure Studio I'm guessing some of you have already done that um so please you in the chat uh let me know what your experience so far has been in terms of using open AI as your open AI that sort of thing uh so there is this you know Studio that you can use you can get to it from the um from the portal now the first thing you need if you're going to use as your open AI is that you do have to fill out a form in order to get access and in that form you have to say what your usage your expected usage is going to be so that Microsoft can say like okay that sounds like a good responsible use of um of open Ai and then once you got it then you can deploy all these models you can see I've got quite a few I have quite a few deployments because I spend way too much time doing this stuff um so let's see I can go to my model deployments and then open those up in as your open AI Studio load load load oh here we go oh I'm just gonna all right so I'll go to as your opening I Studio there is also something called a your AI Studio which is different from a your open AI Studio I tend to only use a your open AI studio um but a your AI studio is where you'd go if you're you know using other models making your own machine learn models that sort of thing I think eventually they're going to merge the two but right now we've got two different Studios so this one's really fun just the chat playground it's just a you know just a wrapper for playing with the API so we can be like you know right haiku about Boston and it'll send it off and we can see Harbor City's charm Boston's history unfolds proud Spirit endures okay so that's cool but maybe we want to change the system message so how people find more you know you're AI assistant that uses so many emojis okay so I'll change the"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:10:08",
        "seconds": 608,
        "text": "see Harbor City's charm Boston's history unfolds proud Spirit endures okay so that's cool but maybe we want to change the system message so how people find more you know you're AI assistant that uses so many emojis okay so I'll change the system message I'll apply the changes and now I'm going to ask ask it to write a haiku about Boston again and there we go we can see a lot more emojis let's also we're talking about hallucinations we can say what is the weather in Boston and those of you who are in in Boston well there you go um it's still doing hus and it's G Gabby a range here so what is the temperature today I'm trying to get it to lie basically uh okay so sometimes it does this response where it says I'm sorry it's an AI I don't have real time data access so that's good uh it's you know it's better when the LM doesn't try to make something up but let's just try to force it so I'm going to change temperature to one and top P to one to try and increase its creativity level and we'll see yeah it still is refusing to answer that's good so sometimes you can get the llms to to uh make stuff up and uh depending on you know how it's been trained sometimes it won't do that for you all right so that's a little playground and you can also grab code from here so once you've played around with something you can actually grab the code uh you can get it in you know they've got different ones they've got curl C Python and Json I'm not sure what the Json is for I typically use Python and so most of the code you're going to see me using today is in Python so as you see here here is an example in Python uh so we pass in the conversation so when we're working with these chat tuned models so we call them like chat tuned models uh so like CH gp35 and gbd4 are chat tuned which means they expect their input to be to look like a conversation so we typically start off with a message which is the system prompt so it has roll system and then it has the system prompt and that gives it just overall tone format expectations uh and then we have the question from the user and then and we can also keep going so we could pass in you know multiple back and forth um so that the you know the chat model could see what messages happened before uh we can choose to stream the responses or just get the whole response back at once so llms can be really great you just saw we could get it to know write Haus and use poems and all that stuff uh but you know as Lucas was saying like you know there's uh it can make stuff up right and it can answer things incorrectly and why is that well one is that llms are have always have outdated public knowledge right because they train the llm you know on the internet up to a certain point and then nothing after that right so if we asked about something recent that happened it would you know it would have no idea uh the other thing about llms is that they do not have access to anything internal so if you know if you have data that's inside your internet there's no way that an llm is going to know anything about that so if you're trying to ask company specific data it's just not going to know right so those are you know the limitations we run into and then we try and figure out like how can we work around these limitations so there's you know three General techniques to incorporating domain knowledge the first technique is to do try to do prompt engineering this prompt engineering is only going to work if the data is inside their inside the weights somewhere right like let me see if I can do an example of this um so I'll say um write SQL Alchemy code uh that's a particular python package for SQL databases okay so yeah so it did this this is the old way of writing seal Alchemy code uh I'm going to see if I can get it I don't know actually if it's seen the 2.0 I think it has code using the declarative base C Class let's see if I can get it to fix itself oh it says squal 2.0 doesn't exist as of my knowledge so yeah unfortunately in this case it can't do it so what I was trying to show is the the fact that if if you know imagine there's you know two different versions of a library in an llm weight you can often get it to you know pick the most recent one if you're giving it a hint that that's what you're trying to get it to do right but that only works if it's in the weight somewhere right in this example it actually didn't even have anything in its you know in its training data at all so we couldn't get it to come out with the code so prompt engineering is generally not going"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:15:10",
        "seconds": 910,
        "text": "in the weight somewhere right in this example it actually didn't even have anything in its you know in its training data at all so we couldn't get it to come out with the code so prompt engineering is generally not going to be that helpful when we're trying to incorporate specific domain knowledge only helpful if it is actually somewhere in those weights and we're trying to steer it the next approach people talk about is fine-tuning that's where you actually are kind of training a subset of the weights and so you would repair like you know maybe thousand examples or or more and those examples would be you know examples of uh you know user questions and chat answer and in that way the llm could actually learn new skills permanently so it's a very it's a it's a you know effective way of getting an llm to you know update it's weight to learn something more however it is expensive right it's expensive to do the fine tuning and then it's more expensive to run uh to you know to use a fine tune model than to use a base model so I actually personally have not done any fine tuning myself I haven't felt the need but uh and and a lot of people have talked about where you know uh you could do fine tuning or you can just use the the the you know the most recent model and and that is generally going to be better so fine-tuning we like to consider a last resort because of the ex you know expense involved you know the time and all that stuff um so it is it is a tool in our toolkit but it's not the thing we should necessarily reach for immediately the technique that I like to use is retrieval augmented generation which is a way of just giving the llm the facts just in time right um you know for example with the SQL Alchemy one that I just showed if I you know wanted to make sure it really did um you know answer something correctly well I could just give it information I could just say like well you know um you know here write a model for a restaurant class based off this example right so I'm basically going to like give it current code and and see if it can learn how to do it yeah it got a little bit better there yeah uh so the idea here is that you know we're we're going to give the llm the information to answer a question based off the domain data and we're just get get going to give it to it at the point where it's answering the question so that it can see what we want to answer the question based off and it can still use its skills of answering questions on that provided data so I have one question if you don't mind previous so where does the few shot fit into in this um yeah that's a good question um yeah I should I should do like an updated version of this I actually I did talk about that in a presentation on um Friday uh so me find yeah ways to improve llm output so F shot examples uh so we could even do that in the playground too you can add examples and this shows the chat what responses you want uh so I would say F shot examples are the most useful for format they could also help like in this case with SEO Alchemy like it might be enough to get it to write the syntactically correct SEO Alchemy code but usually few shot examples is more about learning the format that you're looking for and less about the knowledge um because typically your F shot examples are going to be the same across all the questions but the knowledge for each question would actually be different um does that make sense yes so that means a fuse shot would be for the formatting and for the you would use the rag or fine tuning if it is knowledge based is it yeah yeah and I I can show examples because we do use few shots for our you know for for formatting to try and show the LM this is the kind of format we expect so we use fuse shots in combination with rag so it's definitely a good tool to use f shot examples especially when you're trying to get a particular format particular length that sort of thing um but it's uh I would say it's complimentary to rag got and and irres of which llm we use is that a same how we interact with the with the foundation models in terms of let's say the F shot is the way that we do it for GPT would it be the same for the clot um do they follow the same Pro you know similar way to interact with them yeah generally generally that would be similar um you know you know you see people talking online online about what prompt engineering and few shots they're doing for Claude and and other models there are some differences in terms of"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:20:12",
        "seconds": 1212,
        "text": "with them yeah generally generally that would be similar um you know you know you see people talking online online about what prompt engineering and few shots they're doing for Claude and and other models there are some differences in terms of um if you're going to do something with like function calling or Json output so there there's a a lot of people try to get the llms to Output structured data uh like if you're trying to get it to Output a Json that um you know like you pass it in news article and then you say output a Json that has the title of the article the top you know cities mentioned in the article and the top people mention the article right so doing like an any analysis to get Json out if you're trying to get Json out of an llm that actually is is going to vary based off the model because some llms have like specific uh kind of API endpoints in order to to get Json output because they've been they've tuned it for that uh and with like the open AI use the tools parameter to the API um H but not all the not all the API support that so the main difference I've seen so far is if you're trying to get structured output out of the llm the way you do that per model uh may vary okay thank youh all right so retrieval augmented generation let's dig into this so let's say we have this example here do my company perks cover underwater activities and I actually have I have this one open let's see is it over here there we go yeah I'll even try it again do my company perks cover underwater activities let me zoom zoom zoom so it is going off and trying to figure out the answer to this question and it should be doing it in and this one's this one is actually running locally okay so there we go we see underwater activity such as scuba diving are covered under the perks plus program now this is a chat that's specific for a fictional fictional company's data and it's managed to answer this question and it does that using retrieval augmented generation so how did this actually work so we get the user question and we use that to search a knowledge base right so this knowledge base it's either a search engine in this case it's as your AI search it could be a database we're searching some sort of SE search engine it could even be a numpy array actually like if you had a small enough amount of data it could even be like an inmemory array but you need to search your data somehow based off this user question in order to figure out what are the pieces of knowledge that could help an LM answer this question and then we take that you know we get that information back and we take that and the original user question we send it to llm and say hey answer this user's question based off this data and make sure you site your sources and then we get back this answer that says yes your perks do cover some under activities like scuba diving lessons so this is the general approach to rag is that we're getting the search documents back the search results back and we're passing both the user question and the documents to that llm call and we can actually see that here if we click on the thought process so first we uh you know we search using this query and we get back search results from as your AI search and these are Snippets from employee you know employee HR handbooks type stuff and we can see you know the page number and all that stuff so we get back these and then this is the actual conversation we send to the model so we have the system message and the system message says You must do it according to the data and the sources below then we have the user question and actually here is where you can see we do have few shots so we have an example of a question and sources and an example answer and that's to show it how to do citations right because we're trying to get citations in a particular format just trying to make it bigger bigger bigger right so we're saying like Okay this is an example this is how you answer this is you know how you give those citations and then and then we have the actual user question and the sources that we got back and these are just concatenated you know with new lines and that's it that is what we send to the llm so that is the heart of retrieval augmented generation is that you send the the information along with the question and the LM is able to look through that information in order to synthesize an answer have a question or okay can can I ask a question yeah so P how like what is this is this a python based um web UI you have developed and then how you have developed like what what you are actually trying to achieve"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "answer have a question or okay can can I ask a question yeah so P how like what is this is this a python based um web UI you have developed and then how you have developed like what what you are actually trying to achieve from this how you have developed this UI if you can explain that it will be really great yeah so I'll dive deeper into the actual code for this this is a this is all open source it's a react front end with a python back end and I will I'll I'll step through the code as part of this presentation in a bit sure thank youh all right so as we can see yeah yeah have one small question so when it comes to rag um and this might be just you know your experience but how do you balance the amount of data you're actually putting in either that Vector DB or you know I'm kind of trying to understand this because I've heard these scenarios where people throw in just mountains of PDF files in a vector DB does that then I get to the point like well can't I just search the vector DB and what do I need the llm for so I'm trying to understand the kind of like the balance between you know how much data you have in there or the quality of the data or does it even matter I mean you know for example in your case here you have the HR information do you just basically put the entire every single PDF file you possibly can find and you just scrape it and put it in the vector DB and you're pretty much going to be getting quality results or do you you know how do you balance all the splits or whatever comes in I'm just trying to get a better understanding of that if that kind of makes any sense yeah so here you can see these are the only bits of like chunks of documents uh so when we're doing rag on documents we do split up the documents uh into chunks that are about this this size here about like 500 Words uh so we we split up the documents into these chunks uh because the whole thing is that we don't want send too much I actually think that might be my next slide so okay okay okay I can hold us uh so yeah so as we see rag is beneficial okay so yeah let's talk about that search step and the what the data looks like right um so we need to get good results to the llm or we're not going to get a good answer and yeah another point is that what is the llm actually doing right the llm in this case it's synthesizing information so we're basically I think of brag is making search more accessible right so people they don't want to have to search and click through multiple documents and like synthesize information in the head so we are using an llm to synthesize information and present it to the user in a concise way um but really it's it's it's really like kind of just you know making a more friendly search interface and it turns out like people like people like having a more friendly search interface where they just feel like the answer is right there in front of them um but in fact like we do need to focus a lot on that search step because in order to get a good answer synthesize we need to have really good search results right if we if we give the llm garbage it's going to Output garbage um if we give it gold you know it it it it should you know output gold uh so we want to figure out how can we really make those you know those search results be really helpful for that LM so our general goal is to come up with a small number of searches uh search results that contain the answer uh we don't want to like we don't want to find too much information because if we send too much information to an llm it does tend to get a bit lost like either if we send too much information either it just won't find the answer at all because it'll kind of just ignore it if it if it's just too much being sent at it uh or if that if we send so much information that we kind of have conflicting answers in there and we have some information that's like misleading in there and doesn't actually answer the question the LM could get misled and answer the the thing wrongly right so we really want the search step to find the most relevant documents and nothing more uh and not too many documents right so in my example I'm only retrieving three documents between three to 10 would be the usual um so that's we we don't want to send too much this there's this paper here lost in the middle uh where they were you know looking at how many documents you could send and basically like as you sent more and more the accuracy went down because the llms would you know find it too noisy to find the answers in that large chunk of information uh so you can see here we only got the three document chunks back and uh and and you know these chunks contain the answer and they don't contain too much more that is that's the goal um as like you know how many documents do you throw into your search index I mean you do want to throw in everything that"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:30:22",
        "seconds": 1822,
        "text": "and uh and and you know these chunks contain the answer and they don't contain too much more that is that's the goal um as like you know how many documents do you throw into your search index I mean you do want to throw in everything that could possibly answer a question that a user would have I I I think that's that's true you just want to throw it in in a way that you're going to be able to to you know search well um on that data later uh because you don't want to just send your you know too much information at an LM so when we're doing the actual search uh we want to use the best search strategy for searching with the you know use your question uh these days everybody's talking about Vector search a vector search it means that you turn the user query into a vector and uh you know Vector using like the open AI uh embedding models and it basically like that Vector encodes all this kind of semantic stuff about what's what's in that text so if you had a user question about dogs then that would end up you know in this similarity space where it's similar to cats because dogs and cats are both pets so they are sem atically similar even though they're spelled completely differently right uh so you know this example here I asked about underwater activities but the word underwater is nowhere in the text at all instead the word scuba diving is in the text but underwater and scuba diving are both similar in the vector space so that's why everyone's talking about Vector search because it's a way that we can uh you know we can get results for things that are semantically similar even if they're spelled completely differently so we definitely want to do a vector search so that we can you know find those semantically similar things we still want to do a keyword search because Vector search is not good for some things and this is something I want to stress because there's been such an obsession with Vector search because we're like we're all like discovering it now that people are forgetting about keyword search but oop um but keyword search is still necessary for some stuff like if I search for like an exact you know number like you know what costs you know $1 19991 1999 is not going to do well in a vector search or if I search for an exact name like you know everything about hamla Susan Fox I want that to be done with a keyword search that's an exact name I don't want you know things that people that have names like me right I want Pamela Susan Fox so we still want to have keyword searches done as well so we need a search strategy that's going to do a vector search going to do a keyword search and then is going to combine those together right because you get both those results right so you search using your you your full text query you search using your vector query you get back results you need to somehow merge those results together you know remove duplicates figure out um you know which which scored higher and then you want to you know you need to have some sort of way of ranking the vector versus the keyword search so what uh people often do is they use a reranking model so this would be a machine learning model where you say hey here's the search results here's the user question could you please rerank these search results in the optimal way now this seems like a lot of work and it it is actually because I was actually trying to implement this this morning myself so typically we I use as your AI search because it just does all of this for you and it's very very good at it uh so I do recommend as your AI search but if you were going to do this on your own database then you know you have to implement it on on that database and you can often find examples of how to do that um but the thing I want to stress is that you want to get the best results and a small number of results and generally the way to do that is with a really good hybrid search so you whatever you are using as your search engine make sure that you can get good results from that using a hybrid search uh I see a question from Robert in the chat is there way to leverage a company ontology for vectors and tonies for keywords uh like we provide documents to the llms um yeah that's a good question when you just do the vectors you're generally going to use like the open AI models because they're quite they're quite good if you had your own ontology I mean one thing that's interesting that you could link into this isn't publicly out yet um but I think it should be out in the future this is called graph rag because it sounds like you know you've got an ontology ready uh so let me link to this here um and it actually like in order to use graph rag I think you have to actually Define an an antology and uh they they say it works it can work better for some some types of rag uh so it'll be interesting to see I haven't had a chance to play with it myself um yeah that's a good question um you could also do like custom waiting with res searches and stuff like that but I haven't dug much more into it beyond that uh rajes yeah I have a question suppose you have a millions of Records in a database then you are"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "custom waiting with res searches and stuff like that but I haven't dug much more into it beyond that uh rajes yeah I have a question suppose you have a millions of Records in a database then you are going to go through millions of record create a vector out of it and then merge the keyword I think then that case going to be very very slow uh for the model to search those many records isn't it so yes yeah yeah you're right so doing a Brute Force Vector search would be quite slow um what uh you're usually going to use an index either hnsw or IVF uh those are the two main ones uh like as your AI search uses hssw so you just tell it which kind of index to use and this does as you can see fast approximate nearest neighbor surch so it's using heris in order to be able to quickly search um across so this is the current one that's the most popular and that's supported really well there's also IVF and there's also I was even reading uh people are really experimenting with this space and how to how to do uh Vector search faster so this is an article from Nvidia about doing uh GPU powered Vector search so it is a very hot topic uh but you can generally get pretty good performance with hnsw and uh you can do it with Azure AI search you can do it with postgress um so you can use one of those indexing algorithms with whatever database you use I I was watching some videos nowadays people are talking about graph databases uh yeah I saw somebody post on LinkedIn about doing what is it like neo4j or graph databases with rag I didn't read into it to see what particular approaches they they were using uh but uh that is definitely something look into so I don't know Mindy if you have any videos or articles you want to put in the chat that would be very helpful all right uh and I do also recommend reading this blog post from the Azure AI search team uh so aka.ms rag relevance also just put it in chat this nice chat here and it really nicely demonstrates uh you know the differences between just doing Vector just doing keyword and doing you know hybrid and ranker and and you know for those of you interested in like you know how do you decide how to index documents this is just a really uh really fascinating article so what does it really look like to do a rag with hybrid search so this is just my diagram before but broken down a little bit more right so we get the user query we take that user query and first we actually send it to an embedding model like Ada 002 or even one of the new embedding models from open Ai and we get back that vector and so then we take the vector and the text and use both of them to do a hybrid search which will get back the merge results and then you know with those result results we send both the results uh and the user query to the large language model and get back the the answer so this is still actually even simpler than what we actually do in the app but I'll I'll talk about that soon um but as you can see there's various steps involved here in doing a proper rag with a hybrid search now another thing to think about is what is your rag searching uh is your rag searching documents or you know I would think of as unstructured data or is it searching like rows of an existing database right so imagine uh you know you have like a an online store and you wanted to have a rag where customers could ask questions about your store items right so those I think of as actually being two fairly different rag situations and a lot of times when people are talking about rag they're talking about rag on documents because that's I think where people are really like I don't know I think maybe because it's harder and that's where we tend to focus on it because it's you know it's it's you know trying to figure out how to ingest all those documents but you could also totally do rag on database rows and um and you can have a really com compelling experience with that too so do you have any articles I actually that's one of my um kind of a research item to do uh do you have any articles you could share on how to do database Rod uh yeah that's a good question um I was actually working on it this morning uh so I intend to put out"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:40:32",
        "seconds": 2432,
        "text": "um kind of a research item to do uh do you have any articles you could share on how to do database Rod uh yeah that's a good question um I was actually working on it this morning uh so I intend to put out various samples so you can see um post from this morning so the first thing I did was I implemented a hybrid search for postgress um you know postgress with PJ vector and so you can see the search right so I pass in a text and a vector and then I get back to results so if you can Implement hybrid search on your database um you know it means you need to have some sort of vector support with so with postgress I use PG Vector um various database extensions of different ways of storing vectors so hopefully there's one in your database of choice once you do that it was actually really easy just to swap it in to my um you know to the app that that I've been showing I just kind of substituted the Azure AI search call with the call to the uh hybrid search endpoint for the postgress database uh but I will be putting out uh some repos around this to make it easier for folks so I guess want to be clear so it's it's like you're able to scan the whole database schema and then ask questions in natural language or did you just okay so when I do I I said best shoes and that um that turns into a a hybrid search query on the well in this case just on the shoe table so I did have to decide what is this going to you know what Fields that's the thing you have to decide if you're going to be doing rag on database rows you have to figure out which what are your target columns like are you going to be actually searching across all the columns or just one column and when you make a vector are you going to make a vector for each of The Columns and like search on each of those vectors or what a lot of times people would do is you know they kind of you can do like stuff it so you you would concatenate all the relevant columns together uh and then compute the vector for that so you would still just for each row have a single a single column for the embedding for that row as long as it encoded all the stuff you thought would be semantically relevant so that's that's actually the decision that you have to make is uh you know how many how many embedding columns are you going to have and and what is your you know full Tech search going to search as well yeah this a great question and definitely something we need to talk more about and have more examples for uh so so yeah if you're doing database rows you do need to figure out a way to have Vector support um for the ability to have a vector column and to have efficient search right we were talking about indexing right so you need a database that has support for Vector indexes so you're looking for support for hnsw or IVF those are like the efficient Vector searches uh or just looking for a native Vector database um you know that's an option too so on aure uh the options we have here are you know uh for database rows you could do as your AI search if you wanted to copy the data over that's also an option if you're okay with having a copy of the data as your AI search can connect to various databases and and index it uh but then you'd have a copy of the data so you know if your data changes a lot you might not want to do that uh you can do as your post grass flexible server plus PG Vector you could do as your cosos to be plus their new Vector support you could use container app Services uh with these built-in Vector databases like milis quadrant or weate uh and of course you could use the open AI embedding models in order to actually you know compute that column so that's rag on database Rose and I haven't done that as much as saying like I only really did it this morning to make sure that you know to to kind of prove it um what I've spent much more time on is rag on documents which we can also think of as unstructured data so that's just whatever documents you have PDFs docs PowerPoint HTML markdown IM images all of those are things you could potentially uh you know ingest into a search engine but for that you do need an ingestion process that's going to take that document extract the data from it split it into good siiz chunks because remember we don't want to send too much information at an LM then you know compute vectors for each of those chunks and then store those so on Azure the best option for that is definitely a your AI search uh in combination with document intelligence for the raction and open AI embedding models for the vectorization uh so how would you actually build a rag chat app on Azure there are various Solutions ranging from no code to low code to high code my emphasis is always high code but I will show the no code and the low code"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:45:35",
        "seconds": 2735,
        "text": "vectorization uh so how would you actually build a rag chat app on Azure there are various Solutions ranging from no code to low code to high code my emphasis is always high code but I will show the no code and the low code options because hey if they get the job done that's great the no code option is co-pilot studio and you know is is really meant to be you know a user friendly way of setting up your own co-pilot so you can say like oh here's you know make a co-pilot based off of this blog right so I tried making one based off my blog and it'll you know it'll try to do all the ingestion and indexing for you and give you this chat interface now the thing about co- pilot studio is that I actually don't really know how it works behind the scenes right it is uh it's you know kind of a black box uh I do work at Microsoft but I don't I don't actually know how to like find the code Behind these things so I actually don't know how is it doing the ingestion how is it doing the searching I don't even know actually if it's using gp35 or gbd4 um I'm trying to ask around just to find out for my own edification but generally if you're going to use a you know a no code option like this it's you know you're not going to be able to have that much flexibility right you're not going to be able to really um you know extend it if you realize it's not working for your use cases uh so it's always good to start off with these things just to see does it work for your use case especially if you have like a really low stakes use case um but then you know keep in mind that you'll probably reach a wall now the next option is actually a really compelling option because it actually has some code that you can mess with and that's that as your AI open AI Studio on your data so I think I still have this open here yeah so you can actually go to this add your data Tab and add a data source and you can click you know as your AI search if you have an existing index or you can use blob storage Cosmos CB elastic search I think they're even adding pine cone you can specify a web address upload files so they're trying to figure out what are the common data sources that people want to use and make it easy to connect to them uh so it supports you know all sorts of documents because you can use aure I search uh you can upload documents to it so lots of documents uh it kind of supports databases in that you could connect your as your AI search index to a database um but I don't think it's really uh kind of I don't think it's really Geared for databases I think it's a little more Geared for for documents but uh but there is a cosmo actually I mean there is Cosmos D for  VOR so yeah so you could try that out for for that if you've got your data there and uh and yeah and how does it do the searching it's got lots of different search options right so even some non- aier ones like elastic search and you can choose whether you're going to use three you know 3335 or four so this is a pretty cool one because actually once you you can make it and you can deploy it entirely from the studio and if you want to extend it you can actually get the code for it from their repo so I believe that this you know this is the code that powers it so if you do deploy it and you like it you can try to actually change the code if you need to make some tweaks now there is still limitations to this because I'll I'll show the code um what is doing let me find the relevant bit of code Source uh trying to find the chat completion call so a lot of options here chat. completions do create okay send chat request okay I haven't looked through their code in a while um stram okay let's see yeah okay it's kind of hard to find it but um what it does is actually using a particular parameter to the chat completion yeah these are basically the parameters so it's actually telling the chat completion API like hey here's the elastic search index use this index and search it so and behind the scenes that as your chat completion API knows how to do this this is only on aure you can't do this with open AI um you know on open.com you can only do this on Azure right now at least uh so it's doing the search for you so if you if this works for you great if you end up needing more flexibility over like the searching step and like how it's actually combining the search result with the you know with the system prompt and the user message and and all that stuff then this you know this may not work for you so you may reach a wall if if you find you need to uh you need to extend the actual rag flow more because this basically is like rag orchestration as a service so it there's code going on behind the scenes that's figuring out how to get the search results and how to you"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:50:40",
        "seconds": 3040,
        "text": "if you find you need to uh you need to extend the actual rag flow more because this basically is like rag orchestration as a service so it there's code going on behind the scenes that's figuring out how to get the search results and how to you know how to answer a question based off the search results oh I see a question from Robert like what do you map it to from so you can map stuff like if you're doing like elastic search with you know with a your studio on your data you have to tell it what's the title column what's the URL column what's the content column what's the file name column so if you're you know if your data matches you know you know works with the assumptions they're making here like the assumptions here you can see is that you have a title and a URL and a file name and a Content so it's definitely assuming some sort of document-based rag but if if you're you know if that works for your rag use case then the as your opening eye on your data could work really well for you so lots of folks do start off in this ad data um and and deploy that and um and some of them you know stick with that and that works well for them uh and then if it doesn't then you can go to the full very high code uh solution and this is the one that I spend all my time on so I you know I know you know that on your data a little bit but I basically spend like way too much of my time on this on this repo here uh it came out in March of last year and it just became really super popular so you see it's got 5,000 Stars so it's actually the most popular aure sample in our aure samples repo so it's been deployed thousands of times so we've got lots of feedback from it we we're continually you know improving it you can check our releases to see you know the sort of things were changing um and it's all based off of feedback from you know a your developers as your customers so it's been a really great way to learn about how to make a rag chat application and see all the different ways people are trying to use rag chat apps and it is I would say the most flexible of all the options because uh you know it's it's open source and if something isn't working for you generally you can go in there and mess with it uh it is very much a high code situation like the the code is not necessarily simple we try to do that but it's not always going to work uh to make something simple but um you know it's very flexible and and that's can be the advantage of it so it currently it's geared for documents and for the search engine it's only as your AI search so that is certainly you know a limitation if you were trying to use like elastic search right um but generally aure AI search is the best way to search documents uh if you're you know using aure services and that's why uh we use aure AI search for the LM you can switch whatever you want uh so you can you know have these multi-turn chats you know whole conversations we've got user authentication buil in we've got Access Control built in so if you wanted some users to have access to different files than other users that you could do with this uh you can even use gbd4 with vision we have that as an experimental feature that you can turn on if you're interested in trying that out so a lot of the stuff are features that you can kind of turn on if you want to see if they you know if they work for you okay so now I'm going to dive into that solution so in order to deploy this you need an as your account and subscription uh you can use free account but it has an awful lot of limitations so usually better if not using a free account uh you do need access to as your openai or an open.com account you could use either of them you could even use olama if you really wanted I sometimes I do that just to see how the local models do but they don't do very well so I would recommend gbd3 5 or gbd4 uh you do need as your account permissions to be able to create the rback roles uh and to make the deployment so those are you know prerequisites to deploying uh and then to open the project you can use GitHub code spaces you can use VSS code with Dev containers we like to set up everything with a Dev container so that it's all all the requirements are set up for you or you can go ahead and set up a local environment if you enjoy doing that I do not and then you can deploy using the Azure developer CLI I don't know if you all have talked about the addd CLI before but it is by far my favorite way to deploy things to Azure uh basically what we do is we Define the infrastructure using bicep which is infrastructure as code files like terraform so we Define all the infrastructure in bicep that's just in the repo and that you know declares everything that needs to be provisioned and how they relate to each other and environment variables and all that stuff and then we just have to run you know ACD up in order to get everything provisioned and everything deployed uh in you know onto the platform of choice once it gets deployed what you end up with is is a bunch of azure services so for"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:55:43",
        "seconds": 3343,
        "text": "and then we just have to run you know ACD up in order to get everything provisioned and everything deployed uh in you know onto the platform of choice once it gets deployed what you end up with is is a bunch of azure services so for like the chat application itself that's on aure app service and it uses a your blob storage in order to render the documents and the citations uh it uses AZ your open AI for the embeddings and the large language model calls and it uses a your AI search for the searching we also do data ingestion in this repo and that one also uses all those Services as well as a your document intelligence so there's two ways that we do data ingestion so this is another opportunity we're going to talk more about data ingestion so if there's any additional questions uh I think from like George um this is a good opportunity to to ask them one question for data ingestion so if it's a document and it's unstructured I mean it's just text in a document so if you want to feed it text from your database I guess why would it need to have specific like vector indexing or anything special like that if you want to just you know all the fields of this one table you know are all the same type of text Data no different than you'd scrape it from like a document um so so you're wondering about scraping from a database yeah as data source yeah if you're using a database as a data source you do not need any of this right so I I probably still have my let me find my um here we go okay so if we were going to do you know um this this is like the code for my postgress hybrid search it's not perfect yet but but here I'm just doing uh you know so I just have like you know you you just need to have a database that has um you know you've got your columns here and then you've got an embedding and you have to decide whether that embedding is going to be the embedding of just like a single You Know Field like just the description or you could concatenate all these together and make it embedding based off that so that's probably what I would do is concatenate uh you know all like the text Fields together the things that kind of have semantic things in them concatenate in one thing generate the embedding based off that store that as an embedding column so you can see here like this is my schema um right so I've got all like my standard columns and then I've got a vector column for the embedding and then when I do the search I need to do the vector search with that column and then the keyword search uh right now I'm only searching one column but probably I should do that across multiple columns right and then I need to you know merge those results uh but yeah if you're working off a database you don't have to have all this fancy data ingestion you just really need to have uh you know ideally have an embedding column you could even just use I mean you can also just do it you could do just a full Tech search I I think you're you would be happier if you also had a vector search sech and a hybrid search on top um but you just need some way of searching your database based off a user query yeah that makes more sense okay thank you yep yeah great question all right so yeah so data ingestion this is really relevant to documents right imagine multi-page documents your HR documents that sort of thing right so we get the documents first thing we do is uh you know upload to blob storage actually that's even the last thing we do um uh so we get them to blob at some point just so we can and that's just so that when we have the actual app where we can um click on let me see so I'm going to click on I'm G to click on a bunch of citations and see which of them loads first because sometimes these PDFs can be a little low to SL to load okay there you see so it loaded the um this you know this PDF PDF here uh this one was this one is a rag based off my personal blog which is fun for me and so here you can see it actually loaded the HTML right uh so we you know we need these things stored somewhere so that we can uh you know show the citation so this is coming from blob storage and it's actually checking our um user authentication when it grabs it oh that one's going to be slow so we put them in Blob storage just so we can render citations um the next thing uh is that you know we have the documents and we need to extract data from them so uh we typically use aard document because it supports a ton of formats these days including docx and PowerPoint which was really huge for people when they added that earlier uh you know I think in the fall so it supports lots of documents even supports images it does OCR so it really tries to get as much text as it can get out of a document we do also have local parsers that we make available just because they can be cheaper or more customizable like for my blog I actually just use the local parser for HTML because I then I can just do some custom parsing for"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:00:47",
        "seconds": 3647,
        "text": "document we do also have local parsers that we make available just because they can be cheaper or more customizable like for my blog I actually just use the local parser for HTML because I then I can just do some custom parsing for HTML uh and uh leave off the parts of my blog I don't want like the comments uh but generally the you know approach is to use as your document intelligence because it's very good at document extraction now we have the text extracted for the whole document but we still need it in chunks because we can't send like a 10-page document to an llm or at least we shouldn't because it's going to get lost right it's going to be too noisy for it so then we split the data into chunks uh so we have all this you know python code that looks for sentence boundaries and also tries to you know split things appropriately so that they're a good um you know a good size to send to an llm uh there's lots of other splitting libraries out there like in Lang chain that you could use as well then once we have the chunks for each of the chunks we compute an embedding of that chunk and then finally we put them in as your AI search uh and I can show you once again the results right so this is actually just straight from a your AI search uh so this is what the index looks like so we can see the content and we can see the embedding we've got like an ID uh we've got scores that come back from the search that's only relevant you know that we don't store that that depends on the query uh we've got what page it came from and we also have access control related information if we're using access control like uh the user ID and user groups so this is a local script uh so this is actually like just in the repo um if you know if I wanted to ingest something right so I'll go ahead and run it just to show you also Jason you can remind me if I'm like going way too long there's lots of good questions I no you're fine okay let's see all right I'm just going to see if I can ingest something just to show you okay I'll go here and let's see what environment I'm in right now okay it's a good one okay let's see if my ingestion script is working at the moment I'm always doing so much hacking on this repo that you never quite know what state it's in but on my machine it's good on Main okay so just running the the script here and it's just setting up well first it has to set up the environment to bring in all the you know the AZ your document intelligence SDK and all the other things we use for for the extraction ingestion any questions as it's running so I have quick question in terms of the cost wise right you know like you were saying earlier when when we use the fine-tuning it's definitely more expensive because there are tokens involved and lot in the same thing would it be more expensive when we use Rack or is there a way we can reduce the cost using any kind of caching in it yeah that's good question um I don't think you could use caching of user questions because I think your user questions would be so um so different i' I'd be impressed users were were actually asking the same thing uh generally like ways to reduce cost well I'll say this what are the expensive things uh you know there's app service but app service actually isn't too expensive it can it can handle a fair bit um without getting too expensive as your AI search does cost uh a bit especially if you're going to have if you need multiple replicas for the amount of traffic you think you're going to get and especially if you use the semantic ranker which is the ranker which is actually you know the best thing to do is to use the ranker but both of those are the things that make it the most expenses if you increase the replicas and you do uh keep the semantic ranker enabled so if you want to decrease aure AI search cost you disable the semantic ranker and you keep it one replica if that works for your traffic levels uh the your other approach with Azure I search is you know to replace it with a you know with a you know a database search engine um you know like the post one I was showing but then you do have to reimplement everything that as your AI search comes built in and they are putting a lot of effort into rag because rag is such a use big use case for them right now uh but you know that's just a decision to make and the other big thing that costs well as your document intelligence does cost money and and uh it can it's a that can be a decent amount if you have a ton of documents so if you're trying to reduce cost there you can use a local parser and see if the quality is good enough it depends on your kind of document um I don't think it's"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:05:49",
        "seconds": 3949,
        "text": "decent amount if you have a ton of documents so if you're trying to reduce cost there you can use a local parser and see if the quality is good enough it depends on your kind of document um I don't think it's that the local ones that great for PDF but if you're doing HTML you could do a pretty good job parsing that H and then finally as your open AI cost money uh you that one you can't really reduce the cost except for just making sure you're not sending too much data right so it it's per token so the less you send the better right so if I do three search results that's generally going to be cheaper for me than doing uh you know five search results got it thank you and then velle asked uh does this service need GPU or CPU no this one doesn't because we're using azer open AI as like an API that we're hitting up uh so that's you know that's serve somewhere that has GPU nothing that we're doing requires a uh GPU we would need a GPO if we were running our own model uh but we're not running our own model for any of this all right so here you can see um that it did decide yeah it skipped a bunch of things because we'd already ined them then it decided to ingest this PDF so first it extracts the text then it splits it into sections then it uploaded the file and then it computed the embeding and then it stored it so that's just what the local script uh looks like now the other option we have is integrated vectorization this is something that's now built into as your AI search which is basically just doing everything we just saw but in the cloud hosted you know with uh you know geared for large you know large scale uses uh and it has a little it supports a little bit more um data sources right because as your AI search can be you can make indexers so it's basically making indexers and skill sets and tying them all together so you can have your indexer based off like blob storage or Cosmos Tob or whatever and as your AI search will you can run like a Cron job and basically like every five minutes it would check to see oh is there something new in Blob storage and then reindex it and only index the the things that have changed so if you use integrative vectorization you can take advantage of the indexer which can work well if you want to be able to like you know have it pulling off of some data source dynamically and only indexing the new stuff in that data source then it'll do the it'll do the data extraction and there I think it's just I think it is using document intelligence behind the scenes it'll do the chunking using a similar splitting algorithm it'll use the vectorization using your open AI deployment and then it'll index it but the big Advantage here is that you know it's doing it all it's doing it all the in the cloud and you can connect it to the indexers so that is an option to consider if you're using as your AI search uh and it's an option you can turn on in the repo that I've been showing okay so how does this code actually work okay so let's do a little code walk through just to see all right I'm actually going to go to the chat tab now because this one's more fun uh does all right so let's see actually let me go ahead and um and point put a breakpoint in let's see all right let's see can I do run okay all right I well I don't know if you're gonna want watch me do breako to can be a little slow all right I'll just I'll just put one breakpoint and then display so this is in vs code with the uh the python debugger uh I like to use the debugger when I can because I am very often debugging things so it'll it'll start up but basically what we have is a uh a front end that's in react so we have like you know this chat you know chat react stuff here and when we you know type in a question it's going to make a request to the chat API right so the SL chat and that goes to our you know python routes right so we look for Flash chat here where is it chat chat oh that went that went to the wrong place okay app.py many app.py okay okay so the frontend makes this request to the chat sends a post with the user message and the history and then sends that to our other Python and sometimes it streams it if we ask it to stream otherwise it'll just send it back all right so we should be running now so it say uh do company perks hover underwater activities it should let's see my chat retrieve yeah it should pop open the um I think it should pop open in the debugger are there libraries so you can do this from a c project yeah uh so if you want"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:11:00",
        "seconds": 4260,
        "text": "activities it should let's see my chat retrieve yeah it should pop open the um I think it should pop open in the debugger are there libraries so you can do this from a c project yeah uh so if you want this C equivalent of this product it is this repo here so uh the other Advocates have been trying to Port the python repo into other languages you know because the python repo is so popular uh the other ones aren't as popular yet but you can make them Popular by going into them I think Jason haven't you been I feel like Jason or maybe Jason's been on the JavaScript one I saw Jason committing to one of them yeah I I committed to the JavaScript I'll put the links and so I've reviewed the different ones on my blog site I'll put the links in the chat for people okay thanks Jason okay wait it's it's being too slow so anyway so I'll just show the the thought process okay so right so you know we go into the python H and now I just wanted to show the chat tab because it's a little it's actually more complex and I think it's interesting the way and it's more complex so this is thought process for the for the chat tab so what we see is the original user query and we actually used an llm in order to turn that search query into a good keyword query and now this might seem a little silly because all we did here is just remove the question mark But in other cases it actually makes really helpful um modifications especially based off of the history that gets passed in so that you so we get the generated query and then we use that to search and then we get back the results so uh let me good an example like so then I'm going to do a followup question like more I'm just GNA more that's all I'm going to say is more let's see how it does with the um search query generation here my hope is that it takes more and turns it into a a longer a longer query okay I think it did let's see okay I'm going to click on thought process okay great so the original user query was more the generated search query was sleep strategy so this is where it's really helpful to use this llm to turn the user query into a keyword search because if we had just passed more into our search engine what would we have gotten right we would have not gotten good results at all uh so we you know we ask it like hey turn this into a search query based off of the you know convers a history so the llm realizes like oh okay a good search query would actually be sleep strategy so it's actually going to just redo the Sleep strategy from before and then it's asking the llm down here it with the llm it's saying it tells it the question where it just says more right so the llm can see like oh you wanted more sleep strategies in addition to the ones before so when you are doing you know what we call like multi-turn conversations you know conversations whatever you want to call them when you have chat history you need to keep in mind that users are going to ask follow-up questions that are not going to be as well formed as their original question and you can use the llm in order to turn their followup question into a much better keyword query for your search index okay all right so I wanted to show that so you know there's the general architecture of the code and uh now our code is using you know python for the back end and it's just using the open AI SDK with the Azure you know document search SDK it's not using any fancy llm orchestration libraries and people always ask like why aren't you using Lang chain why aren't you using this why aren't you using that well part of the reason I'm not using any of those is because everybody has a different favorite library for Python and I'd have to pick one of them and I and then that would like alienate other people right so there are many popular rag orchestration libraries and you could totally use those as well you know whichever one works for you uh so the most popular ones in the open source world are Lang chain and llama index and both of them are available in multiple languages and then from Microsoft we've got Mantic kernel which is probably the most similar to linkchain and which is that's in Python and oh I should have said net that's really what it is is net we we'll fix that python and.net I don't think it's in typescript um I obviously haven't used it very much at all and then there's also Microsoft prompt flow and that's built into a your AI studio so it works really well if you're using as your AI studio and doing other machine learning model stuff so you can totally use these libraries uh you know I tend to not use any libraries because"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:16:02",
        "seconds": 4562,
        "text": "prompt flow and that's built into a your AI studio so it works really well if you're using as your AI studio and doing other machine learning model stuff so you can totally use these libraries uh you know I tend to not use any libraries because I like to work really you know really close to the metal H because things are changing all the time and I want to be able to take advantage of everything uh but these libraries do have a lot of advantages as well because they have like documented you know ways of doing things right so llama index for example it actually has a way of indexing into postgress and doing a hybrid search uh just already built in there so they've already got that that built in so definitely if you're you know looking to do search on documents and you're looking to do it with you know you know various um you know search backends check out llama index they have all these different retrievers all these different document pars there's lots and lots of options we also have more starter repository so we just talked about actually a bunch of them so the you know this python one we're trying to Port it into other languages they're they're never going to be exactly the same and generally the python one tends to have more more features or at least more experimental features because we're just working on it so much because it's so so popular but you know we're you know the get more more eyes and more developers uh interested in these then we can you know the teams can spend more and more time on them which would be great because we would like to have full featured rag applications for all languages so if your favorite thing is C definitely check out the C repo it's actually been around for quite a while um it it came out at a similar time as the python one so it's it's got a good number of features and then there's JavaScript that team is great and there's the Java one so those are definitely options for you and if you're seeing something missing in there in there those repos that you want just file an issue and let them know uh there's also uh the one that I showed earlier which is the code that powers as your AI Studio on your data uh so you can check out the code for that uh another one is chat co-pilot and this is a demonstration of semantic colel but it is actually really really cool it has collaborative chat which I think is just really fun um so just putting there especially for those of you who are doing net which is probably quite a bit I see a question will the demonstrated code still work with a free account even in some limited way what are the limitations yeah so that's all documented on let me see H yeah this AA I'll just place this okay yeah so I did try to figure out how to get it working on free and so you can get it on free and I talk about all the limitations here although I will say there is no form of free open aai you're going to have to pay for that somewhere whether that's on open.com you could even you can actually swap out AMA I I do have support for that in the repo I think I talked about that here yeah you can't locally you could use an opening eye compatible model good question all right okay so it is now 4:30 is this the time I meant to be over Jason sorry looking for the mute button um it is but uh if you can go ahead and go through this and I don't know say 15 minutes sure yeah so I won't do like the demo like demo stuff I'll just talk about this so okay so let's see you make a rag chat application and you want to know is it good right is it high quality right you can't just write unit test I mean you should write unit test for the features but you can't just write a a you know test to say yeah it's good to go you need to evaluate the answer quality right so you want to know are these rag answers correct relative to my knowledge base right uh are they clear and understandable usually uh and are they formatted in the desired manner so if you ask for citations in square brackets with file extensions that is exactly how the citation should come through right so that's the stuff we're looking for in our rag chat app answers right so here I have three different answers that came for the same question my favorite one is the bottom one because it answered the question correctly and it has the citation in the right format and that's what I'm looking for lots and lots of things affect the quality and that's what can make it kind of hard to you know to figure out how to improve uh improve quality right so the first thing is the search right we talked about search is really really important right so what search engine are you using are you cleaning up your query like what are your actual queries come in that they look look like are you using hybrid search um any other search options you're using how big is your data like how large are your chunks uh you know are do they overlap with each other how many search results are you returning these are all things that can affect the results and then finally we you know we pass things into the large language model so there the system prompt can affect things especially like whether"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:21:05",
        "seconds": 4865,
        "text": "you know are do they overlap with each other how many search results are you returning these are all things that can affect the results and then finally we you know we pass things into the large language model so there the system prompt can affect things especially like whether it uses citations or not uh the language of the prompt if you're doing something not in English you should actually write your prompt in that Lang Ang instead if you wanted to Output in that language uh how much conversation history you're passing in which model you're using has a huge effect generally qd4 is much it's like really it's just really good at things so um you know model definitely has effect I use gbd 35 a lot but I've definitely seen places where gbd4 was just nicer better more adherent to the instructions I'll say temperature can affect things all these parameters right so you know what do you do like first thing you do is just do manual experimentation right so in our you know in this repo um we can experiment using developer settings so we can you know override the system prompt here we can change the temperature we can change our search results we can do all these other you know changes to the search results and so we could just do manual experimentation just to get a feel for what changes when we change these settings so that's a good thing just to get some more intuition for how things are working but then what you really want to do is to do an automated evaluation once you think you've found settings that work well right if you if your manual tests are working well and you're like okay I think this is working well then you want to do an automated evaluation on a lot of um question answer periods to figure out is it really working well right across lots of questions and answers so the first thing you're going to need is ground truuth data that ground truth Theta is the ideal answer for a particular question so you generally want at least 200 ground truth question answer pairs uh you can use an llm to generate these question answer pairs but you should definitely curate them manually go through them make sure they're actually legit and um you know and grounded uh I have this script here okay so I have this repo AI rag chat evaluator let me uh P put this in the chat which everyone it'll let me click on there we go so this repo has a bunch of tools that I've made to make it easier to evaluate a rag chat app so one of them is a tool that generates ground truth data and it uses this as your AI uh evaluate SDK so this will generate data based off an Azure AI search index uh you could change it if you have a database instead you could just modify it uh and so you could you know generate that data look through it curate it uh if you've got your rag chat live you could add like thumbs up and thumbs down buttons to you know actual answers to find out which answers aren't working well for people and then you should add those questions with their correct answer to your ground truth data to make sure that you're evaluating according to the kind of questions and answers that users are getting now once you've got that ground truth data the next step is to evaluate right so the way we're actually going to do evaluation is hit up our you know our our current version of the app uh whether that's local or deployed or whatever but hit up the version we want to test with the question from the ground to Theta get the the you know the new answer and then we send you know the the new question you know the the current um answer for that question along with the ground truth answer for that question and we actually send that to gb4 and we ask gp4 to rate it and we say hey gbd4 from one to five how grounded was this answer from 1 to five how coherent was the answer from 1 to five how relevant is this answer and our prompt is a lot longer than that but the general idea is that we use GPT in order to evaluate GPT which is a funny thing to do but it actually does work quite well and there's a lot of research around it uh we can also do other calculate other metrics as well like look at how long it was look at whether it had citations look at whether the citation in the new answer match the citation in the ground truth answer that's actually my favorite metric and that we can just do you know with our python so then after we run those evaluations we can compare them so you can see here's a bunch of comparisons I was doing doing where I was playing around with different prompts uh there's lots of things you can change but in this case I was changing prompts and so I was looking at you know what was the groundedness and coherence and then you know which of them had citations because that's really important to me so I can look across the runs to get an idea for how well things are working and uh it can also compare answers between runs and say like okay well what was the answer like for this run versus this other run to try and get a feel for how things changed and yeah I'm going very fast through this part so as Jason said I do have a um a whole video about evaluating chat app and he linked to it there so thank you Jason okay so that's evaluation I definitely recommend doing it because you want to make sure you're putting out a you know a quality application that isn't making stuff up uh and the the uh you asked about hallucinations earlier I"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:26:05",
        "seconds": 5165,
        "text": "you Jason okay so that's evaluation I definitely recommend doing it because you want to make sure you're putting out a you know a quality application that isn't making stuff up uh and the the uh you asked about hallucinations earlier I have a recent I think my most recent blog post is actually about it yeah so I added a metric specifically well this isn't quite hallucinations this is just making sure the app says it doesn't know if something's just completely off topic for it that it shouldn't know so it's slightly different from huc naations and something it should know but this is also something that's really interesting that I've been digging into lately okay and just a few slides about observability for rag chat apps especially on azzer so the first thing you might want to do is integrate with Az your monitor because that's our standard way of you know uh tracing our apps on azir so you can use instrumentation libraries to send uh the open AI traces to application insights so this is how we do it in Python using this Library here and then when we look in Azure monitor we can you know see the nice little water flow and then click on the chat request and we can see like okay you know here's the parameters here's the actual prompt here's the question so we can actually see all that in as your monitor uh it's not perfect and we're trying to make some improvements to it but it's pretty good another thing you could use is an open source tool called Lane fuse and I really like it it is a um a you know it's a tool specifically for open Ai observability and it's also got evaluations and stuff and it's just a really nice UI uh so you know you have to um you know you can deploy that UI to to aser and I have a repo here where you can do that and then you just uh you know bring in their tracing like this and then you get this really really cool UI that's very focused on open AI uh usage so it's very helpful to see all your calls and see all the tokens they use and see how slow your gbd3 calls are versus your gbd4 and all that stuff and okay this is my final slide so uh yeah so if you're interested in this you can try creating a rag app uh you know and I pointed to the free instructions here so so that you're not spending money doing that and you can read about the limitations air you can try out the evaluation tools as well uh anytime you try these please do raise any issues I do see everything that comes in I can't always respond the the day that I see them but I try to respond to everything so that we can make things better and generally I recommend sharing your learning so like Jason has all these blog posts where he reviewed stuff like so if any of you blog or tweet or whatever please share what you learn about building a rag app because I think still early days for this and we still all have a lot to learn in terms of best practices and that's what I have awesome that was awesome any uh any other questions out there I think you got it all that was great that was uh that was uh really good I I've really gotten into the r stuff so the more that I uh see people present it who really know this stuff is it's just fantastic to be there so I think this was probably the most interactive session we've had in a very long time yeah you all had great great questions I love getting the questions because usually there's something afterwards where I'm like oh I really got to figure out a good answer to that question and then it gives me an excuse to dig into something I don't think they asked too many things you didn't have an answer to I have to try harder next time no I gota like export the chat awesome well I I think that's it Bill's going toh do a Hands-On thing after um so yeah all right well thank you everyone thanks yeah thanks pam pam thank you Pamela that was fantastic so quick question great can we get the recording of this session is it possible to share the recording yeah um it will be on our Boston Azure YouTube channel it's youtube.com Boston Azure isn't that right bill I think it's the full boss word yeah and um it'll probably be up there late tonight or B tomorrow morning sometime okay so so from meet up I should be able to access that right and no well we I believe we do have a link to the YouTube channel in the Meetup description so you should be able to find it yeah okay thank you cool all right okay bye everyone have a good night thank you thank you Bill are you gonna take over can you yeah I just I flipped on um sharing and it's I got to go set"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:31:10",
        "seconds": 5470,
        "text": "right okay bye everyone have a good night thank you thank you Bill are you gonna take over can you yeah I just I flipped on um sharing and it's I got to go set a permissions sorry folks give me a second let's see I have here um so let me share my screen why bills getting his duck R here so this is where we're at okay cool Phil's there Bill's got it cool um yeah so you can get the recording at uh youtube.com Boston Azure that'll have pelis stuff and um I'm going to transition um I can only share my um my web browser without having to configure something my apologies so I have a couple of slides I was going to share I'm going to speak to those um what I'm going to show here is a um we I'm I'm going to ask you to create a simple python app or a simple uh C app um per you know instructions I um I basically think you know how to do that that and I'm going to ask you to basically do that and then I have some code to uh to slam in to make it easier the goal of the workshop this mini Workshop is to see um if you've been doing this for a while the this might not be for you but if you're new to this and you you don't really know what the code looks like um my hope is that at the end of this you'll have the aha moment of wow I can do this in about 10 lines of meaningful code not everything Pamela did but you can actually create a program that can do something using the llm that a programmer just before this whole llm thing came on it was impossible to do no programmer was able to do this in you know before this this is a remarkable um change in just the way uh the way the the tools that we have access to as um as developers so I am sharing let's see I'm sharing in the chat two links um this is um okay so I just shared two links um I was also going to go through and show you how to do this that's going to be a little trickier now because like I'm having trouble sharing Beyond just my web browser uh but here's the the idea if you're a a python developer um go follow the python link you know which is which brings you here and if you're a net developer cop developer follow that one and there are directions at the top of each file basically create a folder and then um do do a couple of steps that are normal things to do if you're a python or. net developer and then replace or create the the file if it's cop you're going to replace program.cs with um with this file tells you to do that here um and if you're a python developer you're just going to create a file called hello ai. py and you know do the stuff mentioned here so these two links are in the teams chat um and after you do these few steps up here there's a there's a challenge that um um that you know once you have it running I'll I'll I'll speak to that so I I hope this only takes you know five minutes for folks or maybe 10 minutes for folks to to get running but if you have questions come off you know go on audio or uh post up in the um in the chat bill you want me to share anything and you can talk to it I had it all set up on my um uh it a command lines I you know I have windows open that um maybe in the metime I can I can see if I can even extend my permissions um I so no it'll be hard to give you something to to share Jason unless you wanted to follow along the lab and do that live okay I mean I can do that too meantime I'm going to go see if I can"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:36:14",
        "seconds": 5774,
        "text": "too meantime I'm going to go see if I can enhance my permissions here [Music] m I share mine until you get yours going Bill see this guy so let me take this here so got empty folder do this gu e all right clob or the content just copy and paste the code all right so here paste this guy save okay done it run okay that worked perfectly oh an interesting fact that fast cool if you um so I'll wait I'll wait till to proceed um I'll I'll talk a little more once everybody has this at least running I can do it so I try to put this code in the collab andun trying to run it think I'm just having some issues like configure environment for python no module name no open some those kind of er maybe I need to do few things before so you did the python one yeah I did the Google cab and did the python Google collab I'm not sure what that is yeah collab is the environment where you can run the python Cod um yeah I've heard of it I've never used it okay so let's try the python one where's the link that python [Music] say mac thing um or Linux you know uh thing my mistake you want to run activate um so it's probably just B activate on window po I can"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:41:27",
        "seconds": 6087,
        "text": "say mac thing um or Linux you know uh thing my mistake you want to run activate um so it's probably just B activate on window po I can do it in code if I don't have any luck let me look that one up that's I'm kind of handicapped when it comes to python so yeah this is the let me start over with this close CD MK oh it's activate do PS1 I think but it's do it well actually you you figured out um or or if you're onto something yeah I'm just going to do this so if I go here yeah I do dude trying to type sometimes challenge over okay so now close this welcome window so we'll take this what do you want this to be hello AI well you um there's more to the file than that unfortunately is there okay it's it's above the comments too so I would just do a control a and take the whole thing in all copy paste all right see what we got here so here we have this deployment okay so that's that so now we basically I think I already have these you might not need to do anything except just run it yeah actually it's true um let me just try to run it I could have done a notebook there a there we go different one um and this a uh yes George contributed a scripts activate command which maybe is the one that you need for po shell I probably should have opened the mic let you guys struggle through that but yeah just oh good I thought it was quick on the chat I was like oh well I know C SHP guys anyway so yeah me too try python I can fumble around and get most things working but slowly getting there okay so anybody um anybody have this working besides Jason either one and you hit the uh you keep score if you want to check the I put put a comment in there you could respond to you could click the check box no obligation but trying to have some way to track how people are doing all you got three of them now what do they look like next to each other python anybody have any struggles they want to vocalize who's got it you know my my struggle with these is always the cost right whenever you do any of these cloud computing especially these services like this I'm always very leery I mean I actually I'm working on a project right now where it's all local so our local CPU and GPU I got a local llama 2 model that I'm using um you know the stuff with an Azure is really awesome but do you have any indication or you know setting up like workflows like this the cost involved I mean I well th this one is um uh actually actually that's a good question I don't have a readymade answer for that uh my perception is this is not expensive um but um but if you add uh like the Azure AI search um you know the the it goes up to minimum of some number $100 a month okay uh you add a vector database you know the same thing this is using um if I could show my da uh Graphics here I made a beauti I had uh uh do 3 make me a nice uh uh visual um but um you know this is using the the tip of the tip of the iceberg and um this this just you're not using the the heavyweight uh tools yet not using"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:46:30",
        "seconds": 6390,
        "text": "but um you know this is using the the tip of the tip of the iceberg and um this this just you're not using the the heavyweight uh tools yet not using um um you know the the responsible AI um uh services to you know make sure your your data is safe the the the safety uh service and so forth yeah you're you're in the the cheap Zone here there are different approaches how you can minimize the cost obviously you can drive it to zero especially as you mentioned when you work with Cloud technologes um but you know you're using llama deployed on um your local machine you can deploy the servers so you you kind of escaping that cloud approach Al together so making it a little cheaper and then caching so you can cach the responses so you are not calling the service all the time if you are using something like Azure open AI um or maybe store most popular answers somewhere in um like a a database or something like that that's interesting I never thought about caching the responses that come back yeah so that's that's one uh that it depends what you're building right um so that that's one of the approaches how you can minimize the cost um and then you know something like rag you don't have in in some cases you don't have to call um Azure open AR or something like that at all so if you're um doing the search and then you're getting decent response from the search then you can escape that second and stop of calling them um llm or ji service alog together that's interesting I never thought you got me thinking about maybe cashing the common responses okay thank you no problem so I'm going to grab so does anybody have any struggles any struggles out there who's still here is is doing good so I'm going to grab the screen back and walk through a couple things here so um do you saw the output so I I assume I assume you can see your output and it basically shows um a prompt that appears I'm I'm let me zoom in on this code here that the code is essentially the same between Python and uh C so um this is the prompt that you're that is being sent to the um under the hood the open AI uh llm large language model and and this is the part that's you know magic it's producing a response that is uh unique text uh that you know a response that the kind of a response that was impossible before this um LM Revolution uh started year and a half ago that's like just amazing and if and um one of the things that I claim is if you look at the response there's something wrong wrong about it and I didn't want to spoil it give folks a chance to look at the response but when you look at the the response um um there's there's a lack of um grounding or or the opposite the other side of the grounding coin is uh hallucination of sorts happening in the response so um I'm suggesting that um a hint to help you U solve for that don't want to take a huge amount of time here but that that's that's the point and um this response setting the number of tokens we can talk about these um April 20th setting a prompt um scrolling up here creating this Azure open AI uh you know object and the rest of this is kind of boiler plate stuff um this is like 10 lines of code that that you're now able to do something that no software engineer could do for the first 75 years of the computer industry let's go back here how we doing um it ah so yay somebody declared a"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:51:33",
        "seconds": 6693,
        "text": "the first 75 years of the computer industry let's go back here how we doing um it ah so yay somebody declared a date buug and they fixed it good two people a couple people fix a date buug so um the the date buug if you haven't figured it out by now is actually Jason would you mind sharing again and showing um showing your uh your output sure just SEC let's see share this one the C output was here do you want to see the code or the output the output okay so H this was the python code either one is the output is down here and then up here is the um other one up at the top thank you so if folks look at that you're seeing similar stuff you know what today's date is because it's output as a debug message um and the prompt asks for something from some world history event from today's date and and it gives you one except with great confidence uh on March 18th 18 uh 1965 uh Soviets walked in space um but uh that great confidence is uh untethered from reality because that didn't happen on this day in history it happened on a different day and that's uh that's your llm hallucinating returning a confident result when it has no business doing that and the way to ground it is to do um basically rag this is this is exactly what Pamela was talking about except that with the rag um here it's a much simpler rag where the augmentation is simply the date so you don't have to make a network call to get the the uh the current current date you can just make you know call a a python library or a cop library to uh to get that then weave it into the prompt uh I'll leave that to your imagination how to do that you know on this day in history you know assuming this day is you know X or something like that would do fine which is date whatever you know choose your style and see if you get uh consistent results and if you do then that's that's the win and um and and that was the the goal is to uh to give you the the hands-on experience hopefully a couple of a house quiet group thank you Tony see I go here and if you've accomplished the the goal here and you want to try something different you can instead of just uh prompt engineering or or ragging to to get the date inserted in the in the prompt itself so that the respones um more accurate better grounded uh you can also say something like uh and return the results in French or translate the results to German uh you know append that to your prompt and see if that works I I tested it earlier with mandarin and it was"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:56:38",
        "seconds": 6998,
        "text": "German uh you know append that to your prompt and see if that works I I tested it earlier with mandarin and it was happy to do that and it also worked with pig latin um Mandarin didn't display on my my son was doing some testing on me um uh and um he realized that Mandarin didn't display well in some contexts on his windows box mine is I I'm using a Mac didn't have any trouble for me so your mileage if it's a different alphabet uh your mileage May VAR my response looks gibberish how many uh oh you didn't um no you got 250 tokens used all the tokens it ran out tokens I changed the temperature to two I thought the temperature only went up to one I goes two those people between one Veronica help what's going on yeah temperature can be more than one that one's a little better Al the the one above used all 250 tokens this one only used 50 so it hit some cognitive limit there when it ran out of tokens maybe I thought temperature was a was like a zero to one real number I guess you can scale it if way I know I've seen it from negatives to positives and stuff too but one concept going into junk at 1.7 how about 1.6 1.5 was good it's the top P that's you would want that's also gibberish starts off good it's getting tired it's passes bedtime so um SAR how to fix the date so the the the challenge is that um oops somebody um weighed in Tony so um Yep this this looks like a python solution I don't know which one you're using sadar yes I'm using B okay so T Tony's solution how to do it basically you just want to uh Wordsmith the prompt to also in normal English uh declare what today's date is and that becomes part of the information that the llm uses and again that's a very simple form of rag I see I see Conor so the initial one you're not actually passing what today is on purpose that's the bug that's the the challenge the the my My Hope was people would notice the you know discover for themselves that there's a hallucination there that you ask for today to something today and it gives you something you know in September and then something in June and you know and so forth because it has no concept of the day that's a hallucination then you ground it using rag you know rag light I guess simple Rag by just inserting the date like that let's up with that Jason you you were playing with the uh the temperature can you explain to the to the room what what that um what that means yeah so the temperature is what you see most demos change was it I just passed it fine temperature okay so I guess this is the top pie"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "02:01:42",
        "seconds": 7302,
        "text": "you see most demos change was it I just passed it fine temperature okay so I guess this is the top pie H interesting um the temp here so this is a temperature it's a float it's between zero and two but it typically uh is explained as in it is a spectrum of creativity that you want in the response so a lot of rag Solutions are geared to zero because that you don't want creativity but if you're say doing um writing of some sort say fiction writing you would want to get gaug it closer to two the defaults one right middle of the road a lot of the rag systems will be zero or up to maybe3 but not much more than that that I've seen anyways not saying they all are so this is the one I want nuc nucleus sampling factor is a different one and yeah so here if it's set then temperature is kind of um ignored it's going to be one of the other but this one is geared more toward the sampling here and it's between 0 and one sorry what was the question where's it at on the bottom down here yeah so for co-pilot or chat the creative balanced precise is that basically the temperature yeah sense and then the co-pilot in like word and Outlook have the same idea don't they I don't have those running so I've only seen demos yeah I don't have those either but they should they they're all based on um the same approach um if Pam was sh in both top PE and then the temperature um most people just use temperature um but if you want it extra creative you can adjust both top p and um the temperature cool yeah you kind of just have to play with it see what works for [Music] you I'll mention that in the code um there's a comment up the the top uh that says um do not do this in real code it's a terrible idea uh because I in order to simplify this mini Workshop rather than externalizing the the the variables like the API key value um I burned them in so I'm going to roll those I'm going to roll that key at some point after after we hang up so your your onepage uh AI machine will will uh cease to work at that point good idea actually prepared um a a a bash version a Powershell version a command version and I struggled with it and I ended up I still have them but I ended up uh doing this just to just to simplify and uh I I don't know how much it simplified it but probably at least a little well does anybody um um than thank you"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "02:06:47",
        "seconds": 7607,
        "text": "up uh doing this just to just to simplify and uh I I don't know how much it simplified it but probably at least a little well does anybody um um than thank you all for for attending I hope this was uh useful for those of you newer to the to the uh Azure AI world uh does anybody have any uh closing questions yeah this is great thank you and H how many tokens does the open asure support like um I know normally they would charge right but in this case um is it is it free for to use a or how how long we can use this if I keep running it well I'm going to roll the credentials after this uh call ends so we'll stop working I I I see you know five minutes uh it actually isn't free uh but it's not terribly expensive this is tied to my personal credit card okay but it's it's not like it's not a lot of money to do what we did that's if you look in the comments you'll see I put a comment to not raise the max tokens above 250 so you could go you know everybody could go crazy and try to do a lot of stuff um but you know this felt like a this is experimental for for myself and uh roner and Jason and because we have to also figure out how to do what we going to whatever we're going to do on the Azure um day you know the full day event on April 20th how do we light up this for everybody because it's not an easily available service so um I'll check the the numbers later and see if this cost me more than a dollar I I don't expect it it will though I'd expect it to be pennies if anything so I hope that's that's the best answer I have at the moment oh thank you I really appreciate that I I did run it some sometimes so didn't realize that's the case sorry about that sorry I I think the volumes were at um and it's kind of in 10 people left or something Veronica or Jason do either of you have any ideas how to like what this exercise that we did for this um mini Workshop um given parameters that we were using and the the volume that we were pumping into that would you expect that to not even be a penny or any idea it should be really cheap I'd say less than a quarter um more than a penny though all right yeah uh what is actually hold on I can bring up the pricing open AI pricing it's um it's like it's kind of like reminds me of storage was like per thousand type stuff uh so is it gp4 or 35 it's a 35 turbo5 tur of course this isn't the pricing page uh let's see this is the this doesn't tell me the model pricing uh that's for open a I um think Azure is charging something on top of it are they so Azure open AI model pricing now this one  this thing can't see because of the bar at the top this guy okay so per thousand token so for heading to 50 well see these input output but it does add up but not a lot I mean th tokens if you cap it at 250 and you hit the cap every time four of those you're at this much so time up by you'd have to have like a 100 before you'd hit five I I'll check the uh I I actually have the cost analysis window popped up on the Azure side and I'll say I don't know how much latency there is before it catches up it takes a while yeah I use that in my demo the um but I mean this is a a good thing to point out I mean look how much price difference there is between GPT T4 with 32k and turbo I mean it's huge this is a scent one penny for 100 or a th tokens out and then so you could easily yeah right but I was watching a video actually a couple videos from the guys over Lang chain and they've been doing testing on the context window basically finding I think they call it needle and hay stack so they put like I forget how many needles they were doing needles so they put it something in the context window that they're passing they put were putting like one to seven they did multiple tests to see how often it would find those four things and it other test showed that the larger the window was the more often it paid attention to the end of the context it would sometimes lose things at the beginning of the context so yeah it's all interesting stuff anyways so you did mention that you are going to have some kind of a workshop in the future like is is it to uh open to everyone sure I can answer that sure yeah it's open to everyone so we're this is a um an event that Veronica and Jason and myself have put on a bunch of times over the years where we've been doing it for more than 10 years where we have an all day uh free usually vendor sponsored so we can do food and and such um at nerd in Cambridge Massachusetts uh where uh you show up with a laptop or you know we we'll we'll uh we'll publish a page that describes all this but show up at usually it's around 8:30 or 9 or something and at the at the site and you bring your laptop like I mentioned and we code we do stuff there's a usually a an interwoven set of talks like like the Pamela talk that you just heard um as a you know one example there might be a talk like that and then there'd be um a hands-on experience after that to take advantage of the information there and then you know uh you repeat that three four five six times during the day you know new topic new lab new topic new live that kind of thing and at the end of the day um you uh you leave presumably Having learned a bunch more about Azure you know this is the Boston Azure group but we're um um we're we're expecting to have a heavy AI emphasis on um on this particular workshop on April 20th well that's great I would love to I'm in New Jersey but I would love to come there and join it love to have you great we so watch the Meetup space there'll be a sign up um soon um we like uh we we only found out about this uh quite this is quite recently this late breaking news so we have a couple of details to square away now that we know we have space but we'll we'll get a sign up form out there and um if you should you know assuming you get Meetup notifications that should um should let you know great thank you so much yeah welcome have you been to any in-person uh Boston Azure or North Boston Azure events no no I I haven't come to any Boston a events but I did go to some in New York New York City ah very cool oh welcome thank you any other um questions out there folks we let everybody go sounds good have a good night okay thanks for staying late all uh I'm tired you are too good night everybody Forest gum what's he say I'm tired I'm gonna go home now that's how I feel that's what I'm gonna two and a half hours this is great thank you guys thank you very much take care thanks everybody thank you okay "
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide. This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade. back then but you don't need help with azure now you're you're you've been helping people uh learn their azure skills and uh become you know pretty deep azure expert so it's really um it's really great to be able to tap you from all the way in uh texas for a uh for an event uh so the the the other side of the covet coin is uh this is nice to be able to have the uh uh speakers come from anywhere so uh without further ado um join me in welcoming uh duck over to you sir thank you sir appreciate it um you know i i will tell you that by far some of the most fond memories i have is taking the train or the bus um down to boston for the day to go and hang out with the tech community down there go to a meet-up do something at nerd those were my salad days and i wouldn't trade it for a thing and it's a large part of the success that i've been able to have so i'm in no small part i thank the community for helping me get to where i am so as bill had indicated my name is doug van der weid i'm a director of infant information technology at avanade avenatti is a joint venture of microsoft and accenture we are about 50 000 people worldwide they're trying to hire another 20 000 people in the next two years um we are always hiring microsoft talent so if you're kind of bored in your role today if you know anything about the microsoft stack if you have knowledge around dynamics or sharepoint or anything like that and you think you'd like to learn more about avanade feel free to reach out to me i have been working in azure for about 10 years as bill noted um i got started at my old newspaper group um we got 50 000 worth of azure credits as part of a store simple deal and uh ever since that moment i became an azure developer um my actual steel set goes back quite a time i came up through the ranks as a.net and sql server open source developer um for quite some time as bill indicated i'm originally from maine i've been texas for the last five years and i have a bunch of uh certifications as well so just so you know um you're fine i have a general understanding of which end of azure pounds of the nail as we go through this uh pro uh the thing that i really want to talk about today is uh is setting up some of why we're why we're going to have this conversation on azure policy and uh using uh automation to enforce a tagging strategy and i think the first thing uh that you need to understand in order to get to why this is important is that uh is the concept of governance right and governance is ultimately the ability to be able to identify measure and control all the assets you have deployed so what is the you know it's things like uh what is this thing where is it in the world what does it do who owns it who controls it what relies upon this thing what does it cost is it operating efficiently so on and so forth all of the things that go into making sure that i'm not being wasteful either in terms of science in terms of um cost or being wasteful in terms of effort also things along the lines of who's going to pay for all of this how are we going to uh and how are we going to make sure that we're doing this as well as we can that's governance in a nutshell and it's especially true that in large organizations governance is a is a significant challenge for them um usually speaking a large it organization and by this i mean like a fortune 500 fortune 100 company um they tend to be in multiple clouds so if they're going to be in azure they're probably going to be in aws um they probably have colos someplace so they have data centers somewhere out there they're running private clouds um they may be using vmware uh they may have rack space presence so on and so forth and when they are in azure they tend to be using multiple subscriptions they have very complex subscription hierarchies sometimes they have subscriptions that are specific for dev tests uh sometimes they have subscriptions that are broken out for regional concerns or by business unit sometimes they have they use the hub and spoke model where certain shared services and certain central networking assets are in subscriptions and everything branches off from there oh and i should mention this as well folks um if you have any questions feel free to interrupt me at any point or go ahead and electronically raise your hand i'll try to keep an eye on that and answer any questions you might have the another thing that tends to be true of most large it organizations most organizations that are broad in terms of their total operational footprint you know multiple divisions across the world that sort of thing they all tend to use what's called a chargeback model and what that means is the operational cost of their ikea states the actual cost of delivering the it services that they're using in azure and other places gets built back to a specific to a specific business unit so that business unit has an i.t budget and you they need some means to"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:05:04",
        "seconds": 304,
        "text": "states the actual cost of delivering the it services that they're using in azure and other places gets built back to a specific to a specific business unit so that business unit has an i.t budget and you they need some means to track what the spend against that it budget is that they can charge the business unit and make sure that business unit is isn't exceeding the capacity they've been allotted also in in most large it operations you tend to see that that the model that they use for operating is an i.t servicing model so the it department doesn't actually own anything in the ita state they don't own the computers they don't own the data center they don't own the cloud presence they're not ultimately even really responsible for any of that stuff the decision of what gets created and what gets bought and where it goes and all those other things they might be an advisor but they're not a decider the business units decide what kind of it they're going to have what kind of programs they're going to run how those programs are going to be hosted where they're going to be hosted um so the itu unit is really just a servicing organization they keep the lights on they're they're basically digital janitors as it were right they're there to maintain the inventory to keep things running to enforce you know some guard rails um to you know impose discipline on the operations but ultimately what gets done in the i t world doesn't really belong to the iep department in most large organizations it belongs to the specific business units and then finally and this is where this question of azure policy and tagging comes in most large organizations have a lot of different tools for a lot of different solutions right so uh so seems security incident and event management itsm uh it service management itil um information technology information cmdb configuration management ipam ip management they have all these different tools that do different things for them in terms of you know being able to control their uh being able to control their environments as well as monitor them it is the very rare large organization for example that uses azure monitor as its soul meets as its sole pane of glass to look at azure um generally speaking they want to have a unified pane of glass they're using something like grafana or they're using something like um you know something like that to have a much broader implementation of their monitoring solutions and their learning solutions um they will have very complex implementations of servicenow for example and everything so everything that they need to know has to basically come into everything that they're doing in the it world regardless of where it is if it's an aws if it's an azure if it's on in vmware it's some co-location facility or data or data center they own all that information generally speaking needs to report to the same places so they have the ability to see everything in one place in terms of their operations and i'm sorry i've lost focus on my uh advancer let me get that back all right so that's why tagging comes in so tagging for those who aren't familiar with tagging in azure it's basically key value pairs that can be assigned to most assets there are a few assets in azure that you can't tag but for the most part pretty much anything you're going to encounter that racks a charge is going to be something you can tag and a tag is basically a means of storing metadata about a resource that's useful for understanding its context the real value in tagging at the end of the day especially for large organizations is that using azure native tools using tools you can build yourself bespoke tools or using third-party tool sets such as servicenow and the like you can usually retrieve the tags on an asset when you're trying to call for that resource so i can set up an integration for example in servicenow that or some other catalog service that basically says when i pull the information about this particular virtual machine for example tell me the tags are on that virtual machine and when when i do that i'm doing it probably through the rest api that azure has and i'm getting that information back and i'm able to store it and therefore i can use those tags to help catalog that item for various business concerns i might have the real value of tags at the end of the day is that they exist outside of and therefore they extend the subscription and resource group hierarchy right also management groups and for those who are familiar very large organizations when they buy azure they don't buy pay-as-you-go subscriptions they tend to have enterprise agreements with microsoft and what an enterprise agreement is is it's a way for that large organization to pay for all their microsoft stuff in one place so all their office 365 all of their dynamics um all of their sql server licenses all of their windows desktop licenses and all their azure stuff tends to be part of what's called an enterprise agreement which is all all rolled up price that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:10:09",
        "seconds": 609,
        "text": "their office 365 all of their dynamics um all of their sql server licenses all of their windows desktop licenses and all their azure stuff tends to be part of what's called an enterprise agreement which is all all rolled up price that microsoft gives that customer as part of that process there's additional reporting planes called departments and accounts that they can use as well but again the beauty of a tag is it exists outside all of these hierarchical solutions so um from you know it's it's basically enterprise agreement department account then subscription then resource group tags can be on tags would live outside that ecosystem and therefore they extend um the ability to track assets because i don't have to worry about where they are in that logical hierarchy so we know what governance is now it's the ability to keep control over your stuff especially to understand what it is where why it's there what it's supposed to be doing for you who owns it etc etc we've established that it is difficult to keep a wrassle on that especially if you are a large organization there's stuff everywhere in multiple different types of places and they need all that information to report to external systems so our ability to govern those assets especially for large organizations this can be a challenge and there's some ways that most people tend to solve that problem at least in the shortlist at least as a smaller organization right so we can have a naming standard and depending upon how we name things that name can tell us where that asset is in the world what its purpose is uh what kind of thing it is if it's a virtual machine if it's a network that sort of thing we can use subscriptions as well to group our assets by purpose or business unit right so theoretically we can have a subscription for example that maybe our subscription strategy is every application we have goes to a particular subscription maybe we have a strategy that's a hub spoke again we have a central subscription for all shared services and then every other department gets its own subscription or every other geographical area gets its own subscriptions all the stuff in east u.s is in one subscription and all the stuff in west u.s is in another and typically we see resource groups used to manage assets that are on the same life cycle so any solution any workload any application that i have that's running in azure it's very typical that all the things that are necessary to provide that application the databases the virtual machines the networks the firewalls so on and so forth all tend to live in one or two resource groups that are related to that particular solution and finally again we can use regions regional separations to help uh structure business units but but the challenge with that approach especially as you get larger especially as you become a bigger organization is it doesn't scale well right um the challenge you you if you're gonna have it you know there's a lot of enterprises out there that have hundreds if not thousands of applications you can't have hundreds or thousands of subscriptions it just becomes unmanageable um there are tons of organizations out there that are deploying all the time they can't have every single asset um that's related to a particularly large organizat operation for example like perhaps their inner source re their enterprise re planning uh solution uh you know something that they're using to basically allocate staff and in materials that's probably too broad too large a thing for them to put in a single resource group they need multiple resource groups because there's too many moving parts they can't define it as a single deployment same thing is true of regional approaches some organizations um they have multiple regions for one particular business unit one business unit may very well span the globe so again what tangy does because it's outside of these restrictions it's outside of these hierarchies tagging allows us to identify the what assets are doing without being restricted to any of these logical hierarchies that that exist such as regions resource groups subscriptions and even naming of assets or naming conventions so what are the kinds of tags we tend to see large organizations specifically but organizations in general what kind of tags do they tend to put on assets um there's actually some guidance on the doc site for azure um under their um under their uh framework um part which i'll try to get links to um for you in the in the meetup that talks about typical tags that are advised for most organizations but typically what you'll see in a large organization is specifically a cost center tag most again especially any organization that has a chargeback model that says hey business unit you're financially responsible for everything we deploy on your behalf and azure you need to pay for that thing it has to come off your budget um by far the most easy way to keep track of that is to simply assign a cost center a tag to an asset so that they you know who's racking that charge same thing is true for most organizations to have an owner the owners again especially depending upon how broad an application is"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:15:12",
        "seconds": 912,
        "text": "of that is to simply assign a cost center a tag to an asset so that they you know who's racking that charge same thing is true for most organizations to have an owner the owners again especially depending upon how broad an application is it's not unusual for a single application to have multiple people who own parts of that application there may be a db team that owns the underlying database uh databases for example in the webs in the website there may be another team that owns the firewall there may be another team in the networking concerns there may be another team that is responsible for actually providing the web servers there may be another team that's actually responsible for the devops part of pushing the code there there may be multiple teams with multiple moving parts that all are part of a single application and therefore having an owner tag on individual assets helps keep straight which team owns this part of this solution you'll see versions you'll see um termination dates especially for assets that are put out there some organizations will intentionally tag assets for a particular termination date and automate the process of destroying them most are going to apply a business criticality tag they want to make sure that they can audit any mission critical system is being backed up or is being uh supported in a way that the business can continue to run if there's an incident almost all of them also use a data classification tag almost all of them say hey we want to make absolutely certain that we are able to identify this information systems that are holding confidential information or personally identifiable information so that um in the event of a data breach we can quickly identify places that we need to lock down the summary of this is the next large organization that was 100 tagging coverage on all of its assets will be the first i've talked with dozens of businesses extremely large organizations every single year none of them have this right okay and that's not a bad thing the reason why none of them have it right in short is because there's no efficient means of enforcing both the presence and the quality of a tag in azure for example one of the challenges in azure is that tags are case sensitive so if i spell owner with a capital o in one place an owner with a lowercase o in another place those are two different keys in the azure tagging world and so therefore it may look to me like i've got better coverage than i do but in truth when i query i need to make sure that my case sensitivity and my spacing sensitivity are addressed in the name in the key of that tag so i can actually pull all the information i'm expecting and then again additionally the challenge is for most of the things without some means of insisting that the tag be there a tag is not required to deploy an asset manager an asset can be deployed without tags and what tends to happen is even with the best of intents organizations even highly automated organizations don't have a means of saying oops you forgot the tag that's where azure policy comes in so what is azure policy azure policy is basically a way to allow you to enforce and audit deployment compliance for azure assets so is this thing that i'm putting in azure correctly configured according to my business rules and my technical requirements that's what azure policy does it is is it audits or views the deployment as it happens and it ensures that the asset as it's being deployed complies with those requirements that you set out a manager policy can be applied in multiple scopes so it can be applied to a management group for those who aren't familiar management groups are basically a way to associate both identity or role-based access control and policies to multiple subscriptions at once it's also possible to apply a policy directly to a subscription that's what we'll be doing today in our demo it's also possible to apply a policy at the resource group level we can further uh group our policies together to a common outcome such as an initiative and i'll talk a little bit about more about that in just a minute then finally there's multiple means of enforcement available to you in an azure policy one thing you can do is just outright reject the deployment hey user you forgot to add this tag or you gave me a tag value that's incorrect i'm going to reject the deployment outright go back and try again another thing i can do is i can say well you sent me this deployment it does not have a cost center tag on it so i'm going to automatically assign a generic cost center tag to it so at least i have something may not be right but at least i'll have something that looks correct and then finally you think you can do is you can audit that deployment so you can have the policy say i just deployed this person just deployed this virtual machine i went ahead and created it they did forget to give me a cost center tag now what i'm going to do is tell mom i'm going to send off a message to a queue i'm going to raise the fact to raise an alarm that basically says hey when this guy deployed this asset he forgot to add that tag so what are some typical azure policies that you see out there"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:20:15",
        "seconds": 1215,
        "text": "going to send off a message to a queue i'm going to raise the fact to raise an alarm that basically says hey when this guy deployed this asset he forgot to add that tag so what are some typical azure policies that you see out there very common for most organizations is that there's a regional restriction right we're not going to allow you to deploy this virtual machine to south africa because we don't do business in south africa also very common is policies that say don't deploy expensive skus right so you cannot go out and deploy that giant n c or m series vm uh with 64 cores because it costs a thousand dollars a minute a thousand dollars an hour to run we're just not going to let you make those things you can for example enforce encryption at rest so maybe you have some sql databases you don't you you want to deploy those databases um you want to make sure that everything that you have is all that data is encrypted at rest by default um you could certainly create a policy that says anytime you create a new sql server pass service make sure that encryption at rest is turned on and then the other thing you can as well do as well is for all your public endpoints uh force enforce https so no hdb traffic to that public endpoint it has to come over via https um more advanced stuff is uh ensuring that your virtual machines are set for backups either that the a backup agent is present on the vm or it's actually using the azure backup solution requiring network security groups anytime a new subnet is created so you can't just come out and boldly create a new subnet if you create a new subnet it has to have a network security group associated with it same thing is true for um again providing certain default settings so maybe uh not necessarily a tag default value but maybe for example one of the things you want to do is say anytime that a new network security group is created it needs to have a specific role a specific rule in place that rule needs to block any traffic on 33.89 um and you want to insist on that rule being present in the nsg you can go ahead and create a policy that basically says and if you don't see a rule for 33.89 that's a deny rule you will automatically add that deny rule for 33.89 and then again uh as we talked about here you can check for certain tags as we look at today's demo one of the things we'll be able to see and i'll be able to show you is there's a long list of built-in best practice policies that are already present in every azure subscription most of them are in audit which is why you tend not to run up against them and see them as a bad thing but i can show you what some of those policies are and how you can turn them into enforcement policies to prevent uh some potentially dangerous practices okay that's a lot of stuff i'm going to take a quick pause anybody have any questions before we start talking about the nuts and bolts of what we're going to be looking at today for actual hands-on keyboard stuff all right okay so what are the parts of azure of an azure policy well the first thing you have to have is definition that is what is the condition that needs to be met and what do you want to do to ensure that that condition is met every single time you deploy an asset the next thing you need to do is provide the definition in some cases you need to provide values that describe what's allowed so for example you may very well have and what we'll be looking at today in our demo is we're going to be applying a cost center tag to our assets when they get deployed and we're going to restrict the possible values of that tag to only certain values so that's a definition object the values that are allowed is one of the definition objects that you would supply the next thing is an assignment so you have a policy that is going to require a particular state we have the allowed values for that particular state now we need to assign that we need to assign that policy and give at a specific scope so we need to take the policy definition that we defined that then needs to be assigned to either a management group a subscription or a resource group that's called the assignment there are also initiatives as we described before initiatives are grouping of policy definitions for assignment purposes so for example i may have multiple policies that define the kinds of tags that i need to have on an asset i need to have four or five different required tags every single asset needs to have them i would probably define that in four or five different policies and then i would group those together in an initiative that would be my tagging policy initiative there is the ability to make exclusions so another thing i can do is define i want this policy to apply except in these particular cases and basically you can create an exclusion there for that excludes specific assets from policy definition when it's after it's been assigned finally there's a remediation so i've been speaking about policies as um runtime solutions right that every single time i'm going to make a deployment i can use a policy to ensure that that deployment is compliant with my rules and requirements as defined in my policies but i can also create what's called a remediation and what a"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "runtime solutions right that every single time i'm going to make a deployment i can use a policy to ensure that that deployment is compliant with my rules and requirements as defined in my policies but i can also create what's called a remediation and what a remediation does is it says it is possible that somehow it's certainly possible that prior to implementing the policy you have some assets that are not compliant they do not comply with the policy that you've just defined you may have a bunch of stuff in azure already for example that doesn't have a cost center tag a remediation plan allows you to basically say for those assets that are already existing i want you to go and apply this solution this fix to all of the things that don't comply with this new policy it's also theoretically possible although it shouldn't happen it does occasionally happen that through one way or another you're you see some configuration drift on your assets that azure policy doesn't catch because it's not technically a redeployment especially true with virtual machines sometimes you add things to virtual machines or make changes to them internally that have a fundamental effect on their overall configuration that tends to make them drift you can use a remediation plan also to spot this kind of weird drift that doesn't completely fall into the definition of a redeployment all right so what i'm going to do is show you now how to deploy an azure policy from a powershell um i also mean in a template um i wanted to do this with azure devops but my azure devops uh instance ate my homework um so we're gonna be doing this uh the old-fashioned way um with powershell and arm templates i also do recognize that microsoft would like people to start using bicep um i actually kind of like bicep it's very yummly if you work a lot in azure devops you will like the fact that bicep is pretty ambi um the challenge i have is that i haven't worked with it enough to do this quickly and i didn't give myself enough time to do the demo so arm templates and powershell it is what we're looking at on screen right now is basically an arm template and this arm template is going to define the policy so this is a policy definition arm template and as you can see i've got the schema set for this subscription deployment template scope so i'm going to be putting this right at um right at the subscription level normally i would do this at a management group level and i don't want to get overly nuanced about why i like management groups over subscriptions but if we have time we can have that conversation normally i put this in a management group for this demo i'm going to be doing it at the subscription level um as you can see the cleverly just named uh microsoft authorization policy definitions is the scope is the type of thing we're going to be deploying i'm going to give it the name of required tag billing identifier normally i would not put this in a template i would pass it in as a parameter um again for this demo i'm just going to go ahead and give it a hard-coded name the api version tells um the api which version of this definition to use was it creates a thing these are just basically a friendly name for required billing identifier tag you'll see that just a moment i have to specify if this is a custom policy because it is a policy that i wrote um this description is very helpful you can see it in the portal i'll show that to you in a bit the other thing is that um it's also going to have a category so cat you can categorize um your individual policies with um this thing in this case um i actually stole this from another project i was working on for a customer that had a bunch of stuff they wanted to make they wanted to put policies on one of the things they wanted was required tags having this category piece is something you can filter on in the portal it's really helpful for seeing what's in effect and what isn't in effect this mode index basically means um i forget i forget the exact definition but basically in the index mode is telling um the deployment listen what you're going to do is go and iterate all of the items that this can be applied to and you're going to make sure that it applies to them that's an oversimplification of what it does but good enough for now finally i'm passing into as parameters um this bill id value it's going to be an array and basically what it's saying is when i get a bill id when you provide the billing code id for this uh tag it's going to be have to be one of these three values you can't provide me anything else so here's where we actually create the rule it's a simple if statement and what it basically says if any of these conditions are true then i'm going to deny the deployment okay so if any of these things are true then i'm going to deny the deployment outright in this case i'm saying there has to be a tag with the key of billing identifier if that's not present i'm going to reject the deployment the other thing i'm going to reject the deployment for is if the tag name billing identifier doesn't have a value that's in this list okay any questions about this template before we move on and actually try to use it okey-dokey all right so i'm gonna go ahead and fire up powershell um normally i would do this in the cloud shell"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:30:21",
        "seconds": 1821,
        "text": "identifier doesn't have a value that's in this list okay any questions about this template before we move on and actually try to use it okey-dokey all right so i'm gonna go ahead and fire up powershell um normally i would do this in the cloud shell but for some reason i can't copy paste in the cloud shell today um or at the very least it's decided it's not gonna be nice to me about it uh so we will be using good old console powershell and i will big in so you can see what this looks like okay so the first thing i'm going to do is log in a z account i know there's a lot of different ways to log into an azure account i am using the az module for this um i believe there's a replacement on the horizon i might be wrong about that um but definitely don't use azure rm that module is no longer with us so uh and again i do know there's more than one way to log into azure uh to azure with this thing i'm using again login az account just because it's familiar to me so it'll take just a moment while i get prompted to uh log in all right i'm going to log in with my personal account i don't actually know any of my passwords so i have to go look it up bear with me just a moment i use lastpass by the way to um to record record my passwords i don't know what you guys use but i absolutely adore this thing um it couldn't get a thing done without it so let me go back over here paste that in and i'm gonna have to go ahead and enter my um my code so that is right here oh thank you for asking though all right seven three five seven two four all right and it should dump me in and i should be logged in okay i'm also going to cheat and copy down the individual codes i will give you guys this information as well so the first thing i want to do is i want to go ahead and set a variable that contains the subscription id i'm going to use because i'm going to need that later in this process so i set a variable sub id that's just going to contain the guide that you see right here uh for this thing did i do that right no that's the wrong good i need this one right here well that's the tenant id i suppose this is the id of my azure tenant that's the correct sub id my apologies okay so the next thing i need to do is um normally i would not do this but um if you have more than one azure subscription this is a really useful commandlet um you can then set your context to be this particular subscription so i'm going to set a z context i'm being very specific in this case that this is the subscription i want to use okay next thing i want to do is go ahead and add that template that we were just looking at i have that template saved in an azure storage account that's publicly accessible i'm just going to go ahead and run the new az subscription deployment commandlet which i'll show you before i execute it bear with me all right new az subscription deployment is telling azure i want to go ahead and deploy at the subscription level um i have to provide a location even though this is even though policies are not location based they'll apply to the entire subscription regardless of where assets are located but as you know you can't run a deployment without specifying a region that you're going to deploy to then finally i'm just giving the template uri of the template that i was just showing you so when i hit return it'll take just a few seconds and azure's going to go ahead and create that uh go ahead and create that for me and it's going to spit out basically information about that policy so what i want to do now is look in the portal we're going to look at azure policy in this case i'm going to look at the definitions oh by the way um getting into the azure policy piece getting into this view to be able to manipulate anything in here you need fairly advanced privileges it wouldn't hurt to be an owner if you're a contributor you may or may not have certain uh you may or may not have certain permissions that are necessary to be able to look at this stuff but what i'm going to do right this case i'm going to sort by type and you can see i now have a custom policy named require billing identifier tag and when i click on that i can see the full definition of the policy it looks very much like what i was just talking about again um in this case i need to have a tag that's named billing identifier on a those that tag not only needs to be presents but the values that are in it need to be one of these allowed values let me be real clear about this in the case of making a requirement almost always you need to have one of these any of statements it's very rare that you can pass to this thing just a list of values than say the the value that you're providing this tag have to be present usually azure policy is going to interpret that as the tag is optional but if you provide the tag it can only be one of these values without both these statements you can't have a required tag but if i"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "providing this tag have to be present usually azure policy is going to interpret that as the tag is optional but if you provide the tag it can only be one of these values without both these statements you can't have a required tag but if i got rid of this statement saying that the field needs to be present if i went and deployed something without a billing identifier tag it would accept that if i deployed something with a billing identifier tag that was said abc123 it would reject it okay let me back up one all right so there's our policy it's available but it's not being applied let me show you that so i'm going to come over here to the storage account i'm going to create a storage account i'm going to name the storage account uh we'll use create a new resource group we'll call boston azure [Music] and we'll give this storage account the name of just some random stuff that should do it um i guess not we'll go back there that should take care of it you can see that i can scroll all the way through this even past tags to review and create and i'm going to run my final validation and i pass but i just created a policy that says hey i want these i want this tag this billing identifier tag on this asset and it has to be one of these values the reason that it doesn't work yet is because i haven't assigned it a scope i haven't set its assignment so that's going to be our next task so let me come back up here and go back into my commandments and back into powershell okay so now i need to go ahead and create the policy assignment to do that my automation routine and i realize that i'm running this by hand but normally i would do this if i was going to automate this either with azure automation um which runs powershell scripts for you or with a devops pipeline so um first thing i got to do is i just created this policy i need to get that policy definition so i can actually assign it so i'm going to set the value of the policy to be this and if i go ahead and write output i get back the same information when i got it back so this is an object with these uh param with these um uh values uh parameters and values right okay so now what i want to do is uh go ahead and set the values that can be accepted i know i did that in the policy but for some reason when you create the assignment um the assignment allows you to override the allowed values so i could create a subset of the old i could create a policy with a broad set of a lot values i could then create an assignment that only allows a subset of those values so i could have one subscription that says you can give me any billing code i could have another subscription that this applies to but and say in this one you can only use the billing codes that are appropriate to a particular department or something and use the same policy but a narrower definition of allowed values so in this case i need to create an array of all the allowed values that's what that bill ids variable is and finally i'm ready to go ahead and assign the policy so now what i'm going to do is again run this commandlet i could also do this with template i have a template that i can show you that does this um but i i prefer to do it this way um and this is how i would normally do it with it with an azure automation solution is i'm not just going to go ahead and run a policy assignment this policy assignment is going to go ahead and uh pull the policy definition so that policy variable that we just set that's going to basically that's telling it this is the policy i want to assign scope tells me i'm going to assign it to this particular subscription at the subscription level and the policy parameter object again is those uh values this these particular values that i'm going to allow uh to be passed in so i hit return bingo i've got an assignment if i go back into the portal and i look at policy again i can now see i have assignments there's my assignment okay in this particular case what it's telling me is i'm going to have to have a there's going to be a parameter provided it's bill id it's got to be one of those values that i specified and then it's going to basically deny directly any deployment to the subscription that doesn't have one of those tags let me show you how this actually works when we try to actually use it so now i'm going to go back and create a storage account again again in this case i will call this story i'll just get some random gibberish for a name i'm going to go next to advanced next uh-oh my tags are not showing up there it should show me his errors right there next data protection next tags this should actually not this should not have happened of course this is how you know it's a live demo is that it didn't actually work correctly oh no it didn't it failed okay so what should actually have happened here let me refresh because maybe it's just the portal model normally what will happen here when you try to come and create a storage account is immediately after you provide this basic information you should see a"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:40:28",
        "seconds": 2428,
        "text": "so what should actually have happened here let me refresh because maybe it's just the portal model normally what will happen here when you try to come and create a storage account is immediately after you provide this basic information you should see a little red dot here appear next to tags and it should tell you that hey you've got to apply tags it's a requirement on this deployment but we'll go over right over here we'll get right through and you'll see that i get a validation fail and the reason why it's validating failed is because it's disallowed by policy right and i can actually come over here and click on the policy and see the policy that i'm violating if i were using devops or some other solution to pump uh or to pipe this information into or to pipe this particular uh request into azure there's a strong possibility um i would not get any warning in advance that's why i would want to run some sort of test on it before i actually execute it but in this case if i come over here and i type in billing identifier let me make sure that i've got that correct um i just want to make sure that i've got the name of the uh the key of this correct before i get going it's going to be billing identifier capital b capital i so in this case i'm going to go ahead and provide billing identifier provide a value in this case um i know that one of the values i have to provide is this is one of the values i can provide actually let me provide a wrong value first so let's go ahead and call that like that and i'll go ahead and review and create and you'll see i fail again and in this case the reason i failed is because i provided a bad value so what i'll do this time is go back one more step and this time we'll provide an actual value that's allowed so if i review and create oh i don't know why i'm not passing my validations i'm sorry you have to fix the name you missed oh i didn't miss that there you go that's the reason why there you go yep you're correct so actually yeah i don't know why i can't spell identifier correctly probably because i'm not wearing my reading glasses there we go there we go yeah so in this case let's go ahead and again and take that off just so they still have the wrong name when i validate it shouldn't have passed but um maybe because um actually i think in this case it will pass but it will pass but when i try to create it will fail um because i don't have a correct value so it's it's passing because in this case i have oh because it actually did take it so if i come back here and rotate this entirely there we go yeah fails again this time if i pass in a correct value it will pass me and i can go ahead and create that object so that's basically in a nutshell how i would begin the approach that's the that's the nuts and bolts of how applying a policy to azure can allow me to ensure that a tag with a particular key and a particular set of values is allowed what can policy do and not do out of the box okay policy out of the box can require the presence of a configuration variable that can be again a tag um it can be a uh it could be a particular region it can be a particular skew that sort of thing it can also restrict configuration inputs to of specific values like we just described you can place a default configuration value where value is not provided so for example one of the things i could in theory do is say um [Music] if you don't have a cost center tag i'm going to apply this default cost center to you and finally i can overwrite a provided configuration value with a default value so i can for example say i don't care what you gave me for the value of um of cost center because you're deploying to this particular subscription you will take a cost center that's associated with that subscription what policy can't do natively is provide you with an option list so you saw before that i said there are three different values that you can pass in as a billing identifier for this particular asset uh what i can't do what it won't do for you is like populate in the portal a pull down list of just those values so it won't generate for you even even at deployment time a list of values that are available to you to supply it's also not good at complex if then statements so for example if one of the things i wanted to do is say well if you're deploying to east u.s and this is a dsv3 series vm that you're deploying then you need to give it a tag with a particular value that's too complex for azure policy out of the box to execute the other thing you can't do is restrict configuration inputs to a range right so one of the things you can't say is well you got to have this tag called serial number and that number has to be"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:45:33",
        "seconds": 2733,
        "text": "azure policy out of the box to execute the other thing you can't do is restrict configuration inputs to a range right so one of the things you can't say is well you got to have this tag called serial number and that number has to be somewhere between 1 and a hundred that's not something that um azure a policy can do it can't evaluate things as being in the middle of a range so how do you get there how do you typically work around those limitations most commonly if you're using you're going to use something like azure devops right and what azure devops is going to do is it's going to collect your runtime arguments usually from some sort of configuration file um and that is for example if you're using terraform you're going to get that from your terraform config or from your state file if you're using just powershell or arm templates you may have a flat file or csv or something like that or excel file or even a database that you might be pulling that information from the other thing you can do with something like azure devops is pull from a content from a configuration management database uh from an itsm system like servicenow or from other apis right so you could actually say go give me some information third party service that and i will apply tags according to that uh if you're using powershell scripts and to a lesser degree azure automation generally speaking you'll be prompted for that of course the challenge with azure automation is while it's running powershell scripts for you it you can't really take user input um so you would need to have uh some sort of config file or the like but basically when you're using partial scripts of the like you can just write your powershell in a manner that the user is going to prompt with that information is is user input when executing something automation my opinion is yes others may disagree and we can have a fulsome conversation on that if you'd like finally azure functions are logic apps um azure functions uh more so but logic apps to some degree are useful for solving the complex if-then interpretation right i'm saying when i have i'm deploying to east u.s and it's a dsv3 vm and it has this particular port open then or i want you to do some other thing right that is something that an azure function can do for you quite easily same thing is true if you're pulling from external databases or other data sources um azure functions and logic apps are really good at that and saying hey go get me some information spill it into a very spill it into an object for me so i can pull out the various parts i need in order to inform this uh in order to inform this deployment very useful with that um and that's basically what uh it that's basically you see them using the helping level it's very seldom you will see an azure function used solely to deploy things although i have seen that use case i actually helped a client at one point they uh what they basically did was a stand-up boutique websites um for their customers any single time that they onboarded them um and they had a completely automated solution to provision everything we used an azure function to do that they basically just pushed a button and the function went and deployed everything that they needed uh including point c point code from the right place and all that sort of stuff so you can see functions and even logic apps occasionally running stand-alone deployment solutions more typically they're used to support especially things like azure devops in terms of configuration so to recap what we talked about today large organizations face significant challenges when they're trying to govern their resources um in in the public cloud tagging is almost always and this is true not just of azure but also of aws and like it tends to be the most effective control plane for understanding and identifying assets especially if you're a large organization with stuff everywhere very few organizations have sufficient tagging coverage to really be effectively to be able to effectively govern their assets that's where azure policy come in azure policy when applied correctly and as part of your deployment process can really ensure that your tags are present and that they comply with your guidelines now finally deployment automation is typically required for this to work it's very seldom very rare that you're going to be have that you're going to be able to make an azure policy work if you're just uh freehanding it um in either in the portal or with ad hoc powershell scripts look who you're looking at again i would never actually generally speaking i would never recall what we were looking at with the powershell scripts executed by hand as a mature process but i would plug that into a pipeline a devops pipeline or even an azure automation account and consider that a fairly mature solution to the problem that is all this presentation i had for you guys i am happy to go over anything specific i am happy to uh pop back into the portal and talk about uh policy and how it works i did promise you that i would look at that we could look at the predefined uh solute uh policies in azure and we can do that as well but i'll pause here take any feedback or questions you've got so doug i uh hopefully other folks will come off um off mute and and speak as um as they have questions i i have a comment question uh in the what used to"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "well but i'll pause here take any feedback or questions you've got so doug i uh hopefully other folks will come off um off mute and and speak as um as they have questions i i have a comment question uh in the what used to be known as the azure security center which is now microsoft defender for cloud that's also a you do you want to say anything about its use of policies yeah absolutely so you can see yeah so azure security so if you look at your policies you go to your azure subscription any of them really um especially if you got a p if you got to pay a pay-as-you-go subscription one that you like to play around in your little sandbox like you will see in there um this asc default um paul initiative right and this is an initiative it's a grouping of policies and you'll be able to see that in this um and this is what bill's talking about the azure security center slash defender slash whatever microsoft has decided it should be branded this week comes with a number of predefined policies and these policies are informed by an organization called the uh i think it's called the coalition for internet security cis um they have a bunch of guidelines for what a reliable safe cloud environment looks like and these policies are so the policies that you see in the asc default uh configuration initiative and policy is based on those and it contains things like for example um enable threat uh detection capabilities if we look at that policy for example one of the things you'll see is that it says hey you should totally be using azure defender um and you don't have it enabled on this subscription well okay great hint i'll go back and take a look at that and see what i can do about getting that fixed another thing but more commonly you'll see things along the lines of um well let's take a look um secure cloud services with network controls right which in this case it says we're compliant right in this case the reason why i'm secure i have secure network controls is i don't have any networks but in this particular case what it's saying is you should have private endpoints for any azure service that supports private link in order to be able to provide public private access to the resource and you should disable or restrict public access network uh public service uh access to the public access to the service um i i take a little bit of umbrage at that that's not always true but it's a good guideline it is generally true that if you're going to be in a network environment you should probably be protecting your stuff from public access especially if it's not meant to be public um but i'm also a big believer as an old school developer a big believer in apis and microservices and public endpoints and identity is the new control plane and all that other stuff we can i i'll talk your damn air off about that so don't get me started um yeah so there are a bunch of policies that are here in azure that are available to you the thing you'll notice again when we look at them um under the assignments uh when we look at how those policies are assigned you'll see by far most of them are either disabled or they are in audit if not exist mode or they're in audit mode on and if not exist mode basically says um for example in this case one of the things they're saying is you shouldn't use management well not that one that's not a great uh example but let's okay so like here's one this is basically if you're going to deploy a virtual machine scale set or a virtual machine to azure it should be it should have the agent the log analytics agent installed on it so that azure security center can monitor it that's probably a good piece of advice but from not for every organization some organizations like to use third-party tools semantic or the like to monitor their assets and and keep track of their strength you know keep track of how well they're running and and um you know whether or not they're secure um audit if not exist basically says well okay if you deploy this virtual machine and it doesn't have a log analytics agent on it for the purpose of azure security center i'm just going to make a note i'm just going to stick a note off someplace and again one of the things that that note can do is surface a event so i can capture the fact that this virtual machine was deployed without the azure security center agent i can get i can get that hooked via the event hub through the event hub in turn i can trigger some sort of automated workflow that says something like well go put the agent on it or say something like well go send go send a note to mom and intel on this machine for coming here coming here without uh the stuff it's supposed to have uh that sort of thing um most organizations again um this is probably not you know you could change the mode of this from audit if not exist to deny um you would probably create quite a few enemies um in your it staff and your user base especially if you change audit policies to deny policies right off the bat it's very often the case that um would that people mean well um but they don't have the"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:55:39",
        "seconds": 3339,
        "text": "quite a few enemies um in your it staff and your user base especially if you change audit policies to deny policies right off the bat it's very often the case that um would that people mean well um but they don't have the maturity of the ability to deploy assets that are 100 percent um compliant especially if they've a new policy so what most organizations do is implement a policy with audit and you can see where that paul where the violations come [Music] basically by looking at this compliance report so in this case i can see i've got some stuff that's non-compliant if i click on it i can see right here one of the things that are not compliant i can actually drill in and it will tell me the assets um that are not compliant um so it's uh and i believe it is uh i think it's right here so there's a way to actually pull this information as well i don't remember it off the top of my head but you can pull the information from this of the assets that are not compliant especially you'll see that most of these things that i'm not complying with right now are high level you you know this data protection one you don't have any sort of um you don't have any sort of implementation of a firewall or any other sort of data data exfiltration monitoring on your subscription well that's true but that's because i don't have anything in it so um again i can identify that the assets are non-compliant um i can see what's not there and i can actually go ahead and see the things that are not correct and do something about them from here it's actually easier to do this from the security center itself so and doug thank you that was that was excellent um bringing the context there what is the mechanism through which uh azure allows this all these uh policies to be grouped as a unit because they're all under this asc default thing yeah so that's an initiative so when we look at so when we look at policies again that's basically what's called an initiative in this particular case um i'll go back over here to um definitions um in this case what i'll do is i will filter down for initiatives so um and when i do that i should see come on give me the initiative oh so here's the initiative it's like four i'm sorry didn't mean to click on that so for example here's an initiative that is the nist sp 800 171 r2 initiative this basically implements all of the recommendations that are in the nist 800 171 recommendation again you'll see that most of them in this case are in audit mode we do have a couple that are in modify mode in other words what it will do is it will automatically apply um a system manage identity um on a virtual machine that doesn't have any for example right um the in this particular case the assignment right here of asc default contains all of these initiatives so when i create these initiatives these groupings of all my policies i then assign them to the subscription it is this asc default assignment that contains all of these policies so in each one of these initiatives is a policy or in each one of these initiatives multiple policies within this assignment are multiple initiatives so they appear grouped as a single thing even though they're all interrelated or rather even though they are all addressing different requirements of my governance plan and so just like uh like you can assign an individual policy create a policy assignment to a to some resource scope like a subscription as you would you wouldn't you could um uh apply the initiative with the same mechanism yes absolutely so and i can do that um typically the way i would do that if i was automating the solution end to end right so if was automating this end to end um let's suppose i'm using azure devops if i'm using the raw devops product out of the box um and i'm not going to bring in any third-party tools the way i would do that assignment both create the policy add the policy to an initiative and then um apply the initiative with an assignment to a subscription or a management group of the like the way i would do that is with powershell so in azure devops i would basically call a worker agent it would that worker agent in turn would run powershell and it would pull from get um it would pull from github or some other repo source all of my templates and use powershell to execute them that's typically the way i would do it natively in azure devops increasingly and this is a pro tip if you take nothing else away from this com from this conversation uh take this um increasingly what you are seeing organizations especially large organizations want to do is use terraform terraform is extremely popular especially with large organizations and the primary reason why it's popular is because theoretically i can describe anything anywhere using terraform so i can describe in terraform what a virtual machine looks like in aws what it looks like in vmware what it looks like in azure what it looks like in gcp uh google cloud platform i can describe"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:00:43",
        "seconds": 3643,
        "text": "anything anywhere using terraform so i can describe in terraform what a virtual machine looks like in aws what it looks like in vmware what it looks like in azure what it looks like in gcp uh google cloud platform i can describe it i can use a description in terraform a module that describes a virtual machine and theoretically therefore based upon that one basic description be able to deploy it anywhere i want in any public cloud any private cloud and on-premises as with most things that are described that way it's uh you know be careful of the snake oil you're buying i wouldn't call terraform snake oil but i would say that rumors of its cross-platform support are exaggerated um like all things um there are nuances and tricks not everything that terraform can do is supported in azure in aws for example you could do some things in aws that you can't do in azure and vice versa um more but that notwithstanding it's that's a question of maturity and it's very clear to me that the market the it market especially the high end it market the fortune 500s out there have identified terraform as basically the next the best thing since kubernetes so you know how you can't swing a cat without hitting somebody who wants you to have kubernetes skills the next big thing the thing that if you wanted to learn a skill you would be able to start pretty much asking whatever you want for price i would say is terraform if you are a skilled terraform developer if you demonstrate that you can write modules and configuration files and get them to execute well in a pipeline you are going to have a job for a while yet um so if anybody out there is looking for a skill to get skilled up on that they think is going to be in high demand and you don't particularly think much of kubernetes i would really really recommend looking into terraform it is a very hot commodity right now i see a hand raised but so i would use terraform or something like that if i was going to deploy these as well to answer your question directly i see a hand raised but unfortunately i can't see whose name that is so my apologies oh looks like it's uh jeffrey hi there um i had a question mainly on tagging strategy versus your topic feel free to stop but um one of the things that we're trying to do is you know rely on tags to uh specify you know network access between you know one resource or another um do you have any experience with that and maybe can talk about um any you know potential pitfalls or caveats that you've run into in you know any of your your deployments sure absolutely so if i understand if i understand what you're trying to achieve correctly what you're saying is asset a i want to know i want to know the network relationship between this thing over here and that thing over there so i want to know um for this asset over here that's network connected what is its connectivity to virtual machine a what is its connectivity virtual machine b do i have that right or yep okay yeah typically i would not recommend i would not recommend using tagging to solve that problem um now keep in mind there's a there's a twenty dollar solution there's a five dollar solution and there's a fifty cent solution um the challenge with using a tag to i think you could do it don't don't get me wrong yes you could say um i'm going to define a network group i'm going to where i'm going to define a group of assets that should be able to communicate to each other and i want to tag them so that i have visibility into the fact that they should be able to speak to each other absolutely you could achieve that with tagging my concern would be that that is um that's a configuration variable really um and i think you need to be careful using tags to specify what the configuration on an asset should be um that's typically the solution i would have toward that and i want to be real clear that this is will be real clear this is a consultant speaking to you not a guy who's actually got to do it typically the advice that you would get from a consultant like me is for that sort of traceability what is the network connectivity between device a and device b i want to do that in a configuration management database of some sort i want to have that in my servicenow catalog i want to have that in something else that's tracking what the correct configuration of that asset should be and if i'm using something like terraform or the like i can actually have a supporting file that describes that right so i can i can have in the deployment solution not necessarily on the asset itself but the deployment solution some sort of record as well that indicates virtual machine a should be able to speak to virtual machine b so that i would say is so i would say that that solution the make a note of it and stick it in the spreadsheet is the 50 cent solution right um i don't know is that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:05:45",
        "seconds": 3945,
        "text": "virtual machine a should be able to speak to virtual machine b so that i would say is so i would say that that solution the make a note of it and stick it in the spreadsheet is the 50 cent solution right um i don't know is that that's that's largely unmanageable the challenge with that is it comes out of date very quickly more typically the solution that i see organizations use to address network connectivity is some sort of net flow mapper there are a number of tools that can do that um but so if the challenge is if the challenge is i need to validate that virtual machine a can speak to virtual machine b and my azure presence typically the way i would audit that is with network watcher um in in the azure tool network watcher and just make sure that i can actually do it and actually see the latency and that sort of thing and set up some sort of alert you might have that network watcher um maybe pumping some of its telemetry to log analytics or the like or doing something along those lines so if my concern is i don't want virtual machine a to stop talking to virtual machine b or i don't want any network changes to affect their ability to communicate with each other i would then set up log analytics to basically capture when those two machines aren't capable of speaking to each other anymore via receiving telemetry from network watcher and then i would basically create a logic app or the like that would surface to me an email saying hey virtual machine a can't talk to virtual machine be as of this particular date and that would tell me okay i need to go and look at my deployments somewhere around that time to see who screwed up the network that's the five dollar solution the 50 solution would be to use something like an ipam solution um so using a full-fledged ip address management solution that includes things like dns management um and that sort of thing i forget the name of the one that everybody uses um anybody if you know the name of the thing that i'm thinking about it's something or other one or i forget it's called ipam ip address management a lot of this particular solution i'm thinking of includes things like dns routing uh and actual network latency management tools like that have the ability to also audit um the ability the ability of it has the ability to audit network change you can use to all that said one of if what you're really saying is what i really want is to ensure that my networks are not changing without me knowing about it that there's no changes to the network without somebody being alerted to it or a test being triggered the way to do that and i guess i would call this the 10 solution it's probably the way i would really recommend doing this is saying on everything i'm going to create a uh i'm going to create a policy and what the policy is going to do is it's going to watch for any time or i'm going to create a yeah i'm gonna create an event trigger i'm actually gonna watch the activity log in azure i'm gonna have it raise any single time and i could do this with policy or i could just do it with the event grid i'm sorry with the with the event grid in azure i'm gonna watch for any off the off the activity log i'm going to watch for any time that somebody makes a change to a network security group or deletes or changes a subnet and and if that change takes place i'm going to audit whether or not it affects that change that network security group change or that subnet change affects either virtual machine a or virtual machine b these two machines that have to speak to each other and if that happens i'm going to do one of two things if i'm super sophisticated i'm gonna kick off some sort of pain test i'm gonna go ahead and kick off some sort of test that's gonna say hey virtual machine a make sure you can still talk to virtual machine b and vice versa and if you guys can't talk to each other let me know alternative would be i'm just going to go ahead and send somebody an email and say hey johnny just changed the network security group rules for the subnet that virtual machine b lives on you might want to go look and see make sure that virtual machine b can still talk to virtual machine sorry i didn't want to interrupt you but um the big the big thing i'm trying to get at is like you know the cloud's supposed to be dynamic um if i have resources that are being spun up and spun down via like nsgs they can understand tags and you know we want to be able to spin up new resources apply the tags and have the nsd rules apply to those resources sure yeah absolutely yeah so that is a very i think that's an interesting automation case right i think you can make an automation case for that so if it's if it's i've got a not necessarily a fungible environment but it's an environment in which i'm bringing things up and occasionally getting rid of them and what i want to do is make sure that i can provide at the time that i execute the provisioning of that virtual machine for example i want to make sure that the network is completely ready for that asset to come and then i may need to provide certain custom network rules to that asset yes absolutely in that case that makes sense if you if you can especially if you can narrow the configurations to say a dozen or fifteen if you could narrow um the required configuration on that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:10:48",
        "seconds": 4248,
        "text": "provide certain custom network rules to that asset yes absolutely in that case that makes sense if you if you can especially if you can narrow the configurations to say a dozen or fifteen if you could narrow um the required configuration on that asset to you know a manageable number of templates basically it's very easy to say at run time when i deploy this asset i want something to inspect the asset to pull the tag off of it to identify to pull the tag off it that says what its networking rules should be or what rules i should apply to the nsg as a result of this machine showing up and then i want some routine some sort of service to go and make those changes that's a very clear case for a logic app and that's a very clear case for the event grid so what i would do in that case is i wouldn't necessarily use i wouldn't necessarily use a policy although theoretically you could use a policy to do this as well um i would actually say i'm going to have a logic app the logic app is going to listen for any single time that i create a virtual machine in that particular create a virtual machine it's going to go ahead grab that virtual machine's definition pull the tag on it that tells me what the network configuration should be it's going to identify the correct it's going to identify that correct network security group and it's going to modify it i might not actually be able to do that with a logic app now i think about it but i could definitely do it with a function so i might do it with a function instead just because it's a little more flexible but yes there's absolutely an automation solution you can do there and i might be wrong about this but again depending upon how you do it you theoretically could use that same methodology to call azure devops so you could actually maybe even have a devops routine that responds to a web hook that gets fired off by the fact that the machine happens and the value in that is you have it right there in your total deployment pipeline so the same pipeline you use to deploy the virtual machine you could use to manage the network settings as well completely automated based entirely upon the tag that you associated with a virtual machine that tells it what network configuration to apply all right thank you it's complicated um you know that you know if you want i can you know i can quote you that but it's going to be six figures so it would take it would take some time to do that it'd be it'd be a couple months of project for somebody who knew what he was doing looks like there's a question in there um just solo wins question mark from uh edgar i'm not sure i i understand what that is maybe yeah my apologies yeah so solo wins is a um it's a it's a software program um arguably the most popular software program that's used what's called itsm so it service management so as we all know um something breaks there's got to be a ticketing system of some sort right for example there's got to be some means of being notified that a change or a break or something like that happened and some sort of means of auditing the resolution of that request so um when you call you know when somebody calls the help desk help this guy answers solo wins is basically the database into which he enters your ticket and he tracks whether he tracks the resolution of that um solarwinds is more sophisticated than that it has additional things in it but basically when i'm talking about solarwinds i'm talking about arguably the most popular solution for tracking i.t incidents and managing them and keeping record of them and identifying what they're used for um again the reason i keep repeating solar winds is because everybody uses solarwinds um if you get out there are other solutions but much like there are other ways to do containers everybody uses docker much like there are many ways to manage container instances but everybody uses kubernetes there are many itsm systems out there but everybody uses solarwinds awesome any any further questions for doug sure yeah i would agree edgar solarwinds has many problems um and it is uh the worst thing you can do to solo wins is try to make it better um i am yet to meet the organization that's customized solar winds that wound up with what they were bargaining for um but again um you know it's what everybody uses so um while it's painful at least it's painful for everyone so um the brand is also unfortunately uh tarnished due to uh one of the most notorious uh data breaches ever data breach didn't do them any favors either agreed yeah um it you know it is it you know there are better i would argue there are better programs out there too um and certainly it is you know for most organizations especially that aren't enormous enterprise orgs solarwinds is probably overkill you don't need all the things it can do um generally speaking you'll be better off using something much simpler but again i just promise you that if you go and talk to any of the logos if you see any organization with more than 50 people on the it team um i've got five dollars that says they probably use solar winds or at the very least are at the very least used to use it right on okay well uh left call here i guess um in just a couple of reminders one is um if you so you should definitely follow doug's advice about policy and tagging they work nicely together and that will help you from being an example in our december first talk about azure security problems uh so we look forward to seeing you all on our if you're interested on december 1st that's the last event of 2021 and the video of doug's excellent talk will be posted soon it usually shows up the next day and you'll be able to find it at youtube.com boston azure great thanks doug this was fantastic you you took a a a a topic that has a lot of loose ends to it brought it together in a really coherent way and uh really uh uh gave us a great explanation many thanks thank you all appreciate your time take care everybody good night "
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Automating Azure with Powershell and the Azure CLI with Bob Crowley. This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.. he uh he is a local he's comes he's uh one of our friends from up slightly up north in uh uh new hampshire i'm sorry in maine actually a little further right uh yep um uh we've we've run into each other uh at a number of events over the years so it's good to have him uh come and uh speak to boston azure his uh background in brief as he's a senior software developer in portland maine where he builds solutions on.net and azure he's uh these are his words he's been writing bugs for over 15 years uh as we all have probably mostly in the financial service financial industry despite or because he's still not knowing the difference between a debit and a credit i don't think it's important to know the difference between those two probably i don't even uh in his free time in his free time he likes to make the most out of uh both weeks of maine's summer uh he's he's really into it he takes care of he takes real deep advantage of both summer weeks and he's uh he likes fishing and kayaking i find him on the twitters at contrived ex and contrived example.com is his block and this information is on the meetup page where you can find it as i mentioned this we unless bob prefers we don't we will post this to the youtubes and um with that let join me in welcoming bob great to have you here bob over to you all right thanks bill um yeah youtube is fine if you want to post that up that's perfectly fine with me um i also think i get to consider myself an international speaker now that we have someone from vancouver and serbia in the meeting right i mean that sounds okay that's totally correct all right been looking for that designation for a while so got it great all right so i'm going to be talking about automating azure i'm going to be talking about powershell azure cli arm templates and the new bicep language for for creating arm templates now i'm not um you know i'm not a scripting expert i'm not a super expert on any of these particular topics i'm just a developer that didn't want to be doing tedious things all the time and so this talk is kind of more like um even if you're not scripting all day long you can still make your life easier in azure um just by learning a few things we're not going to go real deep into a bunch of commands there's an ungodly number of commands there's there's no way i could do it justice um even in a week but we're going to learn um a couple of commands and we're going to learn how to do some queries and pull data out of them and maybe a few tricks and tips and things that aren't quite as obvious so hopefully you learned something a couple people already mentioned that you know they have some powershell experience some azure automation experience feel free to jump in if you have anything to add and if anybody has questions jump in at any time um we're gonna kind of do this in blocks you know power shells take a break cli take a break arm take a break for questions all right let's start the slides so if you want to take a screenshot or write this url down all of my resources are on the urllist.com just a caveat if you do actually type this out make sure you spell it correctly that's one l in the url list if you type two ls let's just say i hope you have good malware blocker all right so everything in azure is automatable so if you're familiar with clicking around in the portal all of that stuff can be done in the azure cli or powershell or arm templates again we're going to look at all these three things we're not going to talk about any rest or sdks you know writing code with c-sharp or java or whatever we're just going to strictly talk about command line stuff and my github repo is at the bottom there too all of this stuff is on the github repo if you want to take a look at it all right so this is a quote right off of that link that's on the screen command line interfaces environment create manage azure resources it's available across all services designed to get you working quickly with the emphasis on automation and that's what's that's what this talk is really all about is automation it's cross platform it works in bash shell power shell terminal cloud"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "designed to get you working quickly with the emphasis on automation and that's what's that's what this talk is really all about is automation it's cross platform it works in bash shell power shell terminal cloud shell which i'm gonna um show you supports long-running operations configurable so let's say you're running a bunch of commands you you may not want to put you know what subscription you're using or what resource group you're using in every single command you can you can set that as a configuration setting and it'll just automatically use that interactive mode so assuming i don't forget i'm going to show you cli interactive which is a pretty cool feature and i think one that is off of people's radar quite often i'm not going to go over installation other than to say it's very easy you know it's just standard insulation msi on windows etc if you're familiar with installing software you know there's nothing new here and now let's do the demo all right so if any of my fonts are too small or anything let me know and i'll boost things up but i think i've bumped it up to where it should be pretty good so what i've got here is a demo ps1 file i just said azure cli and here i have a powershell script well you can run azure cli commands in a powershell file and that makes it convenient for setting variables and using them in subsequent commands so that's why it's a powershell script but these are azure cli commands and you can recognize as your cli because they all start with a z okay so that's kind of where the title of the talk came in the land of as so in azure cli it's a z something in powershell all the new powershell commandlets start with a z as well so the first thing you want to do when you're using the cli is log in and i've already done this but what you're going to want to do is use the easy login command and you can pass it a tenant and that's your azure tenant and if you have more than one subscription i i suggest you also run this command as your az account set and set your subscription because if if you don't you're going to be connected to your default subscription and that might not be what you want you might be creating things in a subscription that is going to cost you money that you weren't expecting it to right so just keep that in mind you don't need to do this but it's probably a good idea and i'm pulling these values out of system environment variables just so i don't have to check in my tenant and subscription ids into github all right so all of these commands are pretty simple like i said we're not going to go deep into all kinds of different commands we're just going to basically see how to use the azure cli and so one of the easiest commands right here a z group list so what this is going to do it's going to list all of the resource groups in the subscription that i am connected to and in visual studio code you can highlight a section and you can hit f8 or you can press this button up here and it'll run just what you have selected so it's a convenient way to run part of a file and so here's the output okay there's a whole bunch of resource groups in the subscription that i'm connected to notice that it's json output okay so that's one of the first differences between this and powershell that we're going to see all of that output is all json if you want to work with it you're going to have to query that json and pull data out all right so what i'm going to do next is i'm going to create some resource groups and then i'm going to set some properties on them and then we're going to write some queries so all i'm doing here i need some random resource group names because they have to be unique in the um in the azure tenant so i'm using um some actually some dotnet here system.io.path i get random filename and that's just that's just so i get a random name it's you know i don't care what it is for the demo so i'm doing that three"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "i get random filename and that's just that's just so i get a random name it's you know i don't care what it is for the demo so i'm doing that three times so in the first one here i'm creating a group where the location is the central us and i'm doing a query id so that's one of the first ways to pluck data out of azure cli okay so you write a query you say i want to get the id and that's dumped into this powershell variable id okay now i'm on that same resource group because i'm using that variable i'm going to set some tags so if you're not familiar all resources as far as i know all resources in azure are taggable so you can add like name value pairs for whatever reason you might want so i'm going to add some tags to the resource groups notice this third one down here i'm creating it in the east u.s and i'm creating different tags on every one of them okay so if i run this set of commands okay that didn't take too long all right so notice the json output here i got a random file name as expected i got my tags alice test and true and the location is central us i'm just going to run these two together save a little bit of time okay there's one of them and there's the other one so hopefully over in the azure portal we should be able to see this so if i go to look at resource groups so here we've got looks like i still have some from other demos but you can see we've got a bunch of random named resource groups in here so just like that i mean just creating resource groups is super simple but now we want to query them so let's say we wanted to get resource groups that are located in central us so i'm using the query switch here and what this is is a james path expression okay so if you're not familiar you can go to you can do a search for james path so james path is a uh a method to query json and it's not a microsoft thing it's not an azure thing it's just something that the cli supports and so you can go here and you can do a tutorial you know you can run all these queries and stuff right here in the browser it's a really good resource for learning james path it can be quite complicated um depending on you know your object graph and depending on what you need out of it it can be really complicated so to get good at it you really need to practice but we're only doing some fairly simple things here so what we're doing is a recurring location equals central u.s so we should get two resource groups back for this okay well we got more because again i didn't clean up my resources but notice all of them are in the central us okay so that's probably one of the simplest james path queries next one is we want to get central u.s resource groups that have tags okay so here we're getting just the tags okay before we were getting a whole bunch of information about the resource group and now we're getting an array of objects that are just the tags from the resource groups so that's the dot tags notation and you can further pipe that out so here we go looking for resource groups in central us that have tags where the purpose is qa okay there we go there's only two in there right now okay we can keep going we can you know take that same output we can do dot owner okay now we have an array of just the owners and this is getting to something interesting um i promise so notice that that output was an array okay so we have the"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:15:14",
        "seconds": 914,
        "text": "okay now we have an array of just the owners and this is getting to something interesting um i promise so notice that that output was an array okay so we have the brackets here we can get index zero out of that array okay they're both wally so that's a little bit underwhelming but notice that it has quotes around it so that value actually has those double quotes and i'm pointing this out on purpose because this can throw errors into your scripts it's not necessarily what you want and so the recommended way to get just the string out is after you do your query you can do an output to a table separated value or tab separated value so output is another switch you can add by default it's json so you don't have to do output json it's just there by default but you can output to a table and you can output to tab separated values and if you do it this way you're just going to get the value without the quotes okay and if you're using this in subsequent queries this is probably what you're going to want to do all right so that's a real quick introduction to james path again you can research it there's all kinds of neat little things in there so but like i said it can get really complicated so maybe you don't want to learn james path and write these big long strings you know again like not only is this starting to get complicated but it's just a string right so you have to get the syntax right and you know probably trial and error but you can use some powershell here so you can run a cli command and then you can pipe that into the powershell convert from json and so what that does is it turns your output into a powershell object much easier to work with than json and jamespath okay so let me run these two at the same time okay so notice that's our output we actually got a powershell object this is the default formatting for output but it's not json you know it's a nice it's a nice format that we can work with objects and again we can do the different properties of that object with dot notation there we go get a nice table and then i'm going to clean up so easy group delete and i can throw no weight on there and then it's basically going to be asynchronous i don't have to wait for it to finish and in case you're not aware if you delete a resource group everything inside that resource group gets deleted it's a really great way to just throw everything away you know if if you're conscientious about putting things in proper resource groups for demos or temporary things you can delete them all in one swoop so i'm going to run that the reset color now i'm not getting color here i don't know what's going on exactly but um you can you can mess up your console color and you can get output that you're not able to see because it's like black text on black background and so reset color is a good thing to do all right don't forget az interactive so i think this is the first time i haven't forgotten to do it right now and maybe that's because i gave myself a no but what the az interactive is actually let me start it over here um this is the windows terminal okay and ac interactive helps you write your queries so if i do az interactive it's going to spin up this tool and this tool is something you have to install separately this does not come with the cli installation but it drops you into this it's a terminal window but it's a it's a very smart terminal window so let's say i wanted to list some groups easy notice it's already um showing me some commands i've done before a z group okay and space and then it's telling me what what i can do"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "so let's say i wanted to list some groups easy notice it's already um showing me some commands i've done before a z group okay and space and then it's telling me what what i can do with the groups i can list them i can create them so let's choose list and there it's listing my groups i can do a z key vault secret name okay and then when i type name so not only does it know the switches and the commands it actually interrogates my subscription and it says oh you have two key vaults so i'm going to show you what two key vaults you have and you can pick which one you want to use and so again az interactive separate install super super awesome for um learning cli or just writing commands that you're you know not terribly used to running i really like this and glad i didn't forget this time okay that's the end of the cli portion does anyone have any questions before we move on to powershell i have one quick question yep hi my name is will ryan thank you for taking the time to do this i have one quick question it seems to me that um cli i'm just wondering off top my head i've mostly interacted with getting data out of azure by calling the azure rest apis okay which return data in a similar json format and i'm just wondering if the cli if you know if it's underneath the covers calling the rest apis uh i i actually don't know i i actually have no idea but i've got to imagine at some level there's some convergence you know between all right i'm imagining there's more because because i know that the powershell commandlets i believe called the rest apis um and i do similar things where i iterate through the resource groups i iterate through the different types of resources in the resource groups then i can ask each resource what metrics do you expose so but um this is a really great demo thank you great thank you i i cannot slight color is uh this bill i i do believe that everything that's outside of azure uh resolves to the same rest api so there's a a net you know c sharp sdk there's a there's a python uh you know there are python libraries and javascript and all across you know the whole development spectrum go their their libraries those all are implemented in terms of the of the rest apis they just make them more convenient and that's also my understanding that powershell and cli are no different and to a big degree the portal is the same so when you use the azure portal interactively it's also resolving to the same rest apis although they may have some additional apis they almost certainly have some additional apis that we don't have access to but yeah rest apis are uh at the bottom of uh almost everything you do in azure that makes sense thank you and i i have had to access those things like for example if you wanna maybe they fixed it by now but if you wanna set quotas on application insights you have to call raw rest endpoints which you can find them calling in the portal and you can just go oh i'm going to do that too but you can also use what's called the the azure resource explorer and it shows you that that structure that you would be able to send with those requests in the documentation for the scli there is an as space rest section and that lets you just do like a raw request and and some of my automation scripts i have to do that to take care of things that aren't built into the commands themselves so i'd imagine the whole thing is rest all the way down the rest api yeah that makes sense yeah everything on top of rest is a convenience yeah yeah both of them use the rest api by a little bit different ways so when you use the azure cli uh some of the command commands for creating resources are actually i'd important and in azure powershell they're not so implementation under the hood is not exactly the same but they talk to the same apis that's good to know all right anything else so i just i have a real quick question um i believe in the in in the powershell you can use azure rm and az commands can you use"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:25:25",
        "seconds": 1525,
        "text": "all right anything else so i just i have a real quick question um i believe in the in in the powershell you can use azure rm and az commands can you use the azure rm commands in cli yes you can okay but you can't use the rm commands and the az commands you can't have them both installed at the same time yeah yep but i understand there's like a shim that you can install so that you can still use your old scripts yeah but the cli is a whole separate install from the powershell commandlets okay thank you yeah okay um thanks for the input everyone that was great i love that you know i'm learning and everyone's learning so all right so powershell um just like the cli i'm starting off with the microsoft definition here it's pretty much the same thing the same use case as the cli they try to make it easy to learn you know it keeps standard standard commands it's available on powershell 516 and higher again it's also cross-platform works in all the terminals discoverable so get command get help those are commands that are really great for figuring out what commands are even available and how to use them the apis are consistent as far as you know with the the verb and the nouns interactive environments are available so you know plugins for vs code or powershell ise you know they can give you the intellisense and you know command help as we've already seen it's object oriented not text output so it can be a lot easier to work with you know the data coming out as opposed to you know json data uh again not going to spend a lot of time on installation that's easy enough to look up but you can use msi or you can use powershell to install the powershell commandlets that's the command right there connecting to azure so again we connected with the cli and there was a little caveat about maybe choosing the subscription you're connecting to as opposed to letting it just automatically connect to your default subscription same thing goes here but it's a different connection you use connect az account you don't use a z login and that's the end of my slides we're going to go to the demo and this demo is basically recreating everything i did in the cli except i'm doing in powershell so i'm going to go a little bit faster because we already know what it's doing i'm just going to highlight the differences but again here's here's how to log in um connect a z account and you know pass that tenant is subscription to make sure you are where you think you are all right so again we're going to start out by listing resource groups so get a z resource group and so we should see all the same resource groups we saw before but again it's not coming in as json it's powershell objects okay we're going to create three random resource groups again i'm doing this one a little bit differently than the other two so i'm still using get random file name um i'm using new az resource group as the command and then for this one i'm doing a set a z resource group command on this resource group to set the tags okay so it's two separate commands to create the resource group and set the tags on it but in these two i'm doing it all in one step i'm adding the tags right at the same time so just to show you a little bit of variation there so i'm just going to run all of these at once and there we go so we see the random file the random names you see the tags again it's nicely formatted formatted in tables now we're going to start querying just like we did with the cli but we're going to do a powershell way so what we're going to do is use our get azure resource group that we've been using and pipe it to the where object where location equals central u s so that"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:30:31",
        "seconds": 1831,
        "text": "so what we're going to do is use our get azure resource group that we've been using and pipe it to the where object where location equals central u s so that came back pretty fast those are all central us um we're gonna pipe that again to where you know tags are not null so if you recall with the cli all i had to do was ask it for tags and it only returned me the ones that had tags but now i have to actually say where the tags are not equal to null there we go i'm glad that's nice and speedy that's not always the case on demos um okay so we're gonna carry this a little bit further so we're gonna look for tags for the purpose equals test and apparently i don't have any whoops but i think you get the idea but notice how this is it at least to me this makes more sense than writing james path queries you know which can get complicated they're strings they're just they're just harder to work with in my opinion and this is almost a little bit link like if you're familiar with c c-sharp link you know this this is kind of intuitive all right so again i'm going to clean up and reset my console color there and that's just going to delete all of those random resource groups alright so that was a lot faster we just did the same things as cli i'm just just showing you a few of the ways you can query are there any questions about these powershell commands all right so i've got a question about those are those expected to stick around long because it seems like the new as cli is on a path to replace everything um i don't have any insight into that but i do think they will stick around for a long time um i i don't think they're going anywhere they're cli and powershell to me they have very much overlapping use cases but also slightly different use cases i know that um you know bill talked about the az204 exam group in the slack channel i took that exam at the end of july and it was full of powershell i don't want to violate the nda or anything but there was there was really a lot of powershell to the point where they're like you know which command do you want to use here and you know it's like this long command with you know docker container this and it's like so they're making they're still making investments i i do not think the powershell commands are going anywhere and i think they will continue to make a lot of investment there do you have any insight into that bill so alexander here i can jump in because i just had a chat with the pm for azure powershell and uh azure partial and azure cli will be with us for a long long time yeah the reason why we have them both is that at the time when azure powershell started it was only for windows because the powershell at that time worked only on windows and they needed something for linux and mac so they introduced azure cli for it so now we have two and they are developed in parallel mostly overlapping but the service coverage is not consistent so there are certain services that work only in azure powershell or in azure cli and the promise is that at certain point both of those cli tools will practically cover everything in a pretty much the same way that's kind of a goal so that you can choose instead of being forced to use one or another great wow we have a great resource there so thank you for that all right if there's nothing else i'm going to move on and talk about cloud shell okay so cloud shell if let me bring my terminal back up so i"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:35:34",
        "seconds": 2134,
        "text": "all right if there's nothing else i'm going to move on and talk about cloud shell okay so cloud shell if let me bring my terminal back up so i was doing things in the terminal here you can do things in a powershell terminal you can do things in a regular command prompt terminal you can also do things in the azure cloud shell okay so what i'm gonna do is i'm gonna see what my slides say here so i got a couple screenshots supports powershell sports bash so you know you can choose if you want to use bash or powershell in the cloud shell it has some built-in help i'm going to show you that you know font settings file management you can upload and download files and i'm going to demonstrate running a file that i've uploaded web preview i put this in here because i thought it was interesting but i haven't had time to really dig into it and it appears to let you generate a website right here in powershell in the storage that's backing it i'm not sure what use that's for yet but it looks interesting and i encourage you to you know research that in case um in case it's something i'm really missing there's an editor so i believe this is the monaco editor or what started out as monaco editor um i'm not sure but i think it has vs code bits in there so you have a fairly good editor right inside the cloud shell and now let's demo it so again in in the microsoft terminal you have the option to do cloud shell so you could do it right there in the azure portal if you've never noticed this little icon you've got cloud shell right here and you can start that up if you've never run it it's going to set up a storage account for you behind the scenes to store things and this gives you a power shell or a bash shell that you can run your azure cli commands in or your powershell commands a real advantage to cloud shell is that everything's already installed so you don't have to you know install anything on your machine necessarily it's just already there and it's already connected to your azure subscription so here you get a split screen that may not be what you want so something you can do is go to shell.azure.com and i hope i don't have to do the dance here okay good so it gives you a full screen um cloud shell environment okay so if i were to let's say um if i were to open the editor which i talked about i can see my file system here i can see that i've got some scripts so here's a powershell script it's obviously pretty simple but i can run this get ac subscription so i should be able to run get some and so there you go i've got my subscriptions so what i just did was this ps1 file i've uploaded this to my azure cloud shell at some point in the past and it's just sitting there for me and i can you know do any kind of powershell script actually and that's convenient if you've got something that you need to do on a regular basis obviously you know it's just sitting there you can do it from anywhere um you can even do it from your phone so here's my phone and i've got an azure app installed this is the official microsoft azure app and if i open this up okay so i've got cloud shell right down here so i can run this same cloud shell right in my phone and if you're thinking well why would you ever want to do that um"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:40:37",
        "seconds": 2437,
        "text": "okay so i've got cloud shell right down here so i can run this same cloud shell right in my phone and if you're thinking well why would you ever want to do that um i haven't had a great reason to yet but the interesting thing here is if you're mobile maybe it's three in the morning and you get a phone call you know something's broken you have a script that you know fixes it you can drop in here and you can you know run your get sub you know someone just has an emergency they need to know all of your subscriptions right so there you go you have that script already there you can just run it right on your phone and go back to sleep so hopefully someone has a better use case than that but i just wanted to demo it and i think it's pretty cool that you have that power you know right on your phone you can access those files you uploaded and you can do anything you want all right so that's that's a quick overview of the cloud shell again you can do it right from your terminal if you'd like to do that instead a bunch of different ways you can run it any questions about azure cloud shell is that something that you can share with other people on your team like so you can make like a script and they can uh let me phrase this a different way with more context so like i might make a bunch of scripts but like i worry that my teammates might be too lazy to proactively get them yeah um so like you were saying like three in the morning i might need someone else to run that script is there a way with cloud shell that that script can just be there and you could like tell someone on the phone run this script that you've never run before like can you share that space you can yes you can choose what storage account you want to back this shell and you can give anybody access to that so um that's one way to do it if you just take all the defaults it's going to create a brand new random storage account and tie it in but there is a way that you can tell it the storage account you want to use and when people log in they're still going to log into their own session but they can be connected to that common storage account and get all those files all right anything else before we move on all righty now we're going to talk about azure resource manager templates okay so uh i think someone already mentioned a dislike for arm templates and that's not unwarranted necessarily it's very verbose it can be very daunting to look at a big script now this one i have on the screen is not very big but all it does is creates the storage account and it's already you know going off the screen um it's not the best um experience you'd say and that's where azure bicep comes in which i'm going to talk about at the very end but as your resource manager template does have its advantages okay for one thing it's very machine readable it's just json you know it's it's just json that follows a schema you can run these with powershell cli you can do in the portal you can use azure devops i'm sure there's many more ways that you can run these why would you use them it has declarative syntax okay describes what you want not how so you say i want a storage account you know you're you don't call an api necessarily you just say i want a storage account repeatable results so they're idempotent so if you run the exact same script a second time you're not going to get another storage account necessarily i mean it depends on how you craft the script but it will it will update new things in the script and it will keep the existing things the same orchestration so the correct order of operations is generally handled automatically although you can tell it what dependencies other things have um to make sure it does things in the right order it can perform parallelism so if you're creating a storage account and creating a key vault"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:45:41",
        "seconds": 2741,
        "text": "tell it what dependencies other things have um to make sure it does things in the right order it can perform parallelism so if you're creating a storage account and creating a key vault and you're setting up a managed identity you know these things are kind of mutually exclusive they can all be done at the same time and so you know it's going to parallelize those and save you some save you some time when you're running these built-in validation so the templates get validated before they're run modular you can compose templates from other templates you can nest templates inside other templates to give you some you know code reuse functionality this is one of the best things and any new azure service or feature is immediately available in arm templates okay unlike powershell in the cli which necessarily lag behind at least a little bit they may not lag behind long but with arm templates you can do absolutely anything in azure from the moment the feature is released and so that may be one reason why you have to use arm templates track deployments this is another great feature if you're running a powershell script or an azure cli script um you're just running the script there's no real um visibility into what's going on necessarily of course you get you get audit logs and and things like that in azure but with arm templates you actually get track deployments and i'm going to show you that policy remediation is done if you're not familiar with azure policy these are things that you can put constraints on resources in azure so let's say you don't want people creating a virtual machine that is you know a thousand cpus and the most memory in the world because it's really expensive you can write a policy to prevent certain skus from being created you can write a policy to require tags um it's a huge huge topic but policy remediation is done with arm templates ci cd so different ci cd systems support this azure devops obviously there's a you know a task that you can just drop into your pipeline and it will run the arm template exportable code so all of your resources in azure can be exported to an arm template so you can go into the azure portal and you can go you know choose the correct blade export it to a json file and you've got at least the starting point for an arm template that does um whatever that resource is typically you're not going to be able to use the template as is there are going to be some hard-coded things that you're going to want to parameterize etc but it's a really good starting point authoring support so there are different tools like vs code visual studio that help you write that json again it's it's not the most intuitive thing but you do get some help with the tooling this is the anatomy of a template okay so these files can get really really huge if you're deploying like a whole environment of all kinds of stuff but at the basic root of it this is what a template looks like okay just these sections and that's it these sections get really big but that's them in a nutshell and i'm going to go over each one real quick so schema schema is required um you can actually use this literal value right here this is not the most recent one if you're using a an ide that knows about arm templates like visual studio code with the extension installed it's going to say hey you know there's a newer schemer do you want to use it and you just say yes and i'll write it for you content version so this is required but it's not used by azure for anything it's just for your own use you know what version do you want to give to this template you know version one you can make this whatever you want the api profile so different resources have different apis but if you want to try to use a like a common api profile for all of the resources that you're defining in the template you can use an"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:50:45",
        "seconds": 3045,
        "text": "different resources have different apis but if you want to try to use a like a common api profile for all of the resources that you're defining in the template you can use an api profile kind of at a global level this is not required parameters okay so these are runtime values passed to the template you know if you're a developer you are familiar with parameters the great thing about the different tooling and the and the different things like azure portal they know how to interact with parameters when it reads and we're going to see this when a template has parameters the user interface is going to give you a place to type in values for all those parameters so it's kind of smart that way variables uh again somewhat like parameters but they're not passed in they're just reusable values throughout your script so you don't have to repeat or hard code anything but you don't want to functions so i found this a little odd you can actually write functions in json okay so it's a little strange right json is not executable code but you can write functions in json typically you're going to use the built-in functions quite a bit i don't i honestly i've never written my own function i just use the built-in ones and they've suited me just fine so far the resources are the meat of the script okay these are the things that you want to deploy to azure okay so the resources section is probably by far the biggest section and you can put storage accounts in here azure sql databases cosmos databases um key vaults i mean you can really stack it up and there it there is a maximum arm template size i can't remember what it is but it's pretty huge so you can you can deploy entire environments with a script outputs let you return values okay so these show up in i mentioned deployments earlier you can see a history of deployments with arm scripts you can see the output of your scripts in the deployment history and you can also grab that output from a subsequent arm template and use it as a value a common thing to do like here on the screen is a resource id so if you've created a resource you know you don't know what the id is until you've created it but you need to use it in another script this output is what you can use to um chain those scripts together all right let's do a quick demo not that one this one all right so here is an arm template this is one of the simplest ones that i could write um it's very short it's only deploying a single resource but i'm going to walk through some of the things that we talked about the slides so again the schema here's 2019 instead of 2015 content version again required but doesn't matter what it is here's some parameters okay so storage prefix is a parameter i just named that storage prefix i could have named it mickey mouse but i'm defining some metadata here so the type is a string it has a minimum length that has a maximum length okay the storage sku okay so the default value is standard locally redundant storage if you don't pass a value for a parameter it's going to use that default okay so that default can be really handy to save you some time allowed values so here's a list of values that it will let you use okay so if you try to choose something not in that list the template is not going to allow you to do that a location parameter that's a really common one and here we see our first use of a function okay so this is one of the built-in functions resource group is scoped to the resource group that this is deploying into okay so if you're not familiar with arm templates this is something that i had to wrap my head around at the very beginning you have to have a resource group first okay because this is deploying stuff into a resource group it's not creating a resource group so what this is doing"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "00:55:48",
        "seconds": 3348,
        "text": "head around at the very beginning you have to have a resource group first okay because this is deploying stuff into a resource group it's not creating a resource group so what this is doing is in the resource group you're deploying to you know grab its location and set that as the default value for the location parameter okay i think very often you want to put your resources in the same location as your resource group and so that just saves you some time so here's a variable and we're gonna introduce a couple of couple more functions that are built in okay so i want a unique storage name you know storage accounts have a dns entry they have to be unique across all of azure and so this is a way to generate a unique name and so starting on this end we're going to get a unique string again we're using the resource group function same one we did up here only this time we're using the id and we're using the unique string function and what this does is it hashes the result of this and that's the unique string it's the hash okay so it's not um it's not a random string it's it's a hash and it's going to return the same thing for the same input and we're going to concatenate the storage prefix okay so whatever we put in for this parameter it's going to be that value plus the hash of the id and that's going to be our unique storage name and we can use this multiple times throughout the script if you notice we're using it twice all right so that's our parameters section and that's our variables section so now we get to the resources section this is an array okay so you can put multiple resources in here the type are well documented type names so you can go to the resource explorer which was mentioned earlier by one of the attendees and you can see what um what type you need to use this is very specific and you may need to look it up you may have help from your ide but this is what defines the storage accounts in azure i have an api version if you need to use a specific api the name is coming from a variable okay so the name of my storage account is dynamic location is coming from parameters the sku is coming from parameters okay this is hard coded as storage v2 type of storage account and then properties here supports http traffic only so that you have to access it over tls there are many many more properties that you can set here i'm keeping it simple setting things that i need not bothering with things i don't need but if you were to export a storage account in the azure portal you would see many many many more things here than i've got so just keep that in mind then finally we've got the outputs and i'm not doing anything with the output you know i'm just demonstrating here that i'm going to have a storage endpoint object output from this script and the value is going to be the primary endpoints of this storage account so a storage account you know is a web accessible resource it has primary endpoints urls and what i'm doing here is i'm using a reference function to get a reference to that storage account now that it's already created okay the outputs happens after the creation of the resource and i'm grabbing the primary endpoints properties and outputting that all right so that's a walkthrough of this script to deploy it i've got a powershell script right here okay so new az resource group deployment and i'm going to give it a name i'm going to tell it what resource group i want to put it in again doesn't create a resource group it puts things in a resource group the template file on the storage prefix so this is a parameter this is a parameter so notice i'm stuffing some parameters right into this command right here storage prefix and storage sku those are not documented switches on this powershell command lib okay those are my parameters so if i run that with any luck and there we go awesome so gave me some output okay so"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "01:00:55",
        "seconds": 3655,
        "text": "command lib okay those are my parameters so if i run that with any luck and there we go awesome so gave me some output okay so told me what my parameters were and the values and here's the outputs okay so here the primary endpoints of that storage account that i created and it looks like it was done successfully if i jump over to the azure portal and close my cloud shell here we don't need that anymore then i go to storage accounts okay i should see i'm not sure which one it just created the bottom up it's what the bottom one yeah okay thank you all right so here's my storage account created sorry i'm just looking for um you know has anyone gotten um presenter blindness before i'm looking for deployments you could type it into the search deployments are on the resource go to overview if you go to overview then you have deployments so bob go to the resource group and look for the deployment it's on the resource not on a storage account yeah oh gotcha thanks deployments right here okay so i mentioned that deployments are tracked with arm templates unlike powershell and cli so what you can do here is you can go into your resource group deployments and you can go look at deployments that have happened okay and so here's some inputs that went into the deployment here the outputs that came out of the deployment and here's the template that was run for the deployment okay so you can even see the actual template you used and you can also see the parameters and variables right here okay so i think that's a great feature you know you have that traceability you have that history also you've got this you got this thing in azure called templates okay nice and you can just run them so if i go over here to templates i've got one template here so if i open that up i can i can edit it and i can look at it this is the same thing we've already seen okay should be pretty much exactly what i already ran but i have this deploy feature right here okay so if i upload a template i can go in and just very quickly deploy it at any time you just have to choose your resource group you have to choose any settings that you do not provide a default value for um that's random enough notice i've got default settings already in here i could change it if i want to you agree to the terms you click purchase okay so most of the time what you're doing in here is going to cost you some money so that's why it says purchase i had some validation errors so i'm not sure what that is i may have a error in my script but that's not important the important part is that in this templates section you can save a bunch of templates and just go in and boom boom boom deploy things okay i think that's the end of my demo for arm templates anyone have any questions about that bob i have one question sure um and that powershell command you did they did the new az resource group deployment you had a parameter file in there as a argument can you put in a i mean you have a you have the azure deploy file"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "01:05:57",
        "seconds": 3957,
        "text": "did the new az resource group deployment you had a parameter file in there as a argument can you put in a i mean you have a you have the azure deploy file can you add a parameter json file in there also absolutely um because like you like you say someone can enter the parameters and and obviously it passes it to the deploy so i just was curious no it doesn't come it's just called parameter file that's that's how i used to do my deployments back when i did arm like parameter file all one word i didn't know you could put parameters on the command line like that so i used to do it the opposite way so yes you can definitely do it so yeah all right cool that is a good way to you know to keep your parameters nice and clean and transferable that's why great thank you the reason why i'm asking you is because i need to create resources through a bamboo pipeline and this the way to actually run the command it's a lot easier you this will be a lot easier using that powershell that's more native than bamboo so that's really good right yeah awesome thanks you're welcome all right so we're going to move on um almost done here we're not quite done with arm templates because i want to talk about azure bicep okay so this is fairly new still in preview so it's not production ready yet but what azure bicep is is a domain specific programming language for authoring arm templates so this is something that's been missing with arm you know like i said armed templates can be hard to work with you know a lot of people find it difficult or cumbersome and so they develop this bicep programming language and if you um didn't catch it you know arm templates are on you know bicep is on your arm right i guess it's funny or something um but it's just an easier way to author arm templates it compiles down or it transpiles down depending on who you ask two regular arm templates so the output is exactly an arm template you will use it the exact same way you use any arm template it's just the way that you author it it's a little bit different and here's an example i'm going to go through an actual example real quick in the demo but again it's a very early preview it's command line interface so there is a you know a bicep cli there's a visual studio code plug-in for it of course just like everything how is life better with biceps so this is a paraphrasing right from this github link [Music] github azure bicep so this syntax is simpler than json you can break your project out into modules better copy and paste experience for instance um you know an arm template you have all your parameters all your variables in one section it's very rigid there's some some more leeway as far as variables in bicep scripts automatic dependency management so based on the symbolic name of things you're using it can figure out the dependencies between things so as long as you craft it correctly you can manage dependencies between resources that way and it has richer validation and intellisense so this should be a pretty quick demo so what i've got here is a main.bicep file it doesn't have to be called main but the file extension is bicep and so again this is basically recreating the arm template that we just looked at okay we got parameters we've got variables here's the way you describe a resource looks pretty pretty similar to the json but it's you know not quite um you know things aren't all strings you know these are actual variables it you know it is an actual programming language and then output here is the id of the storage account instead of the primary endpoints what you do here is now once you write your bicep file set build then give your file name okay and over here if you saw it real quick main.json popped in if"
    },
    {
        "speaker": "",
        "title": "Automating Azure with Powershell and the Azure CLI with Bob Crowley",
        "videoId": "6IzPmEa51LI",
        "description": "This is a recording of the January 14, 2021 virtual meeting.The Land of az - Azure automation with Powershell and the Azure CLIThe Azure portal is great for reviewing details of your resources and one-time operations. But when it comes to repetitive tasks, you can save time and reduce errors by executing a tested, repeatable process. This session dives into the scriptibility of Azure through the Azure Command Line Interface and the Azure Powershell cmdlets.We’ll quickly go over installation and general use, including how to accept input from users and other sources like KeyVault. In the case of the Azure CLI, we’ll see how to parse output with JMESPath queries for formatting and for using the results in subsequent commands. Then we’ll see how to execute these commands and scripts from a terminal, the Azure Cloud Shell, Automation Runbooks and even the Azure Android app! Finally, we will introduce Bicep, the new domain specific language for coding ARM templates.Whether you simply want to have a virtual machine automatically started every morning and stopped every night, or you need to provision complex multi-tenant resource deployments, automation scripting is the solution. This session will give you the knowledge to get started automating Azure right away. If you have an Azure subscription, bring your laptop or mobile device and hack along with me.Bob Crowley is a Senior Software Developer in Portland Maine where he builds solutions in the .Net and Azure ecosystems. He has been writing bugs for over fifteen years, mostly in the financial industry despite (or because?) still not knowing the difference between a debit and a credit.In his free time he likes to make the most of both weeks of Maine's summer out on the water either in a kayak or saltwater fishing.",
        "start": "01:11:02",
        "seconds": 4262,
        "text": "what you do here is now once you write your bicep file set build then give your file name okay and over here if you saw it real quick main.json popped in if i open main.json this should look pretty much almost exactly like the arm template that we've been using okay so write it in the programming language i'll put an arm template and from there you know just use it however your preference is all right that i think ends my presentation i already did that demo here's the resource link again all right any any overall questions i got a bicep question um so i looked at bicep a while back and and farmer as well as ways to like get around using arm templates you know because i'm one of those haters of arm templates but like when it get when it comes down to it like you've got to make azure resources right and and even like not liking arm templates like i can see some good sides to them like for example um if you need to create like 10 resources and they don't depend on each other an arm template will create them in parallel which is really nice saves a lot of time um doing that like with the script is like pretty difficult because you have to manage the parallelism and all that right but when i looked at bicep it just looked like a different syntax for making arm templates like not a full-fledged programming language which if it is like a full programming language that gives it a whole new value to me right because then you can start saying like if the state of the world looks like this or if i'm like in my dev subscription do this special super special thing that would be otherwise like really difficult with an arm template in the raw like can this thing like make is this like a full javascript environment can it make like requests to other resources before it generates the arm template and make decisions oh i see not that i know of um that's a good question it's still very early you know it's um i don't know what preview they're in right now i'm probably actually a couple reps behind on my machine but i think they were looking for sometime in the spring even to have a candidate release so i'm not aware of you know libraries or apis that do general purpose you know http requests or or things like that but i wouldn't be surprised i really wouldn't be surprised if they did that i i just don't have an answer for you anything else all global manufacturing plants by 2035 to stand for lower greenhouse gas emissions oh we got a question from the radio what sounds like all right folks please feel free to unmute and uh pop any questions for for any final questions for bob here any uh prediction on when arm will be fully baked um the bicep i'm sorry bicep will be fully bait yeah thank you i i don't really i i think i attended a community stand up for it and i believe they said february for a release candidate and so it's still going to be a while maybe the summer you know before they actually have a v1 or maybe even the fall but i don't really have a lot of insight into that i know that there are there may not be sorry i was just going to say you know there are alternatives um you know there's terraform there's pollumi there's um someone just mentioned another one i i can't remember what it was but um farmer farmer there you go thank you it's the open source version of what bicep is becoming okay okay so there are a number of um there are a number of tools for deploying to azure and aws and google but you know bicep is strictly a microsoft creation um anybody have any final questions for bob if not we can move into up mode i guess actually uh just briefly uh uh an observation on bicep i noticed that the uh that it still includes some complexity that maybe was an opportunity to shed like the version numbers of the apis we really need that by as the you know the default for our new language that's it makes it hard to do file new bicep file you always need to go find an old template somewhere right that's a good observation yeah i don't know well so so with uh with that um if there are no more questions i'd like to to thank you bob uh it was excellent uh really informative and uh great combination of the why does this matter and the practical and and then right before our very eyes um some um you know entitled demo so so really appreciate that i appreciate that the group joining from across the world here i noticed mark eisenberg's here too i don't know if he was in from stateside here or from hermann and from israel "
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Monitor Azure Resources with Kusto Query Language with Taiob Ali. This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.. okay we are recording um and i just want to introduce our big friend uh he already uh presented at boris uh north boston azure and boston azure user groups in person and virtually um tayo valley he is a microsoft data platform mvp he's also a data solutions architect he is a public speaker and just amazing person um so i just want to introduce him and pass the virtual mic to him okay thank you thank you veronica and bill for you know inviting me again uh this has been few times that i spoke to the combined group and also your group in nerd and also jason's group in burlington so thanks to everybody those who joined because you know things are a little bit difficult for everyone right you know working remote children's are home uh what not right and then after working a whole day and then you know uh spending the evening uh to listening to me it's not a you know easy thing to commit so i admire your uh you know your dedication and uh so i'm going to shut down the camera for now and i'll bring it back for q a uh so you know it's a small group so you know i'm not monitoring the chat actively so very can stop me anytime uh if it is okay you cannot mute ask me question i'm okay with it uh you know i'm not too too formal or i don't need to be and um i also noticed that the next month's speaker uh hassan i met him a few times he actually came to speak at boston sql saturday i was in wyo uh before the pandemic uh awesome speaker so you want to sign up uh you know for the next month's meeting for this for this group uh so let's move on i only have few slides uh most of it uh probably 80 to 85 percent will be demo and you know my goal is not to really teach you how to write kql because if you're familiar with you know i know some of you personally you are way better developer than me so if you know t-sql or some other programming language kusto is a very easy language to understand i will try to show you some bells and whistles so you can appreciate that as bill was saying you know how the azure business is expanding worldwide um you know and bill was just saying that you know average twenty five thousand dollars spend uh can get to that limit and i know at least my company is using manifold more than that so it's going to just grow and as you are expanding right you know you need to monitor your resources and and for me that was the reason that you know i i started looking at it so i'll try to you know show you a couple of things that you can take all this uh and hopefully put it into use and and i'll also show you if you really you know do not know anything about this language i'll also try to show you a couple of uh you know sources or resource and couple of just basic syntax that where you can start and build up learning this language so let's let's move on not sure if it's just me but are you um uh sharing your screen i'm probably not so that's a good point thank you bill so just give me a minute should be there show a screen why it's not giving me that option now okay i got it so screen two you should be able to see it now okay great yes thank you bill uh for reminding me uh so as again you know i'm not gonna read about myself if you just take a note on the things on the left side you can contact me if you know any questions comments any feedback after this event you can use any of this linkedin twitter email a contact page from my blog post uh please do contact me and i'm i'll always respond you know hopefully within two days uh but you are i'll guarantee that you know you will get a response and if i don't know that's okay you know i know people are smarter than me so that's a good thing i can go back you know i can go to them with your questions and get a feedback and and send it to you so you know at least i can do that so if i don't know the answer so let's uh just talk about a little bit you know what is this this custo right and and"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "send it to you so you know at least i can do that so if i don't know the answer so let's uh just talk about a little bit you know what is this this custo right and and where it came from uh so kusto it's a it's a language also there's acousto engine so don't get confused with these two things the name can be confusing um one thing of the bet is uh whatever you're going to use crystal for it's going to be only read-only so it's a read-only request and we look at the schema a little bit it also follow a hierarchy uh it's all column story index uh pre indexed for you and the goal is to when you have huge amount of data terabytes or petabytes how you can quickly get uh insight out of it right that was kind of the primary need of microsoft in 2014 um you know when azure was you know expanding they were building big data centers so microsoft had to internally monitor all their resources right all the hardware all the cooling power and whatnot so they had this challenge right they're collecting all these logs metrics what did they do with this how did they quickly know in real time what's happening so you know microsoft has r d facility big in israel and it was actually a grassroot project incubation project in israel uh into the rnd center and from there you know they came up with this language again to fast and scalable log you know to get the telemetry analytics and in 2016 this became the back end for application insight i personally do not work with application insights they're a team in my company where i work full time they do use it i know that for sure and in 2018 it was in public preview uh was announced in the uh ignite in 2018 and in 2019 uh in february in the ignite uh it became ga and so there are two things um i do not personally use there is a service called azure data explorer that's a total uh full place service that you can use you can dump your data into the into that service and you can use custom query language to extract data from there you can do that and i'll show you some of that what i use primarily is against log analytics workspace and we'll talk about that also a little bit that how i use it and why do i use it so i just took it from microsoft documentation i put the url on the right side just so you know that you know i did not made this slide by myself so you know i've been doing this uh you know working with sql server for a while and i had pretty good grasp on for my on-prem infrastructure i knew if any server goes down any host goes down anything out of ordinary cpu memory you know number of batches per second queries what not but as i started you know moving stuff to cloud primarily into azure sql database i needed something similar right i want to know when things are out of ordinary and i also wanted to do one thing is you know today i might be having i'm not going to give you exact number you know say smaller number of resources on-prem uh sorry in the cloud but down the road if i have hundreds and hundreds of those right at your sql database managed instance as your synapse what not how do i scale this thing out right how do i not you know keep doing the same thing over and over right i wanted to set this up one time make sure i can scale it out and doesn't matter how many of those resources i have you know it should do the same for me so i looked at couple of things you know i looked at in a couple of solutions uh in writing powershell into notebooks and all that and at the end i figured out for me at least uh log analytics workspace which you see here on the right side under the analyze you know blade that worked you know best for me so out of you know azure synapse as your sql server or pretty much any kind of azure resource because you know i gave this stock internally at my company for folks to for network folks to manage their searches and routers and all that right um and and and other groups because they all can send their metrics and logs to log analytics workspace and what does that do for you once you have that microsoft already has predefined schema for all kind of resources and nowadays actually you can install agent and send your on-premise uh resources logs and matrixes also to log analytics workspace so it's all in one place and azure"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "that do for you once you have that microsoft already has predefined schema for all kind of resources and nowadays actually you can install agent and send your on-premise uh resources logs and matrixes also to log analytics workspace so it's all in one place and azure monitor actually work on top of that and from there you can do whatever you want like in my case we use servicenow and i know you know bill was talking about like bill has a team in india and there's you know she can't join from south india i also have offshore team in pune and they're 24 by 7. so i use service now so from log analytics workspace i can write custom query language and whatever i want to get alerted on i can send a call to the service now and generate a ticket and it will land into there into the ticket queue and there are other stuff you can do you can use web hooks you can send a phone call you can send pager you can send notification to your teams app also and you know if you're just using matrix you know matrix is some we call this like uh it's a you know single time and a single matrix right and microsoft also you know in azure you have metric explorer they will do it for you but if you have to do it for each resource individually like for each azure sql adapter you go and have to do this over and over which you don't want to right you just want to send everything in one place and um you know query from there now is it the only destination no you can send your matrix and log analytics logs to a storage account you can also send it to event hub and it's actually recommended if you need to keep this for a longer period don't use log analytics send it to a storage account it'll be a lot cheaper but uh you know you can keep whatever you need to you know to look at your trend and and alert send those to log analytics uh one other thing is microsoft also has built-in solutions so if you see on the under the insights bled on the top right side there's something called additional solutions so these solutions are built in so if i'm sending azure sql data to log analytics i can enable those solutions turn it on i don't have to do anything and behind the scene microsoft is going to aggregate all data and you know graph it for me and i can drill down and find my problems very quickly um if you don't want to write any query you can have all these built-in solutions but if you want to go more granular and more specific alerts like dynamic alarms right i don't want to know when cpu is 90 i want to know if cpu is more than x number of percent compared to the last week at the same time right week by week day by day you can do all those with custom query language and get alerted so that's the one of the reason that i started looking at this uh you know these are a couple of other things that you know you can use with security center application inside windows defender i talked about it so you know everywhere pretty much every azure resource uh you can use this so now you know folks like me who came from a database background we've been working with t-sql i'm like you know okay now you you have to learn another language right uh why can't i use t sql so if you are using azure data explorer there is certain things you can do with t sql though it's not recommended but with azure monitor you cannot uh you really cannot do anything with t sql so you have to use custom query language and this is a quote from microsoft documentation and i kind of highlighted that you know microsoft also recommend even if you use data explorer uh use use custo instead of t sql where can i learn or how can i learn so go to my reference slide at the end and there are three different demo environments uh i'm going to use the top one today and i'm going to use another one that i'll show you so this demo um data collections are happening around the clock so microsoft actually pushing data to this demo um you know like data stores continuously as a you know for demo purpose so if you just have a portal account you do not need to spend any money uh you can log into this and you can start writing uh you know queries and i'll show you that and there are also some of the queries are saved for you so you can go and look at those and start from there recently you know i use a azure data studio a lot if you do not know this is a cross-platform tool um i wouldn't say similar to management studio is a lot richer but in certain extent it's not as rich as management studio when it comes to purely sql server uh so with azure studio it's a extension base uh we use it a lot you can use uh you know different languages and now actually there are menus that you can switch between management studio and azure data explorer so there has been two things been released recently um the the top one you know is called kql magic this is really not extension this is a kind of it's the extension of python kernel uh that once you enable it and i'll show you this in demo uh it gets you all the modules that you need"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:15:10",
        "seconds": 910,
        "text": "magic this is really not extension this is a kind of it's the extension of python kernel uh that once you enable it and i'll show you this in demo uh it gets you all the modules that you need and then you can actually write a python uh notebook uh using cousteau query language so um and i'll show you some of the examples how you can do it and the bottom one is actually a pure extension in azure data studio that microsoft released this will uh and and with this you can also you can have just a pure kql current notebook using couster kernel within azure data studio and today it's primarily done for azure data explorer but i also show you a workaround that how you can connect to your directory to your log analytics workspace it's not pretty but you know there is a someone at microsoft that i i talk julie she's in that team i talked to her all the time i was talking to her this morning um you know it's in the pipeline it's not in nda or anything i'm not giving you any insight scope but very soon you know there will be native uh connect connectivity to directly to log analytics workspace and then you will be able to you know pull your data and bring it to azure data studio and do more uh you know built-in visualization with the there is another extension called sendance which you can download so you can you know get this kql queries run those and and you know produce graph within azure data studio uh very powerful so those are some of the stuff in the pipeline and coming uh these are you know i put bunch of references uh i'm not going to talk about this only one thing the the second bullet point uh it's a gentleman called robert robert kane uh he has a four-hour pluralsight course on custom query language and this was actually sponsored by most probably microsoft so even if you do not have a paid account if you just have an account in poorer's site they have a bunch of courses that you really do not have to have a paid account because other companies sponsor those courses so this is one of those so you can do it you do not have to you know pay anything this is a nice course if you really want to get into the syntax from very basic to advanced level i would highly recommend some other stuff that i read in preparation for this course or you know over you know whenever i use it and that's all i have so i'm going to go to demo uh i'll primarily be using portal azure sql database and azure data studio this is the version i'm going to use and so i'm just going to take a pause and see if any questions comments at this time before i switch to demo i don't see any comments in the chat but if anyone has a question feel free to amuse yourself okay so i'm going to move on if if someone has anything please uh you know speak up or i i'm also watching the chat so so let's move on uh i'm not going to run this script right now the reason i'm running you know there's no reason for you to sit down here and watch me running this it takes about five to eight minutes uh i already uploaded this in my github repo which i'll show you and what it does i'll show you in portal what it did for us and then i'll let me bring this so running that script created some of these resources so let me go back to dashboard it created a azure sql server which is just a logical container uh and a sample azure sql database and a log analytics workspace that's all was done from that script that i showed you and also i did something within the log analytics workspace but before i go there i want to show you something else so whenever i deploy a azure sql database in production um you know i do a bunch of things at my work but i'm not going to show you all those i'm just going to show you just for the sake of this so as you can see here i'm under diagnostics it is saying that i already have this setup and it is going to this log analytics workspace so if i go to edit settings as i said you have three options you can send your log analytics storage account event hub and i'm sending all these logs now do you need to send all this i don't know it's up to you right you have to decide you know what you want to collect what you want to you know monitor what you want to alert on but just"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "i don't know it's up to you right you have to decide you know what you want to collect what you want to you know monitor what you want to alert on but just for demo purpose you know i'm sending all this to this log analytics workspace now let me close this i'm not sure if i understand yep okay now over here if i go to logs so all this data is being fed it and it's being you know automatically uh is being loaded into this tables and if i have you know other kind of data that you know i keep sending uh i do not have to do any of this here it will automatically get sorted out predefined uh schema it will get loaded it will get indexed and all that for me to to run queries now one thing i'm going to show you just for demo purpose what i did here i have one lrt enabled i call it found deadlock a lot and you know this is a very simple i'm just trying to give you a concept as i said before and you can you know take it as much you know as far as you want and as complex as you need so what i'm saying here that if i have a metric named deadlock if the count is greater than zero triggered this alert and you know i know i have overlap here i'm saying you know check for last 30 minutes but i'm running this every 15 minutes i'm going to get two alerts for same one i get that but i'm just doing it you know just picked up some numbers here and there's something called action group so i have action group called notify dba deadlock this is going to send an email sms and a voice call now you know do i want to get call at the middle of the night for every deadlock probably no you know again i said you know you have to decide this for yourself i have a subject line for email and you know i have a description i put a cv 83 here what does this cpa mean it really doesn't mean anything in this case but there are some apps that i know like i was just talking about servicenow you can create template in servicenow and you can look for text so if it says that okay it's coming with the cb 83 text then i'm going to do this i'm just going to send the email if i coming with the severity one i'm going to page someone if i'm coming with cv82 probably i'm going to do this so you know just an example so now i have this setup right so i don't need to save it because it's all said before now let's do a deadlock you know create a deadlock just for demo purpose and see what happen okay so i should have a what happened to mine okay similar deadlock and i'm doing this against this demo server that you saw on the dashboard that i just created on against that demo database so before i do this let me make sure i connect to this this is azure sql database and in edge or you cannot use the statement use database name so you always have to be in the right context of the database without your sql so and this is a very you know simple uh that if you if you you know google online how to create a deadlock you will see this probably thousands of examples so i'm just creating two tables and just having two rows of data and this is a common trick that you can do you use do a begin trend you're beginning a transaction you're not committing or anything you leave this open go to another window oops i didn't mean that run this here this will keep running i'm going to come here and now one of those should get deadlocked yep so as you see now a deadlock happened right so within five or seven minutes i kept my phone purposely on it should ring i'll also get a sms"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "those should get deadlocked yep so as you see now a deadlock happened right so within five or seven minutes i kept my phone purposely on it should ring i'll also get a sms i'll get an email um i'll show you uh once you get those but i'm not gonna you know i'm gonna move on so this is a very you know quick example but what i wanted to show it is that now i have this alert set up right for this condition as you saw that i didn't have a server name there or a database name right it's going to do for everything now you know this is probably not production ready right if you have you know a different tier of applications you might want to group those and do it in a different way you might have different log analytics workspace for different tier and based on that you can decide how you want to do that so you can take this concept and now you know write your queries and get alerted for anything you want to and get notified in any way you want like that was kind of my my goal of showing this that you can you know this is very you know scalable uh you know doesn't matter how many resources you are you are monitoring so i'm just going to close all this we don't need anymore uh so this script is there you know it will do everything for you there is only one place that you want to make sure that the one in the github i didn't put my of course my phone number and my email address you want to change that when you otherwise you can pretty much run this as is one other place you need to keep it careful is your subscription id that i have no idea and then at the end i have this one line code that's going to clean up so if you want to save your money make sure you delete this because i could build everything in one resource group so it's a very easy to clean up so there are two things that i talked about kql magic and these are also in in the github repo you can you can download so i actually downloaded this from here i didn't change much as you can see this is still using a python kernel and this is first time when you do this you need to install kql magic um and if you already have it installed uh you can always run this if there's a newer version to upgrade you can do that and then you load this into this notebook and then once you're done now i can actually connect to a azure data explorer i can give the tenant name cluster name and the database name and i need to do that authentications okay so you're connected now and now because i'm in a python kernel i can say you know person person kql that it knows that i'm using kql i can directly query the data here and if you have the other extension sentence uh you can also uh put this you know in in in in graph format uh and and we'll we'll see some of this or you can directly do this here if you say render time chart uh so we're looking at a storm event uh you know summarized by count and you can create a time chart right here you can do a pie chart by looking at the same you know similar data now as i said i personally do not work with azure data explorer um sorry i do not use uh you know the the service i mostly use with the you know the the log analytics workspace so uh this is another one like you know i was telling you about this this demo uh workspace in my slide uh you can connect through this um you know you same workspace application key and then the alias i'm not gonna run this but you can do that now you can also connect to the log analytics workspace directly this was a little bit tricky microsoft documentation was"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "but you can do that now you can also connect to the log analytics workspace directly this was a little bit tricky microsoft documentation was not very clear so i put a url here there is a gentleman named dennis he's a microsoft mvp he wrote extensively how to get this work and so there are a couple of different ways i'm not going to use this one because you know i have to create secret and change bunch of things so i don't want to but if you go to this article it will explain and then you can take this string that i have and you can just change the values and get it worked but there is another way you can you can do this as i'm doing it right here now this is directly connecting to the log analytics workspace that you saw in the portal that i i created okay so you're connected now and now i'm actually running this against this this localities workspace the one that i created not the microsoft's demo or anything it's directly getting the data i'm not sure yet if the deadlock landed there or no probably not yet but we can try another query let me let me bring that one in you can also look at from the matrix if you don't see it in diagnostics it land in two different places yep so 23 1847 yep this one so this is the one we just did right so uh it's there uh i also you know there are some more urls that if you want to you know read further and do some more stuff you can do that uh the next notebook it's a little bit about this is now not using a python kernel you can directly go and use custom and for this one what it's using it's using this extension called kql this is still in preview just so you know now with this one i can directly connect to a cluster from here and once i'm connected then it's and as you see here i do not have any person person kql because now i'm in acoustic kernel so i can directly write in crystal query language there's another one now these are as you see i'm connecting to a sample from microsoft right now how can i connect to the log analytics workspace and query the way i showed it in the other place it's very messy if i take this just give me a minute so let me see if i can put in a notepad and show you the whole thing now it is not ctrl shift and copy so as you hear my phone ringing this is actually uh about the deadlock i also got a text message and i'm gonna also try to show you the email so anyway uh so this is not pretty you have to you know create this whole string and then you have to put your query at the end um but again you know this has been still in preview so microsoft is actively actually building on this and i i think this is going to go away and you should be able to you know go to your connection string window and"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "still in preview so microsoft is actively actually building on this and i i think this is going to go away and you should be able to you know go to your connection string window and be able to connect your log analytics workspace pretty quickly i mean this works but you know you're not going to for every query you don't want to you know copy the whole thing and put your query then as you can see that we can get results but it's still it's not a you know i don't think so it's ready for you know for for prime time yet i want to show you that email that i received so let me get it in the different window and then because it's my personal email address so just give me a minute so you got a i got an email from that from the deadlock and i just want to show you that so you know i'm not going to read the whole thing but as you can see cb 83 this is the utc interval 30 minute and it actually gives you the you know the whole details uh about the you know the resources that was involved into the deadlock uh so i just wanted to okay so any questions so far otherwise i'm just going to go and show you a couple of syntaxes and you know run few things okay so someone has a question that pricing model for queries against localities workspace i think on my resource page i have a url because i don't remember every time you know there is a uh how much it cost and and all that uh there's definitely a price uh uh also in your log analytics workspace if you are keeping um over you know when it first came out you could not keep anything older than 30 days it will automatically get punched now you can actually customize what things you want to keep for how long um and i think there is a certain gigs are free for long entities workspace and after that you have to pay per gig and for uh you know for the period that you keep it um so you have to you know the more you keep and the longer you keep you pay more money also the queries yep okay so i have let me show you this i have the six queries i wrote those uh using visual studio code just so you know it gives me all the syntax error and all that but uh you can open this in pretty much any place i am not going to you know go through everything but they are also in my github repo uh i'm going to show you a couple of things out of these six queries but not not every operator because it's just going to get too boring and like i said at the beginning some of you are way better developer than me so i don't need to teach you every syntax of of this of this language the first one i'm not as i said i'm using one of those demo data collections to show you this but this is pretty much same as what you see in the portal so you know the look and feel is pretty same so i just want you to you know i'm just going to show you a couple of things to get around in the portal when you go into log analytics workspace so on the left you see your collections as you as i said few times these are all predefined right i'm speaking very loosely you can consider each one of these as a database these are your tables within the tables these are your columns right this is kind of i have a hierarchy same as a relational database on the left side you see the symbols telling you the data type right and on each one of these even without knowing anything if you click this it gives you a preview of your data and you can also click this and it will take the query show you what query was ran behind the scene to give you this data also gives you some ideas right what is this collection about right it's about virtual machines and this data is also being used by built-in solutions for azure monitor for vm so if you open that solution that solution actually use some data from this table so you know give you"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "and this data is also being used by built-in solutions for azure monitor for vm so if you open that solution that solution actually use some data from this table so you know give you some ideas one thing i'll probably mention few times if you just run this or if you see both of my queries i do not have any predicate with date time right for how long i'm looking at like how far back i'm going be careful with it especially if you're doing aggregation you might get caught with this i did few times by default it will always show you 24 hours last 24 hours for everything if you do a count you do some aggregation always for last 24 hours and by default it only gives you the first first 10 000 records so just keep these two things in mind last 24 hours and 10 000 records there is a query explorer if you want to save your queries and share with your teams you can use this uh under the saved queries if you go to purse site the course that i was talking to you as telling you before by robert kane all of his queries from that through a site is bundled here so you do not have to even start from scratch you can just open this and you start running those and you know see how he did this and if you go step by step from m1 to m8 he goes from very basic and build some complex queries so this is a good place for you if you want to get started it also gives you some link for getting started online courses and all that and what else i can tell you okay so let's let's let's look at few things and please i'm also monitoring the chat so if you have any question you know like i said you're a small group so please stop me because from here everything is available for you so i do not have to kill myself or kill yourself you know make you bored you know to to get this finished so the main purpose of this uh let me make this a little bit bigger and press f11 so you get a little bit more real estate uh one thing primarily we will be using this to search stuff right as i said these are all read-only queries we want to find this stuff means we'll be searching now i'll start with something negative you know you might not like me for that so do not do this as i said you know do not run this saying that search cpu means go to every database every table every column all rows and find the cpu case insensitive right so not a good thing for you to do if you have large collection it might take some you know longer time plus you'll be probably paying for some compute this one i'm restricting right now i'm saying just look at this table as your matrix again i'm looking at all columns case insensitive sorry case yes case insensitive if i want it to be case sensitive i need to mention this that i want the case sensitive search now this is a finally i'm restricting myself now i'm saying within azure matrix look at the column name named metric name and give me this again i'll mention that as you see here showing the first 10 000 which i told you it will always do that and time ranges last 24 hours i can do exact search with equal equal i can search for two different things with the end operator now this is first time i'm saying as you can see a time generated and notice this as soon as i click here [Music] bill is that a comment for me or no say someone else sorry yeah it was uh it seemed like it might be so jim o'neill was one who asked the question about the pricing and that one seemed to be uh pricing related uh if it has to do with cpu credits but i'm not actually sure yeah uh no i was just i i didn't mean i was just searching you know just to show exact search so um if you see that you know if i come here see this automatically says that"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:45:32",
        "seconds": 2732,
        "text": "i'm not actually sure yeah uh no i was just i i didn't mean i was just searching you know just to show exact search so um if you see that you know if i come here see this automatically says that it's last 24 hours here now you can see that it changed to set inquiry right now here i'm saying that just give me for last one hour right and it says that my time range is set in in the query but again within the last one hour i have more than ten thousand records and it's gonna only show me the first ten thousand i can do a wire and and one thing is unusual here uh it's giving me that alert again so let me just mute my phone so i don't get okay you can use three where clause this is something uh you know i don't know many uh programming language you know some of you probably know a lot more than me i'm primarily a t sql based and a little bit of c sharp but in t sql i cannot have this this will give me a syntax error i cannot have three word clauses but here you can do that or you can replace this by hand both works and there all you see as you can see is pipeline so it's going to take this reduce this then reduce the radius so it's always better uh if you have a if you're restricting it by time i would put that at the top so reducing your set um like you know if you work with sql server i'm sorry to bring you know sql server example that's what i work most if you're looking at a execution plan you always try to reduce your data set at the beginning of the query right on the right side of the plan so the rest of the plan has to work with the smaller data set you don't want to work with millions of said and at the end you know put a filter that uh you know reduce the set from one million to a thousand right you want to if you can do it at the beginning of the query that's better so here is the same deal if you are addressing your time range uh you know you want to do it first i i don't know if you bring it down you know someone asked me uh is it clever enough to do that before right um i you know these things doesn't have any query plan or stuff i cannot see behind the scenes so i really don't know if you know sql server i could tell you exactly what's the order of the operation but here i do not have that inside yet this is a syntax that you can use if you're searching in the all the columns there is some support for regular expressions i just wanted to mention that so you can run this and see that you know you can use it uh take and limit is synonyms so it's just a you know just give me the top 10. um keep in mind we always alert people when you're using top statement without order by uh you have no guarantee um though you keep seeing the same result set uh sometimes people think that you know there is order it's really not it's just bringing it you know what's in the memory is serving you the same data because that pages are already in the memory but there's really no order it's just a random 10. you can have a bunch of where clauses and then at the end you can decide when to just see top 10. count obvious is going to count it you can again combine count with other predicates obvious summarize this is pretty much what we call in sql t sql or or sql is a group by so i can do account group by metric name and i can also as you can see this column name is not very friendly it's count underscore i can give it a friendly name if i want to that also works now count by metric name uh i can group by with multiple columns i can also have aggregate functions so i do have a group by here but i'm also using a max value so for each one do a count also give me the maximum value for each bucket as an extra column i can do that i like this one bin it does a group by but then it also slice it you know based on what i'm passing here so what i mean by that here i'm saying you know do this per day now if i'm trying to troubleshoot this something you know select per hour so when did this thing change now it's going to give me per hour and then i can you know put this in a chart right and if i see a deviation probably will tell me when things start going wrong and you know if i do not like this i'm not sure the minute is the right syntax probably m i can slice and dice it every 15 minute chart it go"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:50:32",
        "seconds": 3032,
        "text": "tell me when things start going wrong and you know if i do not like this i'm not sure the minute is the right syntax probably m i can slice and dice it every 15 minute chart it go to more granular right as you can see you can see a pattern here probably so bean is a very you know powerful for troubleshooting i can also have calculated columns here i'm saying you know give me the headroom total minus average um so 312 is kind of weird for you know for for for a cpu i don't know it's because probably like it has four core uh that's a possibility i'm really not sure uh you can do project so what does that mean like you know we always say uh you know do not use select star right because if your schema change behind the scene you don't know always put your column names uh here's something so they're a bunch of columns that by default whenever you're looking at any collections it gives you certain columns but there are a lot more columns and if you do not want to you know if you do not want the default ones you want some particular ones you can just say give me these column names means it's basically saying select this this this column name from this collection so it's just going to give you those column names and you can combine project uh you know with a calculated column and give it a you know your your own name and what i'm showing here is even though i'm using a calculated column here with headroom total and average it shows total average and my headroom right so if i go to the right i'm showing total average and also headroom but if i say i do not want to see total on average i just want to see headroom so i can bring this up and in my project i just have headroom not the total end average and i can do that there's something called project away which is very interesting that that that t sql doesn't have something like this uh what it does it's saying give me all the columns except this so i don't know equivalent you know i haven't seen one uh which is which is new to me so projectile is saying give me all columns accept this uh distinct i'm not going to run this it's similar to any other language just give me the distinct values you can do a sample distinct so this is like no order uh just give me random 10 distinct values out of this collection you can do this in t sql but it's just two different keyword or two different operators but here you know they have a built-in one okay this is a top 20 by now i have a you know order so means i'm going to get you know definite result right it's like deterministic not not not random sort same you know very obvious now one thing you'll see this with these collections a lot of time there will be columns with json there will be columns with xml uh there will be columns in different format and some of those uh are not you know pretty to look at or pretty to query on right or when you are sending your alert uh to the person who is looking at the alert if you send like a whole big xml or or a json uh probably not very useful to them so you can parse some of those data and uh so i'll show you a couple of examples here uh no this is this is not doing that so yeah okay so parse number one i wrote two of these because recently i've been noticing that microsoft is not sending data to the event collection yep there is no data there so it stopped recently so i just wrote something and i know i'm getting ahead i did not explain what is let let is pretty much declaring a variable type you know table one column with the string data type i have couple of other examples how to use let but for this one as you can see i'm putting all these you know key value pairs right adding those into this column but then i don't want to send this data like this and i want to you know pivot this or or twist it to a to a column and and and you know put those values there and there i can use parse and then i can project those names so if i run this it will be more clear as you can see here now i have resource name total slice slice number i have this in each column and now i"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:55:36",
        "seconds": 3336,
        "text": "project those names so if i run this it will be more clear as you can see here now i have resource name total slice slice number i have this in each column and now i can you know have further query if i want to look you know if i'm looking for anything that i want to alert on you can do that uh between um i wrote this one interesting because they also have a you know i don't know if not between is a t-sql syntax but here you can use this symbol and say you know i want to between this and i do not want between this so uh two dynamic if you have a json column type you can use two dynamic and you can only extract the key value pairs that you want so look at this column extended property right so if we just run this and try to right here extended property as you can see right i have this compromised host username and all this and i do not want you know all of this data i just want to get resource type service id i just want to get this for alert name and time generator so i can get this by two dynamic uh and i put this into an array and then i can get those the one that i want i can extract those and now i'm getting only those key value pairs that i want in a column it's similar you know i have xml i have all these data i do not want all this i just want some particular you know key value pairs i can use parsex ml and get those extracted i put bunch of print statement with datetime because all of these collections will you know starts with the datetime column so if you want to present your daytime in a different way you want to parse it and whatnot so i just you know put a couple of examples here uh and then again you know like you can all kind of you know values from the date time column if you need this uh i know if some of your you know using without you know using data warehouse i'm sure you probably have a table something similar for daytime series and then you can use it to you know to do a bunch of things i'm going to take a detour here just to show you that i showed you i think couple of charts uh using the azure data studio i just want to show it here again and that you know these are built in you can use render column chart time chart you can also do it from the portal i showed you a few times so again you know i think and there's also you know some feature i think is built in here that you can change your chart type and stuff uh and if you do not want that if you just want data you can just do this it will give you your you know their data there um so these are some of the examples number three this is these are also a little bit advanced aggregation uh i'm not going to bore you with this uh you can read those by yourself and and you know just just run those and you'll see and i put for each one also each operator i also put url for microsoft documentation for everyone so if you want to read more see more examples please go to these urls and you will see it uh this is a couple of examples as i was saying with the let uh so again as you know we just saw that the event collection is not populated so i'm not going to use this but i have another one that that you can you can run and see declaring variables and you know stepping through these i'm not going to read this but this one is a little bit interesting so especially um let me get a little bit more real estate so especially if you came from t sql background we know that by default when you're joining two tables you get a inner join right if you do not say what kind of join it is and then of course you can do our join left outer join right outer join and what not uh kql by default does not do an inner"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "01:00:40",
        "seconds": 3640,
        "text": "say what kind of join it is and then of course you can do our join left outer join right outer join and what not uh kql by default does not do an inner join and that was a surprise for me so just to show you this on the left side just keep a note that i have twice april right so i'm doing a left table right table i didn't have to say that the join kind is inner unique because that's default i just said it to make clear that this is doing a inner unique so if i run this we got five rows we only got april once on the left side if you do a inner join which is default in t sql or in sql in general see that i got april twice okay so just bear in mind if you are doing a join between two tables uh keep that in mind uh just to show you another example the power of you know late statement so i'm looking at some cpu and memory data i'm putting those into two different data set and then i'm using both in the in the third one i mean it's not obvious always that you know just for demo purpose i'm looking at you know a correlation between cpu uh and memory can can i uh ask a question about that yes go ahead great thanks uh uh i was waiting for an example and i'm not sure this one is one that uses two tables oh this is correlating across um i'm sorry i didn't read it fast enough the first time i don't think my question quite applies here yet uh but these are both off the we'll call the perf table yeah you probably i think your question will lead to can we do a cross to database and i'm talking database here very loose term metaphorically yeah yeah yeah yeah that's possible that's possible i probably do not have an example here but i think if you go to that query explorer in plural site probably in m7 or m8 you will see bunch couple of examples cool thanks i'll check it out yep these are pretty there's something still not available in log analytics workspace but i'm pretty confident that it will be coming soon that is if i'm querying the same data set over and over right do i go to and fetch those every time so right now this is available in azure data explorer what you can do so let me get out of this come here if you are using this as a service you have this materialize function you get i think par i don't remember the cache size is a five gig i know that but there is a i think it's power uh not log entries workspace um i i have to go through i i'm following the right term uh so it's it's you know you get five gig and uh here if you see that i'm just giving it a name random set and i'm going to put this data into this and then i'm using it three times so it doesn't have to go back and fetch this data three times right you can it's a caching mechanism so that's available and as you can see i did it three times and if you go to this url there's more examples uh here it is getting it from the storm event collection and you know it's going to do a count and summaries and then it's putting it into the detailed data and now it's then you are using it and then you are joining to itself you know to look at uh you know some more data so you you can do this there are some some caching mechanisms uh built in there i will commit to all of you that i do not work with any of the machine learning stuff but some of you are probably doing it so for you folks uh you probably know these algorithms you know they're very common basket is one and auto cluster and i think basket is you know we all know you know retail industry probably use it all the"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "01:05:43",
        "seconds": 3943,
        "text": "you know they're very common basket is one and auto cluster and i think basket is you know we all know you know retail industry probably use it all the time right uh they're trying to find out you know what things they should put beside bread what things they should put beside you know bread or egg or whatnot right during christmas they want to figure out you know what are the things they put it together what are the things they put in the front what in the background they're always using this algorithm so these algorithms are actually available using with custom query language without doing anything you just evaluate and then you you know give your algorithm name and if you have a threshold you pass that and i again as i said you know i copied this from this example but if you go to this url uh you know there are other ones that you can read uh what are the algorithms they you know is allowed as of today so you you can just use those as as is so if you can see this one you know these are a couple of you know security events uh if you want to see that you know what kind of you know event id you are getting and you know how frequently you are getting what percent of this of your total and if you change this number um you know you you the weight of your groupings are going to change as you see now we shrinked it right if you want to go you know see like more smaller buckets uh you change this now you're going to you know see a larger result set again like you know just as an example this is telling me about my patching uh you know how much in compliance what are installed what not and if i want to say no this is you know very high level i want to give me more granular you can change that and you can see those i do not use this i'll be honest i just thought i'm going to mention it in case if some of you are using this machine learning algorithms so the last thing can you export this data right because uh for whatever reason right you might need that so if i run this so i should have used this now i have this data i can come here i can save it export to csv i can do a bunch of stuff so if you are into power bi i will just show you something this will be the last demo and before you know when i get this talk last time actually you had to do this query to power bi and then what do you do i have to go and get an advanced you know data source and paste all this right it comes with your source your your your cluster name and all that and luckily you do not have to do that anymore so power bi now have a connector for this hopefully help i should have given the query i did not okay let me go and get my inquiry system events you can bring you know all the data you can write your query you can filter it uh you know i'm again i'm not a power bi person uh but i just thought you know i'm just going to mention it in case if some of you are working on uh you can now directly bring this data and then you know build your dashboard share it send the links to people whatever you need to do so that's all i have before i go back to my slide let me just show you one more thing because i mentioned this few times and i can send this to no this is not my account just give me a minute i just want to show you where the where you can find everything and i i can definitely send this to veronica bill and jason if they want to you know put it somewhere or send you another email with this but where am i now okay i did refresh this just two hours ago as you can see so everything is here so if you just go you know sql worldwide and then presentation under this uh download play with it you don't need to ask me you know whatever you need to do feel free so that's it so i do not have anything else i'm just going to bring up my i'm just going to bring up my contact page again in case if anyone yeah so that's all i have um you know let me know if you have any question comments um if you you know when you download stuff if you can you know if you think of anything just send me a note and as i said you know if i do not know the answer i'll try to find it for you uh just keep an eye on the azure data in azure data studio there's going to be a bunch of kql extension is going to uh i think expand there's going to be a lot of you know good work is being done hopefully one day we can just directly connect to log analytics workspace without all these hoops and you know pull down data and do visualization there so so uh that was uh fantastic uh does anybody have any questions like to lob at him before we wrap this up okay well i guess everything was 100 crystal clear to everybody as usual uh uh that that was great and and you do you do a fantastic job of just making it so easy to continue the the quest after you leave because this the rich set of resources is you know just so uh well thought out and complete so appreciate that you've launched us all any of us who want to dig in further into uh cousteau made it easy uh last last uh last chance for a uh for a question you can come off mute if you like or you can text it uh well uh we'll wait a few seconds in case that happens i'll mention uh that two not two weeks from tonight um uh about almost four weeks from tonight on tuesday today's thursday the next meeting is on a tuesday february 23rd we have uh how does uh azuma azure cosmos db work under the hood hassan savran will be our uh guest uh speaker there so that's the next one to sign up and we have the number of other ones coming online after that as always follow us on you know meet up and you'll "
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints. This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.. screen can you see my slide deck i can see it oh good okay excellent okay well thanks very much jason bill veronica for having me thank you all for showing up tonight or today wherever you are in the world this is going to be on azure blueprints and the learning objectives i have for us i've prepared about an hour's worth of content and at any point in time you have any questions let me know and jason definitely feel free to stop me because i got a couple monitors here and it can be difficult to see a scrolling chat screen i want to spend just a couple minutes with the slides i want to do 90 of this presentation in demo mode but i want to make sure we understand the business use case of azure blueprints and the high level workflow and you'll find i think that if you've already done work with azure resource manager deployment templates and if you've worked with azure policy for example you're well on your way to mastering azure blueprints by the end of this session you'll understand how to create deploy and track blueprints in a number of different ways i want to make sure that we cover not only the azure portal which is normally the introductory approach but also how to do the same in azure powershell azure cli and then how we can integrate azure blueprints into azure devops pipelines all right arino well let's see what do we have here session materials right the session materials are in github in particular the short url is tim w dot info forward slash azb and if you go out there you'll find um well it's just a simple repo that's got the slide doc and the supporting files from the session a lot of good goodies in there i think azb stands for azure blueprints whoops i'm presenting on my home computer which is a mac and i very very rarely present on a mac so i'm kind of clumsy i'm not even entirely sure you can hear or see me i hope that it's the case otherwise i'll be presenting to myself and to my cat all right hopefully you see a screen that says azure blueprints and what i want to call your attention to is the sneaky little word preview as azure azure blueprints has been in public preview status for literally years now to the point where if you've taken any of the azure certification exams blueprints is on most of them and i don't know if you know this but microsoft worldwide learning has a policy where they don't cover public preview features of course i asked them what the heck's going on with blueprints and their response was well blueprints is a mature enough product to where we include it so take that for what it's worth but i also whoops sorry about the slides i wanted to call this out here that of course the preview terms of use state that they're provided as is with all faults and as available and are excluded from slas and warranties now if you do find something in the azure blogs maybe the blueprints product team is providing production support if that's true let us know because i don't know that to be the case there's the traditional disclaimer that under normal circumstances public preview means you're on your own the problem statements that go into azure blueprints are as follows how do we track our deployments i know everything that's deployed in azure is recorded in json and you can get to those files and the resource groups and your subscriptions but how do we more granularly control those deployments we might have a golden deployment of a virtual network but now we need to deploy that and number of times yes we can fetch the json but we've got different people with different versions of these json files we need consistency in our infrastructure you might ask well well we're we're doing infrastructure as code and azure devops what else do you want well how about layering beyond just the json deployment templates you might have issues with taxonomic tag inconsistencies missing tags misspelled tags this kind of stuff you might have deployments that get snuck out to unauthorized regions there's the question of role-based access control and least privileged security how can you make sure that you're on top of that your security and compliance professionals are probably most concerned with that and then maybe you're not yet at the point of infrastructure as code and keeping your infrastructure alongside your applications in a pipeline but you need to do that how can we solve these problems it's quite a few headaches and i think i really love to know some of the background at microsoft about what their opinion of blueprints are because it's a pretty cool product very cool actually and i think that i'm going to make a strong case on how useful it can be for you and it seems to have gotten enough pickup at microsoft to where it's nicely documented across the board in the portal the"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "that i'm going to make a strong case on how useful it can be for you and it seems to have gotten enough pickup at microsoft to where it's nicely documented across the board in the portal the rest api definitions seem pretty complete to me the powershell the cli support all that's pretty robust yet it remains in preview and at least the portal experience is a little bit non-optimal more on that in a moment the things that we can do with azure blueprint definitions are the resource groups of course that's the fundamental deployment unit in azure after all you can deploy anything and an arm template as i'm sure you know but we can also layer in our back role assignments and azure policy in other words the picture here is that we can create entire deployment environments instead of just a one-off virtual machine or virtual network or aks cluster whatever it is you can define the entire environment of the deployment and track it end to end we therefore are ensuring consistency in our infrastructure deployments and as i'm going to teach you we do have a fair fairly good integration at this point with azure devops build and release pipelines the workflow as i said earlier is similar to existing azure technologies particularly azure blueprints you start your azure excuse me azure policy where in an azure policy you have your draft of your policy and then you publish your policy and then assign it it's the same exact thing with azure blueprints your blueprint starts its life cycle as a collection of json documents that you draft work on collaborate with your teammates potentially then when you're ready to start using a blueprint you publish it as a version and then the idea is over time you'll have potentially a library of blueprint versions and you may need version 1.5 for this environment or version 2.0 for the other environment etc the assignment i don't really like that word myself it's a little confusing in a way assignment is simply an instance of the deployment where you take a published blueprint and you tell azure resource manager to go ahead and deploy it and then as i said you can track those deployments using all of your traditional azure tools from log analytics to monitor etc blueprints also bring to the table a pretty darn powerful locking mechanism i don't know if you're familiar with resource locks in azure where you can apply read only or do not delete locks at different scopes i don't know if you can do it at the subscription scope but you certainly can do locks at the resource group and resource levels but here in blueprints it's actually much more powerful when you assign a blueprint you can optionally attach a read only or do not delete lock to the entire environment and you can look at the blueprint as basically being a protector a protection layer over that entire environment and what you'll see in a moment is that azure will put a deny our back permission on at that scope so if it's at the resource group scope everything inside it might be protected against the delete operation let's say and it's a deny and you might have got if you've got experience working with role-based access control in azure you know that ordinarily we people we human beings can't do anything with deny assignments that can cause problems where you've got the question of permissions inheritance flowing down through resource groups to resources and you want to do an override normally in a windows world you might consider a deny which would always overcome and allow at that same level but anyway you're going to see that blueprints make use of a very special azure security principle that i didn't know existed before i learned about blueprints where nobody including owners i don't care if you're a global administrator an azure id nobody can overcome the lock and that's by design because the idea is you'll be doing all of your life cycle management of the blueprint in the blueprint definition it's kind of a paradigm change you know for example in azure ad you have the privileged identity management or pim product if you've heard of that and microsoft would like us for instead of doing our role-based access control you know at the resource level or in azure a.d microsoft wants us to use pim to do all of our our back similarly for infrastructure life cycle i think microsoft is trying to gently steer us toward blueprints ready for a demo let me dump out a powerpoint i think we'll begin at the beginning we'll continue to the end and then we'll be done to quote alice's and adventures in wonderland here we are in the azure"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:10:11",
        "seconds": 611,
        "text": "ready for a demo let me dump out a powerpoint i think we'll begin at the beginning we'll continue to the end and then we'll be done to quote alice's and adventures in wonderland here we are in the azure portal and i'm going to head on over first to the blueprints area and once again if you're familiar with azure policy we have a very similar metaphor here we've got our collection of definitions and our collection of assignments it's pretty bare bones at least policy has a whole section for monitoring and tracking this doesn't yet that's that goes to what i said earlier to where this is a strange product and as much as microsoft seems to feel it's pretty important and now they've given the instruction that they've got to have powershell and cli support and all this other stuff but yet it still seems unfinished in some ways and it is here right over here preview whatever it's another discussion but we'll start by taking a look at the built-in definitions of course you can create your own definitions from scratch you can build upon the existing templates that microsoft gives you so we can hit create blueprint here and we'll see there's a blank blueprint template what you'd expect starting from scratch and then there's a collection of samples these are pretty interesting and i want to draw your attention to there's really three categories that i see here there's just the basic starter one the simplest one i found is this basic networking one that defines the deployment of a virtual network a subnet and a network security group that's the one that we'll proceed with in a moment but you also see several pre-built templates that are aligned to different compliance certifications fad ramp hipaa i'm sure that there's gdpr in here there's iso 27001 etc and that can give you a good head start because if you're wrestling with those kind of certifications you're probably wondering if you're newish to azure well what what knobs do i need to twiddle what switches do i need to flip to make sure that my infrastructure is going to pass those audits so that's the purpose of those templates my understanding is that these templates all come from microsoft's own full-time cloud solution architects and probably by extension in the microsoft partner network as well so those are two of the three categories of templates the third that i see come again from the azure solution architect community if you're familiar with the cloud adoption framework that microsoft publishes they have a foundation template they've got a migration landing zone template these again can save you potentially a lot of time and give you some really good tips and tricks and it's just a baseline environment to start with you can also go out to github if we do a search for github azure blueprints you can get all of the source code from those by going out to it looks like the repo is azure and then azure dash blueprints i actually cloned that for you in the the presentation files that i'm sharing with you again the short url if you want to go out there now is tim w dot info slash azb and what i did is cloned that entire repo in here of course i give attribution but let me see no it's the wrong one where the heck is it azure blueprints repo yeah i think it's in there like the old prego pasta sauce commercial it's in there there's a lot of stuff in there for sure including that repo but anyway let's come back to the portal let's go back to the correct page and let's select the basic networking v-net so we can kick the tires and see just the high level of how this works let's call this boston reference v-net how's that and optional description and then again very similar to azure policy we scope or place the definition at a particular level and we can do either management group or subscription here so we can choose our i'm going to choose my sponsorship subscription and scope it there this is going to be where the blueprint is available of course the benefit of the management group is that it's the level above subscription so you'd then have the blueprint be available to end number of subscriptions because this is all json anyway and i'm going to show you some ways to integrate this with source code control it's really trivial to keep your blueprint definitions out of azure at least initially and then just deploy them into whatever environment you need them to be visible at hope that makes sense let's go to the next step and the individual components of an azure blueprint are called artifacts and as you can see in the user interface you can scope your artifacts at the subscription or the resource group scope and we've got in this definition as i said you've got a resource group definition an nsg and"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:15:13",
        "seconds": 913,
        "text": "and as you can see in the user interface you can scope your artifacts at the subscription or the resource group scope and we've got in this definition as i said you've got a resource group definition an nsg and a v-net so the icons tell us that we've got first this resource group and then the paper references an arm template and then we'll see that there's a couple other artifact types that we can choose from all right so the artifact type for the resource group you might be wondering here now is this going to define a new or an existing resource group that speaks to the item potency of azure resource manager which defaults to an incremental deployment mode by default so if you define a resource group here that's called boston let's say and there's already one when you assign it it's going to leave it alone unless you do a force a complete rather than an incremental but incremental is the default so what you're going to see here is depending upon the type of artifact there's going to be a display name and then the actual resource name when you deploy it and as you can see if you're familiar with built-in functions and resource manager templates you can use some of those like in this case we're doing a concatenation to grab the resource name prefix parameter and then we're going to add rg to the end of it and notice here that you can specify that the value should either be hard coded in the blueprint or it should be specified when the blueprint is assigned if you want it to be more flexible then you probably want to choose this flag here and just make sure to name the resource group when you assign it resource group's going to need a location again you can either hard code that or say that this value should be specified and then there's just a convenience factor here where you can put in some tags whatever okay so this is the portal experience we're trucking on along here as i said we've got an artifact type of arm template so if we select what's in this starter template here it's defining v-net and one subnet and then this is where i meant that this is a little bit non-optimized best case scenario you're going to have all of your definitions and source code control and i did ask the blueprints team over a year ago hey just in case you haven't been suggested this it would be awesome to be able to dip into azure devops or any repository from here instead of having to do an import operation where you can pull the file manually from your system let's say or even worse do a control a control v to copy and paste and they took the suggestion they said it's on their roadmap again it's kind of been a strange situation i don't know if the pandemics come into play i suspect between yumi and the wall here that that jedi project the huge contract with the u.s federal government might shift shifted some priorities somewhere i don't know that's just speculation so we've got just a regular old garden variety template here and then the parameters show up in the gui here and the interface is either you specify them when it's assigned or you can hard code to do an override so the the resource manager template is defining the nsg and the v-net and then we can hit add artifact and as i said there's a couple other options here we can choose role assignment for example to pre-populate role assignments simple as that now just i want you to think for a second about how this might benefit your company i mean if you do work as a cloud solution provider or a managed service provider you might have blueprints that define a landing zone or an ideal environment for your client and you may want to basically scaffold the entire thing your best practices as far as the deployment definitions azure policy definitions and role-based assignment definitions which could include custom roles not just built-in roles so for example we might choose here from our role collection there's a virtual network or maybe it's just called network contributor let's see yeah there's a network contributor built-in role and we want we might want to make sure that we have an entry for that here and once again same song and dance about when to populate it and then lastly we can come back here and choose policy assignment and here we can choose custom or built-in and then we can just filter the list it's a little bit sluggish over here again if you're not familiar with azure policy these are json documents that you can use to enforce whatever it is you need to enforce governance wise whether you need to ensure that tags are present that you're using only allowed azure regions that you're enforcing only"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "policy these are json documents that you can use to enforce whatever it is you need to enforce governance wise whether you need to ensure that tags are present that you're using only allowed azure regions that you're enforcing only certain skus or stock keeping units of resources whatever that's a whole other subject but notice that you can grab individual policies and bring those in or more conveniently chances are if you're using azure policy to any degree you've rolled up collected or related policies into one or more initiative definitions and you can bring those in that just as a convenience factor let me just search for what might be nice inherit if i can type inherit i'm not looking at the right tab here inherit a tag from the resource group if missing how's that so let's grab that guy click add okay there you go so once you've finished horsing around here and structuring your blueprint you're ready to move to the next step let's save this as a draft and then it's going to get stored at the scope that we chose to store it at which in my case as you can see on the right the definition location field is my sponsorship subscription so this is an unpublished draft that you presumably would work with your team until it's just right and then when you're ready to do publication you can simply select it in the azure portal and you can edit or delete but you can also publish the blueprint which is going to make it ready for use you have to give it a version and that version and of course would be up to your team and what you want you've got some change notes which you can get to through azure log on analytics using kql queries etc if you need to retrieve that in the future and once you've got it published after this is again a little jarring we have to come up here yeah it says that it succeeded but you ever notice that that sometimes when you do an operation in azure it keeps you at that page you're like wait a minute what actually happened here so let's step back one and we can see now we've got our boston reference v-net latest version is 1.0 good deal we shouldn't have any assignments yet nope we don't so the last thing we can do now is actually conduct a deployment using that published version so let's go back into the published boston reference v-net and to do a deployment it's called an assignment so let's assign the blueprint we've got our subscription scope where it lives let's give it a name assignment boston that's fine i'll make sure to choose my home region let's see here east u.s like i said you may have over time a library of multiple versions and you can pick whichever one you want and then here's that bit about locking that i was telling you the default is not to lock but you can also do just protect against deletion you know how inactive directory local a.d you create an organizational unit you've got that flag protect against accidental deletion that's what this reminds me of you've got do not delete and you also have read only now be careful with that because that's exactly what it says you can't make a single change to that resource does say that not all resource type due to caching locks may take up to 30 minutes there's some legalese going on here let's choose the do not delete lock assignment and then azure is going to need a security context to do the deployment nowadays we have these handy dandy managed identities and a system assigned identity is one that azure will auto create in your azure ad tenant user assigned is a standalone one that you can create yourself in the portal by browsing over to the identities blade identities managed identities blade you can create your own the main difference is that system assigned azure will create it and dispose of it automatically as it needs to whereas the user assigned you control its life cycle now notice here that by clicking a sign with the system designed identity azure blueprints will create an a service principal identity that has owner access to the subscription so it can properly do the deployment and then check this out we will automatically remove this accent access when the assignment process is finished pretty cool all right and then there's the time consuming piece of filling out the parameter values so depending upon how you've defined your parameters in your source artifacts and how you want those specified that is either hard-coded or provided assignment we can add those values here and this will respect any defaults and any allowed value arrays that you've included in your json so resource group name i'll call this boston ug rg for our network"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "hard-coded or provided assignment we can add those values here and this will respect any defaults and any allowed value arrays that you've included in your json so resource group name i'll call this boston ug rg for our network contributor this is going to tap into our azure ad tenant i'll grab a fictional user actually better yet check this out i'm going to add bill zach who's here with us now and he's in the tenant tag name inherit a name what was the name of that tag i think it was location so i'll make sure that all of the resources that deploy into that resource group pick up the tag from the resource group i'll accept the defaults for the virtual network and the nsg definition looks like it doesn't have any parameters so i'll complete the assignment here now again this isn't a test to bring up the old whatever that's from this is actually going to conduct the deployment as you would expect and again the ui kind of just bombs out here but let's see let me refresh my portal let's go to assigned yeah so it looks like it's in waiting status so let's see if we click into the detail what it shows us here view activity log okay that's helpful yeah it's in a waiting status but at any rate it should all else being equal create that resource group and then create the rest of the artifacts but i'm looking forward to showing you that locking mechanism like i mentioned so the idea is that from now on if we have any maintenance to do on that infrastructure we're not going to want to go to the boston user group and start horsing around with the v-net there in fact depending on the lock that you choose you won't be able to you'll want to do all of your maintenance in the context of the blueprint so you would come back to the blueprints ui or your source code wherever the underlying files are and we could let's see if we go to our assignment we can update the assignment that's what you would do and then you optionally can go right back to the draft level and go through the publish assignment workflow iteratively however you want to do that again i want you to think of the azure blueprint as a strong protection layer on top of those resources such that the locks are going to prevent deletions or changes across the board the if you reassign the blueprint it's going to replace anything that was deleted let's say that we did this assignment without any kind of locking and one of your colleagues not you i understand but one of your colleagues were to make a change that you didn't want delete and update whatever it is the next time you could reassign the the um blueprint and just like item potency incremental mode deployments may or may not remove the change but it would make sure that anything that was deleted gets re-established based on the blueprint definition if that makes sense now the workflow if you wanted to delete this it looks like it completed good deal the way that you would remove this like let's say that this entire environment you wanted to get rid of which i actually will at the end of this session i'm not going to necessarily be in fact i'm not going to be able to delete look here it says cannot delete it shows the lock state right there we're going to have that i'm going to have to come in here and unassign the blueprint the unassignment i envision it in my head is that contact that protector that's on top of those resources when you do an unassigned operation it's like you're lifting that protection and then the resources are essentially unmanaged and then you can do whatever you want with them up to your level of our back privilege okay all right so i wanted to jump out to that resource group so let's jump out there and let's um let me show you what that deny assignment looks like that what the how the lock actually is manifested here so if we go to access control i am and go to deny assignments we see something here normally unless you're using blueprints this is totally empty all the time isn't it because it says that deny assignments block users from performing specific actions even if you have a corresponding allow but at this time the only way that you can add your own deny assignments is to use blueprints well here we are and we've got a deny assignment here at the scope but look who it's given to this is that special identity all principles that's analogous to the everyone identity that we have in windows in local active directory so that's going to affect everybody no matter what"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "but look who it's given to this is that special identity all principles that's analogous to the everyone identity that we have in windows in local active directory so that's going to affect everybody no matter what your privilege pretty powerful so let's say let's go into the blueprint and let's go into the subnet definition and just for grins i'll attempt to delete it of course again this again is bringing up that unfinished aspect that i've mentioned a few times this is obviously a bug it should give you a graceful dialogue that you might have expected to see in another context and the notification it should give you you know this operation is disallowed by a lock etc not a crash screen but that's what we get so again to finish this graphical bit the idea going forward now is that we can come back and modify the assignment we can do an unassign in fact we can get to that from the context menu here we can do an either an update or an unassigned are you sure you want to remove this assignment now look i want to call this out all resources created by the blueprint will remain so that answers the possible question when you do an unassignment is that going to whack those resources no not at all it just lifts that protection layer that the blueprint has on it so once that's it's going to say provisioning state deleting and it looks kind of scary but again it's not going the actual resources aren't going to go away that boston resource group should remain standing in my subscription questions comments concerns curiosities thus far anyone bueller anyone i don't think so yet okay let's turn our attention now to the conference files and look at azure blueprints from a more automative um standpoint because you know let's face it the portal's all well and good if you're learning certainly and even after the fact if you just know exactly what you need to do in and out fast that's good but for repeatability we want to look at automation and as i said at the beginning of the presentation blueprints pretty well covered with the other abstractions over the azure resource manager api so let's see where do i want to start first let's see what's this guy doing getting started with azure blueprints okay yeah this is fine so there's a powershell file in the in the files i've shared called warner azure blueprints and just as a side note i'm using a font called operator mono i there's a really cool course called vs pro it's called vs code.pro this dude trainer technical trainer put together this collection of vs code tips and tricks is worth the money for me it was think it was like 40 or 50 bucks usd but he recommended using another font and i like cascadia code a lot but i like operator an operator does this cool kind of cursive when you do a comment anyway assuming that you've installed the azure powershell modules which you probably know this you could just do an install module you don't do that install module az to bring down those modules now interestingly i don't think azure blueprint comes down when you do that though i think you'll have to do that separately i've got the code here in any case so make sure your azure powershell is installed we can do connect ac account or log in az account authenticate into your subscription you may need to set your context if you've got more than one subscription and then just make sure you could do a get module but otherwise you can grab the az blueprint module from the powershell gallery as you can see on line 12 here that is microsoft's official module for az blueprint and then we could for instance do something like get command from the module az dot blueprint boy it's awkward typing on this mac keyboard let's run that in my terminal there's not a whole lot of commands as you can see here very small number but they really cover the main ground right i mean what do we have here new az blueprint so we're going to see that there's going to be a json definition for the blueprint itself and then as you start to plug in artifacts to do this programmatically with powershell new az blueprint artifact pretty straightforward when it's time to publish the blueprint to a version we've got an appropriate command and then the assignment where is that set a z blueprint assignment right so pretty straightforward garden variety powershell as far as that goes"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:35:27",
        "seconds": 2127,
        "text": "straightforward when it's time to publish the blueprint to a version we've got an appropriate command and then the assignment where is that set a z blueprint assignment right so pretty straightforward garden variety powershell as far as that goes all right let's see here okay what am i doing get a reference to a sample blueprint object okay so it looks like here on line 16 i'm creating a variable to create a new blueprint definition assuming that i have the source on my system do i yeah i have a basic networking blueprint here and i think this is probably the same code that we were working with in azure but it's the same idea what you're going to have in your source code or on your local system in your blueprint project you want a folder for the blueprint and then inside there the blueprint definition itself needs to be called from what i understand blueprint.json and it's just pretty garden variety json format as you can see and we've got the artifact subfolder that you'll populate and these can have any names these are going to be the different artifact types arm templates i think you can even do an arm template parameter file then you'd have potentially one or more than one for your rbac role definitions and your azure policies that these have weird good names again this is definitely one i downloaded directly from the portal so you can see here we've got json with a kind of policy assignment and this is defining a resource id of one of my policy definitions uh i got this code again from just doing a download or an export from the portal and it's a little bit ugly with those goods if i did this manually i would use more friendly names but it's just meant there's several other examples in here that you can take a look at you know the drill modify to suit your needs let me go back to the file here yeah so to define a new blueprint give it a friendly name and then you path out to your blueprint.json file right and then i stored that as a variable because we're then going to plug the artifacts into that blueprint definition as you can see the next several examples new az blueprint artifact are going to plug those different json files into the blueprint definition then easy peasy when it's time to publish again just pass in the blueprint object and give it a version number and blueprint assignment anything special there the assignment name and then the assignment file oh that's kind of different i'm not sure what that's all about let's see if i can grab that blueprintassignment.json what's this doing here it looks like it's more or less a manifest that ties in the blueprint id the blueprint definition okay this must be where you provide your parameters i haven't gotten really really deep into this as you can tell which is why i'm being a little more tentative with my language yeah so this looks like the programmatic equivalent of what we did in the portal during assignment where you're plugging in any values that need to be supplied at run time or at go time okay and then i finish off here with remove az blueprint assignment i got the sample code from the docs and you'll notice again i'm not a plagiarist i always give my attributions on line four you can see a link that'll take you to the doc tutorial that this code came from all righty let's see so that's that what do i want to show next here i've got blueprints.ps1 is this any yeah this is a little bit different what this is doing is for example how to grab a blueprint from azure and bring it down to your system so any of those samples i know you can go to github but maybe let's say that one of your colleagues already published to azure and you don't have access to his or her source files i'm just trying to come up with an example off the top of my head there's a couple commands bookend commandlets in that az blueprint library we've got export az blueprint with artifact and import blueprint with artifact i get them confused here let's see input because and it's kind of backwards isn't it well not really if you think about azure being your source of truth for your blueprints i guess export makes sense we'll use export az blueprint with artifact where you want to grab a blueprint from azure and bring it down to your system so on line 14 i'm i'm creating a variable that's going to grab a reference to an existing blueprint in my subscription that's presumably what's happening on line 14 and then on 16 let me shrink this guy up here and then on line 16 we're doing export az blueprint with artifact just specifying there's my blueprint i want it to come down to my local"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:40:31",
        "seconds": 2431,
        "text": "and then on 16 let me shrink this guy up here and then on line 16 we're doing export az blueprint with artifact just specifying there's my blueprint i want it to come down to my local wherever i am in the terminal and if there's multiple published versions grab this version that's it and then the opposite effect would be import az blueprint with artifact push the sample blueprint to azure as a draft look that's kind of a handy command because we're able to take an entire folder so instead of horsing around with that manifest file that we looked at a few minutes ago i'm a little confused now honestly let's make sure that this export command is in that module because yeah it is they're here okay but i'm just thinking out loud now what the difference is between this and doing a oh okay we're sending it up as a draft i guess that would be the difference okay makes sense i hope this is making some semblance of sense uh all right let me see trucking on i don't have any sample code for azure cli but i did verify before we started tonight if i do a search for azure blueprints azure cli that there is a context a command context in the azure command line interface called az blueprint and it looks like policy create role yeah so they're doing their own thing you know that's been the situation with the azure cli isn't it i consider the app at the azure cli almost like an apple apple computer where they kind of march to the beat of their own drummer all right next if you want to go right down to the ground floor so to speak remember that everything in azure resource manager comes down to that fabric of rest api definitions we can of course interact with the azure blueprint product family using rest api directly and this is some code that i borrowed from the docs that uses power shells and abstraction but you know you could use your sdk or postman for that matter the general process here is pretty garden variety what this is showing us is first we're authenticating into azure as usual and then we need to get a bearer token or an api token that will attach to every request that we make to to the api so on line 12 it looks like we're building first of all they our identity and azure programmatically and then grabbing that token and then it's just walking through creating the authorization header and then i've got a bunch of examples here of making predominantly put calls into the api to create a blueprint to add artifacts to the blueprint to publish all the same stuff it's just these are the actual underlying naked rest api calls so the authorization header is going to have your api key and the body of the message is going to be the json itself i didn't include the json here but if you want to look at sample it's actually elsewhere in this collection of files i've shared and it's also in the the link of the tutorial itself all right next on our trolley ride let's take a look at some of the extensions in azure devops considering that you want to put your blueprint files in source code control and maybe ultimately integrate this into your continuous integration continuous deployment pipelines so let me go to that let me go to my organization and actually let me bring out my favorites because there's another repo i want to show you another project i want to show you let's see here show favorites bar always there's a microsoft engineer named paul toller he's australian and he kindly gave me a permission actually shared all of his source files for this project here's what happens here's how i find it found it i did a google search quite a while ago for azure blueprints azure devops and paul toller wrote a really nice linkedin article he posted it there for some reason where he walked through and he actually did quite a bit of work himself i think he wrote the azure blueprints um well he wrote a powershell module that does azure blueprints slash azure devops integration sorry about this ah i think i'm okay and he created a public azure devops project that showcases integration of azure blueprints in a build release pipeline context so all that's to say to give you the cliff notes version in the course files that i've shared or in the session files i"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:45:34",
        "seconds": 2734,
        "text": "showcases integration of azure blueprints in a build release pipeline context so all that's to say to give you the cliff notes version in the course files that i've shared or in the session files i created a folder in there called paultoller where i dumped all of the assets that he shared with me and gave me permission to share with you and also in the course files in the blueprints learning references document there's a markdown file that i created for you and i've just tried to summarize the most important links that come up in this discussion some docs links of course i give you a link to the microsoft azure blueprint definitions at github and then some of the specific extensions the azure blueprint powershell module paul's own az.devops.blueprint powershell module that's in the powershell gallery and then there's an azure devops and azure blueprints pipeline task that you can import as an extension into your azure devops project and then i give you links to paul's original linkedin article as well as to that azure devops public project and lastly another microsoft person named jim britt wrote his own powershell script module and you might want to look at that as an alternative to microsoft's own daisy blueprints it just does imports and exports i understand it's particularly useful when you want to download azure based blueprints and maybe it gives them in a slightly better format than just using that export command i don't know i haven't tested that but anyway what we've got here if i come back to the portal in my project i've created a project called azure blueprints if we go over to azure repos first there's good news and there's bad news in terms of this integration with azure blueprints and azure devops pipelines the good news is that it it's here and it works the bad news is i don't know if you're going to be able to do it if you're using the classic build pipelines the gui ones it's the eighth the azure blueprints task is only for the yaml pipeline experience which is really again speaking of themes where microsoft wants us all to go in the future to define your build and release processes in yaml format makes sense because you're putting the pipeline definition in source code right alongside your infrastructure which could be blueprint and right alongside your application's code base itself it's all in there which is kind of cool so let me see here what do i have in my pipeline script file yeah this is just starting let me see if i can zoom in a little bit just some initial little bit of work i did before i realized i needed more from paul and i gave all that in the conference files i didn't have time to put it all in here yet of course but let me just share my thinking with you what's going on here so in your build pipeline for example we've got this azure powershell task and i got that from the extension gallery azure blueprints task yeah here it is right here neil peterson wrote this one and this like i said is yamo only but there's two things that you can do here there's a blueprint creation and the blueprint publishing there's two things that you can do in here so it looks like in this case what's this actually doing well it's using my azure subscription service this is doing some different stuff actually it looks like this is doing pester testing and that's actually a good conversational point so just thinking off the top of my head here you might want to have your infrastructure defined as a blueprint definition and then using those azure blueprint tasks and also perhaps the inline script capability you could use pester for example to do unit testing on those json files make sure that they exist make sure that they're valid they um they what's that term that validate yeah and then once your testing is finished you can call that other task to do an assignment i think i've got some of that visible in my pipeline let me see let's see here let me go down to the bottom and add a new task let me search my task library for blueprint yeah there it is so if you go to the gallery and you import that as your blueprint as your devops task set you'll get two new tasks that you can incorporate into your pipelines as i said one for creating the blueprint the"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "so if you go to the gallery and you import that as your blueprint as your devops task set you'll get two new tasks that you can incorporate into your pipelines as i said one for creating the blueprint the other for assigning it the limitation there if you consider it a limitation is that there's not the gui form that's in the classic pipeline you have to use the the raw yaml to fill in the properties but it's pretty nicely documented i found if you as you can see here it walks through each of the configuration parameters what you have to plug in here it's pretty straightforward to create the blueprint you need your azure service connection name of the blueprint the path in azure repos presumably where you've got the the folder your project folder include subfolders yeah because that's going to be where your artifacts are are you going to publish etc so they're pretty pretty straightforward i found in my humble opinion so that is about that let me see if there's anything missing here that i wanted to cover um i don't think so let me cue this slide and let me go back to vs code one more time and do one more pass over here him yeah you know uh there are a couple of questions good let's do it okay the first question is uh can we this is from uh uh uh i think nigeria can we provision aks cluster via azure blueprint so kubernetes aks cluster yes what's beautiful about the blueprint metaphor is that if if it's uh deployable in an azure resource manager deployment template then you can use it with blueprints yeah i mean the arm template is one of the four or so artifacts that are available to you in blueprints yeah yeah literally any azure infrastructure that you can do in a json deployment template you can include in your blueprint definition okay um if that didn't answer the question please uh please let us know and that was actually from uh uh maryland not um sorry my name is rocco maryland yeah thanks okay thanks thank you sure and then um is there any part of the infrastructure that needs to stay live in the environment that you will deploy to with blueprints and then it goes on uh azure ad tenant or active or azure or uh active directory directory services or active directory vm any of that stuff uh use case came up with a customer they were looking to turn down uh wvd due to costs but i started wondering about a d and user accounts it's kind of a long um involved question maybe you want to glance at it if you have the um that the team's chat available to you tim rather than my to read it yeah well some things that came to my mind i hope i'm striking on at least a couple of the right notes here i heard dependencies perhaps and i heard the question of deployment modes as i mentioned earlier the default deployment mode is going to be incremental which says that you know azure says so to speak that i'm going to put these resources in this resource group and if they're already there i'm just going to leave them alone and if they're not there i'm going to add them and if the value is changed from what's in the template i'm going to put what's in the template you can alternatively do your deployment in complete mode which says that anything that's in the template is going to go in that resource group and if there's anything else in there it's gone you know so it's kind of wielding a pretty heavy hammer as far as other dependencies yeah the deployment is going to fail if azure resource manager needs to reach out and touch a particular service like you mentioned azure ad domain services and if it's not there if it's not present then it's to me if i'm understanding your question correctly it's just going to come down to looking at the details of the deployment and seeing what failed and trying to fare it out what it is you know that kind of thing and just to review all of our deployments are going to take place in the context of a resource group and i don't care whether it was you who did the deployment or blueprints it doesn't matter we can go under deployments in the resource group and we can see and track specifically every single deployment and we can did this change in the last couple of days or maybe it's my my screen resolution yeah you normally can look at every single operation and ultimately view the json of the json and see exactly what happened and grab the template i don't know if something changed or if it's just my resolution but this is kind of bugging out on me here i hope that response made some"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:55:40",
        "seconds": 3340,
        "text": "and ultimately view the json of the json and see exactly what happened and grab the template i don't know if something changed or if it's just my resolution but this is kind of bugging out on me here i hope that response made some semblance of sense so thanks that tim and uh christopher if you'd like to elaborate or or unmute and ask further feel free can you guys hear me okay yes excellent thanks uh thanks for taking the time tim yeah so i was speaking to a a partner the other day and they had a customer and the customer was concerned about the price of wvd and they wanted to be able to turn down wvd and then turn it up whenever they needed it and my concern i was thinking blueprints and i was thinking like infrastructure as a code but i was wondering about the users and kind of can blueprints build out active directory and would you then import users and things like that that's kind of where my question was headed or is that need to be there kind of like asr right when they do asr you should have a virtual machine that's a domain controller in the failover site always there for testing purposes and things like that um so that's kind of what i was thinking about and you did kind of touch on it with the different implementation strategies but kind of getting into do you need to have a tenant or could you build a tenant out with blueprints and stuff like that okay yeah let me answer what i think i heard two things there first you mentioned about a windows virtual desktop being too expensive so is it possible to scale it down and scale it up and i've done i haven't done that with wvd but i've done that with several other azure services and what i would recommend you consider is maybe using either azure functions or azure automation run books to where you can programmatically and on a schedule or on some other event some other trigger you can do that of course there's going to be limitations if you're using a particular service level and then you wanna during off hours or whatever scale down if you're using features that can't be scaled down that could be a blocker but as long as you have some wiggle room i found that's a nice solution for for cost savings now the the directory thing's a bit trickier because i mean that's really the top of your hierarchy you've got your azure ad tenant and then your subscriptions that trust the tenant it seems you could deploy a tenant with a blueprint it seems to me but shifting that context because you know that this the blueprint has to live somewhere and you've got the management group the management group and the subscription is your only scope so so i don't i i don't think you know i wasn't i wasn't expecting a full answer because this is kind of uh you know an out there use case but i just felt that there was a lot of value if you could do something like this because i felt like it was something along the lines of devops right where you're spinning out a whole development environment uh only when developers need it um you know my thing was just about what are the dependencies are there any that need to be there like virtual machines active directory stuff like that or users um to be able to grant them the access right but uh i i your advice i think was good though i mean scaling in and out and uh doing that i think is a good idea and given that the blueprint definitions are in json and i showed you all some powershell you can always port blueprints to another tenant it's just with a couple line of code re-authenticate to the new tenant import the blueprint into into that tenant and away you go they're not trapped the blueprint definitions aren't trapped in in your current tenant by any means yeah i think that's good for for partners that are going to market with some of these things uh leveraging blueprints right could kind of uh shave off a lot of time with going to market there's a lot of power there yeah yep great thank you thank you again tim i didn't realize it was you until i heard your voice and then i got the pluralsight and i was like oh my god look who it is legislation with you likewise that's such a humbling thing thank you and it's kind of shocking like at a conference or something i remember when's the last time we've been at a conference in person you know but i i've introduced myself to somebody and he's like oh i knew who you were by your voice it's like whoa it's humbling it's gratifying thank you that's great yeah cheers cheers any other questions comments concerns let me bring up my contact deets and again the link to the resources are on this slide there there we go and my twitter's open my dms are open you don't have to follow my account if you want to get in touch that way or through my website it's all good as they say whoever they are but i think that's all i have jason thank you awesome thank you yeah me too good good jason no i was just going to say yeah thanks it was it was it was really good so one of the one of the drawbacks well it's kind of off topic but some of the one of the drawbacks to the virtual thing the events are that we're like doing things behind the scenes trying to you know keep things going and social media and all this stuff and it's like well at least it's been recorded so now i can go back and watch it because i did catch most of it but i definitely have to watch it again yeah that's how i am too once i i might have to watch initially but once whatever it is that's being presented i know what it looks like i can normally just listen to the audio stream and fill in the blanks in my mind it's convenient way to learn definitely were you going to say something in there bill no uh i was gonna also uh wrap up and uh thank tim in the audience uh see if there's any more questions so i'll just go to that so folks in the audience uh uh if there are any more questions feel free to unmute and ask them right now or uh mention something in uh in text and uh in the chat channel uh while we we'll give that a minute to see if anything pops up but uh in case it doesn't either way tim uh thank you for uh enlightening talk and helping us figure out another important area of azure and how we might put it to work for us and folks you see from tim's last slide how you can find him and rumor has he has quite a quite a lot of useful material on the plural sites so you can check them out further there uh thanks everybody for joining us from uh as far away as uh nigeria and uh uh nashville and um uh and uh around the united states and uh well i i don't know if we have another meeting booked but you can look follow us uh you know on boston azure on twitter or the on the boston azure.org we'll lead you to the meetup sites where we'll post the next events but we've been on a roughly two month cadence for uh uh and that's what we've for some months now since coven and that's what we plan to do into the future so so there's uh you can expect you know check back frequently we always we're adding new uh new events uh uh as soon as we book them so thanks everybody i guess that's uh we call it a night thank you again tim excellent talk appreciate it thanks tim all right i think that's uh probably "
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Running Kubernetes in Azure using AKS. This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral. okay did it come up there we go cool we're good all right thanks Jason hey everyone uh my audio is coming okay right loud and clear okay um Jason just give me a heads up if you lose my audio because in the in some of the other meetings I have been lately uh my audio has been dropping but I hope it won't drop today and hey everyone I welcome you all to today's session for Boston Azure User Group uh I would like to thank uh the organizers of the group who have given me this opportunity to present uh once again in front of you all uh especially Jason and Veronica um I guess by now as Jason mentioned you would be aware that we are going to talk about running kubernetes in Azure or in short we are going to look at the managed as kubernetes service in Azure which is known as AKs and before we jump onto that I generally go ahead and introduce myself but Jason has done a great job about that he did covered everything that I wanted to talk about yes I work at capgemini I'm based out of Omaha Nebraska Azure MVP and yeah I I keep myself up to date on certifications and with that let's get jumped into kubernetes for which everyone is here today so to start with uh I would like to start with the very basics for the benefit of people who have not walked on kubernetes in the past uh then we'll see how you can run kubernetes in Azure using a managed offering so to start with kubernetes is defined as a portable extensible open source platform for automating the deployment scaling and management of containerized workloads if you are aware of a term called container orchestration so essentially kubernetes is a container orchestrator it essentially helps you manage bunch of containers running in parallel you can do things like service Discovery you can maintain the health of the containers you can spin up scale up scale down those containers you can do all that uh work using kubernetes some of the other container orchestration orchestrators you might have heard of includes uh Docker swamp which is a comparative tool so that might give you some perspective very basic uh how kubernetes came up with uh it's essentially is a Greek term it uh in Greek it means healthmen of a ship uh and one of the clue you can get even out of the logos or kubernetes as well if you will see the logo of our kubernetes it has that steering wheel for a ship which is controlled by the uh by the captain of the ship that's why uh kubernetes and again if you will see a ship is meant to uh move containers from one port to the another that's why kubernetes a little brief history of it it was announced by Google in 2014 before that it was uh used in tunneli by Google it's heavily influenced by Google's barf system which is a project they used to use internally before coming up with kubernetes original code name for it was Project seven so if there are any Star Trek uh fans in the group here today they would remember export director called as seven of nine so project seven was derived from that and even if you will see the kubernetes logo those in the handle and the staying of that ship there are seven knobs so that also indicates the project seven uh well uh coming back to history the first version of kubernetes was released on July 21st 2015 the current version is 1.26.1 which was released earlier last month I have provided a link to the release history there so you once you get slides you can go and uh keep yourself up to date on the current version which is released and also version 1.27 is related to be released in April and I have provided a link to the schedule so that if you would like to go ahead and keep yourself up to date on that you can check that out it was originally written in C plus plus but I believe a few years back it was Rewritten in go language looking at kubernetes architecture from 30 000 feet view essentially when we when you talk about kubernetes essentially you are going to create a kubernetes cluster and that cluster contains two different components one is known as control plane and the other is known as workers plane in"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:05:05",
        "seconds": 305,
        "text": "when you talk about kubernetes essentially you are going to create a kubernetes cluster and that cluster contains two different components one is known as control plane and the other is known as workers plane in the control plane uh you create your master nodes in the workers plane you create your worker nodes your master notes essentially run your kubernetes core Services the services which make kubernetes kubernetes which does all the magic and then you as a developer deploy your applications and workloads on the worker nodes in a control plane and Vector plane have their own concept of components to make kubernetes work the way it works on the control plane there are four main components starting from API server scheduler uh hcd and control and manager API server is essentially the front front end of the kubernetes control plane it exposes kubernetes API that you can make calls to to perform any kind of operation on your kubernetes cluster uh controller manager runs the controller processes controlling the different kinds of objects that you can create and manage within kubernetes like deployments jobs replica sets and so on uh once you are ready to run your schedule and run your parts and your working nodes you utilize a service known as scheduler which tracks the newly created Parts as well as it selects the worker nodes on which the newly uh newly New Ports have to be created on and then SCD is the uh brain or the memory of your kubernetes cluster it's a persisted store in which whenever the API server is called the very first activity that it does is it goes ahead and stores the state of your kubernetes cluster in that persistent store called as hcd it is in other words it's your system of record which tracks each and every activity that's happening inside your kubernetes cluster uh looking at the worker nodes uh for components are installed on every worker node starting with uh cubelet which is an agent that runs on each node in a cluster it ensures that all the containers that are scheduled by the scheduler to run on your node are running in a healthy state uh the other component is Q proxy which essentially provides the networking features between your working nodes between your thoughts and between your control plane and the worker node uh and the parts uh or the con are the actual workloads that run on your container runtime and container runtime by default used to be Docker before but now if they have switched to uh container a few years ago a few Concepts uh you should be aware of in kubernetes starting with parts which are the smallest units of q in kubernetes it provides a con an abstraction over containers they are ephemeral and that's a key point there and they get their own IP address within q and arrays Services a level above Parts what they do is they provide a persistent IP addresses for a set of Parts running your workload and they it's like like a load balancer and the life cycle office service is not linked to the life cycle of a pot so the disadvantage that you get out of managing Parts which are familiar is basically taken care in Services because services are not ephemeral and they are not linked to a pod Parts life cycle but Services comes with their own limitations sometimes we want to expose your services running inside the cluster to the outside world over HTTP and https so for that you essentially utilize a component known as Ingress uh when you're running your workloads in kubernetes you also need to store your configuration somewhere and for that purpose you use uh config Maps which lets you store text based key value pair but you cannot as with any other system you cannot store plain text based uh config play I mean you cannot store your secrets in plain text based key value stores you need a place to store your secret somewhere like passwords and connection strings uh for that purpose you can utilize Secrets which provides your base64 encoded store for storing the secure information volumes uh help you store your persistent data in Azure it could you can utilize things like Azure storage as a persistent volume a replica set is uh is utilized to maintain a stable state of your parts uh I mean you can create as many replicas of your parts within kubernetes so that your incoming request to the kubernetes cluster can be handled uh deployment is"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:10:08",
        "seconds": 608,
        "text": "is utilized to maintain a stable state of your parts uh I mean you can create as many replicas of your parts within kubernetes so that your incoming request to the kubernetes cluster can be handled uh deployment is the next abstraction of our replica set which provides declarative updates for your replica sets and parts meaning how many replicas needs to run how many parts needs to run you can Define all that in deployment the challenge with deployment object is that it doesn't comes with a state if you are looking for uh a sticky uh deployment so that you can maintain the state for your parts for that purpose you can use something known as stateful set for example if you have a stateless application you can utilize deployment to run in your kubernetes cluster but if you have a stateful workload like a database that you want to run in your kubernetes cluster you can utilize stateful set our demon set is utilized for running any of the on any of the background tasks that you want to run in your kubernetes cluster uh job uh is when you want to continue to retry the execution of your parts until a certain specified number of them successfully terminate you can utilize jobs and extension on jobs is a crown job that you can run on a repeated schedule so these are some of the concepts you should be aware of if you are using containers uh on kubernetes in uh in a real world in a 34 000 feet view this is how it looks like I did Cover the control Pane and worker nodes the different components that run in those uh planes on top of it kubernetes cluster also provides three different ways so that users can interact you can interact using an API you can interact with a kubernetes UI dashboard or you can also interact using kubernetes command line called kubernetes Cube CTL and either regardless of whichever option you opt for you need to provide a declarative template in EML format which defines the state of your kubernetes cluster defining uh how many parts how many replicas what container image should be run on and so on and you can provide that ml based declaration uh template to any of the uh any of the options like API UI or cube CTL and which in under the hood goes ahead and passes it to API server and then APA server takes care of the state of your kubernetes cluster it ensures that your kubernetes cluster always uh matches the state that you have declared in your ml file now uh at a very high level it looks very simple but when you start implementing and deploying your kubernetes cluster on a bare metal machines it really gets uh tricky and difficult to manage each of these components and make them work together it's a it's a really difficult thing to uh maintain you need a specific uh Team to handle that if you are not aware of that I suggest you to go ahead and look at a GitHub repo that I have given a link to uh it's uh it's a repository that Kelsey Hightower has uh created he has given all these steps that you need to set up a kubernetes cluster from scratch he has given an example using Google Cloud platform but uh it really doesn't matter because it's he has provided these steps to configure your kubernetes cluster from uh scratch which you can replicate very well in Azure or in AWS or in any other environment but the idea there is if we will go through those steps you will realize that it's not easy to manage a kubernetes cluster it's not easy to set up all these components and make them work the way you would like them to and for that very purpose each of the cloud providers hyperscalers have come up with their own managed kubernetes Services which are kind of platform Services likewise Azure have their own managed kubernetes service known as Azure kubernetes service it essentially is uh hosted kubernetes service in Azure it reduces overall complexity and overhead of managing your kubernetes cluster in next few slides we'll look into how what uh what are the aspects that Microsoft takes care for you when you create an AKs cluster uh in a nutshell the control plane that I was showing you in one of the earlier slides is provided uh is managed by Microsoft completely and you as a developer or an administrator are only responsible for your worker nodes the advantage is since the control plane is totally managed by Microsoft and you get it all free of course you have don't have to pay anything for utilizing a control plane but what you essentially end"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:15:12",
        "seconds": 912,
        "text": "nodes the advantage is since the control plane is totally managed by Microsoft and you get it all free of course you have don't have to pay anything for utilizing a control plane but what you essentially end up paying is for the workout nodes that you set up in your kubernetes cluster uh to give you a screen a very high level idea on what I've been mentioning on the left side is what is managed by Microsoft on your behalf and on the right side in the worker plane is what is managed by you as a customer so like any other uh managed service in Azure or in any other Cloud platform uh it works it operates on a shared responsibility model so sense control plane is totally managed by Microsoft some of the responsibilities are owned by Microsoft for example Microsoft ensures the scalability and reliability aspects of your control plane it does ensures that monitoring and logging is implemented in your control plane but when it comes to running your application workloads in your worker nodes designing your work and node strategy is all on your own it's your own responsibility to handle that some of the benefits you get out of using a managed service like AKs over running your own kubernetes cluster and setting it up the hard way as kills the high tower asset suggested is certainly like any other pass service you get automated upgrades and patches it supports highly High reliability and availability uh itself feeling if anything happens in your uh control plane or if any of your node goes down in worker node you can configure it for self-healing and control plane is totally at no charge you still pay for the Computing compute storage and networking resources for your worker node and your API server which is a component in your control plane is monitored by Microsoft at no cost for you yeah and it is very easy also to get started uh I I believe everyone on this call would have used one of these different methods to provision any of the other Azure resources similarly for AKs if you are looking to create or configure an AKs cluster you can utilize Azure CLI and use azaks create command if you are using Azure Powershell you can use new azaks cluster command you can certainly go ahead and create a new Azure kubernetes service cluster directly in Azure portal you can utilize Azure arm templates or the newly announced bicep language and you can also utilize Azure rest based management API you can make a put call to their API to create a new AKs cluster for you uh the advantage you get out of an offering like AKs is if you any one of you have worked on humanities in the past or if you will go through the steps that Kelsey has listed in his GitHub repo you will see the old way was if you have to set up your kubernetes cluster just to create it you have to provision your network you have to provision virtual machines to host both your uh control as well as the worker plane you have to install all these system components including hcd database API server cubelets and so on you have to create and install and manage certificates across all these servers you have to register your worker agent notes with the control plane so that scheduler can work with them so it was a hectic thing if you want to start with creating a kubernetes cluster from scratch but when you move to Azure using Azure kubernetes service it's as simple as using azaks read command in CLI or any other competitive command using Powershell or using rest API likewise if you have to upgrade your cluster it you it used to be a set of steps that you had to perform before you can upgrade your cluster whereas if you utilize a service like AKs it is as simple as using a single command like azks upgrade stealing is another aspect of managing your kubernetes cluster because depending upon your workloads you have to scale up or scale out your kubernetes worker nodes it used to take time to provision your new virtual machines install the worker plane components to it register those with the API servers and so on whereas with a service like AKs it is as simple as calling easy AKs scale command uh with that let me quickly showcase to you uh a quick demo so what I have done is uh I have already gone into Azure portal and I have created a resource group called RG Boston Azure for this particular demo I went ahead and I created uh I logged"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "so what I have done is uh I have already gone into Azure portal and I have created a resource group called RG Boston Azure for this particular demo I went ahead and I created uh I logged in into my Azure subscription I went ahead and I created a resource Group here which is this RG Boston Azure then I went ahead and I utilized a zaks create command I have provided my Resource Group name there I provided the name of my kubernetes cluster there I have provided the node count which is one I only want one worker node then I have enabled monitoring add-on for now I want my AKs cluster to be monitored and I also want to generate SSH keys so that I can connect my Azure CLI instance to manage my AKs cluster and unlike a kubernetes cluster if I have to do from scratch it would have taken hours for me this particular command took less than three minutes for me to create everything for me and what you are seeing on the right side is a q a race cluster uh that just got created is it's it is an AKs cluster what I have also done is I've linked this particular kubernetes cluster 2 and Azure container registry uh I can host my images in the is ACR in this particular ACR as of now I don't have any image in there but I can I've already linked this ACR to my kubernetes instance here in eks so that I can deploy my images directly from that particular ACR rather than from any other external repository and as you can see it is pretty straightforward it is running on version 1.2 24.9 you will notice that I did mention in one of the slides on kubernetes the latest version is 1.26.1 but the kubernetes version on which AKs is running its older one and there is a specific reason for that because kubernetes releases versions earlier stage than when these Cloud providers release those versions because whenever a version of kubernetes is released hyperscalers like Microsoft Amazon and Google go back and they make the appropriate changes in the version so that they can support their managed offering based on kubernetes before they can release the updated version so if it'll go here under the configuration not here cluster configuration here you can go ahead and you can see the main version that it is there it is currently set to manual upgrade but you can certainly go ahead and get it updated upgraded to our highest version that is supported by microsoftware which is 1.25.5 you can change it to automatic upgrade currently it is disabled and if you will go and look into node pools as I said I have provided it I've asked only to create one node inside my worker node that's why you see here under node count if I go ahead and click here under node tools node pool one you can see I only have one node which is running in here uh another thing you will have to be aware of that if I go here in this AKs resource it's just a single resource but under the hood what Microsoft does is it has also created one more uh managed Resource Group for me for that kubernetes cluster which has which holds all the supporting infrastructure to run my AKs service it has a network security group it has the virtual machine scale set which includes the same node that I created the node count one and if you'll see it is the same node that I was showing you inside the node pool in the AKs cluster it has its own managed identity load balancer it has its own route table to maintain the routes of a bit for communication between your pods going back to that AKs cluster you can go ahead and you can pretty much what you can do using Cube CTL or cube uh kubernetes dashboard or kubernetes API are also exposed through API AKs dashboard here you can maintain everything here and we'll again go through these again once we deploy something to this jumping onto my terminal what I have done is I have switched my context for Local Q a it is Cube CTL to use my k8s Boston Azure kubernetes instance earlier as you would see I only had Docker desktop since I have been using Docker desktop as a container runtime on my laptop but then I went ahead and I have created a context to connect to my AKs cluster using the command credentials as soon as I execute that command remember I have you generate SSH keys in my azaks create command this after"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:25:22",
        "seconds": 1522,
        "text": "a context to connect to my AKs cluster using the command credentials as soon as I execute that command remember I have you generate SSH keys in my azaks create command this after that when I execute this command it essentially helps me connect you my AKs cluster and I can then manage my AKs cluster using cubectl online top and desktop so let me go ahead and clear this I'll go ahead and uh let's say let's start with q c here create deployment and Gen X essentially this is a plain Cube CTL command that we will execute it against any kubernetes instance in this case since our set the context to connect to my uks instance I'm going to create a deployment Engineers deployment on my uh eks cluster let me get my as you can see there is one nginx deployment running there let me see there is only single part let me go back to Azure portal and refresh this and here's the nginx deployment that I just created as you can see it's only running one single instance to ensure that I'm connected to the correct instance let me go ahead and edit my deployment so this is my yaml deployment file which when I have executed the command using cubectl to create a deployment for nginx it has downloaded an image and it has created a yaml for my kubernetes Lester and this is where it is saying that it should be creating one replica I'm going to make it two and I'm going to exit and Save so I'll go back and pull kubernetes Cube CDL get deployment as we will see now I'm running to dip two in replicas let me go ahead and see Cube Ctrl get parts as you will see there are not two parts running for my deployment and you go ahead to in Azure portal and go ahead and refresh and as you will see I have one more part running earlier it was only one likewise I mean I can execute any of the kubernetes uh Cube CTL commands on eks like it would be for any other uh kubernetes implementation I can go ahead and get services as you can see right now I don't have any uh load balancer service hence I cannot really connect to uh the nginx deployment just that I just had in kubernetes in my AKs instance I'm going to go ahead and create a load balance of service there using Cube CTL exposed deployment command so essentially what I'm doing here is in my nginx deployment that I just had I'm creating a new service of type load balancer which will expose my nginx server on Port 80 to on Port 8765 I'll go ahead and create that let me go ahead and do cubesatel cap Services again as I will see you will see my load balancer service is created but it is still pending I'll wait for it to be ready as soon as it gets ready you will see that it has already assigned a public IP address and as you will see that public IP address in Cube CTL you can see the same information inside service and increases section in AKs portal if I go ahead and look here you will see nginx service that just got created that is in Cube CTL and it is the same IP address if I go ahead and click on that it won't go to anywhere because it's listening on Port 80 but instead I want to go and see access it on Port 8765 where my engine X is listening and here is my engine x uh deployment responding within AKs so with that let me jump on to my slides but the idea here was to Showcase that how easy it is to get started to get this particular nginx deployment working uh including the creation of the AKs cluster then took me more than five to seven minutes moving on I wanted to touch upon some of the concepts around AKs when you are creating your AKs cluster there are two different options you"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:30:27",
        "seconds": 1827,
        "text": "AKs cluster then took me more than five to seven minutes moving on I wanted to touch upon some of the concepts around AKs when you are creating your AKs cluster there are two different options you can create you can set up networking inside your Azure kubernetes service cluster the first uh option is to utilize cubenet networking in which typically the network resources are created and configured as the AKs cluster is deployed meaning uh you create a node you create your pots each of the Pod gets its own IP address likewise the node gets its own IP address then when you create an AKs cluster it also creates a virtual Network and creates a subnet so what happens is in your node gets the IP address from the subnet within the virtual Network that you created whereas inside each node it meant kubernetes maintains its own cider range for the IP addresses that can be used for assigning IP addresses to your Port foreign for your pods for example in this particular example in this node uh it has assigned aside a range of 10.10.0.16 so any parts that gets pinned up in in this node gets IP address from this particular range whereas the node on which all these parts were running get their IP address from the subnet range so if there are multiple nodes the nodes as soon as you get a new node created in your AKs cluster it gets an IP address from the subnet whereas each node then comes up with its own cider range and it creates those spots the challenge here is that your uh Bots running in one node cannot talk to the ports running in the other not because they are running on different cider range and there is no mechanism to between them so that they can talk to each other uh to enable the communication between those parts uh What uh the solution uh is or a solution that is workable is to create a route table which gets automatically created if you remember the managed Resource Group I was showing you for AKs it also has a has a route table that route table essentially maintains uh uh entry for all the cider ranges for each of the node to highlight which cider range belongs to which node and using that route table the interaction between the communication between the parts on different nodes becomes possible the other option to implement networking within Azure uh kubernetes services using Azure container networking instance or cni networking so unlike the previous option in this the AKs cluster is connected to the existing virtual network resources and configuration meaning just not the nodes but the underlying pods also get IP addresses from the virtual Network for example if the subnet range was 192.168.0.020 your node gets IP address from that but your ports also running inside your node gets virtual IP addresses from that subnet now uh security is another important aspect when you are creating your kubernetes cluster or your AKs cluster AKs comes with different Security Options that you can utilize to start with you can utilize things like Azure policies to enforce compliance on your AKs clusters similar to how you will use Azure policies with any other resource type though kubernetes comes with its own uh rbac you can also utilize Azure active directory for identity and access control for your access AKs clusters AKs supports encryption at rest for all the persisted data by default the data is encrypted using a Microsoft provided key but you can also bring your own key for encryption you can utilize Azure security Center which is a tool for security posture management across your Azure environment and that includes our AKs cluster Azure security Center and Azure Defender has been combined now to be known as Microsoft Defender which offers protection not just for your AKs cluster but rather any kubernetes clusters running anywhere using Azure art and in some situations you would also like to uh your kubernetes API server to be truly private and you will not like it to be accessible from public internet you can achieve that by using a service called as Azure private link which only allows incoming traffic from your private Network and returns 403 forbid an error from everywhere else and again this private link service is just not specific to eks but and you can utilize it with many other services in Azure the idea here is that Azure private link works with AKs and you can utilize that to have truly private AKs clusters lastly you can also use Azure application Gateway along"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:35:30",
        "seconds": 2130,
        "text": "it with many other services in Azure the idea here is that Azure private link works with AKs and you can utilize that to have truly private AKs clusters lastly you can also use Azure application Gateway along with your web application Fair firewall as an Ingress controller for your eks cluster to improve your overall security posture because then in your application Gateway you can handle and take care take benefit of all the feature sets that are available as part of that Gateway I did touch upon the Azure policies in the last slide but this is just to depict uh how it all looks like at a high level essentially a cloud architect or a cloud engineer assigns a deployment policy across your clusters and then the developer uses a standard kubernetes API it could be Cube CTL it could be at through dashboard developer deploys the cluster and as soon as uh the cluster gets deployed and there is something which is not correct it is detected by the Azure policy and Cloud architect who has created the original policy obtains Cloud compliance report in Azure policies dashboard which shows what's wrong with your clusters that was created now again Azure policies as a concept as our topic can have its own one hour session but in Azure policies you can actually have different levels of uh actions you can or it is called as Effects by default I prefer using audit which doesn't blocks users from doing anything in Azure environment but as an architect I do get a compliance report of what is not uh matching my policy requirement but there are situations where I want to block people from doing certain things for that I can also use uh deny effects in my Azure policy which will block the users from creating let's say KS plus which don't have specific properties assigned now I did test upon eks identity and management in one of the previous slides I was mentioning that apart from kubernetes are back which is then built to any kubernetes cluster we can also utilize tool like Azure active directory for identity and access management uh and if you are using kubernetes role-based access control you can actually Grant users groups and service accounts access only to the uh kubernetes resources that they need you can create things like roles and cluster roles inside your kubernetes cluster and assign them to role bindings and based on that your users and groups can get access to the resources within your cluster now you can provision access only to specific parts or notes or you can also provision access to your whole cluster using kubernetes are back with Azure kubernetes service you can enhance the overall identity and management posture in your cluster using Azure active directory and Azure role-based Access Control if you are aware of azure rule based access control it comes with a set of built-in roles that you can utilize to provide access to your users to your kubernetes cluster for at least for administration so there are available roles in Azure rbac like Azure kubernetes service our back reader service our back writer and so on which you can utilize to control the access to your AKs cluster now one thing that you are seeing there is azure active directory pod identity uh which is uh very common today which where you can assign the manager entities at the Pod level uh this poor managed identity allows the workload or your application access the resources through Azure active directory but this has been replaced last year with a different identity called as workload identity which integrates with the kubernetes native capabilities to Federate with other external identity providers now if you will pull up or research on what a workload identity is different uh Technologies different organizations Define workload identities in a different way but essentially in Azure active directory it could be uh it it means something very unique to Azure active directory which I will touch upon in one of the following slides with uh if you if you go ahead and integrate your Azure kubernetes service clusters AKs clusters with Azure ad uh you can grant your users or groups access to kubernetes resources within a namespace or inside your whole cluster essentially you remember I was using uh azaks get credentials command in my AZ Azure CLI that you can utilize the same command to obtain a cube cutter configuration context and then you can essentially interact with your kubernetes cluster using Cube CTL now this approach provides a single source for your user account management and password credentials user can only access the resources defined by your cluster administrator through this means uh"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:40:35",
        "seconds": 2435,
        "text": "kubernetes cluster using Cube CTL now this approach provides a single source for your user account management and password credentials user can only access the resources defined by your cluster administrator through this means uh under the hood if you are utilizing Azure radio authentication to connect your AKs cluster what it essentially uses under the word a is open ID connect which is an identity layer built on top of oauth 2.0 and within the kubernetes cluster it comes with its own token authentication mechanism through which it verifies the authentication tokens that comes from Azure ad I have provided a link down there which details everything around how you can integrate Azure ID with your kubernetes AKs clusters quickly to touch upon workload identity uh it's as I was saying different organizations different Technologies mean different things by workload identity but strictly speaking from Azure ad point of view it's an identity that is used by a software workload or an application to authenticate and access other services and resources and Azure uh before we think about Azure active directly uh consider there could be only two kinds of identities it could be human identities or it could be non-human identities or machine identities human identities as the names of the study identities which are used by actual humans it could be employees Partners customers and so on whereas the non-human identities could be either workload identities which are utilized by a service or a software whereas the device identities are assigned to individual devices like mobile devices or iot devices now strictly speaking about Azure ad workload identities could be of three types it could be an application it could be a service principle or it could be a managed identity so just for the context be aware of what workload and entities are and workload identities replaces the Border entities in eks when you are deploying your kubernetes cluster in AKs scaling is a key aspect to it because uh you as you will deploy your workloads as your workloads will be made accessible you will need to scale in or out your underlying kubernetes nodes and parts for that there are two different uh types of Auto scalers that that are available within AKs cluster on the uh at the cluster level is a cluster Auto scaler which watches your pods that cannot be scheduled on the existing nodes because those nodes are out of resources again those nodes that we are referring here are defined by the virtual machine sizes that you define inside your VM scale set and once those nodes are occupy other resources of those nodes are already occupied in running existing parts uh the cluster Auto scaler goes ahead and Spins up new number of nodes to provision the new incoming Parts whereas the horizontal Part auto scalar uses the metric server in kubernetes cluster to monitor the resource demand of individual parts and if a single application or workload that you are deploying in AKs requires more resources the number of parts are automatically scaled up or down depending upon the need by its application uh there is a new event Driven Auto scaling uh known as Keda which is a joint effort by Microsoft and red hat it is essentially Auto scales your cluster based on the underlying events whenever those events get triggered uh your cluster is automatically scaled out or up and down and I have provided a link down there for more information but Akira is just not a unique concept within eks it is actually uh supported for many other kubernetes implementations including uh on AWS and Google uh someone asked about go ahead sir we had a uh we had a couple questions but um one of them was a relatively recent has to do with the the identities uh James was asking um if pods have identities that's right that was what the bordered entities are for because when the original concept was for those spotter entities where each spot can have its own identity that can be used to connect to other resources but that is that is being replaced now with workload identities cool does that answer your question James and there was another question but we can cover it later since you uh I'm trying to go through uh or we can take the questions at the end that's fine yeah yeah we"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:45:38",
        "seconds": 2738,
        "text": "and there was another question but we can cover it later since you uh I'm trying to go through uh or we can take the questions at the end that's fine yeah yeah we can clear the others up at the end cool carry on man okay yeah uh someone asked earlier around Azure monitor how we can get it integrated with eks and how how that works uh I just have a single slide today but essentially you can integrate your Azure monitor with AKs to get detailed insights about your workloads that you are running inside AKs cluster you can filter for details about your notes your controllers your containers running in AKs cluster you can uh see graphical visualizations about your cluster the cluster health and so on you can pull events and loss for detailed activity analysis within your AKs cluster I've missed to add a link here probably that would be have been helpful for folks to go and check it out how to get started with it but it's it's the integration between Azure Monitor and AKs is very seamless and it provides a way uh easy it provides a very easy way to get insights into what's happening in your AKs cluster similar to monitoring you can also utilize Diagnostics within your AKs cluster which helps you find resolution for common issues faster it essentially a case Diagnostics offers an intelligentenna what you should say is a seller diagnostic experience you can help it you can easily identify and resolve the issues that are happening in your cluster it is completely Cloud native it's part of your AKs implementation and it the best part is Microsoft doesn't charges anything for that and you don't and you don't need to do any extra configuration to set up AKs diagnostic it's all done when you are creating your AKs cluster uh Azure AKs storage options when you are creating your AKs cluster you also might have requirements to create persistent volumes uh for your uh notes or for reports for that purpose you can utilize other supporting services like Azure storage Azure managedies Azure files as persistent volumes and you can utilize persistent volume claims to ensure that you are you can hook up to those persistent volumes Azure container registry or ACR in short is a first class Azure resource which is a managed private Docker registry service based on the open source Docker registry 2.0 you can use ACR with existing container development and deployment Pipelines you can use ACR tasks to build your container images in Azure you can use Docker CLI as well to push images to ACR just like how you will push it to any other Docker registry ACR does comes with three service tiers basic standard and Premier premium what really differs is the storage space that you get get with each of these uh service tiers but unlike basic and standard with the premium here you also get uh things like uh Geo replication support for private link and uh you can bring your own managed keys and so on I provided a link there for uh ACR pricing in the difference between the three pricing tiers in case you are interested moving on Azure container instances uh offer the fastest and simplest ways to run a single container in Azure without having to manage any underlying infrastructure like virtual machine and so on essentially it's a serverless way to run it Azure container instances are best suited for any scenario where you can run your workloads in isolated containers for example smaller applications task Automation and build jobs etc for running your containers the flow is straightforward as I've shown in that picture there you create a Docker image you push it into Azure container registry or any other container registry for that purpose and then your Azure container instances run containers based on those images the reason why I have touched upon acis is to briefly highlight the option of utilizing those Azure container instances as virtual nodes along with your AKs cluster so that you can elastically provision compute capacity in for our AKs cluster in seconds since ACI is serverless there is no underlying infrastructure you have to manage that is built on top of Virtual cubelet Technology which"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:50:43",
        "seconds": 3043,
        "text": "in for our AKs cluster in seconds since ACI is serverless there is no underlying infrastructure you have to manage that is built on top of Virtual cubelet Technology which is donated to cncf it's an open source technology you can go and check it out but essentially you can hook up your ACI instances as virtual nodes to your AKs clusters Azure container apps the most recent entrant to the ecosystem uh are the Apple app Services which can enable you to run your micro services and containerized applications on a serverless platform I haven't got a chance to play around with it a lot but with the minimum understanding the basic understanding I have got so far is it's kind of a serverless offering built on top of Cuban area so instead of kks it's a Cuban it's a serverless cube and it is based offering where you can deploy your use cases like microservices public API endpoints using container apps without have to worry about maintaining underlying AKs cluster going back to my terminal here if I go ahead and let's say uh and I'll pick up a demo I we can create an application on our local system as well but on for the demo purpose I'm going to utilize a sample that is provided by Microsoft it's a.net sample which runs a asp.net application the so the first thing that I'm gonna do to Showcase what it does is I'm going to run the uh container locally in my Docker instance to show what it worked what it does so since this is for the first time it goes to the Microsoft's registry and downloads uh the image now as it says it's lit it's downloaded and it's deployed in my Docker instance and it's it's not listening on Port 80 let me go ahead and see what it does and it's listening on Port 80. I export 8 000 sorry as you can see I've mentioned here and I didn't check I overlooked that but 1.8 000 it's mapped to Port 80 on my local host and as you can see it downloaded that image and it is very plain simple.net asp.net application what it essentially does is goes to my system and fetches the system configuration and displays it here is my host name uh let me cancel this and show you Docker to yes oh it's because I have shut it down the let me run that again I'd probably create a new go here I will see Dr PS as you will see p303 FF is the container that's running and if I go ahead and I refresh it you'll see this is running in my local Docker instance so the next thing I'm gonna do I'm going to verify my Docker images right now this is running in my local Docker but I want to get this deployed to my AKs cluster that I created so what I'm gonna do I already created an ACR I'm going to push this image to my ACR since my ACR is connected to my AKs instance I'm gonna login into my ACR using my credentials once it lets me log in I'm going to go ahead and fetch the name of my unable to login I'm going to fetch the full name of my ACR that I can use in my command in this example it is ACR Boston Azure dot Azure cr.io I go ahead and I'll go change my tag for the docker image which was asp.net app I'm going to change the its stat to later to my ACR [Music] ity oops ah look at that the final mistake as you can see I created a copy of that image with my repository name and"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "00:56:26",
        "seconds": 3386,
        "text": "oops ah look at that the final mistake as you can see I created a copy of that image with my repository name and the appropriate tag I'll go ahead and post it into my ACR registry there using Docker push command I'll go back to my Azure portal inside my Resource Group let me go back inside this and pull up repositories you'll see that here is the image that just got pushed and it has completely test let me go ahead and let me open up my ml5 [Music] let me update my EML file Mark for my instance and deploy it that's my ml file that deploys the same image to the kubernetes cluster and go ahead and run Cube CDL apply command let me go back to my it's not ready let me see if it's a failing looks like it's not able to access my let's go and see what's happening in my uks cluster and just got deployed but it is failing it is raining on Clash Loop that looks like I messed up with configuring my ACR with AKs but the idea was to get it deployed and then access it using AKs which is where again a straightforward uh thanks to demo God my demo stopped working but uh essentially what I have us showing you so far was doing everything manually where I can diploma EML files to my AKs cluster using tools like Docker and Cube CDL just like how I will do it for any of the other kubernetes implementations be it on time or any other hyperscaler it is very straightforward doing it with Azure kubernetes service and it supports all the uh benefits I've shown you before you can take it further you can also integrate Azure kubernetes service with your CI CD pipelines if you are a work for an organization where you use a tool like Azure devops and you use Azure repo and Azure pipelines to deploy your workloads you can integrate it with Azure kubernetes service and you can deploy your workloads directly uh from Azure devops to AKs what essentially you are seeing in this particular workflow is as soon as a developer make changes to your application source code the code change is committed to uh Azure repo and then to start the CI process [Music] Azure pipeline gets triggered and pushes the image to contain a registry and then deploys that to Azure kubernetes service which gets also hooked up to Azure SQL database Azure monitor for monitoring if you are an organization who is using another tool like GitHub and Jenkins you can integrate that as well with AKs uh for package management within your Azure within your kubernetes you can utilize Helen which is a package manager and you can use the same with your installations on AKs some of the best practices for AKs plan your IP addresses correctly plan for that I always follow the methodology measure twice cut one so plan your IP addresses strategy up front before creating your AKs cluster always keep your AKs cluster to the latest version or whatever is supported by Microsoft"
    },
    {
        "speaker": "",
        "title": "Running Kubernetes in Azure using AKS",
        "videoId": "eNwBCKvco9Y",
        "description": "This is a recording of the February 7, 2023 meeting.The related After Show Podcast can be found here: https://sites.libsyn.com/464280/after-show-with-vaibav-gujralAzure Kubernetes Service (AKS) is a managed Kubernetes service offered by Microsoft simplifying deployment of a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. In this deep dive session, Vaibhav will cover how to manage your AKS environment in Azure and run Kubernetes workloads in Azure, including some quick demos.About the speaker:Vaibhav GujralVaibhav is a thought leader and a seasoned cloud professional currently working at Capgemini as a Director in Global Microsoft Cloud CoE, where he provides trusted technology advisory to the clients while demonstrating a deep understanding of cloud technologies.He specializes in cloud strategy and governance with deep technical expertise in cloud architecture, application architecture, micro-services architecture, and DevOps practices. He helps organizations adopt the cloud the right way by clearly understanding the business drivers and developing a cost-effective solution utilizing suitable architectural patterns and design principles. In addition, he had led several cloud transformation and cloud migration projects for clients located across geographies in the insurance, banking, real estate, and healthcare industries.He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category since 2020, and he is a Microsoft Certified Trainer. He holds numerous cloud certifications, including Microsoft Certified Azure Solutions Architect Expert and AWS Certified Solutions Architect Associate. He has a Bachelor of Engineering degree with Information Technology as the specialization.He has been an active member of the global Azure community. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group (https://omahaazure.org/), a meetup community of more than 1000 members. He also moderates a Twitter community for Microsoft Azure with over 600 members.Blog: https://vaibhavgujral.comEmail: vaibhav@vaibhavgujral.comYouTube: https://www.youtube.com/c/VaibhavGujral",
        "start": "01:01:30",
        "seconds": 3690,
        "text": "that I always follow the methodology measure twice cut one so plan your IP addresses strategy up front before creating your AKs cluster always keep your AKs cluster to the latest version or whatever is supported by Microsoft utilize Azure ID for an entity management as much as possible secure the network flow the data flow to your AKs and compute for your base cluster policy management utilize things like Azure policies always try to utilize things like cicd pipelines Azure devops are some of the workflows that I was showing you before and avoid managing your AKs clusters manually using Azure portals some of these best practices are listed on the dial link down below there feel free to check it out if you are interested more about learning on AKs there are handful of resources that you can refer to there is this book Hands-On kubernetes on Azure its Third Edition is out now it's it's a pretty great book the book that I read initially to get an understanding of how AKs works but apart from that Microsoft learn also offers say a learning path to learn kubernetes and AKs there are several case studies that are available for AKs that you can go through even if you will go to Azure architecture Center there are several reference architectures that you can refer to which might match as use case and it will help it get started if you are if you want to stay up to date on what's coming up in AKs in terms of feature sets then you can go and uh track that on uh AKs roadmap map and then again you can start with a for free recently Microsoft announced the free tier in eks which essentially just not free you will still have to pay for the working nodes but still it doesn't it's it's a very less expensive than the premium one that being said uh uh and this is a time for crucial and answer and if you would like to connect to me you can connect to me as John was uh Jason was saying you can connect to me where on social media you can send me email you can uh connect me on LinkedIn Twitter whatever works for you if you are looking for slides you can scan this QR code and you can download the slides and if there are any questions I think I would love to answer them and we've got one question from Nathan weeks and feel free to come off mute if you want Nathan he was he was saying it's been a while since he's played with AKs but he was wondering if they've made uh setting up an Ingress or load balancer with TLS termination any easier than it used to be uh I don't know when he has done that but if you go inside the networking tab here this is where it gives this the only condition here is you should have either an app Gateway already created in the past or you can go ahead and create a new form here and provide the configuration and get it set up so it is as easy it is it is here yeah it definitely seems like it closer than it used to be when I was playing with it last yeah and likewise I mean you can set up other things as well in inside this what you are seeing here I mean if you have your applications that needs to be exposed uh to internet on HTTP you need to have your application routing enabled uh it's just a check box here you can you can if you as I was saying in my slides you can utilize private link to keep your AKs cluster truly private in that case if you're you have a private cluster you might still like your uh API server to be accessible only through authorized IP addresses and you can provide that IP address changes here and it will restrict access to your API server from only those authorized IP ranges and I generally recommend this as a best practice to limit access to your API server using IP ranges yeah that makes sense that they have been improvising on this a lot this is from a long way I still when when I look at gke gke is still little Advanced uh probably one step ahead of AKs and eks for AWS the primary reason is because kubernetes is was a Google's Project so they somehow have that uh advantaged for them so that they can actually be one step ahead but I have seen AKs has come up really well and it's a great offering and with Azure R coming up now you can connect to different other kubernetes instances and manage them similar to how AKs is managed I haven't played with them a lot but that also looks very promising that's cool it also probably helps to have Brendan Burns part of the team yeah and and I have published my slides if anyone needs slides they can scan this QR code and you can download it and I know Jason you have been recording this and we will be uploading it in YouTube as well yep I will uh mention it in the Meetup whenever I get it published on YouTube awesome but I uh asked does not like we have any other questions out there lots of positive feedback Nathan said I answered his question uh he wasn't he wasn't aware of the app Gateway Ingress so I'm just gonna look into that awesome someone's typing that here all right I think that's pretty much I had Jason uh awesome well thank you very much and um yeah we'll touch base um later on if we get any other questions uh we'll make sure we get those answers too everybody send my very end and if anyone wants to connect with me feel free to connect on Twitter or LinkedIn and I'll I'd certainly love to help you and answer any queries you might have awesome thanks everybody and have a good night thanks for joining us thanks all have a good night thanks everyone bye everybody thank you that was a great presentation thank you very much yeah thank you thank you thank you "
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Azure Landing Zone by Abdul Kazi. This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog). um and let me know when you guys can see my screen i can see it perfect so um hi everybody uh so my name is abdul qazi um and i'll be presenting on uh microsoft azure lan uh landing zone so it's gonna be an overview before i get started quickly you know i want to keep this very interactive uh so feel free to come off mute i won't be looking at the chat but if you have any questions just come up off mute or you know um bail uh veronica these guys are going to be uh monitoring the chat anyways is there somebody speaking in the background okay thank you so before we jump start uh get started so here's a quick introduction uh about myself you know um i've been in the iit industry for almost 20 years now and one thing i want to bring your attention is about my blog so i have actually written a couple of blog series on azure landing zone and caf cloud adoption framework so do check them out uh they're pretty detailed today it's gonna be really an overview so i'm not gonna go into much detail but uh hopefully you'll find uh those articles uh helpful uh what i'll do is also at the end of the presentation i'll put the links in there that is you have them there and then feel free to connect with me on twitter i'm very active on there also on linkedin uh always nice to have people and learn from others as well so quick agenda uh for today so we'll talk about uh cloud adoption motivations why people are moving to the cloud the value that the cloud ready environment brings i'll do a quick overview about uh the cloud adoption framework uh cloud adoption framework is a huge uh piece and it can take you know days to cover so i'll just give an overview of what that entails then i'll talk about the azure landing zone uh how it relates to the cloud adoption framework and then we'll talk about the azure landing zone design areas and then uh go through azure footprint uh blueprints blueprints is still in preview but i'll uh go through it anyways and then lastly talk about the azure policy and how it relates to the azure uh landing zone so let's talk about uh cloud adoption motivations right why people are moving to the cloud so as you might know cloud has really become a buzzword a couple of years ago you know a lot of people were saying okay everybody's moving to the cloud i should move to the cloud where you know so really a buzzword but i think as cloud has mature people have understood okay why do you really want to move to the cloud um because any company regardless if it's enterprise smb mid market what have you you know you have to provide a justification to move to the cloud why do you want to move to the cloud is there a cost savings is there a reason that you want to exit out of your own data center you know or are you looking to move to the cloud because you want to build a dr disaster recovery or you want to build a second data center in the cloud rather than building a another location or an extension to your on-prem environment so it really depends on what the motivation is going to be but there are multiple motivations there a lot of people are moving to the cloud what i've noticed with our um enterprise customers um at least they have one workload in the cloud now so um i work for a microsoft partner who is a azure expert msp so we usually work with the enterprise space and those customers you know are already in the cloud now but the challenge i'm seeing with them is they have no idea um how to get there or um when i start doing their landings on reviews things were not properly set up or it was not properly accounted for meaning they said okay let's go to the cloud and then there was not a lot of planning done why they want to go to the cloud the other biggest thing about the cloud and it's a challenge i'm seeing is around um you know it's a different model so cloud is really a opex model"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:05:04",
        "seconds": 304,
        "text": "done why they want to go to the cloud the other biggest thing about the cloud and it's a challenge i'm seeing is around um you know it's a different model so cloud is really a opex model versus a capital expenditure so if you think about a traditional on-prem environment you're buying hardware you know software hardware what have you you're buying servers networking equipment firewall switches you're usually buying them on a capital expenditure generally speaking uh you would do a depreciation of three five seven years and after that you know you'll go back and do the same thing cloud has changed that paradigm what we're doing now is um think of a netflix right we're renting the equipment uh from the public cloud company in this case azure and as long as you're paying rent uh you have the services available um i try not to use the netflix example because the challenge with netflix is it's a flat fee so the much more uh better example that is the line is a utility bill you know the more consumption you're using the more cost it's going to be so the biggest challenge i'm seeing with the cloud is people um do not understand how they are being charged or or what the cost is going to look like so i think uh that's the biggest challenge right now um cost optimization so uh when people generally speaking move to the cloud uh what they're doing is they're taking their on-prem environment from the architecture uh and design aspect and moving is as is which sometimes does not match um i'm not talking about lift and shift so lift and shift is you know something different but what people are doing they're saying okay what do we have on prem just move it to the cloud and we'll uh go with it uh it doesn't work that way the other thing is operational uh compatibility you have a cloud operates on a different operational compatibility versus on-prem environment right so those things um have to be accounted for the other piece uh important one is um lack of cloud skill set and we've seen this in the industry um working with one of my enterprise customers they're moving from on-prem environment to the cloud and they're bringing their on-prem skill set into the cloud uh and they're struggling you know uh for example is automation so devops a lot of people there's still a lot of need for automation for example terraform or jetkins or you know the other uh languages that might be out there so that's still innate so what you need to do you know you don't not only have to plan for if your cloud is ready but uh you also have to plan if your workforce is ready if you still have the skill set and how that's going to play when you move to the cloud otherwise uh it's not going to be a smooth transition the other thing is compliancy your compliance is going to be very different um in the cloud versus on-prem because on-prem it's your location you are basically you know you are going to be hosting in that location if you're multi cl like if you're doing a private cloud then that's a different story but majority of the things we've seen is people when they have their own data center they're abiding by you know the compliancy but when you move to the cloud uh you can host your data anywhere any country then that becomes much more complicated um and we'll talk about that so that's uh other another thing and then the other thing was lack of trust and desire for control that was the biggest um i would say drawback why people were not moving to the cloud or they were not ready because they wanted to hold on to that you know data they're like oh this data belongs to me i need to hold it i need to you know see it um but i think with with time they're seeing that cloud is much more secure uh microsoft spends around a billion dollars a year on security alone uh so they're seeing uh cloud is becoming much more secure than their environment and it has become much more relevant than to host um workloads in their own data centers so before i jump into the landing zone i want to talk briefly talk about um what the microsoft cloud adoption framework looks like so for any of you who are not familiar with the caf it's known as caf cloud adoption framework um it's basically a collection of documentation technical guidance best practices and tools uh for companies to move to the cloud and adopt cl or make a easy"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:10:06",
        "seconds": 606,
        "text": "caf it's known as caf cloud adoption framework um it's basically a collection of documentation technical guidance best practices and tools uh for companies to move to the cloud and adopt cl or make a easy transition for cloud adoption uh cap actually started with microsoft own consulting services this is what they used to use internally and then they made it public now so anybody can look at cap and then follow uh the framework and then the adoption the clouded option framework basically brings so it's three faceted it's people process and technology one thing to note here is uh cloud is always going to be a iterative process so regardless if you uh have done a project or uh build a service or an application what have you you you know it's gonna come back again because things keep changing so it's really iterative process um and then as you can see the circle is going around because it's really a iterative process around people process and technology uh technology might change people might change and then you might have to change up change your processes um to make sure that it's aligning with the technology and the people so it really becomes um a strategy and then for calf i would uh say you know the first thing is governance and we'll talk more about i'll touch on governance but governance really becomes a important piece of for anybody moving to the cloud i cannot stress that enough so let's take a look at what the cloud adoption framework uh phases look like so there are uh six different phases so the first phase is strategy so in the strategy phase you define your business justification and expected outcome so basically you say okay why do i want to really move to the cloud you know what is the business justification the second one is plan so you uh create a plan and basically an actionable plan for the adoption how you are going to be adopting cloud to meet your strategy or to meet your desired business outcome uh the third one is going to be ready and the ready is really you know preparing the cloud environment for the plant changes and that's really where the landing zone comes into play so landing zone comes um is part of the ready phase of the cloud adoption framework now moving along once you've uh planned or prepared are you ready then you start doing the migration so you can you can start migrating uh your workload so the different ways of migrating uh mainly two you can do a lift and shift so you can migrate as is or you can do modernization of your application so you can refactor re-host you know those kind of things um so it really depends on what are you trying to migrate where are you going to migrate and what the use case is uh the other one is govern and govern actually comes again from a governance standpoint uh before you even go to the cloud you have to start thinking okay how is the cloud um going to look like from a governance standpoint there should be a government board uh who should be making the decisions for example saying okay uh how are we going to limit people from provisioning everything because once uh it's think of cloud as the pandora box if people open it you know it it can go haywire very quickly so you really need governance from that aspect and lastly manage uh you have to have um some kind of uh plan how are you going to basically conducting your operation for the cloud so from patch management to you know compliancy security those kind of things and then management can also include your uh hybrid environment as well if you are going to be going that route uh so that is very important as well but today we are only going to be focusing on the ready state for the landing zone pins so now let's talk about uh what exactly is a landing zone and why use a landing zone so first off you know um you'll be surprised i guess you won't be surprised but a landings a lot of things within a landing zone you probably would already have used it or would be familiar but i'll use an example of a house or a building or even a bridge right when you're building a house you lay the"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:15:10",
        "seconds": 910,
        "text": "landing zone you probably would already have used it or would be familiar but i'll use an example of a house or a building or even a bridge right when you're building a house you lay the foundation so you have to start from the foundation you just don't go in and start building the rooms or you know start putting um construction the foundation there has to be very strong foundation same concept with azure is an azure landing zone helps the customer set up the environment you know not only for scalability but security governance networking and identity because these things have to be planned uh beforehand before you even get there so i'll give you an example uh from a identity standpoint right uh people might um already have an on-prem environment they want to move to azure now if you did not plan your identity properly then when you move to the cloud there are going to be hiccups there another example is networking and we'll you'll see that in the networking slide is if you do not properly manage your ip space there could be a potential conflict between your on-prem uh environment ip versus in the cloud ip scheme uh so that has to be planned so that's why what happens is azure landing zone is crucial for any new environment when i'm doing a lot of reviews for my enterprise customers the challenge i see is that you know they um lag planning on all the services and they were quick to move into uh testing they're like okay we want to start looking at this workload and just start testing and start moving the challenge is you have to have a better a very strong framework and very strong base if you will um to make sure that your azure environment is smooth and up to par now with landings on uh you know you can uh so so for example i'll back up actually so basically what happens is let's say you're setting up a brand new azure environment so you'll set up a new tenant then you'll have the azure active directory and then on that you'll set up subscriptions now you can have multiple subscriptions or different kind of subscription azure offers so for example you can have a enterprise agreement ea you can have a microsoft customer agreement mca or you can even have csp cloud service provider agreement which is fairly common among the smb market uh based on those subscriptions you can have landing zones within it so landing zone is not limited just to enterprise agreements or mca and actually it also includes other offers so if you want to test out landing zone you can even do it under your msg and account or other accounts there there's no limit that i know of where you can not install or you can configure landing zone so hopefully hopefully this is making uh sense so far if you have any questions just feel free to ask any questions so how do you get started with landing zone so with landing zone you know as i mentioned it's really a iterative process uh there are tools out there so microsoft actually provides terraform modules for the people who um want to automate the entire process this can be automated i mean amazingly from setting up management groups to win v-nets to you know um ip addresses what have you everything can be done so it's really a iterative process and depending where uh you are in the life cycle and how big is the environment sometimes what i've seen is customers really want to start small so smb customers they want to start small maybe with one vm uh you know a couple of virtual machines so that can be they prefer to do it manually because also learning process but and then if you're rolling it out for an enterprise customer you definitely want to go with the enterprise scale landing zone um which really um is a much bigger piece of the pie so it involves much more um things if you are going to be doing a landing zone for a smb because estima uh enterprise customers in this example is enterprise customer requirement would be having an express route versus a side-to-side vpn so those are the minor differences but that actually makes a huge difference in the environment and those things have to be planned out up front because if you don't plan that out accordingly then that can cause a lot of issues from a latency from performance from"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "makes a huge difference in the environment and those things have to be planned out up front because if you don't plan that out accordingly then that can cause a lot of issues from a latency from performance from you know downtime um so those things really need to be planned accordingly can i ask a question the um so i get the importance of uh planning your landing zone right uh you know so it's right sized for your enterprise if you're so so some companies start small like you pointed out and they they might want to grow is the landing zone something that can also grow with you is you know can it be very lightly uh you know a very light uh landing zone at first then a year from now you've uh built it out so that it matches your you know maybe you go from one workload to 10 workloads can it grow with your workloads i guess is a good way to put it yeah exactly and i'll actually answer your question in the next slide because that is going to be the perfect slide for you to see how that's going to work for a small and large environment so i'll come back to your question okay thank you sure no problem uh so moving along let's talk about the design areas and so these are all the design areas i'm not going to go into all of these because i can literally do a session on each of them and actually it does require a vast amount of time um to go through it because there's so much information that is required but the first one is the enterprise enrollment and generally speaking uh you know what you've seen is majority of the companies are doing a enterprise agreement that's why it's an enterprise enrollment but it's not limited just to uh ea it can be c uh csp mca right so the first thing is you're setting up your tenant so azure 80 tenant that's the first thing the second thing is going to be identity so are you using your existing azure 80 tenant from your office 365 um or is this going to be a green field environment and just cloud identity so there are a lot of things that needs to be discussed because if you are you bringing um if you already have a let's say on-prem environment you'll have your active directory you'll have to do a azure ad sync those identities have to be synced properly you know permissioning would probably be there uh as far as our back or that should be there with uh our back so those things have to be uh figured out upfront because uh you don't wanna assign too much permissioning and then i'll talk about our back in a second and then resource organization uh organization so what that means is um how are you basically going to be organizing your resources so from a management standpoint you know management growth subscriptions um your risk your resources how are they going to be assigned so those are the things you have to start thinking and then network topology and connectivity so you know that is something that is important as i mentioned before so what you need to start thinking is okay how's that going to look like um do can we get away with a side to side vpn do we really need a express route uh you know do we need multiple express routes and then from a networking uh aspect are we only gonna be doing a single cloud are we do we have to connect to other uh public clouds like gcp or aws so that has to be a factor in there as well and then obviously business continuity disaster recovery right because anything you do you do you have to account for and as you might know azure by default does not come with any backup uh so and i use the term backup but it only the backup only is one facet of uh vcdr but you know you have to think about other aspects okay like you know there's there shouldn't be any single point of failure so are you gonna be uh using um availability zone does your region even has availability zones so for example um in canada in the um we have two regions so the central uh canada region toronto we have availability zones but the east region which is quebec city does not offer availability zones so uh how are you going to plan for that if a disaster happens you know are you looking at that region or do you have to go to a another region outside of your country and is that going to be an issue from a"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "disaster happens you know are you looking at that region or do you have to go to a another region outside of your country and is that going to be an issue from a compliancy aspect so those are things that have to be accounted for as well governance this uh discipline so from a governance aspect you know like how is that gonna um what is the baseline gonna look like because moving to the cloud you have to have a baseline you have to have some policies uh security policies compliancy policies uh so that there has to be a baseline before you even start rolling out the services and then deployment options deployment options could be you know automated you can uh do it manually so those are the things that you'll have to talk about and then from a operational uh baseline so the operation baseline you can um talk about you know how the process gonna it is gonna work uh is your team ready from an operational standpoint can they even take care of this um so so these are all the design areas that um need attention today i'll be only talking briefly about uh resource organization networking and sum of governance um because we don't have enough time to cover everything so coming to the question now so if you look at this slide um you know you start small so you start from the three things what you really need uh you really need our back it's a role based access control because regardless of the moment you spin up a new tenant you know um and you're adding users you would be assigning them um permissioning so uh start with our back start with networking naming and tagging is uh absolutely paramount very important and i would actually add policies to that list and i'll explain that in the last slides why policies are important but um if you have a really small environment start with that you know uh governance would still uh play a key role but security operations and you know of shared foundation utilities might not come into play but those are the main things you really want to start looking at and saying okay um from a rvac standpoint how does it look like and hopefully that answers the question i'm good thank you perfect so let's talk about our back so um azure rollback base access control you know so it's you're providing access to the azure environment uh and i would say anybody moving to azure should um have the rule where you basically limit the uh access you know provide least amount of access for all the resources or all the services uh you just don't want to start you know giving out a lot of permissioning like owner access and what have you because that's going to cause a lot of issues so with our back basically there are three uh scope uh that are in here right the first one is a security principle so a security principle could be really a user uh group service principle and a managed identity a security identity is really used for applications and services to access specific azure resources and then the managed identities are identities in azure active directory that is automatically managed by azure um so that's really the scope that's where you would say okay so i'm going to be using a user group service principle or manage identity um as a service principle and that's where the permissioning is gonna be assigned the second thing is gonna be role definition and the role definition is really a collection of permissioning right uh and then so the definitions are and the built-in definitions are you could be a owner contributor reader um so those are really you know uh the high level ones i do not recommend any you assign any of those readers yes uh when i'm reviewing my enterprise customers account they provide me with reader access because you know um but i don't recommend owner or contributor assignments right off the bat you should uh find out okay why um they should be assigned those roles and honestly there should be a"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:30:22",
        "seconds": 1822,
        "text": "you know um but i don't recommend owner or contributor assignments right off the bat you should uh find out okay why um they should be assigned those roles and honestly there should be a racy um define for our back because who's responsible you know who's going to be taking care of this who's accounted for those kind of things if you have a racy that really helps put accountability and then that's that's how you can define the roles better as well uh the other thing that also is under the role definition is um there are built-in accounts and they're custom accounts so for example the virtual machine operator is a custom account um for custom account or for you to create a custom account you need a azure ad premium p1 or p2 license unfortunately those are not free so the built-in ones are there but if you want to create custom accounts you have to buy the azure 80 premium licenses um and that and then you can add a lot of custom accounts so uh if you have a special need say for example if you uh have a person who's doing patch management or doing backup you know you can really create custom accounts for that and define the scope based on that and that lastly you know the scope piece you can uh define the scope on the management group subscription resources or resource groups and resources as well and keep in mind our back is um inherited down like a to the resource hierarchy so it really depends how you want to assign the roles and how the management groups are going to be defined we'll talk about management groups uh in the next couple of slides but generally speaking what i've seen is usually people assign our back on the management group or on the subscription groups depending on the use cases and that works fairly well for them so resource groups tax and are back right so as i mentioned uh you need to basically let's say so this is actually a good use case uh for the finance department so they need to basically break down cost by various dimensions such as customer cost center environment right and then you create a role based on the appropriate permissioning based on our back and then you would assign tags um to the resources so depending on what the resources are and then based on that you can do our back you can do actually do tagging as well um and then resources and then uh resource resources and and resource group should always be tagged as a best practice um and actually i'll talk about the policies as well what i recommend is anytime a new resource is going to be spin up uh it should have a tag otherwise it should be denied or if it says okay a tag is not there then the policy should deny uh creating a new resource because in the beginning it's not gonna be a problem but once you have a bigger azure environment and it's going to get big as time goes on it's going to be hard to manage so if you if you don't have tags right away it's going to be hard to manage not only from a cost aspect but from an operational standpoint as well so uh tagging is absolutely critical for all the resources that you will be managing as well so now let's talk about uh tagging decision guide how do you do tagging so let me take a step back and say okay what exactly is tagging so azure tagging is leveraged to logically grow and track azure resources you know uh it can also help you to automate the deployment and provide visibility on reoccurring cost so the perfect example is if you uh are going to be doing a chargeback to an inter department then azure tagging is going to help you because what you can do is tag those resources with the name tag for those departments so let's say accounting is running uh some accounting software in azure you would tag all those resources there and then based on the tagging you can do a charge back to the accounting department and um go from there now larger companies uh they're starting"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:35:27",
        "seconds": 2127,
        "text": "you would tag all those resources there and then based on the tagging you can do a charge back to the accounting department and um go from there now larger companies uh they're starting to use third-party tools um you know there are many tools out there that you can use such as cloud checker and there are many others so it really depends on are you going to be using all the native ad azure features or um are you going to be bringing other third-party applications the other thing about cost management is um is there's a finops practice going on right now because a lot of enterprise customers are doing now is they're starting to build their uh finance practice and based on that they're bringing third-party software or applications to manage their azure and cloud environment and then cost management is only is one piece of that but tagging really helps with that as well so and then tagging the way you do tagging is you tag the names um which tags are uh name value pairs right and they're organized in resources uh in the azure portal and then tags can be applied to individual resources or resource group that are part of you cannot assign tax to any uh to management groups not that i know of um so generally speaking you assign tax to resource groups and resources and that that way you can definitely manage all the tags and do a chargeback and then they're all obviously the other thing is you have to understand the limitations so each resource can have a maximum of 15 tags associated with it so that's going to be a limitation there the other limitation i want to point out is um there is a limit on storage accounts of 128 characters so if you're doing storage account that's going to be your limit there the maximum number of characters for tag names is 512 characters so those are the things you have to also consider because a lot of companies i've seen that do is um they use preferences and preferences can get really longer with their name um naming convention so because if you have multiple regions you'll have that in the naming convention or tagging then resource groups then resources then the application uh then the project or depend so uh you have to figure out naming convention right off the bat because it's gonna help you with tagging and how you're gonna do tagging as well um the other thing is there are some tags that you cannot use so for example um azure windows microsoft are reserved and cannot be used uh the other thing is there is no inheritance hierarchy for tags so unfortunately you won't be able to use inheritance when it comes to tagging before i jump into the next section any questions so far hopefully this is making sense okay i'll take that as a yes so now let's talk about networking and i think networking is the most crucial piece uh when we talk about landing zone or if you're moving to azure regardless if you're talking about landing zone or not uh um networking is to me is the most crucial piece and here's a reason why especially if you have a on-prem environment you know um i've seen time and time again people did not plan their networking properly uh so they ran into issues where um the ip addressing planning was not done in the design phase and then they had a conflict uh or they had an overlapping ip space uh with their on payment environment and azure environment and that's a big issue um so that actually has to be figured out first of all and then this actually if you look at the diagram this does a great job of looking at how things are going to work out meaning let's say if you are looking at a virtual network you do not require a virtual network then you are going to be doing a pass model platform as a service you know so if you let's say you're running a web app um on azure or you're running functions or what have you then you will probably would need a virtual network depending on depending on the use"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "you know so if you let's say you're running a web app um on azure or you're running functions or what have you then you will probably would need a virtual network depending on depending on the use case and the requirement but in case you need a virtual network um you'll go down and then look at the decision tree so for on-premise connectivity as i mentioned before let's say if you uh are an enterprise customer yes you would probably need a express route if you do not need express route then you would need probably need a vpn gateway so you have to go and start thinking okay how are things going to look like what are the requirements how are things going to look like um and what do we need uh the one thing i also want to mention out is azure firewall uh in the enterprise customer space i see a lot of companies bringing their own firewall uh because they already have the licenses um they just bring it as appliance nva and then um just attach it to their on-frame environment uh and that they don't really use the azure firewall so and that also becomes challenging depending on how you want to set that up because bringing your own firewall you know it can get complicated um enabling if you want to do bgp um and all those things you also really require that um networking background as well um and how the network is going to look like so these are all decisions that you have to make um the other considerations you have to do is a vaf web application firewall if you have a front-facing application are you going to go through your vav through azure bath or are you going to be using uh your nvf firewall for that so those are the things that you have to start thinking and saying okay how is this going to look like uh and then if you have let's say um multiple regions how is that going to look like from a um redundancy standpoint if you have to do uh you know failover um is is the third-party firewall capable of doing that can you even do that so those are the things that you have to start thinking in in the design phase right um the other thing to mention is um and and i see this quite a bit is that azure reserves five ip addresses which each subnet so when you're defining your subnet uh factor those ip addresses in there because a lot of people don't think from that aspect right i'm not saying just go and do all your sliders with slash 16 to me that's sometimes too much as well but look at the use case depending on how much growth is going to be there um so look at that the other thing when you're designing the networking is some services um you know some azure services such as the application gateway your vav web application firewall azure firewall azure bastion and vpn gateway require uh dedicated subnets so you have to account for those subnets and how that's going to play into uh your virtual network and is that going to be an issue so those things have to be planned properly um and then you can you can delegate subnets to some azure services that can be injected into the virtual network so that actually might help you uh and as i mentioned plan for future growth because if you do not what i've seen with customers that they did not plan properly and then um it caused a lot of headache and then it can even cause outages as well so that's um that can be challenging from that aspect um and then the other best practice from a networking standpoint is uh public ip addresses should not be used for virtual networks uh i've seen people do that and that's not a recommendation so avoid doing that the other thing is dns so azure dns is a critical part of networking because some you know companies may use their existing dns solution and some others may adopt native azure capabilities um we already saw case with another pro public cloud provider in december uh they went down because of their dns um so dns is absolutely critical so it really depends on how you want to do it again i'll come back and look at seeing here requiring custom dns settings if you say no then use azure dns and if you want to bring your own dns then deploy your own dns you might already have your own dns running um in your own data"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:45:37",
        "seconds": 2737,
        "text": "requiring custom dns settings if you say no then use azure dns and if you want to bring your own dns then deploy your own dns you might already have your own dns running um in your own data center so these you know really this is really a great decision guide because it gives you an idea of um what you need to do um and then majority of time i've seen is oh connectivity you will be doing a vlan so hub and spoke is pretty much a standard uh given and then if you do not need uh v-net peering um or if you don't need uh centrally managed share then do v-net otherwise you know i've seen majority of the time hub and spoke with v-net work perfectly fine um so it really depends on the use case on the on the customer environment how big is it how much they want to grow and then what the long-term solution is the other thing is um uh express route i'll say this and i've seen this is if you're doing express route and this is um saying without giving that you know don't have just one express round because that's going to be a single point of failure um at least have two express route the other thing actually you can do is if that's not going to be cost prohibit then what you can do is go with one express route and then use a vpn gateway like a side to side vpn as a backup so in case your express rod goes down you have a second option the other thing is use private link uh for all azure platform as services over express route you know so that's very important um i see a lot of people not using that that's actually a very secure way of doing it so private links should absolutely be used for any all the past services regardless of what you're doing and then um express route should be the primary connection if you're doing it and then the backup should the vpn gateway um and then the other thing is all both on express route and vpn gateway there are so many skills so for example on the vpn gateway i don't personally like to use the basic skill because it's very basic it has quite a bit of limitations uh so i'd usually go with udw1 or you know the higher ones the cost honestly is not that much it's not that um it's not as higher from the basic one but the features are much uh higher and i believe if i'm not wrong don't quote me on this but if you go with the basic one you won't be able to change that uh last time when i deployed i had i ran into that issue that when i deployed the basic uh sku i wasn't able to change it but with the vp with the other skills you are able to do it so that's another uh drawback of the basic ski for the vpn gateway same thing with with express route there's so many different skills choose the proper skill express route obviously is very costly uh you know and depending on what the bandwidth is needed start small and just start small and then you can always go up so that's going to be my recommendation the other um thing that we've seen especially on the networking side and this is really a gotcha for a lot of people who are moving to the cloud is um people don't realize that you know data going out of azure data centers between two virtual network has a cost uh obviously data transfer going um in between the virtual network is free right so data going into um azure data centers between the two virtual machines is going to be free so that's not a problem but data going out of azure data centers between two virtual network is going to be costly so um the challenge is you cannot predict the bandwidth cost because you don't know um unless currently you're doing a lot of testing and you are testing it out for multiple uh months and whatnot even when you go live the bandwidth is always going to be uh go up and down and it's going to vary be uh depending on the usage um so that's one of the things you have to be very careful about is the bandwidth cost um and actually um i don't know if you guys know uh troy hunt he's a aussie um who who runs the site known as i've been pawned uh he got hit actually with 11 000 dollars because of the bandwidth charts and whatnot so i'll actually put the link in there after uh"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:50:40",
        "seconds": 3040,
        "text": "who who runs the site known as i've been pawned uh he got hit actually with 11 000 dollars because of the bandwidth charts and whatnot so i'll actually put the link in there after uh the session but yeah that's a that was actually a really a ah moment for for him saying okay i didn't realize that the cost can be higher too so those are things that uh you have to be careful when you're designing and um figuring out how these things should be set up time for a quick question sure go ahead so on the uh on the would you mind go back to the price slide for a moment sure on the um uh the need to connect virtual networks subscriptions row i'm curious just in your experience how often you see v-net peering across essentially across spokes i guess as you know something that happens in practice or is that super rare and usually pure pure spoke model prevails um actually uh with my customers enterprise customers it's very common it's actually a need so i've seen vina appearing done with spock all the time so again you know those are enterprise customers they have the need but it might differ from use case to use case of course yeah it makes sense yeah i'm curious about your experience thanks for sharing that yeah so i've uh worked with a enterprise customer in the financial industry and they have they're in both the regions and they are doing a v-net pairing yes got it uh and then um jeff is curious um will there be a demo deploying the landing zones or is the focus on covering the um cloud adoption framework decisions uh honestly we don't have enough time to do a demo at this point maybe in the future i might come back and do a demo um but yeah unfortunately no demo today i'll take it take that as the action item for next time okay yeah uh and and that's um there's some comments here so people might want to check them out their references to external stuff but that's it for the questions right now thanks abdul okay thanks so much so moving along you know uh factors that influence the right setup so you might be asking okay why um or what is the or what is influencing us moving to the cloud so i'll give you a quick example you know um and i'll start with governance so as you might know azure has 300 services right um and then if users don't or if there's no governance anybody can go and start spinning up um those 300 services so that's going to be a huge challenge right off the bat so what should happen is a customer uh should create um you know guidelines of what needs to be done so i had a customer who was creating a new recovery services world every time they were provisioning a new virtual machine uh because things were not defined there was no responsibility there was no governance you know so those things um have to be put in place uh so those are things very important so as i mentioned you know like tagging and ownership this comes into play and depending on the organization some organizations are centralized so tagging and ownership is going to be dependent on them if the organized uh station is decentralized meaning each line of business is going to be managing their own azure environment then they would be responsible uh of managing their own uh subscription or management growth or depending on what the level of accountability is right uh and that should be defined really in the roles and responsibilities that who has a access to what what owners and delegations um should be assigned and who is given what and the minimum access to carry a task right so as i previously allowed it in the example if somebody uh is doing patch management or somebody is doing backup you know they should not be assigned a owner role they should not be assigned even a contributor role because that's way too much access for them so they should be assigned whatever the appropriate role is maybe have a custom role uh and provide them with a minimum access there and then from a compliancy aspect you know um so for example me i'm in canada and then a lot of our financial customers or the customers who are regulated they"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:55:44",
        "seconds": 3344,
        "text": "access there and then from a compliancy aspect you know um so for example me i'm in canada and then a lot of our financial customers or the customers who are regulated they can cannot leave their data or they cannot their data cannot be outside of canada um neither in u.s or you know south america or what have you so those are things that have to be a factor when you are doing the right setup so those are the things that have to be figured out before you even get into the cloud so now let's talk about uh how do you organize your azure resources uh says you're aware when you whenever you set up a a new tenant you have the rule tenant on the top then you have the management groups subscriptions then you have the resource groups and then you have the resources um so you have to basically um make sure that this is thought out depending on the organization and how this is gonna look like we'll talk about how this should be done but these are the main four layers of how things are going to look like from a organizational or structure standpoint um and then as i said before having a effective naming convention strategy is very important because um not having a um great naming convention or not even having a naming convention uh the challenge is going to be that you know everything is going to be hotspot um i was working with the customer they did not have a naming convention now they want to move to a naming convention the challenge is you cannot change uh the names on resource level uh and resource groups sure you can rename your subscriptions if you want to but resources absolutely not so the challenge becomes is now what happens are you going to move them over to a new resource group new naming convention uh that's going to be timely and costly too so that's why having a naming convention is very critical because from the get get go you know okay how we are going to be doing and i get it it might be difficult because sometimes you don't know if you are going to be in multiple regions or or if you're just going to start small but microsoft actually does a great job of providing um the best practices for naming convention um so yeah start with that that would be actually uh really good so now talk about uh resource consistency right so why should you have a consistent um management such or management groups so the management so the first the one is the management drop right so management group really depending on your organization it really reflects the hierarchy so this could be a line of business this could be a department uh and depending on how you want to basically break this out and then you have subscriptions you can have multiple subscriptions so let's say if you have a line of business um and then you can do subscriptions so even subscriptions could be production subscription non-production you know those kind of things and then resource groups where you have the actual resources there and it really depends how the organization is going to look like so let's take a look at the example so these are two different examples the first one is done by the service process so they're doing development subscription uh so these are subscriptions then the lab subscription keyword subscription and then production subscription right and then these are all the resources under here so this these could be resource groups and resources up there whereas from an organizational unit design what they're doing it they're splitting the subscription under hr accounting and marketing so it really depends on what the business requirement looks like and how that's going to be and then who is going to be managing the subscription you know because let's say hr you might only want hr department to have or user to have access to the subscription then yes then the rbac would come here you can apply policies because the hr policies might be different from accounting policies so"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:00:49",
        "seconds": 3649,
        "text": "want hr department to have or user to have access to the subscription then yes then the rbac would come here you can apply policies because the hr policies might be different from accounting policies so it really depends on how you want to do it but this is mainly the subscription level um and subscription you know management groups and subscriptions can get uh complicated very quickly my what what i tell people and the best example i can use is going back to my uh active directory days is whenever you're setting up a new active directory uh you figured out okay what kind of uh org is it gonna be and how many organizational units would you need and you would based your oil use based on that right is it going to be on a department level uh is it going to be on the product level right so same concept for subscriptions and management drops are you going to be splitting the now uh based on the department hierarchy or is it going to be based on line of uh business application and then from a subscription aspect you know uh obviously there are going to be multiple subscriptions i cannot uh foresee having a single subscription uh obviously there are limitations on subscriptions so know the limits on what kind of subscriptions or what this limits are for subscriptions right um and then based on that you can define okay how many subscriptions you want um how the subscriptions are gonna look like and so forth and then from an organizational structure subscription as i said you know do you want to uh separate from a separation of duties is it going to be test versus uh dev environment different end customers uh what i've seen also is a lot of uh if you are a isv i've seen some isvs put their customer uh by subscriptions separate them out by subscription so it's easier for them from building aspects i've seen even some of some uh put their customers on a group resource group level so you know it really depends on how you want to do it some do it on a project basis as well some say okay this pro we're doing this special project so we just um make this a new subscription and then once the project is done now um this is going to be done so it really depends on the organization what the use case is what the needs are but uh this can get complicated fairly quickly so i will say just keep it as simple as possible because you're gonna grow right uh you might start with two three subscriptions and then you might end up having at least five ten i've even seen some customers um having 12 15 subscriptions so now let's talk about uh the management group you know before we're talking about subscriptions which are under the management drop so now let's talk about management row so what you can do is you have the tenant then you have the root management group under the root management group i would say create a i corporate it and then you can do production development or qa right or the other one i've usually seen is uh is you can do core services so all your core services can be under that so under core services you can have a another management group for networking and then uh under that you can have a subscription for your hub and spoke um so under network and then you can have another subscription for security so all your security subscriptions can be there that's going to be the main core services then you can have production management group and then you can have non-production right um and then under production you can have all the production subscriptions there and then resource groups and all that so it really depends on how the organization is going to look like but yeah it's really an exercise you have to go through the process and finding out okay how do you want to structure uh who's going to have access where the policies are going to be implemented are we going to implement policies on a subscription level management group level right uh or their resource group level um where are we going to be uh doing tagging tagging is obviously going to be done on the resource group level and the resources level"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:05:53",
        "seconds": 3953,
        "text": "management group level right uh or their resource group level um where are we going to be uh doing tagging tagging is obviously going to be done on the resource group level and the resources level so those are the things that are going to be defining how you do your management group uh there's another this is also a great example of how you can do um management group based on geography right so you have the business unit you can do the uh geography um and then you can do the environment so production non-progress production um all that and then you can split them up so mission critical productive data you know other production um and then these are resource group based on the applications you have and again depending on how the environment is going to look like as they say there's there are multiple ways of skinning the cat so depending depending on how you want to start your hierarchy and i think hierarchy is going to be you need to define the hierarchy first and then the subscription because once you have the hierarchy then it's easier to define the subscription groups or subscriptions rather than defining the subscription first and then the management groups a lot of companies do line of businesses so they might even what they do is they might even uh create a management group for future line of businesses and say yeah you know we have this project coming we'll create this line of uh line of business management group now and then one once that project comes in we'll have the subscription under that line of business management group um so it really depends on how you want to do it and azure actually does a good job of showing so when you go into the management group in the portal it's going to show you okay how how does the hierarchy look and it's easier to navigate from there and from a management group aspect you can go in up to five or six layers i don't recommend going that deep because it can get complicated fairly quickly maybe just keep it two or three layers if that to the most because the more management groups you have um the more complicated it's going to be to manage you want to keep this as simple as possible to manage your environment because once it grows you'll have more management groups you'll have more subscriptions you'll have more resource groups that's going to be a challenge to manage the question that's coming in abdul yeah sure uh montu asks uh how does this play with companies which are rapidly growing and evolving you know that's a good question if you're evolving and rapidly growing you need to define okay how are you going to do things uh and depending on the company as well right so what kind what kind of company are you um are you a isv you know are you a uh service provider are you a managed service company you know are you a stand-alone so are you a startup i i think that's those are the things those are the questions you really need to ask and depending on that you need to start positioning the management groups and the subscriptions so for example let's say a company is growing rapidly uh if they're growing rapidly it might not even affect the management growth it might not even affect their subscriptions because if they're rapidly growing they might even bring uh those new services that they might uh spin up in the same region in the same subscription and even in the same resource group right so it really depends on on the need and what the use case is and what they're trying to achieve so yeah hopefully that answers the question any other questions yeah there's another question um before asking that um your answer to that makes a lot of sense um to the question monty's question is just answered i think you're saying uh think about this stuff in advance keep it as simple as possible and that's your best chance of growth right if you've got your tagging and your uh our back models in the right places growth is a snap you just add more uh branches down below i think it's a good story exactly exactly because you don't know and i said you know if you know you're growing and if your company let's say um is project based for example you know you can always add management groups so you can"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:10:55",
        "seconds": 4255,
        "text": "exactly exactly because you don't know and i said you know if you know you're growing and if your company let's say um is project based for example you know you can always add management groups so you can say okay yeah we have this new project coming up we'll add a new management group so for example you might just say okay maybe uh add another management group here bring that service or product or what have you there so adding under the management group and then doing it that way or if that service or product or offering that you're building or that's coming up now doesn't even affect any of the environment just bring it inside uh because the more management groups you have the harder it's going to be managing the environment uh and then depending on your i.t um landscape as well right i think that that's going to be the biggest question uh how does your it landscape look like because as i mentioned if you if your i.t is decentralized then definitely you'll have to uh you know scale out your management drops because let's say if your i.t let's take example here let's say uh this management group is the u.s and this is canada for example right now you want to keep uh this management group permissioning separate from this management group right so so that's gonna uh make a difference now if your i.t department um is not decentralized it's all centralized then they probably come at this level and then manage these two environment as well right so one of the reasons you want to also split up your management groups is from a our back standpoint from a policy standpoint tagging honestly won't make a much difference uh naming convention is going to be pretty much the same because you want to follow the same naming convention regardless of uh if you are even in a different tenant because you know that should be your standard um i have customers who actually have separate tenants complete separate tenants for testing purposes so it's a live environment they have two environment one is full production one is full uh testing they don't want to do any testing in the production environment so they have a like a replica of testing and they're following the same guideline same naming convention uh same policy structure um you know for testing purposes so it also depends from that um i think our back and policies play a key role in defining how you are going to be defining your management groups and subscriptions and how that's going to lay out so i think i uh abdul you almost uh anticipated this and and might have just you know answered it uh uh before you heard it but uh uh matu had a follow-up asking can the hierarchies in terms of lines of business be changed at a later point of time so changing the hierarchy that you show here that's really the question can you change that as your i guess as your lines of business evolve oh absolutely yes you can so you can change hierarchies what you can also do is um you can even change um yeah so you can absolutely change hierarchy so i'm working with one enterprise customer we're changing the entire hierarchy it's a lot of work because some of the things are limited some things you cannot move some things you can move um so yeah depending on how much work you want to go through and what it's going to look like it is doable but um there are going to be some challenges and some pain points that uh that brings us up to date on questions back to you abdul thank you so much so now moving on to uh the next topic which is going to be the azure uh blueprints and this can be fairly quick because i i honestly wanted to add this because it is part of azure net zone the biggest challenge right now is azure blueprint uh has been in preview for more than two years now i don't know when microsoft is going to make this ga but it's an amazing tool and the challenges this cannot be used in production environment because since this is a preview you know there's no support for it uh but the amazing thing about azure blueprint is it's really a package for creating specific sets of standard and requirements right that governs the implementation of azure services security and design so in in uh clear terms what that means is azure blueprints makes uh azure landing zone repeatable very easily you know you can uh repeat the process of landing zone with azure blueprint so you can define and then you can start repeating the process again and again and again and"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:15:59",
        "seconds": 4559,
        "text": "very easily you know you can uh repeat the process of landing zone with azure blueprint so you can define and then you can start repeating the process again and again and again and again rather than uh you know doing it manually and and it's best for scaling so if you have a larger environment for uh enterprise customers or big customers uh you know it's amazing and then the good thing is it works with arm azure resource management manager so you know they go up hand in hand now you might say okay you know i'm not using arm i'm using third party uh software like terraform or other you know devops which is fine um but this is a good product and hopefully microsoft brings this tool light ga soon and would be nice to have this useful because this is definitely going to be a very useful for the purposes because it gives you a artifacts and then you can go and start deploying it at scale so now let's talk about the first landing zone so you know you've spin up the azure canon environment you have the azure ad there you've done some you have those cloud identity users now you're basically uh synced up your uh users from your on-prem id using azure id so now you're thinking okay what is the next step so if you look up here you know from an architectural complexity um compute is simple you know identity is fairly simple um networking and data it tends to be more and more complex as i as we talked about in the networking section right depending on the networking if you're going to be doing um express route then yeah you would need uh bgp and other things if you're just doing side to side then yeah it's going to be less of a complicated architecture so it really depends on what the architecture is going to look like but this actually paints a good picture of how the architecture is going to be looking like for the azure landing zone and then for the azure landing zone once you start expanding there are three main categories so the first one is hosting so you know decision to um the student has to be made what services are you going to be using and majority of the time i've seen compute storage networking and databases right that's pretty much um given you would be using those services now other than if you're moving to [Music] a pass model then yeah some services might not be there but majority of the time those hosting services would be required then the other thing is azure fundamentals those are the building blocks and i'll we'll see them in the next slide what the fundamentals look like and then as i've mentioned again and again applying governance principles for each landing zone i cannot stress governance is uh key to success for azure environment not only for landing zone but azure in general because um for example let's say you know if you don't have any governance in place uh people can go start spinning up and series uh virtual machines which are the high compute gpus which are be expensive and then once you get the build finance people are not going to be happy right so you have to have governance uh what i've seen with a lot of customers is they say okay these are the services that we have authorized or we have quote encode blessed that you can only provision because out of you know you don't want to start saying okay yeah go ahead and start spinning up all those 300 services because the thing is you have to do start testing because you have to maintain those applications or services as well do you have the skill set is there going to be an issue have you done any testing so a lot of companies what i've noticed is they're starting to um approve a set of azure services and you can start with compute storage networking databases um and say yep you know these are the services you can do um also they say okay these are the virtual machines so could be you know like a d series just like"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:21:02",
        "seconds": 4862,
        "text": "um and say yep you know these are the services you can do um also they say okay these are the virtual machines so could be you know like a d series just like yeah you know for our regular workload um we're just using um d series now there are exceptions so let's say if you're using a high compute power let's say you want to use cad applications sure um d series might not be the ideal one you might have to use n series or the f series or depending on the requirement so that has to be also called out in your governance policy um and the governance board has to say yes there are exceptions but in general you have to do that um i've seen companies where there were no governance and people were just starting to spin up different level of series and that became an issue because they could not uh automate a lot of things um they didn't have the proper structure so from a governance aspect and from an operational standpoint that's going to help you a lot and hopefully that makes sense so recommendation practices uh abdul uh if i can inject um a question from sandro uh since blueprints are not ga yet they're not um they're still in you know preview or beta or something uh how do you typically deploy the uh uh the caf basic landing zone for your customers so how do you deploy it if you don't have blueprints yeah good great question so generally speaking uh we use terraform for automation uh because we don't want to do it manually um so yeah that's what we're using and we have pretty much scripted out from creating management groups to creating subscriptions to you know resource groups even to the nsg levels so it's all automated you and i think that's the direction you want to go in um depending on the company you are so my company is a azure expert msp and then we are amanda services as well so um automation is really key for us we're trying uh to make sure you know more and more automation in that sense uh and even if you're not even you know like a microsoft partner or msp or um or whatnot um you should look at automation that's going to actually save you a ton of time because when you are doing changes that's going to make your life easier as well yeah sure you can go into the portal and do a lot of things but um our automation is the way to go and a lot of things actually sometimes um you can only do things through the you know cli or automated so for example when um windows virtual desktop came out now it's azure virtual desktop uh you could not do a lot of things within the portal the azure portal right you have to go and use the powershell command list so yeah automation is going to be the key and i think that's going to be your best bet thank you i think we're caught up with questions perfect okay so um and then from recommended practices right so these are the fundamentals that you should be looking out for so the azure fundamentals networking uh identity access storage databases and cost management cost management obviously as i mentioned you know there are multiple ways of of doing it if you are a enterprise customer and you have multiple cloud and and this is becoming a very common occurrence now and i think that's one of the trends uh i've already saw in 2021 and i'm gonna see this a lot in 2022 uh companies are going to be in multiple public clouds and then from a cost management they'd probably be buying a third-party software to manage that but if you guys get an opportunity to look at finops so finops is a like a non-profit org um which basically does guidelines for cost management for the cloud uh and i think that's gonna gain a lot of traction now as well uh but for this session you know i'm not going to go into detail uh because honestly each of these subjects are taught require a session by itself but these are the main pillars um which"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:26:07",
        "seconds": 5167,
        "text": "uh but for this session you know i'm not going to go into detail uh because honestly each of these subjects are taught require a session by itself but these are the main pillars um which are pretty standard and then the other thing is if you want to look uh at cost management i look at my blog i've done multiple cost management uh sessions so you can look at the recordings on that as well and lastly uh we're looking at azure policy so you know uh azure policy before i start talking about the importance of azure policy let's let's take a look and see what azure policy is so azure policy is you is used to create assign and make uh you know policies which can help you enforce compliance and enforce uh auditing for azure environment um and then one of the things about azure policy is you know uh you can implement azure policy at various uh scope levels so you can do it from a management groups subscription resource group and individual resources as well so that's the best thing about azure policy and then um the reason you want to use azure policy is you know there's a couple of reasons is you can apply compliancy security policies to existing resources uh you can automate compliancy um and then for security purposes as well uh the one big thing about azure policy and if you have logged into the um azure policy section is it gives you a word iv of all the compliancy posture across the resources so it's going to say okay you are complying you're not in compliance uh you know and you can go and take a look and see why this is happening now we could take a look at the use cases for azure policies as well uh the multiple use cases so i'll talk about that as well in the next slide but from a uh azure policy building block uh there are three building blocks right so the first one is going to be the policy definition you are going to define um a policy from for a compliance aspect like taken into evaluation what exactly is the policy going to do then you would initiate that definition the policy definition that you defined um so basically then you can manage that policy and lastly you would initiate that policy okay um and then the scope of that policy the policy could be on the management group or the individual level so it really depends on where you want to apply and then coming back to the point of the management groups and subscription groups if you want to keep it simple because if you have many management groups you'll have to go and apply those policies into each managed brain groups as well so um the less management groups you have the better it is because then it's easier to manage from that aspect um here are some use cases for uh the policies so you know one of the uh uses i've actually talked about is limiting the ski types for virtual machines to help control cost so when people go into provisioning a um resource if you have a azure policy that you know uh that is going to limit the skew so you say okay only d level skus can be provisioned and you have a policy uh and depending on if you are enforcing that policy um then none of the uh vms are even going to be visible in the list so or if you're doing through automation then you know you have to keep that policy in mind because otherwise you'll get errors thrown back at you um the other one is um you know allowing resources to be provisioned in the approved region so as i mentioned you know if you have compliance reasons you want to only provision uh resources in specific regions you can enforce that policy um so that's always a good way so these are the minimum use cases but my microsoft actually has a lot of um built-in policies that you can use you can also customize policies but these are built-in policies that you can start with i would say start with a handful policies roll them out and then see what happens my recommendation is to start with audit policies do policies in auditing mode do not start with enforcing right away uh and do not uh have policies in denying mode because the challenges the deny especially"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:31:12",
        "seconds": 5472,
        "text": "is to start with audit policies do policies in auditing mode do not start with enforcing right away uh and do not uh have policies in denying mode because the challenges the deny especially if you're automate automating you'll get a lot of errors [Music] and then if you start denying denying policies um you will know where the issue is right so start in stages start everything with audit mode audit everything uh understand what that's going to entail and then start denying where you know that it's not going to make a difference so for example the skew i mentioned right only allowing the uh approved skew and then everything should be as should be denied that that will work fine or only provisioning uh resources in allowed region so for me like canada central and canada east uh any other region you know east u.s west u.s uh even brazil would be denied by policy so those are things you can really do um to make it easier um so yeah and then lastly you know and policies um they're always remediation you can always go back and see what is working for you what is not working for you um but yeah policies are intriguing part of landing zone uh it's not talked much about but it's going to help you manage your environment and keep that operationally and compliantly healthy so with that you know um that's the end of my session fantastic abdul uh thank you uh very much does anybody from the audience have any final questions for up to them and before uh we get to the questions i want to point out um this github repo uh this came out like four days ago um go check it out it has the checklist so it actually i think has 160 ish um values where when you're doing the landing zone review it's going to basically go check you can check those and say okay yep we've done this done this done this and especially for us um when we go through the microsoft msp audit this checklist is absolutely helpful for us so that's going to be very helpful what i'll do is i'll put the link in the chat there the other thing i also want to quickly mention is um i don't know if you guys saw this but this um i have a blog on the azure landing zone overview so you can take a look at that and then the networking piece because i get a lot of questions on networking so i also have a um blog on networking so that's um there as well so i'll i'll put the links up there okay um they uh there don't seem to be more questions pouring in just uh gratitude and uh positive vibes about a good talk so uh i'll echo that it was uh illuminating and uh very well delivered so thank you for that abdul but jason do you have any announcements no not that i know do you want to say anything about the youtube video um yeah so the youtube video be out i'll post it out tonight but then i want to index it so i'll go through i'll watch the video through and index it with um time stamp so that you can skip to the relevant sections easier later on cool thank you and that'll be available at youtube.com boston azure starting uh tomorrow awesome yeah i'll tweet the link and and send it to all those presenters when i get it but um the indexing won't happen probably till this weekend fantastic okay and uh veronica anything to uh add before we roll i just want to thank abdul and everyone for joining us and yeah keep keep your eyes open for future events we'll post them and meet up and share on twitter and social media okay abdul uh thank you very much it's uh it was uh it was great i appreciate your uh you're sharing your expertise with us all oh thank you so much i really appreciate it stay warm you too thanks so much okay thanks everybody good night everybody "
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Udai Ramachandran: Azure Front Door. This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.. if you guys don't mind i'm going to turn off the camera all right great um yeah you can record if you want to i already think you already started it okay so today's topic is going to be as a front door um it's i use as a front door for ghost and a year now we have built a platform which is a multi-tenancy platform that completely route through the as a front row okay my name is ramachandran uh call me it's easy i work for a company called akumina as a cto um i've been um playing with the cloud for a long time um not only microsoft azure i also uh worked a lot with the aws and google i do have a user group in nashville um please visit and become a member uh meetup.comg i have great topics aligned and i put all my presentations over there and my personal blog is would i dot io today we're going to talk about the load balancing solutions you know front door is not the only one there are you know three three other solutions we will look at it um and why we need a front door um then how we use the front door different concept like domains and back ends or origins routings and how we can do a firewall and then there is a front door b2 is coming which is the preview right now and what's the difference between v1 and v2 and run the same demo using the vita as well so load balancing solution so microsoft provides these four types of load balancing solutions right so load balancer is technically a network layer load balancing um and then there is application gateway which is the regional load balancer with the vaf enabled another application firewall can inbuilt and then there is a traffic manager which is again the load balancer but you know it's not ssl you know tls based it can you can't do a ssl offload like terminating the dls and all those things you cannot do it it's just a incoming request and forwarding it but the one benefit of a traffic manager is the dns based routing so you can do a dns based routing where you cannot perform that type of dns based routing in a front door but the front door is the global load balancer just like a traffic manager but it probably it brings the you know tls product called tls termination and it also gives it runs on the edge and it gives you without you throwing any files into um cdn you can map that everything to go through a cdn so you get a better performance um you know are the cool benefits that load balancer plus the tls plus the edge caching all those things so as a front door um as i said it's a uh edge network to create a fast secure and very scalable web applications it depends on the layer 7 just like um app gateway this is a layer seven applicator is regional this is a global um it's composed of a three concept domains and domains can work with a web application firewall so even before you get into a in you know where your instances are running now you have full control over there um back-ends or origins is your website where you're hosting it or a static web app or even an external endpoint that you're running it um they provide a multiple programming model that you can work with it you know the easiest model is the acid portal that's what we're going to see it today but you can do everything that we're going to do in azure portal by using the power power shell or cli or arm template or even using the management endpoints so in my case now i used a lot of azure portal power cell on template plus for programmatic of multi-tenancy you know we have a multi-tenancy application to do a lot of onboarding things dynamically i'll walk you through we use a lot of management endpoints by using the shisha and we pass payload as arm template so if you look at the diagram over here it's a very simple and i will dive into that later as we go through so you know the incoming request is coming in and you have a region's region one region two region three for in this case and you can do a path-based routing or you know latency based routing um all those cool things but i will walk you through how this works over there but the key concept take away in this diagram you can route one or more regions based on the configurations but you know from the edge if you take the features of the front door itself the first topmost feature is the tcp uh split what does that mean um you know instead of long request right for example you are browsing from uk but your server is in um us for example right so you know instead of coming all the way to the uk's us server it runs on the edge right so front door runs on the edge so first your route is requested to"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "uk but your server is in um us for example right so you know instead of coming all the way to the uk's us server it runs on the edge right so front door runs on the edge so first your route is requested to the edge location from the edge it will constantly ping the server where the server is if you have a server located in the uk eu and eus it knows that which server is the optimal route okay split your one long request into a multiple short request so your first request is always goes to a front door it terminates there and then it creates the you know pre-request in making sure which connection is optimal for this request it it has um you know type of uh prepared uh like http 2 kind of things like um caching the next user comes in it will it will use the same connection again from the front door to your application wherever your application is right so it's always split the request one request from edge your your user to edge where the front door is running the another request from front door to a application where the application is running if you have multiple application it knows constantly scan and get the optimal route possible um it's it provides the health you know constantly scans um you can't figure how often how when to take that from the load balancer and then when to bring it back into a load balancer um and it has the routing you a path-based routing so you have multiple endpoints running in a multiple different regions um it may be a application that you won't run it or it may be a static resource that you want to provide from the multiple different regions so you can route through a path for example slash image go to one servers last video goes to other server and so on um so it you know again it's a multiple websites you can bring it in um if it supports affinity some application may be a stateful um the stateful applications always need affinity so they're constantly connected to the same server until they terminate the system so it supports that and then it says offloading you can take https through a front door and you can terminate and then you can go http from front door to your applications if required um you can define your own custom domain it can be a wild card um you know star.yourdomain.com or you can go you know x dot your domain.com y.o.domain.com and you can set a different origins and then so on um and then the you know integration um which is always you know your request is always come to the front door then you can configure the app to to ideas or ips um uh the intuition detection or intuition prevention techniques um redirect http to http yes now you can get http request and then you can redirect to https request if that's a requirement um custom forwarding with the url right there is a rewrite options you can do that or the forward options um it also supports the ipv6 and http 2.con and your user to a front door is http 2 protocol but front door to backend is http 1.1 is not flushed yet with http 2 product cards um it has the basic td os productions now we said that second the few concept to here is um like domains packets and routings those are the three concepts right so now when you look at the domains you know you can bring any number of domains there's some limitations but you know you can technically customize your domains you don't have to use the um use the front door domains right so for example if you create a web app it comes with you know app name.azurewebsites.net you know similarly front door comes with whatever name dot you know uh fronto.net right so you don't have to use that you can map to a custom domain and then you can route route to the domains um if you use a wildcard domain once it's used you can only have one front door you cannot have additional front doors for example you you know you have a domain called yourdomain.com but you want to split them into multiple different sites right in my case i have hundreds and hundreds and thousands of sites running um i don't mind sub domains but if i use a wild wild record map it's a star.eodomain.com i cannot create another front door and configure it for that i have to say group of domains in a domain of you know 1 through 10 runs in this front door domain of 11 through 20 runs in the other front row um you can do everything in one go but that's not the right way to do it sometimes you get a problem also in a demo why it's not advisable um wildcard is not always available but you can do that with card if you want to you know once you have the front door you can only go up to 100 domains so that's where the wildcard limitation will come in so if you do a wild card you don't have limitations right so all your domains is going to come you know x dot y dot z dot it's all going to go look at the wild card okay here is my um you know end point and it's going to go to the end"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:10:11",
        "seconds": 611,
        "text": "you don't have limitations right so all your domains is going to come you know x dot y dot z dot it's all going to go look at the wild card okay here is my um you know end point and it's going to go to the end point good to go but if you don't use a wild card you can only can't view 100 dominance and then you get to create another front door and then reconfigure it and then you create another front door and then reconfigure it no but the management ui is pretty pretty not not very clean but you can you can do that or you can pay a little bit more for domains to configure the same same front door configuration that you created if you don't want to create a multiple front door you want to use the one front door to manage everything then you can do that but it's going to be extra additional cost five per domain looks better with the azure dns i use azure dns all the time uh it's very transparent fast high you know it looks better in my opinion um test certificate are not allowed so if you want to try with http yes they provide um they will provide you a trend or defined certificate but some reason you want to enforce that with your own certificate you will have to bring an enterprise certificate paid a certificate you can use the you know testers that you created using the make set that's only works other services but not for this service um you can't use the subject alternative sand like for example um you know you can define asan um x.y.o.domain.com right so you know some people will cheat dot star.y.e.o.domain.com and you might have noticed even as a web app won't take that certificate if you try to cheat with the sam name you cannot do it you will have to find the fully qualified one sub domain in this case you will have to buy star.y.e domain.com and then the star can be any any second level sub domain so you cannot go star dot star even that concept won't even work with any of those services in the cloud it has to be always one sub domain or one sub sub domain so it is only one star is allowed next to the concept is the backend backend is also called the origin or origin servers right so it can be azure resource such as the uh you know the old platform cloud services or the web apps um or the virtual machine or the container any any services web endpoint that running or it can be the external endpoint you know somewhere you're running some site which is exposed to the public internet you can use that why i set the public internet the front door cannot connect to the private internet that's why the printer the next version of the front door comes in the the current go was a live version of the front door you can only connect to the public endpoint um it has a host header you can map to the host together to take a valid request you know sometimes when you you know if you leave it in a public internet anybody can pass anything to secure if you want to pass additional host header from the trusted resource you can do that it also has the priority you know how the backend is defined so you have a back end you know you have a two uh two missions running on it are two load balancers behind us attack and you know then you can set the priority um you know how to route the traffic it's again the same concept as traffic manager how you would perform and then it's also gas that has the concept of weight you can set the weight how do you want to write it you know um like a you know maximum request to go here or there the default um routing is the uh the latency sensitive route meaning that it will route the fastest uh node or the low latency node for example i am uk connecting to eu node may be closest but it may have some latency some traffic just like you know point a to point b we take a highway we assume that's the fastest and that is true most of the time but sometimes you know something happened on the highway taking the local road is the most optimal route right likewise you know you know if you like the user connecting from uk there is no no node in the uk there is a node in eu that may be the closest but them is still connected to a node in line or west coast because the traffic goes free it's easy to go low latency then they will always connect to a um you know to a best node so that's that's the logic built into it but you can override all those things by using the priority weight and then there is a last one called the latency sensitivity but you can enforce some no don't go to a us and you still work on you know you are closest to no and you can set some value that value can be 500 milliseconds connecting to the us best maybe a hundred milliseconds but now you can change that latency to you know until 500 milliseconds you know if my local node is going to find a millisecond still stay here i'm fine with it don't go to us west you can set that that's called latency sensitivity you can set that and then the health probe has a lot of things you know you can help the probe using the path protocol method there's you know they support two method head ht head request which will not download any data just send the request"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:15:12",
        "seconds": 912,
        "text": "you can set that and then the health probe has a lot of things you know you can help the probe using the path protocol method there's you know they support two method head ht head request which will not download any data just send the request or then see get all the header details and come with it the get request is going to download the data it based on how your health endpoint is designed one can use the head request or get request in most cases i would recommend you have another endpoint or add another router type head which just sends message and then sees it okay i'm good and come back the get will bring the message why it is important um the front door is going to do a crazy number of pink to your end point right so you have a three endpoint three region running there is a 200 plus edges running that is going to pink coming from all the edges to your application right so if you know you you know even your get is going to return at 10 bytes now assuming that 200 requests coming in a second you know you multiply that right so 10 bytes of 200 will become 1000 bytes which is equal to close to a you know one kb and and if you leave it for one hour it's going to be like a large number of requests if you leave it one hour it will be about 12 000 request that then you multiply by 10 you're setting a large of data you're paying for no reasons to avoid that you know they recommend the head request so which will not download the data but still tells them that the service is healthy or not can take can can forward the request to the edge or not um in the load balancing concept they are sample size you know how many iterations that you want to consider as the pass or fail you know you can say successful sample in the total number of samples and then the successful sample those are the property to keep the service in the routing table or not but it will constantly scan you know there is a health issue detector it will remove it and as the health you know it will still constantly ping but once the service is up and running they will add it back to routing next one is the rules engine um the rules engine is help will help lot in this case uh for example uh that's the one i was telling like edge level caching so if you have a static files you know you want to cache it you know you don't want to cast the dynamic files right for example um you know um so anything that the dynamic data the login route or user profile and so on you don't want to cancel those urls but you still want to cast all the static routes right you know anything that comes slash image slash css no slash j is you know and so on then you can define a rule now how do you want to define that how long you want to cash it the cash comes with the multiple options you know you can go up to three days uh 24 hours to three days or you can set a hard limit you know how long you want to you want to set it by the default option anywhere from one day to three days um that's because the one day is the gdpr requirement so you have the gdpr right that you know you hosting in the uk uh eq regions but you're browsing from the us they kind of keep the data more than 24 hours um so that's why that limit comes in um so it's also help you to do a geo filtering so you can set the user come from so and so region either a load deny or you know log and some options and then ip filtering sometimes you know you have you see that the some ip address constantly you know pinging your server or doing some bad things you can block that you can also set the security header so for example you want to allow somebody to post data without being in your own domain then you can set the content security policy who can post the data to you you define that you know then those customers can post the data of course caching so now the routing um when the the routing comes in the routing and the rules are you know hand to hand but you know it has the pattern match how do you want to route it you know slash images or slash images star x and so on it can either forward to the service or it can redirect to somewhere else and then roots engine decoration that's what we see in the previous slide um previous slide that does the road syncing and then the vap um so front door that's that's a good thing you know even before you you know you don't infuse application gateway you will have it's a region right so you have to run it on every region um if you run your application in uh three regions now you need to define a three application gateways and configure it but the front door you don't have to do it because it's a global and then the map is also global you know it runs there it runs on the edge and it sees it okay policy violated either you know based on the configuration either you did ideas or ips i know it's a province it's going to stop it if it's a detection it's going to log it and then let you browse to the"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "okay policy violated either you know based on the configuration either you did ideas or ips i know it's a province it's going to stop it if it's a detection it's going to log it and then let you browse to the site um it has the ru it it has the top 10 ow asp it has the crs drs meaning that common rule set drs meaning their default rules rule set they are they have some versions coming in some they have some vulnerability packed into every person in the front door old uh the current front front door which uses the 1.0 common rule set 1.21 default rule set they have a vulnerability defined and then the new front door the version is lifted 3.0 which has the you know little bit more added rule sets for the vulnerabilities again the key point for the app is for conventional detections you know how you want to predict all your you know malicious request versus the valid request you can also set some access access restrictions by using the custom custom rule just like a root table uh of um of a front door you can also different rule on the web you know if you have a detection mode and on our prevention mode anymore um you can add some more rules you know how do you want to you know restrict certain type of jio or ip or you know based on the conditions you can do a rate limiting um and then you can also do a redirect for example the user comes from xyz location or the or the body contains so and so message or the header is missing so and so message then redirect to a different site right so you can do that as well uh rest api so this is what we use uh we just go here play with it uh and then see how the payload look like and then we put the payload in our system and then we create it right so they have a rest api playground you just log into the portal and then you browse to a rest api you see all the methods they support click on it and then you can play right there simulate the payload and then see whether it's working or not if it's not going to work there it's not going to work in your code so that's the right way to test it um we do we just we use this rest ap there online more often to validate our request or if you see something is not working this is the first place for us to go all right so this is standard premium i'll hold these and let's go some demo and then i will come back and then we will have the preview and then i will show how everything mapped you are not going to see a lot of difference uh between the v1 and v2 i call it sp1 and v2 the other one is the front door this one is called front door standard premium um we'll come back and check that one any questions so far you guys are there yeah i've got a question about some some of the differences in relationships between domains uh domains routes rules and pools correct i'm really confused about like how all those relate to each other yeah um so can i give you a quick scenario and then maybe you can explain based off that yeah so if i have two domains uh two completely different domains and in two different regions i have two pairs of app azure web apps so they're completely different sites right and i want them mirrored between east and west coast do i need two well i mean before we continue let me do a whiteboard i'm going to share a different screen now okay continue on i got your point keep going yeah so i i what i want to do is i don't want to have to have two different front doors for two websites i'd like to use the same as your front door yeah for both websites both my applications um does that mean i need to have two what i think are called routes um yes let me explain to you uh so so let me go back over here you see me whiteboard or no not yet i'm looking at a google google home page or a new tab rather it's a different window yeah let me know when you see my whiteboard now i see a whiteboard okay so first thing you said don't mind right i'm going to say you know one dot your domain dot com okay two dot yeah you are domain.com uh now let's say the next one is uh two.mydomain.com all right completely okay great mydomain.com right so those are the two domains now you have the front door over here you're going to add one.yourdomain.com and the two dot my domain.com right you also said you have multiple services which called the back end pools are origins okay so in the east region you have some app running is that right you said sorry say that again east the east you have an app running right"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "you also said you have multiple services which called the back end pools are origins okay so in the east region you have some app running is that right you said sorry say that again east the east you have an app running right yeah so i have an i have an application running mirrored in both the east and the west coast okay so i have the best for both applications so really there's four azure same application it's the same application no they're different applications okay different applications so a1 and b1 let's call it as a1 and the b1 okay yeah all right so now routing right so route comes in over here so you know they're they're both running in both locations so east has has a copy of a and a copy a copy of your domain and a copy of my domain is it like that you want yeah just like that okay so you have the both side running over here yeah for redundancy and also you know if someone's on the west coast i want to send them to the west server server pool right okay so those are the packets right you know it's completely disconnected back end is a packet that is all it's going to do is the packet is healthy or not and i know i'm a healthy to take a request that's all it does the route table is what tells you where you're going to route it so now you need to define a router for one dot your domain.com right that's that you're going to define a route in this route you're going to tell so before i do that so here the pack and you can consider this as a pool one this is a pool two r you can change you know um you know like all together one pool okay so i was thinking like mydomain.com would have one pool where one service is in the east and another service is in the west and yourdomain.com would be a different pool for one services in the east and in other services in the west you can do that um you can do that so uh so let me take this one so so you you're going to have a pool one consists of a1 and b1 right sure pull 2 consists of these two like you know p1 and uh changes slightly different color here this one and this one right so this is two this is is that right that's how you configure you there oh sorry muted my goal here is to have for yourdomain.com to have geo redundancy okay so let me keep the high level so what you can do here so you can define mix and match right so you have the your domain.com in the route table you're going to say i'm going to say one.eodomine.com is going to go to the pool p1 you can only say one pool right r2.mydomain.com is going to p2 okay so what happen at this time so there is a constant ping is going to go and all the places here to here one and then p1 and and so on a one year one this constant being we know based on how you configure the default is 30 seconds if you leave that way there is going to be 12 000 things per node it's going to happen you know in an hour okay anyway so now it's it's going to you can do it what do you just explain there is no restriction you can just do it so one dot our domain.com comes in it's going to go to a yeast you know and then if the user browse from the west it's going to go to a west and then similarly 2.mydomain.com it's going to go to east if the user draws from the east and west the only thing you can do because you putting the node a1 b1 into both back and pools you cannot restrict by the front door headers because it's going to say nope that header is already configured so you cannot do that so other than that you should be able to do what you exactly explained you can mix and match and the same same um pack and can be a part of another pool to do the two dot my domain.com that's fine yeah so like i know i know that i can do this but i'm i'm kind of unclear on what primitives are involved in doing this so would this require two different routes to say that your domain.com goes to all one as soon as you have the domain here so this is the front door you know like the the first configuration you have to say here like i'm going to have this domain this moment right as soon as you do mine it's invalid until you define the route right so you define your domains which is the domain is the first configuration and then you will have to complete the route how are you going to route to the domain so the you use the url kits one dot your domain.com this is the route is where you're telling either a path or the you know and the the pack and port where you want to rotate right and the host header so now which header you want to send you want to send to one.yourdomain.com or you want to send"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "telling either a path or the you know and the the pack and port where you want to rotate right and the host header so now which header you want to send you want to send to one.yourdomain.com or you want to send you know some sort of static headers x dot y dot com you know those three parameters you can only set it over here plus the caching how do you want to cache it it's going to be a dynamic cache or the static cache and all those things you set it on the route not here so each application should probably get its own route exactly every domain needs to have its own router so that's a massive massive difference between azure front door and as your front door standard and premium no in my opinion yeah no because money no the front door premium is just brings additional functionality like you know you know right now this is a public endpoint right so you are you are these things most likely to be in a virtual network but it's still exposed to a public right but you can prevent that by setting the header but these endpoints are can be virtual network but still port 443 r80 is open to a public somebody can hit it right but that you can prevent that you can put this this package completely private that's where the premium brings into it for you know added value so you can now those are routed within the microsoft network layers maybe i'm confused then because all right so i don't whenever i go to the pricing page for the old azure front door you have to pay per routing rule beyond whereas on the new standard premium model i don't see any pricing based on it's still a preview it's still a preview so you don't they don't talk about them it's still so nice so they might still charge yeah yes yeah it's still a preview so and you know a few things you know when i started look at like six months ago um for the same demo talk that i'm giving i gave six months ago it wasn't working um they said you know certain things we are working on it i looked at it today this is one functionality still not working which is the caching still not working um you know there is there is no better way to configure caching the front door provides some much better option than the front door preview that we are talking about anyway um thanks for the question i will change gear here sorry guys thank you for the explanation oh let's go here so what are you going to do um so i have um some samples i already created because you know creating on the fly it will work but it's time consuming process so for the interest of audience just to go quick uh know how we can create things uh and i look for the front door right so either front door or front door standard premium the way the configuration work is entirely different the terminology they used is entirely different but once you configured no they all work i will show you the the key difference between a front door and front door premium but once you once you get into it and you understand okay that it that's what it is so i'm going to select the front door and just click create go for it and then you know you just say here you know um whatever the host name i usually say ft just copy that word for now um azure ft.net right so like creating it and then i can say i need assess an affinity or not which is mainly for the stateful applications who needs to be routed to the same node if you have a stateless application you don't need to bother about it the other one is the application firewall so you can you need to create the firework first and then you can add it over here right so um if you enable it it will ask you to select what firewall you want to pick so you can pick it i'm not going to complete so i will take whatever i i can do right now okay and then just add it now you need to come back to the packet port so which is also called origins um you know you come here you give some name and then you add the packet right so i'm going to select something here app services and i have that subscription i'm going to select maybe um east to us so here is the key if i have to pass in the incoming header right the url to all the way to the um the application then i have to keep this as empty okay if i leave the value over there you know when the request opens it's going to pass whatever value was there so that value will be passed but you don't want that value to be going some application you may need to but you know you know most likely you want to pass in the incoming cost header all the way back so in my my case when i build a sas application we have you know 500 plus customers url hosted in one front door and not one multiple front doors but when we come in it's"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "most likely you want to pass in the incoming cost header all the way back so in my my case when i build a sas application we have you know 500 plus customers url hosted in one front door and not one multiple front doors but when we come in it's the same compute it has the domains but we want to pass in the incoming uh header right so it comes like you know um would i dot my company dot com i want to pass in all the way to the back end woody.mycompany.com so i can do some partitioning based on the top level domain name i can look up the particular data customers data and then you know let them work with it so if you put that value any domain come in it's going to pass to our endpoint that domain so you have to keep that as empty and then you can enable those port and then add it and then you can keep add to the packets right so um you know you can say again i have your app service and i'm going to say this is going to be um used to use this to us you know just speaking randomly and then you keep adding it so you keep add as many as many backends as you want um then your path you know if you want to differentiate the path you know you keep creating it you know one for images one for things but in this simple demo we're going to keep everything dynamic and static mixed so i'm not going to set any path um there is no requirement for us to isolate it but if you want to isolate it you put a path and then you come back create another another attack and pull right and so on uh probe method is a head our get uh as i said head is just connect and gets it get download the data so even if the 10 bytes is a lot you're going to pay a lot of money so you have to be very careful using the head request this sample size you know it checks for four and then to mark it as a healthy you know this money is needs to be passed um latency sensitivity zero is the default meaning that it will always know the closest route in the example i told you you know highway is the best route to go from point a to point b but sometimes there's something happening on the highway it takes a longer so we start tend to take the shortcuts right so like that mechanism built into it sometimes it's also called dynamic site acceleration tsa so it's constantly sends the ping and then make sure what is my best route possible okay so i say add and then routing rules okay in the routing rules you get to say some you know whatever name it is and then you accept the protocol and then you say the frontal domain so this is where it's going to be as you add a domain here so right now we said azure eft.net but you know when we have the custom domain we're going to add custom domain one custom domain to custom domain three and it would be here and then you select which term and you want to map and then the match path again and then you either forward or redirect within the back and forth you select right now there is only one you select it and then either you redirect rewrite um our caching i would if you say enable over here it's a dynamic route caching say you you're expecting the dynamic data for example your endpoint returns the current date and time right but that will never return for 24 hours the one time it's returned that value is cached so you don't want to cache it here but i will show you where you can cache it so this is the one for routing when i set it here that is not this is only for the path for the healthy check i i miss spoken here this is only for health check if you want to route image versus image versus you know other thing then you you come back and create a multiple routes routes table one for image one for video and so on but this is back end of that path was for health check where your end point is you know in my case is you know i might say api slash health right you know wherever your health is um endpoint is health and finance but if you leave a route and that's not a good idea because most of the time the route side tend to have more data than the uh other sub routes dedicated for the intersection anyway you got the concept so that's it and then you know one other thing that we have to note down here is the interval seconds right if you leave it 30 seconds based on how many regions you run you're going to hit that number pretty high pretty high in an hour so if you increase the value you can go up to 255 if you said 256 it's going to throw error 255. now you are in you are increasing the value to run you know close to 4 minutes 15 seconds right but the problem of that as i said in the highway example you know you see like there was now there is an accident two minutes later everything is clear the road is clear it can go high right but that that optimal route it's not recorded for next to four minutes so it's going to check every four minutes instead of every 30 seconds right so the lower the value is better to detect your latency but the higher is higher the value it saves a lot of data on money side of it so you you're going to play with some you know based on your requirement you know what value might work for you there um you know the optimal value may be 120 that's what i do it but you know but you can play with that value but you have to have some value more than the the front of preview they make that as"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:40:27",
        "seconds": 2427,
        "text": "work for you there um you know the optimal value may be 120 that's what i do it but you know but you can play with that value but you have to have some value more than the the front of preview they make that as a deep order 60. okay so that's it that's all and then you know next section is tag and then review and create you're good to go you created the fronto right so let's go back to the one we already created any question all right so i'll take this one so so once you create this is what you're going to see it right so this is how it looked like um you know friend print ends i have a domain here so how do i add a domain so i can add one domain here but now it's going to say boston demo 3 because i already used two boston demo 3. my wr right it says okay you don't have the name defined um in the latest they will have a lot of way to fix it from the portal itself but in the current printer you will have to add those values so i'm going to go back to my um goodness just stop me guys if you're any question so come come back to cost you brought up the health probes costing is that at the the inbound data transfer to origin rate exactly yeah so it's it's from your application to a front door it's uh you know how much state i took from so the front door knows where the your application right your application and then the front door right so that's where the request is originated those data you need to pay for it um if you your health endpoint is going to written say you have a generic health endpoint that gives a much more details than the health check of 200 okay you know says i have like a health endpoint gives me um you know 50 bytes but when you run that that number of requests it's going to be a pretty pain you know a lot more consumption over there so if it's just like a 200 okay with no body no real body it's no different from a head from a cost point of view yes exactly so you know i mean you are not going to see it right away there is a you know money saved but you just look at it you run it you see it then you will realize how this tiny bit of data increases your billings um so i'm going to have this boston demo 3 here i'm adding it i'm going to route to my cname record here so the one that i created ft b1 dot azure ft.net right so i'm say ft view on azure ft.net go to that one so i create it okay so i go back to here so it found it that's the cool thing about you know using the azure dns you know one thing is a performance other thing is very easy to work together you know they are on the same service blade and then status enabled this one is the https you want to do it if i do enable i have option to select the front door managed or use my own certificate okay um so if i say front door managed then they're going to renew it they're going to maintain it it's pretty much free you don't have to pay for it but you know you will also have to use your own then you know it's good idea to use the key vault and then use the latest option so that way um that way you know as you renew the certificate it trades the latest and then apply to it okay and then you give the latest instead of the selected versions um here is the one place that you can use the test certificate you have to have the industry certificate or you have to use the front door managed certificates but again front door managed certificate is not applicable when you use a wildcard domain if you map the star.active.here then then render many certificate is not updated and then i have some app already created i selected it will get into it later and it says an affinity in this demo we don't need it you know it's a very simple website you're running it and then say now we have the domain added right so now in the routing table so i go back to my routing i say boston demo three i accept these two protocols you know and then here i'm not going to route there i'm going to route over here okay and then my path is going to be default i'm not going to change it and then i have a rules i have a ruled one i'll tell you why i need that rule you can keep it empty in that rule i'm you know i i disabled the caching here because i don't want the dynamic caching but i do need the static caching any static file that is used in the system i want to be served from the edge i don't want to go to the server so that rule i depend on the rule one i will show it to you so i'm going to select that's my role in gene and then whatever the packet port that i can't figure over here right and then if forward you know either http or https comes in you forward to https only but you know our http are the match requests so whatever the income is db then match request will power to http"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:45:31",
        "seconds": 2731,
        "text": "here right and then if forward you know either http or https comes in you forward to https only but you know our http are the match requests so whatever the income is db then match request will power to http is to be yes then power https we are not going to rewrite any url here we are not going to enable caching's ad okay and that's it now that the other settings that you need to worry about is this one the timeout this also the preview they made it at 60 seconds um you know most cases 30 seconds is optimal but you know your application does a lot of processing it needs more than 30 seconds then you can do so i believe the max is a 240 yeah 240. so you can go up to a four minutes um so it will not time out your front door will not time out otherwise it'll timeout terminate the request so you can set any value you want i'll save it it's going to take a time because we put https over here so that's going to take a uh oh we didn't do it okay i've saved it okay it's still not done yet okay we'll save it um any change you perform you will have to you know once everything is done you will have to put if you make any changes you will have to post that post might take anywhere from five minutes to 30 minutes um if you don't see it right out of five minutes i know the first time it will be frustrating but you know you will get used to it but it takes at least 15 to 30 minutes to get the value over there all right let me go back and then uh show you so now we add a domain right so how do you route to the domain to your app services so i go back to my app service you know i pick these are the two app service in the pool i go back and then do a custom domain and then i add the custom domain constant demo three we know and then i say validate okay so it says invalid right but after they mapped the boston demo three i came out item.ft so you know if you run your application in multiple regions you still need those those domains to be added you will have that text record as it explained over here so you copy this value and then you create a asuid you know text together that's what b do when you create a app uh when we onboard a customer say you are a customer you know your url is going to be x dot you know mydomain.com then we ask the onboard process we will create this recorder first is uid dot the x right and that will let us mount that to our add the custom domain to all the regions that we are running so we run pretty much 12 regions across the world so it will automatically close and runs all the dns records and then we will add a you know mapping to a front door just like how we did you know the real domain boston domain three i couldn't do as a c name to a front row but in this case it won't let me add because i need either a permanent record or a asuid record it's a temporary account so i'm going to create a temporary record here copy this value oh god there has to be a text record because cname required already mapped to a friendly value you say okay right now i go back to these and then okay so now it's valid because it sees the temporary card and then it won't it will let me add it so now i can go and add that record now i just you know since i enabled the https only so it takes few minutes to refresh that i select from the theme you know you either you import it in my case in my demo i have everything keyword so i'm browsing it and adding it in your case whatever where you want to work now you are you can also create a temporary certificate from here if you want to just valid for six months so you can create using here if you want to create one in my case i have imported using this one anyway so i got it now i got to the same thing for the you know uh the you know other regions but due to the time constraint i'm not going to do it but i will but you got the concept how you enable from you know from the adding the domain your dns records to a front door to a routing table to your application so we gone through the data flow for the demo purpose i'm going to use the one i already have it which is the boston right so that's the that's how the front door any question here so the next one is the web application firewall so i you know"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:50:33",
        "seconds": 3033,
        "text": "through the data flow for the demo purpose i'm going to use the one i already have it which is the boston right so that's the that's how the front door any question here so the next one is the web application firewall so i you know the creator application firewall so here we we mapped demo map one so once you click on it you see what it is and um you can do the managed rules so if you look at it this is what i was telling you the default route set to 1.0 and that's a that's in the preview the latest one i believe 1.1 and then common rules at 3.0 they will keep add these vulnerabilities the more vulnerabilities they will add it is running right now in a detection mode we are not stopping it uh you know it's more reset to direction so we enabled all the rules but it's not even black somebody's going to give this you know um sql injection you know um you know vulnerability it's going to pass in it's going to go to the server but it because we said to a direction if you do a prevention mode it's going to provide it top error you can also add a custom rule so if you want to add a custom rules over here you can define a custom rule rule one whatever you want to call it as rule 1 you know and then put the policy uh priority just a number they you know you might have used as they everywhere there is a priority and then you can say geo or ip size or some sort of condition that you want to pass it in if you do a jio and it's not in the u.s and i don't want my my site is only for us customer then i would now say the user is not in us then you know you deny traffic or redirect traffic and so on you got the concept since we are running out of time all required to be passed you got the concept so you can write as many rules as you want they all execute okay now the next thing is the association how you associate the rules that is not allowed here no you can don't secrete the once you create the web now how you associate with them that's what that code over here now let's go back to the printer and then take about the rules in gene right so what is this rules in general so this is what i was telling i was turning off the caching when i was adding the routing table right because in the routing table i said no don't cache anything but i can override that by coming back to over here so if you look at my rule here i create a rule 1 and then i said static assets it contains that you know you can put a multiple js css link right and like you know if you think that one of your path also has a lib somewhere else not intend to have a live of what you're thinking then you can add multiple conditions you know have that and not have these then do that so what i'm saying what we are doing here we take the request url you say contains and one of those you know if you want to multiple you can do a you know underline delimiter so just enter one at a time on one line one one per line js css leap and then you do that condense after converting to lower case if the path contains one of that then i want to do a forward to this pack and pool you you know then you do a you know either you can say match request again you can do a match request into https only i am not rewriting it but i'm enabling the cache and the cache is going to be a time i also enable the dynamic compression for the better performance and then use the default cache duration yes that means it's going to cash from 24 to 36 uh 24 to 72 hours if it is gdpr compliance you know based on where you browse where the origin located they will do a 24 or the 72 hours okay so now we create these rules and the rules is already configured so for that reason only it will cache it and tell you okay i'm going to cast that request any any any request that goes to a css that contains the js css lib will never go to a server it will terminate the first request will go to the server the subsequent request will stopped at the edge um you know and then it serves the data properly all right so that's the rules engine um today yeah yeah can i ask a question about rules engine suicide yeah this is basically it's not really a question about rules engine but i'm curious about your experience with the rules engine in that i know you run some complex systems i'm curious in in in such a world is it common to have a few rules or come and have 50 rules like what's the what's the span of rules that you see in the real world um i i know so if okay good question it depends on the requirement uh you know you might think if it's a 50 rule it needs to run all the 50 rules right somebody might say oh how fast it's going to run but i believe there you know it's kind of 50 else condition they will optimize index they will optimize it the answer to that question is is it's it's absolutely it depends on the requirement but now i'll give another example here you can split this into"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:55:35",
        "seconds": 3335,
        "text": "going to run but i believe there you know it's kind of 50 else condition they will optimize index they will optimize it the answer to that question is is it's it's absolutely it depends on the requirement but now i'll give another example here you can split this into three rules right you know one rule just to say yes alone and then create another rule and then you tell them you know tell them request to url and then contains uh operator contains and just say a css right you can do that as well but now you technically running three rules this is the bad practice if you can compose all those parameters into the one rule then you do that but if you want to do it like you have a 20 different 20 different path just for 20 different paths you want to repeat that for 20 different path then maybe maybe not a best practice you know you may have some requirement that you know certain path want to be cast at a lower interval than the other path but that in that case okay but they are going to be duplicate of what is defined on the first rule then don't do it just do it in the value as this like that but again i answered your question i think it it case my case but you know i i had a maximum of three rules that's all i'm running today um but i don't know i'm answering correctly to your question but you know i i don't i did not see a requirement for 50 rules but i think if you have a system that gives you 50 rules yeah it needs the 50 rules but what i'm saying is don't worry about the performance of computing those 50 rules they have a pretty good indexing very very helpful i appreciate it today thank you yeah all right let's get back to this one over here then and the other and the final thing that you must configure is the diagnostic settings okay if you don't configure diagnostics i don't know why they call diagnostic settings if you don't configure you go to a lock it will say you didn't configure anything but i wouldn't say that as a diagnostic you know diagnostic my my opinion i maybe you know you guys can correct me like something problem is going to happen that's going to help me but it's in the you know but i need to have the complete logging then you have to come here and add it so just go here you know put some name on it and select the values what do you want to log i always select all three and then i i send it to a log analytics workspace okay but don't even try to send it to some storage account or somewhere because those things is never going to help you um log analytics workspace is the best tool that i ever seen you can run it but it also it's not a free tool it's pretty expensive as you know the more you curry the more data you store the more money also you're going to pay in my in my case is the the project that i'm working on the more money go to the log analytics and any other services that's because there's too much of logging going on too much of korean going on then that leads to a more money like no per day the 100 gig you put them in a log analytics workspace you keep it for three months and you think about it how much log you accumulated you have to pay for all those things when you want to query they have to go through index through all those data so that's that's pretty expensive so you know do some analysis but you know some people might store it to a storage account for the auditing purpose i probably gonna look at it if you put on a storage account you can read it friendly nobody's going to look at it maybe the financial data you know if you keep financial data i may add it for the auditing purpose you know for seven years otherwise there is no use but i always use a log analytics and our system is not a critical system it's a content management so we don't care all those loggings we just put them in a log analytics we never configure more than 90 days you don't need those data more than 90 days for pre-production 90 days you know production we have a two cloud pre-production production cloud uh production cloud we give for owner eight days anyway so you got the concept you need to have those value in order to run some analytics logging over here right um so i think we covered the basic concept we saw the front door designer firewall rules and then now how you query the data right so you go back over here and then you can you can you know for example uh so you see the locked request i don't know it's it's not populated thing is hanging there something coming i don't know all right well it's so that takes some time while it's working on it uh that is not working i will show some lock from the other system but you got the concept so that you know even though the lock says even though the log says in a blocked request which is a blocked request now in the demo case we made it as a detection only so it's plot but it detected and then we move forward because that's what we want but they come under the blocked request category um you know they've brought a lot of sample queries you know you can look at it you know request for queries for example you know they're pretty good this demo site has set up this afternoon so you know enough data for you to see it all right let's go back to our ftv one so we have the you know this is the main blade right here so if you look at it in the"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:00:38",
        "seconds": 3638,
        "text": "this demo site has set up this afternoon so you know enough data for you to see it all right let's go back to our ftv one so we have the you know this is the main blade right here so if you look at it in the request count you can see this is not not affect us because it's a demo site request to size nothing you know we haven't promised anything we've been talking for the last one hour we didn't browse anything so there is no data to show and if you look at the back and health percentage i see it tells you okay you have two endpoint one is talking to a dewc which is the germany west central other one is the eus which is the east u.s right so i have two end points they both seems to be healthy right if it's not healthy obviously the bar is going to go down as it becomes healthy the body is going to go up and then stay in that level okay so that's a very helpful uh blade over here the next thing is you know we go back to the front door and then we look at it not this one i don't know maybe ready or not so if you can look at it it will tell you the status it will take uh 15 to 30 minutes right now it's ready um but you know we can browse it but we did not configure all the end points right so this endpoint is configured same exact way that i was configuring the boston demo 3 so we will use this endpoint to see some data i'm browsing from the u.s east uh you know i look at it i see my sample code i put on my now okay what is the incoming domain coming okay which region it's coming from and the data so if you look at it the data changes if i put check that caching enabled yes then this will be the static right you know it's coming from the edge then i will not get this value increased at all so now since we set the static route to see do some static level caching so if you look at it i don't know anything over here i reload i look at the css if you look at tcp heat what does that mean you didn't go to the server at all okay so tcp hit means and this is another indicator that you are your data is coming through the front door okay and it tells you i'm coming from the front door but i had a caching i never go to a server so this file is never gone to a server i did a pressure lock disable cache so i'm forcing to go to server but it found the file on the on the edge and then it gave me the file okay so i got it you know if i had another another path uh yeah this also this path has to limb this path has the css and then this may be having the js yeah it's also tcp heat so you got the concept what will happen if it goes to the server you will see the tcp miss meaning that it will find the content on the edge and it has to go to the server and then download it back and then give you back but once you refresh all the other users coming from the same region they will they will be sold from the yes they will get a tcp hit the key advantage here is now i don't have to worry about not say i'm a application that i've been building for several years i never throw all my static into you know this was a design issue i never and i won't be able to throw everything into a cdn right me hosting a cdn throwing it over there and then calling from the city i don't have to do now the front door does it for me you know it's all running on the same system but front door does it for me uh you know for all the path that i configured okay so that completes that one so when i go back to a different region hopefully my dm works i will show you otherwise you'll skip what happened okay any question while i'm waiting for these things to load so this is another vm that i have it in a different region entirely different regions um you know if i go and browse the same url here so i'm going to go ahead over here now it's gonna give us to germany right so so it's gone to west germany and then i got everything um we look at the network stack it should be a tcp miss because i didn't get it i refresh it tcp hit right so i'm first time browsing to that when the first request over here it wasn't missed it didn't find on the on this on the edge because this this when i when i hit from somewhere in asia the the front door tells them okay are you the closest is the west germany i'm going to route you to west germany okay it's going to west germany and then that's the first request after clearing all the i know i i cleared before demo everything so tcp means but now the second time it goes it sees it easily if somebody else is browsing they are going to dissipate them okay so you got the concept all right on next what else i'm missing here i will come back um so let's go back to the slide here um a standard premium um so the standard premium is the same functionality plus it has the uh you know um inbuilt the cdn and and"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:05:45",
        "seconds": 3945,
        "text": "what else i'm missing here i will come back um so let's go back to the slide here um a standard premium um so the standard premium is the same functionality plus it has the uh you know um inbuilt the cdn and and then the uh it has the uh and i have another tech that explains how you can do it it has the functionality called a private linking uh which is a cool concept and i use it in in my hosting deployment remove everything behind the door we only expose the back and nothing else is exposed to the web app outside to the public internet you know so you can connect to the connect to um on-premises which uses the internet you know they use the express the private private linking you need to download and install it you can do that so that way you know your front door can talk to on premises in a secure way but again the same concept is available um they have two skus uh one is the uh standard skew uh which is same as the uh what we have today plus the uh traffic analytics and some most um security capabilities the premium sku has the part protection i mean the bot production still available as a preview to a current front door uh but you know there you know it's it's optional bot protection is optional on the current different door and also a preview but in the new front door they are not optional i think you can buy it um as a private link support that's a key and the thread intelligence and secure analytics i know some more money more price the second point over here is the global load balancing that's the same dynamic site acceleration that's the same you know that's how it tells you what is the closest node by sending hundreds and thousands of ping to your servers i'll skip this one and i'll go this one so front door what we have today is a cdn static file website caching dynamic site api acceleration all those things that we signed the standard they call it as a delivery optimized because they have a inbuilt cd cdn that's what they say but i don't care as long as i get a senior functionality they also have a small little bit more smart way of doing the dynamic site acceleration and how we want to connect you to a closest to their back uh traffic analytics and a health report and then the premium sku the main thing is the private link support uh then they have that the common rules of three point two drs loads so don't find one and then some more okay now things to know there are five zones in india australia are those things um you know ensure json is properly promoted udf8 encoding you know sometimes you know you download from the git this may be a utf-64 encoding to underwork it has to be edified encoding if you use json file uh minimum builder response is 2 kb even it's less than 2 even if okay so this is where i was telling it right so if you you you send the data which has the data data in the body then you multiply by 2 kb you know it's it's you're going to pay a lot of money so right so and then 100 domains um per front door uh that's not going to include the wildcard domain um or i don't mind more five dollar more per domain afterwards um so data transfer from back into a front door is the bandwidth building how much data was moved in the wire um it's a hoverly building all right now let me go and walk you through uh front door uh v2 okay so it's the same exact uh but the the you know the the the play the ui the the naming is slightly different this is the v2 if you look at the v1 this is you know defined over here like this but if you have more than say 25 this will overflow in a pretty bad way so i go back um how do you create a front door v2 so i select weapon door premium i create i would select this option because this option is i'm comfortable using this option but you can select any option but anyway you will have to complete it uh you know then continue on um you put some name on it as he said it doesn't matter what option you select but you will have to select before you you you complete the creating the service but once you created it you have to date and change it um again you know it's a private link everything is a cool console but you're going to pay for the money after their private network data flowing um and then and so on add a certificate uh you know add an endpoint endpoint is nothing but uh you know when we create a front door we give the name right that itself become an endpoint and here they're forcing you to they call that ascend point okay but there are different naming conversions and then uh go tagging and then review create but we are not going to complete it but let's go over look at it uh how we did as a existing one so i have to v2 uh again in find manager so when we when we do the endpoint this"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:10:48",
        "seconds": 4248,
        "text": "and then review create but we are not going to complete it but let's go over look at it uh how we did as a existing one so i have to v2 uh again in find manager so when we when we do the endpoint this is the endpoint manager right so ftv to z0 on azure ft.net if you look at the you know f1 uh open a new tab uh if you go back to the front door design you can look at the overview now you see there are some request coming in so let's go back to the designer so this is the end point right so we're going to use that end point to route all the dnses so that is over there and then you add the domains right here they call it as the origins and front door is called back pack and poll so if you look at it it's nothing but you know how many servers the same servers that i added over here okay and the settings also remain same right sample size and then successful sample latency sensitivity and all those things stays there um and then the route tables again same routing we had a routing there too right so you click on the routings and then you tell them um so you want to edit just to say edit endpoint and then look at it here's more data so you say that you know it's a routing table for um this time and what i'm going to do for you okay this case doesn't matter so i was selected accidentally but it doesn't matter for me because i'm not going to browse through that i'm only going to browse through this because i don't have access to add that domain into my application because my application needs the incoming valid domain not that domain but i will never be able to add that to my activity okay so um and then you know origin group which is the pack and the routing table just like before right so you you create a route you select the pack and port here it's origin right so it's like the origin and then how do you want to route it and then again the road table this rule is what is not working um i discovered around two o'clock i create a case but they never able to answer me we have a direct support we're never able to answer me um it's not working the caching is not working same as a rule that we created on the front door but this particular rule is not casting the static price but it will work caching if i check that but but the problem is that is it's going to do a dynamic caching all the routes that i have um that's bad right so you don't you want when you browse this data you want to get this data to be dynamic this to be dynamic uh but that's that's what i call it as a dynamic um okay so that's what it's all same there is no difference if you look at it and then the security is again a firewall so we saw it over there in ah you go through here domain so if you want to add a new domain just click on add a new domain and then and here there's a little bit of integration so if you want to add a new i just put a name since i have everything in the the same uh as you turn and then they will do all the work you know you don't have to go back remember when we did it when we had a domain boston demo 3 we went in we added all those things but here they will do it for you if you want if you if you use their blade but if you use it programmatically you have to do all those things um origin groups again that's the same as the back end you know this is the other way to add if you had a more origin group we can add it here then rule set same as the rule set security is the same as um optimizations um the complaining here you enable it but i don't want to enable it my site is a dynamic site i have no idea why they said you know things um it's kind of funny to me again diagnostic logs you have to enable it once you enable you should be able to query the diagnostic logs right so he got we haven't browsed anything that configured this url but if you browse the url then it would say the url that configured over there um boss demo 2 surprising boss number two here oh god oh god mismatch one word it goes to somewhere else all right so that's easier the incoming domain i think right now it's dynamic but if you look at it my caching wasn't working i don't know it's working now so if i look at it over here it's supposed to say cache miss or hit but it's still not saying anything but if you look at my configuration here we already configured all those things so look at the rule one we have this rule but here they provided uh it's a different way to edit uh you know there there was a text box you put one line at a time so here you have a little lady but i don't understand this concept they completely the rule ui is slightly different even the microsoft engine is"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:15:52",
        "seconds": 4552,
        "text": "one line at a time so here you have a little lady but i don't understand this concept they completely the rule ui is slightly different even the microsoft engine is not able to answer but they'll get the answer today or tomorrow all right so that ah okay one last thing so so here you know if you if you write a more programming like i do um you can go back here right so you check you know i'm just picking this name for example and then try it you log into check and then put the values and then you take that payload and then attach to your request you know so whatever the payload you generate over there attached to the record so i pick this one say but the type is little problematic for me to find out on sorry bill you are saying something yes i am copying this i need to tell you okay 200 name is available right so tell all the methods here you just browse through it you know find out which one you want and look at it then you copy the payload you have all the end points here and then just send it good to go it will create so it's easy coding all right any question guys okay i'm done if you um so if i if folks have questions for uday feel free to unmute yourself and just ask him verbally great thank you for staying till the end it was great i always enjoyed talking to this user group and thanks you thank you team for having me here tonight it's always a pleasure to have you and i love your your demos you always give interesting demos that uh reveal what's going on at a deeper level uh you know looking at http headers and such i always have i always enjoy uh watching that um uh so folks have questions for uday you can you can chime in in the meantime i'm just going to wrap up with i'm going to ask in a second if there are any announcements but in the meantime i'm going to hop to the um to the list of upcoming events we have three events planned only two of them have made it to the um uh oh i'm sorry we have two more events planned including including uday tonight it was three but we have our next event is uh tuesday november 2nd same time same bat channel and it's on application insights and telemetry in azure of course uh and it's uh the speaker is uh isaac levin and that that promises to be a good um a good session with uh telemetry that's already posted and you can rcp repeat that on either the north boston azure or boston azure meetup site to uh you know to register your interest and get access to the link and then we have another one that i think is two weeks after but we'll get it posted and that's um from doug vanderwaad who'll be calling in from presenting from texas taking advantage of our ability to support remote speakers and uh the topic of his uh talk is escaping me at the moment veronica jason do you remember sorry bill i was looking at the the meetup we have two in october um they i put them out there as drafts maybe i didn't post them um so we have uh bicep by um alex frankl october 19th and then kubernetes for data scientists is october 5th so there oh we haven't cloned those over to the boston azure side then they must be on the okay so a little out of sync between north and boston azure let me publish them yeah they're still in draft mode so we're going to publish them soon that's fine i was just um saying that they are in draft mode so we're gonna publish them soon and we'll have two events in october october 5th and october 19th um and then one in november for now sorry for the confusion i see a silo moment everybody's here yeah oops i was talking to myself too um so okay so veronica just posted uh we have two in october that will be posted soon two in november that will be posted soon only the first one in november is posted so we have little uh clerical work to do but stay tuned um any final questions for uday and any other announcements from anybody i have a user group meeting coming up i'm you know we have a couple of topics um please visit meetup.com [Music] you are over here awesome so you get um more of uday and azure stuff from nashua ug uh i've been to uh a number of those events in perth and in virtually uh good stuff any further announcement okay well uh uday um thank you again for speaking uh the the talk was recorded and it'll show up on uh youtube.com boston azure starting tomorrow usually and um and we'll post a link in the meetup site that points you into uday.io wherever in there the the slides and other material are that's on radar day yes i will send you the link tonight very very good thank you everybody uh good to see everybody from uh from all over the place thank you guys good night thank you "
    }
]