[
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Map Azure DevOps Runtime Variables to Terraform Input Variables. This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790. opportunity to present our work you know we blog and you know there are a lot of people blogging there are a lot of people writing automations nowadays and if you see the Twitter and Linkedin it's like exploding like you know and every second somebody is posting something so these meetups you know gets opportunity People Like Us uh to showcase our work and uh thank you so much for that uh a little introduction about myself uh my name is Aranda Mitra and I have overall of 16 years of experience and in information technology I started uh as a data center uh specialist and I worked in data center in all Technologies being there and perhaps Cisco the next Windows you need it and I have worked on it um for close to 10 10 11 years and then I slowly moved into Cloud I started working with AWS for it for a year and then when I switched to Marshall so I'm now close to five years working in Azure I started with assessment and lift and shift and then I slowly moved into uh to Azure and then I slowly moved into infrastructure as a code devops and now currently I am working as a Azure Cloud solution a devops architect in Oxford Solutions um I normally block uh mostly about devops I in a way you can say that I love to automate things as much as possible wherever it is possible I I like to explore more so I normally specialize in Azure devops GitHub actions uh Powershell accli terraform so these are my core areas and uh with all the projects which I have worked I have right now worked on 50 or 52 Azure Services overall so so you can you can uh you can see that uh that you know I I normally put everything on my GitHub it's public so I I normally blog in in Dev dot two so this is where I blog and uh this is this is uh at the moment you know everything is here you can see you can have it and all this infrastructure as a code and I have like a lot of CDs out here I have a security started recently I have a terraform I have troubleshooting I have architecture detective actions there's also series called ops intervals so uh depending upon which category I'm writing or maybe when I'm working I find that you know something is really good enough to share that the world I know you do that so you can find uh you can you can have a look out here so for each of my topic uh what I do is I create a repository I'm sorry I normally create a repository out here and and after the repository you know I put my code for example like uh like catalog and access packages the other one so I spokes like you know this year I spoken um Azure spring clean so this is how I maintain so you can find the code out here the complete code so this is the whole code you will find out here um which ideally in your environment you have to just change few values and it should run and then I I put put I whatever I block that is also Version Control so whatever you see here you will also see it in my GitHub so I also document or uh the blog which I'm writing that is also Version Control so this is how I maintain it uh in my things so for everything you can have it for uh for any things you know which uh for example which is uh the sessions which I give and evidence to record it so that is also a part of a part of my tweet augmentations and everything so you can see that in anywhere which I have spoken wherever I had spoken that's all the YouTube videos are linked out here and it's a similar fashion you know which like you know today is my topic is there's there's no mapping of this adjective of runtime data booster terraform input field you will see that and I have already put it into that you know this is the this is what I'm presenting in first country so um so again going back to my GitHub repository so you can find me in uh in blog uh in dev.to you can find me in LinkedIn Twitter you can also find me such nice Facebook anything so this is my session next profile uh where I I normally apply for all the speaker sessions it has also uh deeply up to date wherever I do I have paid here as well so this is a little bit about my Twitter profile and of course this is my LinkedIn uh you know whenever I'm posting a blog or I'm speaking somewhere uh I normally put as much as detail as possible so that you know can benefit from that now the only thing you know so I'm basically blogging and basically speaking for close to like um like you know like five six years now uh with Azure I started blogging a year back and uh just to just for everybody to know"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:05:04",
        "seconds": 304,
        "text": "from that now the only thing you know so I'm basically blogging and basically speaking for close to like um like you know like five six years now uh with Azure I started blogging a year back and uh just to just for everybody to know that um I have recently applied for my MVP so I submitted my application eight for example I'm still waiting I don't know whether it's selected or not so this is about me and why I say about the citizen of the world is because you know I travel a lot a person with uh professionally so total like you know with my personal and professionally I have visited 22 countries till late and I have worked in I started working from Kuwait and then I worked in Dubai and after that I moved to hungari after from India in Zurich direct to New York New York to Baltimore Baltimore to Canada and then back to Switzerland so this is the because I was working in managed services and a lot of customer platforms so I traveled a lot and I learned a lot from that so uh this is a little bit about myself and uh now I will immediately jump into my topic uh which is like you know how uh mapping of the Azure devops runtime variables to telephone so a little background background about this that you know how I I came up with this topic it was mostly like you know if somebody has worked in terraform uh there is always like a variable uh there's a variable file and there is also a TF parse file the readable file is where you are defining that what is the type of the variable whether it's an array whether it's a string uh whether it's a Boolean whether it's a map so you define the variable out there but again you know uh in order to put the value so it's just like a key value pair so you define a variable and then you uh you put a value to that variable so that value is in tfrs and then all of a sudden you know I was reading one of the documentation that was uh I was reading this documentation of environmental variables and there they wrote that uh data from a hashicorp the group that you can you don't have to define the value um you don't have to define the value in the tfrs file but you can always use as an input variable from your yaml pipeline and that gave me the use case that okay what happens if like you know I'm I'm writing like for example I want to deploy a resource Group and I want to deploy a user assigned manager identity so this is about my blog of course so um then I have to give a name so I have to Define uh that okay there has to be a variable for my Resource Group and there has to be a variable for my user defined managed entity uh so uh for those you know I have to again have a value in my TF parse file what happens if I don't give it and you know I'm not hard coding those values but you know I am asking the user who is executing the pipeline to put the values and then you know that value I'm automatically passing without even refining in the TFS file so that is how I came up with this and this is what I'm going to explain you first a little bit and then I'm going to run a live demo so that you can see that you know what all things have happened so here so this is what I tried to explain as as what I'm going to demonstrate so I'm going to map the the runtime variables to the input variables and then you know we'll see that you know there is no need of defining the values of the variable and the quality of fast file so uh scrolling up a little bit you know of course you know for all these things you know I would be requiring a subscription I would be requiring a devops organization a project I would be requiring a SPI in the azure 80. that SBI I need to configure in my devops project as service connection because Azure devops is one entity Azure is another entity and you have to connect those that is how you know when you are going to run the infrastructure as a code that is how it gets deployed to your Azure portal so that is the magic which the SPI which is defined in in the Azure tenant Azure 80 and your directory services and that you know uh the object ID or the client ID and the secret then you use in this service connection Define and then of course uh we need the the terraform extension and the startup from extension has to be in the Microsoft because there are a lot of custom terraform extension as well available in the visual studio Marketplace so um so again you know from from my blog you can immediately from here you can jump to the GitHub repository and of course you know just to give a look uh that you know how my code plays with the looks because you know when I I read others blog and I see the problems which I face when I'm reading or I'm trying to follow somebody has written something and I'm trying to follow in my real life uh I see the problem and for me it's very important to see that anybody who has blocked or has written something you"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:10:07",
        "seconds": 607,
        "text": "I'm reading or I'm trying to follow somebody has written something and I'm trying to follow in my real life uh I see the problem and for me it's very important to see that anybody who has blocked or has written something you know how his local environment looks like because then that gives me an idea that gives me an inkling in my head I can map it out that okay so he developed the whole code like this so that is why I put the small screenshot showing the audiences that hey uh the way I did it is like I created a folder like you as a USR hyphen mid managed entity and then I have my yaml pipeline then I have my name dot EF and then I have the resource dot here then I had the tfrs where I'm defining the values and this is the variable that identifying people get an idea and kind of thing and then you know I'm I'm setting the uh setting the objective that okay what my automation is going to do so I'm going to Define so I'm going to deploy a small very small Resource Group and I'm going to define a user assigned manage identity inside that research Resource Group but I am not going to provide the value in my TF class the value is going to come from the runtime variables and this is this is my main entire code is here uh and uh and this is how it looks like so I will what I will do is I will immediately jump into my code so that I can extreme you better so um when when we are uh when we are doing this infrastructure as a code or devops uh it's very essential that you know we have to understand few things very important so your terraform is your scripting language where you're defining that how and what resources you want to deploy and your devops pipeline is a mechanism which is taking that infrastructure as a code and then helping you push it uh to to Azure to to build those resources so when we are doing this whole CI CD continuous integration continuous deployment it is basically like you know you are amalgamating two different languages one is the yaml another is a terraforms cutting language and then it starts becoming a little bit complex it's just like Azure you know when you're playing with one resource it's simple you add another resource on the top 10 percent complexity increases then you add another two three resources another twenty percent of complexity increases so it's just like that so that is why some terminologies has to be understood very very clearly the first thing about this whole automation is um I'm talking about the runtime variables what does this runtime variable means so this is the pipeline runtime variables I'm talking about so it means that these are the variables which I am asking the user who is running this pipeline to put those values so this is a user input value since there's a pipeline runtime variables then there is like my pipeline variables which is this part so these are the variables which I am defining so this is my key and this is my value so this is the key value pair and then you have the environmental variables the environmental variables are nothing but it's the uh the the variables which uh doesn't need so your entire uh pipeline which is running it needs a compute that compute is the build agent that build agent can be a Microsoft hosted agent it can be a self-hosted agent doesn't matter but it needs a compute it cannot run like a magic so when you are running that pipeline which is taking the terraform as your input so that whole thing is running basically on a VM which is which we are calling as a build agent and that VM can have a lot of environmental variables so that you know when they they want that value the build agent automatically knows that okay this is an environmental variable I don't have to look into terraform I don't have to look into Devo I mean like my yaml pipeline but I can use that as an environmental variables I can use that value automatically so so these are the three different concepts we have pipeline runtime variables we have the pipeline variables and then we have environmental variables so I'm actually using all the three in my automation so these are my pipeline runtime variable these are my pipeline variables and I very shortly I will come to the environmental units then I have like you know my building gym so I have I'm using the Microsoft hosted one you can see that you know I'm using this Windows latest which is my build agent variable so this is my value and this is what I'm passing out to you and then what I'm having is I'm having two different stages one is like plan so this is my plan that I'm I'm generating the terraform plan and after that I'm using the stage called deploy fair in the plan stage when I'm generating the plan that okay this is a resource of the script which will be getting deployed that plan I'm using in my"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:15:10",
        "seconds": 910,
        "text": "and after that I'm using the stage called deploy fair in the plan stage when I'm generating the plan that okay this is a resource of the script which will be getting deployed that plan I'm using in my deploy stage okay so what happens in my uh plan stage before I go here you can see that you know for all these things for all these things uh I know I have I have like lowercase only for my Resource Group name variable and for user assign manage identity see that I have in caps why so so what I'm doing with this is that you see that in my variable section I have the resource Group name which I have taken a string I have location which I've defined as string I have defined the user assign manage identity as a stream now you have defined the variables but if you go to the value I have only mentioned the location I have not mentioned the name of the resource Group I have not mentioned the name of the user assigned managed entity so how will terraform and by proxy my devops pipeline will know that by what name the resource Group should be deployed and by what name the user assigned manage identity should be deployed they don't know that because I have not specified yet this is just the location this is where this is coming in pictures so you see in the runtime variable I'm taking the user input so user is putting the name of the resource code and then I have a user is putting the name of the user assignment once they put it what I'm doing is I am taking that value and I'm putting it into this one so basically what I'm doing is I'm capturing the value from the runtime variable and then I am putting into pipeline variables but when I am putting into pipeline behaviors when I'm putting this whole value as the Caps according to the environmental variables documentation you see that here hashicorp had mentioned that if you are starting anything any any variable if you start with TF underscore VAR underscore the name of the variable in my case it is DF underscore bar underscore something like amrg then it automatically converts into the environmental variable that is why when it Maps into my uh environmental variable then I am using that environmental variable as the input to my terraform site that is how I'm converting it so this is the whole workflow and then what I'm doing here is and my plan stage I am running the terraform installer then I am initializing the terraform out here once I'm initializing the terraform then I'm validating the error form when I'm validating the data from then and generating the Terra function plan out here so you can see that the brand new institution plan then I am copying the files everything and then I'm just putting in my staging directory and publishing as an artifact why I am doing this because unless until because this these are two stages so whatever I'm doing in this stage somehow my my deploy stage has to consume what I have generated in my plan stage so the only way to consume is in pipelines is you have to publish us as an artifact there is no other way so you have to publish something then you can consume something it's just like you know if anybody has worked on the messaging services it's just like a pub sub model publish something then consume something subscribe something so then in the deploy stage what I'm doing is first I'm validating and putting a condition like succeeded which means that my previous stage which is my plan has to be successful otherwise they will just deploy the script if something goes wrong here and it doesn't execute my deploy stage will be skipped because I have put a condition like succeeded and then what I'm doing is the first is I'm downloading the artifacts so whatever I have published here I'm downloading it once I download it then I'm again initializing instead of from again because this is accepted stage and then what I'm doing is I'm applying uh this whole thing uh using the the terraform plan which is generated in the plan stage in which I have downloaded from the artifacts and that is how it is getting to uh that the whole thing is running and if I refer back to my documentation see that you know I have I have mentioned out here I have put a note about this one this thing which I extreme you so the user input values from the devops run times are referred to as a devops video so so all this this is a runtime variable and this is this has been reference to the pipeline"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "this thing which I extreme you so the user input values from the devops run times are referred to as a devops video so so all this this is a runtime variable and this is this has been reference to the pipeline variables and then I I explicitly mentioned that notice the variable that you know this is all caps where I try to explain that azure devops uh variable gets automatically mapped to the environment variables and the adjective of spirit agent and then you know automatically it it helps me to put it as a terraform in quickly represent this link which I'm talking about where if you can read you know you can you can understand this is also referencing my blog achievement okay so uh so this is the rest is the rest is all the same uh in your environment if you want to run my code uh the only thing uh which you have to change is always this section there's always like you know not this section because you know this is a user input but this is a section which you have to alter because you might be having different you might be having a different uh Resource Group names and the storage accounts so uh this is about the yaml pipeline now I come to the main file so the main.tf is the the main terraform file so the way I do it is like I always use the main TF for storing the backend State file uh this is a terraform stage file where I keep it so the first one is the resource Group at my storage account exist next is my storage account name then what is the container name inside my storage account and then uh what I do is since I I run a lot of use cases then what I do is whenever I'm running something I always prepare a folder inside the container just to keep it organized so this your umid is the folder name and this is my station then again you know uh the first one is the terraform version and this is my provider so I'm using Azure Autumn which is the Azure resource manager and I'm putting it in the version not here this is the the resource uh terraform file that I'm defining that okay Resource Group will be deployed and the user design management entity will be deployed uh I have used a depends on um uh a parameter out here it says that this piece of code will not start running unless the resource Group is created so this is what is called as the uh as the implicit dependency so I am creating depends on parameter which says that okay Azure RM underscore resource underscore group and the name of this one uh the module name and the and the name of the module I am putting it as it depends so unless oriented even if it is taking like for example one minute this piece of code Will Wait So once this gets executed Resource Group is ready then it will be here so that you know it doesn't happen because uh many a times when I'm running a code I see that uh Gerald form doesn't identify and it starts defining the user a user assigned managed entity but it fails because the resource Group doesn't exist so there is a lot of scenarios which I have seen in that view and this is the variable section which you are defining and then in the psrs where you're defining the value of the variables which I mean absolutely so this is this is all about the code now what I normally do you know when I'm running such pipeline is like you know I always as part of the best practices I always create a folder by the name so you see that I have a folder up to you so um because then it helps me understand the history of all the pipelines I'm running and if I go into this folder which is my current presentation like runtime variable terraform input variable if I click on this one then you see the history that how many times I've run I just ran like you know like before my presentation just to be sure that my code is running you know I ran it like you know so you can see it and this is how it looks like so you have a plan stage you have a deploy stage and that is how it do it the one thing I I always do is like uh if I go back to the code sorry uh if I go back to the repo and so one thing I would like to explain you one more is uh so I have one validation which is like uh uh the plan and the deploy stage so I have like you know the deploy will not work and doesn't plan is successful but there is also like a approval gate which I have put so I'm using this parameter environment so what it does in the in-depth for people who have used Azure devops you know earlier they started with classic pipeline the classic pipelines for something like a completely"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "which I have put so I'm using this parameter environment so what it does in the in-depth for people who have used Azure devops you know earlier they started with classic pipeline the classic pipelines for something like a completely a GUI base it's a it's a graphical user interface so used to define the whole thing which I'm defining in yaml uh you could you could do it graphically and in that graphically they had the option to add approval which means that you're running a pipeline and after a certain stage he cannot go further because there's an approval gate but when they switch from classic to yaml based pipeline uh primarily because then they wanted to do Microsoft wanted to do the Version Control of pipelines as well that is the main reason that is the main uh motivation to move from classic to yaml based uh then this was the piece which was missing and then Microsoft what they did is like you know they said that okay uh in case if you want to want to put an approval gate in your yaml based pipeline you have to use environment so that is why I have defined the environment and when you go to pipelines you see the environment section on the left if you click on the environment section you see that and I have defined a non prod if you click on non-prod and on the right hand side three dots PC approvals and checks if you click on approval you see that and I have created an approval so I have added my name this is approval so if you are including that in your yaml pipeline then it will it will automatically wait till the time it's improved so this was the last piece I wanted to say so I will go back to my folder again and what I will do is I will simply go here and I will just run I just ran from here because then I will just automatically get the values I don't have to think of some some name or something that is why I I meant for the otherwise you can always go here you go to the other one and then you can run the pipeline so then you know it will look a little bit different It'll ask you to specify the needs so here you see that you know I have used my subscription and my service connection depending upon your environment you can always change it and then I'm asking the user hey uh can you just provide me a resource Group name or can you provide me the user assign manage to entertain you just asking also when you're doing this you can always click on stages to run click on this this does a validation to to make you aware that your yaml syntax and everything which you have defined is perfectly okay so so there should not be any syntax problem when you are executing your pipeline but if there is an any other problem that would be something different but there is no syntax problem so this ensures that and so I will now fall back here so this is a pipeline which I previously run and if I run from here and just getting the value I'm little bit lazy out here just not to Define uh think of some some other names or something so what I would do is now I have my resource GroupMe so these are my pipeline runtime variations then I'm going to run it and now I will just wait uh please bear with me because you know I'm running on Microsoft host cities which means that you know it's a cold VM so whenever I'm executing uh then first it will just allocate me a VM from a pool then it will spin the VM up and then it will run so ideally it takes a minute or two so it was pretty much fast so um uh till the time this pipeline is running uh I will just pause for a moment and see if you guys have any questions and then I will resume uh what's the Pipelines I have a question I'm not sure if I caught had the back end set up for terraform but um not sure based on what I see this probably would would not work on terraform Club so uh so terraform cloud is a little bit different than the uh one which we are associating so terraform Cloud gives you the provision of of doing everything it's it's just like one front end so they have all the functionalities within their their own infrastructure but here we are using the terraform extension so it's it's it's basically um if I go here if I go to the organization settings and if you see the extension so I'm actually availing this extension so this is coming with the visual studio thing and then I"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "um if I go here if I go to the organization settings and if you see the extension so I'm actually availing this extension so this is coming with the visual studio thing and then I have to incorporate that when you are running the terraform init uh plan and apply without devops pipeline when you're running locally so there is always a state file which gets stored locally and then you also have a provision to uh to store the file remotely uh in terraform cloud of course there is there but uh when you are using terraform Cloud then there is no options of azure devops or GitHub action so terraform cloud is providing the whole CI CD as well as the hashicor as well as HCL as well as the terraform the whole package there often so it's the nomenclature or the way we are doing here where we are amalgamating uh Microsoft stack and a hashicot stack together to build the whole CI CD and the infrastructure as a code in terraform Cloud it is a little bit different terraform Cloud you know you're running the pipeline there you are you are using their own languages so it's it's basically like an of it's just like a one front end if that makes sense yeah thank you so if I go here um so this is what I was I was talking about uh and now you see that you know it's it's waiting uh this is the approval I was talking about so first thing first you see that um uh the best way of of doing is this like you know the way I have learned uh with my projects is that you know whenever you're writing a pipeline just Define what exactly things are doing so the first thing is you know they are installing the terraform versions and in each slides in the terraform validating then I'm generating the plan so this is the plan which I was talking so here in the plan you see that uh two resources we'll be getting added there is no modification done there is nothing to destroy zero to destroy zero to change and zero to uh two to add so this is what it gives me and this is the plan which I'm going to use in the deploy stage but in order to do that I have to copy the first files to the artifacts uh staging directory and then I have to publish the artifacts now before I proceed I will show you that where the artifacts is so you see here this is the artifact so basically my Pipeline and my terraform is running inside of VM which is somewhere in the Microsoft Data Center so all the files are there but how would I consume again so I have to publish so that is why I'm copying those things to a devops staging directory and from the devops staging directory and publishing as an artifact so all the code which you saw mean uh user uh the the resource file the dfrs the variable files everything it is putting it in the artifacts along with the plan file and this plan file is basically I'm consuming in my in my deploy stage so if I go here that would do is I'll just say okay I prove it and here you see that I have to put a check I have Google and you can see the name of the environment where the approval gate is attached to and then I approve it and now and now I'm going to deploy station so this got deployed uh so first thing first let's uh check in the portal um normally it will take some time to reflect but till the time it is getting reflected I will go to the part where which is the most important as a state file so this is my this is my uh storage account and then I have a container for TF pipeline essay and then I have a terraform container and here you see that I have created a folder inside the folder you see the stage file if you go here and if you edit it you can see the entire State file so the first section you know this old part this is the the resource Group State and the next part you will see is like this is the the user is saying manage it entity so this is like you know this is very important at the time you know if if"
    },
    {
        "speaker": "",
        "title": "Map Azure DevOps Runtime Variables to Terraform Input Variables",
        "videoId": "-ssTKjHVP_Q",
        "description": "This is a recording of the March 29, 2023 virtual meetup.The notes for this talk can be found at: https://github.com/arindam0310018/23-May-2022-DevOps__Runtime-Variables-To-Terraform-Input-VariablesIn this Session, I will demonstrate -How to Map Azure DevOps Runtime Variables to Terraform Input Variables.If at all we need to put the values in variables.tf or in tfvars.Arindam MitraArindam is an Azure Cloud Solutions & DevOps Architect | Technical Blogger & Speaker Focused on Cloud Adoption, Architecture, Automation, Build and Run in Azure.Links: - Blog: https://dev.to/arindam0310018/- LinkedIn: https://www.linkedin.com/in/arindam-mitra-28981095/- Twitter: https://twitter.com/arindam0310018/- Sessionize: https://sessionize.com/arindam0310018/- GitHub: https://github.com/arindam0310018- Facebook: https://www.facebook.com/arindam.mitra.790",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "the next part you will see is like this is the the user is saying manage it entity so this is like you know this is very important at the time you know if if you have deployed the infrastructure using terraform and then you know you have manually deleted something then the next time if you try to deploy it will not allow you to deploy because because of the State Fair because the state uh the state file contents and your and their resource content this is a mismatch and then you have to first do the terraform surgery you have to remove those all contents and then you have to reapply the terraform that is that is why the the state file is so so important and if I go to the resource Group yep so this is my Resource Group and then I know this is my user design managed entity so the the whole the whole beauty of this is that I am I'm just asking my user or anybody uh to provide the appropriate names I'm not hard-coding any values in any of my code I'm just converting the whole uh pipeline variables into local variables local to environmental variables and from environmental variables Innovative and taking those as a terraform input variables passing those values and then then deploying those resources in in into Azure so this is this is this is what I I meant to say that that you know without even specifying the values for your variable you can still deploy and this is what I I I understood you know about what hashikov was trying to explain I'm sure but you know feel free to go through this documentation feel free to uh go to my blog and if you have any questions to to write to um so yeah this is this is all uh I had to present first day so you guys have any questions uh feel free to ask uh so feel free to come off of uh off of mute and uh pose any questions that you've got well sometimes uh sometimes uh demonstrations are so clear that people just know so uh so that uh don't be shocked um we'll give it one more minute and see if anybody has any uh questions feel free to type them in or come on mute and and ask away while we're waiting for that I'll uh I'll make a couple quick announcements uh this um recording will show up on the Boston Azure YouTube channel so you can find that at youtube.com Boston azure and also I mentioned at the beginning of this that there would be uh that we have a couple of uh we we still have some virtual events coming our whole pipeline coming so watch the either the North Boston Azure or the Boston Azure neither one uh meet up space for that and there are two in-person events coming to uh Boston Azure the one of them is the Boston Boston Edition uh Jason Veronica and I and uh We've are working on that and we've sent out a call for speakers just uh I think Veronica kicked it out um just uh in the last day or so and um that's Saturday May 13th at nerd in Cambridge and then we have one also tentatively scheduled in late April um for in person on a weekday night that so watch the space the usual spaces for those the Meetup sites and Twitter um and I will come back to uh has anybody anybody want to take advantage of the last movement to uh pop a question okay well that that's um that's cool um I I wish to I thank everybody for attending uh and it's the uh pretty late um uh in um Switzerland right you're in Switzerland yes what time what time is it right now it's one in the morning okay so uh uh Arundel Mitra thank you very much for being our speaker for staying up to one in the morning to entertain our uh our crew and uh we'll we'll see all the next uh event everybody uh Jason or Veronica did you have any uh any closing remarks or or uh our random do you have any uh any any uh closing remarks no thank you so much bill again uh for the opportunity uh uh I I wish you guys all the best and I hope that I would again get an opportunity to collaborate with you and uh Jason for you uh feel free to drop me an email for your podcast happy to happy to join that as well we'll do thanks man thanks everyone good night everybody take care yeah see you bye "
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Deploy Your GO API to Azure Functions. This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.. my name is susan abbasi i am a head of technology at a local company here called taiwan um i've been doing mostly a lot of mobile work so i'm mostly a mobile developer but i have been playing with back ends because a lot of times when i'm working on a front end i find myself needing a back end that doesn't exist and i haven't done backing in a very long time so i started doing a little bit of back-end work i started with typescript uh built some apis in typescript and built some in of course asp.net core or dot net core sorry uh then i built some in java i'm actually working on java one right now and then i came across go and i just loved it uh it was it was much lighter uh very fast it's much performant and i've talked about it before but in performance-wise it's it's more performant than your javascript stack so it's better than your node.js for instance uh in performance but it's not as good as rust just yet but it one of the main strengths it has is the dev experience and we'll see that in a second so um today uh thank you again for having me i know that the topic says deploy your go on on azure but i if we were in a room i would ask you know show of hands how many people have actually heard of golang or actually done any work in golang and you know get responses but since we are not in person and we are virtual uh feel free to raise your hand and then veronica or jason can tell me like to tell you how many people have actually dabbled in that uh go or not but my assumption is is not a lot so i have an hour what i would like to do is in the first half of the of this i just want to introduce you to the language what it is and the second half we'll talk about the actual api that i built and then we'll deploy it to azure function and then we will take q a at the end and i have a little surprise for you at the end uh hopefully you'll be able to do that so let me get started like i mentioned i work for a company called taiwan it's a digital consulting company so we do a lot of consultation for a fortune 500 companies we do mostly or not mostly we do anything industrial and startups and oil and gas and energy and we are we have a big plane energy transition right now that is going on so these are some of the logos that we've been working with our strategy is we don't just go in and get requirements and build we have a very mature experience group that does uh the user research and and works from bottom up to match the top-down approach and then we design solutions that actually work in the field and get adopted so we do a lot of strategy work with research our phd group does all the research design and then we have development of course then we have the data science piece to to help you go see after that we are hiring so if you are someone who is a a.net javascript stack project manager data scientist user research if you are in any of those domains and which would like to uh you know particularly fancy or like a change uh think of change reach out to me and we can talk afterwards that's enough about me and and taiwan let's get into it so i will not go through the whole stack i just wanted to have it here but i will go through some of the basics so we all know what this language is so when we actually look at the code it will make a lot of sense so what is golang or i should say go not golang so it's an open source programming language it was it was found in 2009 i think i should know but i believe it's 2009 and let me give you guys a full screen version because you guys have been seeing the non-full screen version um so it was built by the the founders of the the c language and b language as well and the founders of of the language want this to be a super simple uh you know no nonsense slim language that just works because they were working a lot with the existing languages for the back end and they realized that they needed something better so it's funded by it's backed by google the team that built it and is working on it is is in google is google team as well so what's the idea behind it well it's a journal per general purpose language so it can be used to build all sorts of applications it's it is compiled into your native code so when we compile it on windows where i mean x86 arm wasm you know it compiles to a machine code and then you can run it right on that platform and has a very light syntax so who who's using it the big names that you see here docker actually is built in go so if you guys are working in docker you know it's built uh in golang as well and cockroachdb as well so anyway like i mentioned is cross compiled so we take the the code and then based on how we compile it"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:05:05",
        "seconds": 305,
        "text": "actually is built in go so if you guys are working in docker you know it's built uh in golang as well and cockroachdb as well so anyway like i mentioned is cross compiled so we take the the code and then based on how we compile it uh it will give us that exe if we are in windows or or without the extension if we are on arm for instance um what is it good for web development not the front end i wouldn't go out and replace your javascript with your uh go just for the furnace just yet but for your apis and all the stack behind that it's great for that cloud and network services so devops a lot of the the devop workload is or it's great for uh handling that kind of workload uh developing sres right and command line so it's also good if you are building command line applications like tools tools whatever it's great for that as well we'll focus on the web part today though so really quickly what are the basics it has the primitive types that like you would expect it to have it has hints 8 16 32 signed and unsigned and only signed 64. it has float boolean string byte etc it one of the the the simplicity or the whole idea on keeping the syntax lightweight is that it doesn't have a ton and ton of data structures out of the out of the box available to us so it has arrays and slices a slice is our projection of an array we'll take a look at that it has a map so it's key value pair uh dictionary it has a struct so it doesn't have a it's not an object oriented based language so it doesn't have object and inheritance and all that stuff and we'll talk about that as well but it does have struct struct is your type so you can create all your types instruct right and then it has an interface which is a very powerful type as well that you can use to have behaviors defined for your types in go but also it could be used for a variety of open-ended return types for instance so logic control it has if like you you would expect it to have there is an if okay pattern um which we'll take a look at which is pretty cool it it kind of saves us a bit of typing it has for loop it has four range loop which is awesome you will see that in a second as well and then it has a switch now you don't see do while while and all those loops in here because you don't really need them the for loop is is pretty much good for for all those scenarios so let's take a look at a quick some of the quick code thing how do we declare a variable uh just basics we start with the keyword var then the name of the variable and then the type of the variable so in this case you know var name string we can also declare and initialize by doing this but a lot a lot of places in go you will see something like this which is declaring and initializing at the same time by using the colon equal sign so you will see this a whole lot in the code then the the top two you will see the var keyword when we are declaring items in the beginning of your code and initializing somewhere else down the line but if we are doing everything within a block of code or in this in a scope then you'll probably see them all like this and then there's a concept of the i don't know what the actual word is but i call it throwaway variable so imagine if you have a function that returns two two different types which we can do in go but you don't really care about one type for instance if you are looping over a range you don't really care about the index you only care about the value but you need to collect the index in some cases so you can collect it but since you're not going to use it you can just put a underscore and all it will do is it will accept the value but it won't give it you won't be able to access it right so it'll just be there but it will just get thrown away functions and method very simple the we start with funk keyword the name of the method and then the block we can also have anonymous functions so if you don't give it any name you can just leave it blank the return types so in this case you put the return type after your method declaration right so in this case it's just a single return type of end you can also return multiple types so in this case you are seeing that there is a person object and an error object being returned in that order right so when you call get person somewhere else you just need to know you will get these two values in that order and then there is this function where it can have a number of variables separated by comma so you can use that now we can tie a function to a type so for instance get full name if we put the type before that between the func and the method name then that method will only apply to that type so you will only be able to do person.getfull you won't be able to do that on any other type because this matches the the signature of that right so i know it's a little off if you're coming from network right where things are just different you will have this function within a class and it will be public or protected or something and then you will just use the"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "matches the the signature of that right so i know it's a little off if you're coming from network right where things are just different you will have this function within a class and it will be public or protected or something and then you will just use the dot notation you will still do that here but it won't be inside that code it'll live outside of that type but you will attach it to that type by doing that arrays and slices i know i'm going a little fast so just bear with me right and if you have questions feel free to ask but i want to show you the actual code and not spend a whole lot of time in the slides but i don't want to show you this in that code because it'll take longer so so a slice is just a projection on an array what that means is there's actually an underlying array that the slice is using but you don't you don't have to worry about it just let the slides do the work for you resizing and all that stuff for you so you don't have to resize the array yourself and what happens is for instance here i have an a slice or an array called integer as an array of integer with three values in it and if i pull out the length of this array using the built-in length function i get three back and if i wanted to turn this slice into an array all i have to do is just give it size in the in the brackets in the square brackets right so if i give it a size it becomes an array because now i'm dealing with the actual underlying array and if i do that you can see that i gave it a size of five but i only gave it three values it filled in the rest with the defaults of that type which is zeros and if i pull the length now i get the full five length for the array as opposed to the other one pretty stairs forward stuff map is as simple as it can get uh it's kind of weird but you know your you'll pick it up once you see it once you use it one time so for using the dictionary or the map key value pair you just have the word map the key is in the brackets and the values right next to it so if you see i'm initializing a map in m i'm telling it it's a map where the key is going to be string and the value is going to be an integer right and i knew up this by using those curly braces empty curly braces and then to write into that dictionary you just do like you would do in pretty much any other language you just have the m give it a key give it a value when you print that you get this representation of the key which is actually pretty nice so you don't have to worry about overriding the two string like you have to with some of the languages right it's pretty neat so i ran through some of that stuff i hope it made sense it wasn't uh it wasn't too uh out of the way if you are coming from c sharp background now this is where things change a little bit so we already know what struct is right from other languages which is fine in this case um i have a struct called vehicle that has two properties make and model they're of type string right so you see that there now what i don't have here is well let me just let me just go in here one nice thing about uh keeping it simple is that i can actually have nested structs so you can see here i added a category for that vehicle within that struct and i just nested it in there so now category is of type struct that has its own property called code which is of type integer and there is a concept of so there's a built-in support for json in the library or in the in the frame in the language we bring in this package called encoding.json and if we want if we're using this type for any serialization or deserialization with json we kind of just give it a what this is called a tag we just put a tag in front of the type by calling you json and then what the name needs to be in json so when now when you serialize or deserialize it will give it those values so you can see i have a make a model and for category i have the category json but that's after the last curly brace right okay now composition over inheritance like i mentioned there is no go is not based on oop so you you don't really have inheritance per se but you can compose your types so in here you have a type vehicle that is that has two properties and then you have a type car that is a vehicle right but instead of saying car struct you know extends or colon or whatever we just put the vehicle type within our car type so now that vehicle type becomes part of the car so now you have the make and model properties available in your car as well how do you initialize this it's pretty simple so now when you are creating a composing a car object you just create a new car object and then pass in the values for the vehicle by passing in a vehicle type and then the speed or if you simplify at the bottom just say car vehicle make model and then the speed right so it's it's a little different but once you play with it it will make a lot of sense and we will see an example of this in in the api called i'll show you now interface so interface defines a behavior for your code right so"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:15:11",
        "seconds": 911,
        "text": "right so it's it's a little different but once you play with it it will make a lot of sense and we will see an example of this in in the api called i'll show you now interface so interface defines a behavior for your code right so in this case when we use interface the way for us to have a type implement an interface is just mimic that behavior for instance if we have an interface called drivable that has an interface that has a method called drive then if we have any type any struct that has or implements that drive method we'll now implement that interface so then we can pass in that type for the interface wherever it needs to as long as it has the matching signature so in this case you can see i have a car and a truck they both have a drive method so they they are implementing the drivable interface but then i also have vehicle that has more than one interface implemented it has the drive and the fly the fly belongs to a whole different interface which is flyable and then let's just say plane is is just flying vehicle could be a car or a plane so it does both so it matches the behavior of your interface and not you know right click implement uh interface stuff that we are used to in it how does it look like a good a better example of that is think of a shape so if shape was an interface that had an area but then you wanted to get the area for a circle and an area for a square now how you compute those is completely different but you can pass the area or you can pass the circle or a square into it into a method that expects the shape interface and it will just be able to get the value for you so you can see the bottom half shows you how it's done we are passing in a circle with a radius and a square with an x and y and passing it into a method that is print area that takes in a shape and because circle and square also have an area method that is that is calculating the area they are able to pass into that shape interface right so it's again it's a little it's a little it seems a bit off once you work in it it'll make a lot of sense and if you're coming from other languages you know it'll probably be easier for you as well uh there is such a thing as empty interface empty interface if you're coming from javascript world it's like any so you can return an empty interface which means expect anything to come back from here and it'll still work next is just an example of what i was showing you right so here you can see actually let me show you the next one here let's say i have a um i have a car that has a drive method and i'm saying that car is driving then i have a vehicle that has a drive and fly that this is the the vehicle is is driving or flying and if i have a method that that said i i expect a drivable interface and then i'm i'm just going to call the drive a method on the interface and you pass in a car and pass that car into the start driving you will get the result as you would expect and same for flying right so pretty straight forward um nothing too crazy now i'll run through these as well any if there is no parenthesis no semicolons that you may have noticed but there the parentheses are uh sorry the curly braces are required so you cannot have an if a single line f without that you have to have curly brace so you know you win some you lose them whatever i did mention earlier you know where you can do things like get multiple return values what if can do you can actually have multiple statements on a single line but these are scoped what do i mean by this so you can do something like if val initialize the val object or val variable with whatever comes back from foo method and then right away some i call and check if val is null or not and if it is nil then you know don't do anything if it's not nil then go ahead and print it now this val actually scoped to this if so if you try to use val out after the f block you probably won't get to it so this makes sure that if you are initializing any variable in the if it stays scoped to the if block which is pretty neat easier to read if okay that's the pattern i mentioned earlier how does that help so imagine you have a full method that returns an actual value and an error and what you want to do is you only want to move on if the error was not nil and this is just like what we did before but instead of error you will do something like this where it comes in very handy so imagine if you're trying to get a value out of a dictionary and the value doesn't exist instead of crashing or throwing an exception you will just get a false right so here the pattern is if okay means if get me the value comma d okay which means if it exists or not out of this map for this key so that call to map will return false if that value doesn't exist and you can say oh do something with val if okay and you can see okay doesn't have if all k equals true and all this okay music price by itself means it's true so"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:20:14",
        "seconds": 1214,
        "text": "so that call to map will return false if that value doesn't exist and you can say oh do something with val if okay and you can see okay doesn't have if all k equals true and all this okay music price by itself means it's true so it's it's pretty neat for loop uh like i said it does a bunch of things uh it's one loop you know to to win them all so you have the traditional uh condition cursor loop uh you have infinite loop so it's like a while true so you can run as much as you want until you want to set your own break it has a conditional so you can have four condition and then continue going so after every block it will check the expression and if you want to get out of the loop you use your break or continue which is um sorry about that it's raining uh too many devices in my room right now uh okay so now let's talk about my favorite thing which is the four range uh loop so what four range does you can run that full range on any collection in go and the range the method will or the range operator will return different values to you based on the type you're running in a case of the collection so imagine we have an array of two strings hello and word if i run the four range i can get the index and the value at the same time so it's kind of like the four and the four each loop you know played together with the index and here we have so you can see i'm saying for the first variable is index the next one is value out of the range arr and i'm printing them out and it is giving me the index and the value and imagine if here we didn't want one of the two set like we don't care about the value we just care about the index or we don't care about the index we only care about the value we just use the underscore and it just kicks it out same thing goes for a map right when we run the range on a map we get the key and a value at the same time right so which is which is awesome we can check for values we can check for keys at the same time so four range is very powerful i mean i love it i use it for wherever i i need to check for one of the two switch so switch has a little um a little i don't know if it's neat trick or is not but so switch just like any other language works here but switch and go actually can do expression uh evaluation in as a case instead of only looking for constants or something like this so in this case you can see let's just say i have a state a switch on a state for a task if it's new i just say it's created if it's resolved or complete i just say it's resolved because if you are coming from your scrum background and every time you resolve it you want it to automatically close you know it's the same thing but you can also do things like this where you can switch on today and you can actually initialize it as a variable and then you can like i mentioned do evaluation expressions within your case which is pretty awesome right it's pretty strong now there is one more thing in sewage that that you should know which is again kind of crazy but as we as the control goes through switch right it goes through each case one by one but imagine if you were on a case for in this case let's just say if the state is new it'll come to task created and then it'll jump out we can do break we don't have to but it'll jump out of this switch statement and we'll move on if the task was resolved it'll say resolve and move on but there is a thing called fall through if we use fall through in a switch statement then the control will fall through to the next case without checking the expression so in this case for example if the state was resolved it will print the result it will say task resolved and then it will see oh you want me to follow through fine it will just next it will jump in next to or jump into the next case straight into the task closed print statement it will not evaluate the case at that point where is it useful i'm sure there are ways where if we have a reason to jump through cases and touch all of them if there's a if there's a case we can use that but this is the best i uh this is one of the things i could think of like maybe you want to resolve and close at the same time i don't know but it's pretty pretty cool uh moving on quickly to the structure itself so go structures is code and packages everything inside a package is scoped to that package so there is no private public internal keywords or accessories everything that is inside a package is available to that whole package now there is a difference between exported uh and and unexported right so for example what we saw earlier if the name of the variable or a method starts with a capital then it's considered to export out a package if it's lowercase then it's only scoped within the package so you will see when we go through some of the code that all the all the function method names for all the external libraries or even internal libraries start with a capital but internal methods are all lower case right so it's pretty it's it's"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "within the package so you will see when we go through some of the code that all the all the function method names for all the external libraries or even internal libraries start with a capital but internal methods are all lower case right so it's pretty it's it's pretty convenient so generics i'll run through this really quick so genetics is kind of new to the language i don't want to spend a lot of time on there but for generic you can see we can add a so you can see if we have an add function uh and we are if you are familiar with the generics in net for instance there is a you can pass in the values in this case i'm saying that the integer and float they're both um types that i want you to run this operation on and then i can call it with or without the with the the type and they will know how to handle that if i have more than one i can create an interface out of all the types i want for a single generic in this case i have a generic call number that has integer floor 32 and floor 64 and then i can say add the type number and then bring in uh you know the t from there and return that so pretty there so go routines are the the main or one of the main reasons you would want to use go language in the first place so what our goal routines go routines are user threads that execution threads that run uh in your application they're not os threads so they're not expensive we can have as many routines as we want they're all very cheap because they're running on the same user thread and then they come back to to the main thread when they're done um well they don't come back they're most like they're more like fire and forget but we can get information out of them right and then i'll show you how that is so what are go routines how do you actually do a go call a function as a go routine all we have to do is just add the word go before method and it will turn into a go routine now imagine you have a function like this one i'm doing two things here i am calling foo which is a method at the bottom you can see as a go routine or i'm just wrapping it within a function which is which is within an anonymous function to call it and i actually have to i would have to put parenthesis at the end of the last function for it to execute right otherwise it won't execute but what happens is with go if you have a method that has more than one goal routine as soon as the first go routine is done the method will jump out of it right so if you had more then you probably won't get the results back or you won't get those go routines completed in that scenario so if you want or if your code needs to wait for all those go routines to finish then we can use something called a weight group it's kind of like async await in.net but in here we control how many weight groups we should be waiting for so in this case you can see it's a bad example i'm only waiting on one but to show you how it works i have a function um that that i have an anonymous function that's a wrapper function i'm i'm doing something in there called foo and then i'm calling this thing called uh wait group dot done so you notice i said add one and i said done as soon as that number goes down to zero my weight group.weight method gets triggered and then i can move on in the execution so this is this is great you will see it makes sense when i show you the example now remember i said go routines were fire and forget well what if one go routine needs to talk to another go routine they can do that by using channels right so channels are in a single channel or buffer channel the way they work is you declare a channel using the make built and make function here we are saying make me a channel or make me a type oh sorry make me a channel of type integer because channel can only be singly typed so you cannot have a channel that can take more than one type in it and then if i want to set anything into that channel i just use that arrow dash so the arrow into the channel and of course if i don't take something out of the channel i just i don't switch the arrow as you would imagine because everything that gets the value should be on the left but in this case i put the c and that you can see when i'm reading from the channel the arrow is coming out of the channel and the value whatever value has sent which is one goes into i in this particular case right so again the reason i'm running through this is because i want to show you the actual code this is an example one of the examples of using a channel in my main function i initialize a channel and then i start a go routine and i pass this channel into that go routine and then inside that guru routine i'm passing in the value 10 to that channel and then outside back in my main function i'm waiting for a value as soon as that value gets sent to the channel i get the value out and i print that value onto the screen or whatever i'm doing now like i mentioned channels are only single typed so i can send information from one go routine to the other using channels it's"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "i get the value out and i print that value onto the screen or whatever i'm doing now like i mentioned channels are only single typed so i can send information from one go routine to the other using channels it's it's pretty fun now there is a whole uh it so the reason i call go routines and channels advanced functions because uh we can shoot ourselves in the foot with channels if you're not doing them right or we can write a lot of blocking code where we may have a we we may have a listener or receiver waiting on a channel and then a sender that never sends the information so now you have a blocking code but we also have we may have a receiver that send too many more than one data to the channel and the channel may you know panic and and the app will crash then we have to buffer when we buffer then we can send as many as if we want and then receivers will so it's it's a very powerful topic right and and i encourage you to look into that for for when you get to working on go routine channels i'll just breathe through this i also worked on making this work in the browser so i built a a fibonacci sequence or calculation calculator to run in the browser and i was able to do that by setting my operating system from my main go to javascript and then my architecture to wasm and this is how it looks like so in the brow i have a file main.go pretty simple i have a library called syscall slash js to communicate with javascript and there i map my javascript functions to my go functions by name and then when i compile it or cross compile it into wasm then i get a file called main.what that i can then load into my browser and read it using that wasmexact.js file and then my wasm code or sorry my go code runs directly in the browser without having to make any server call this is just how it works you can take a look at it later you can see it's just getting the the value from go from the browser from from whatever the ui is and this is how it looked so you can see i tried it on all three browsers i send in a limit i press the button it runs it creates the it calculates the value and then it just tells me how long it took to do that right not very efficient but it works this is what we've been waiting for so now i want to jump into code now you will find that most of the uh oops you will find that most of the world uses vs code uh i use vs code as well uh can you guys see my screen you probably cannot see my screen at this point but you are about to see my screen which is right here let me know if it's hard for you to read what's on the screen if not then i'm going to continue so all right cool well how do we actually cool how do we actually get started with the with go uh we can i mean i can do that late uh maybe at a different event where i can go through how to start go but i am using a different ide than vs code but it works perfectly fine in vs code i've done it vs code so here i wanted to show you my code structure first so what i have here is this is my project directory and i have three folders here i have a source code folder i have a build folder and then i have a az functions folder right so the reason i have it this way is because i want my code to be built separately and then whatever delivery mechanism or distribution mechanism i'm going to use or deployment i'll use that separately so if it is hazy function if it's docker if it's you know aws whatever the case is so in my source code i have a file called main.go and then i have handlers and that will take a look at we have services and then we have models and all that is in here so let's take a look so in here what i'm doing is i'm using a library called gin to create my it's a it's a framework to run your to write your rest apis in now there is a http package that's built into go it's an entire it's a first class package that also has a rest capability but i'm using gin just because it kind of takes some of some of that code and makes it easier to work with so we import and as you can see in the go code when you do import this is same as doing import fmt import log et cetera et cetera i can have multiple import statements or i can just have one import and group them in a in a parenthesis so you"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:35:23",
        "seconds": 2123,
        "text": "code when you do import this is same as doing import fmt import log et cetera et cetera i can have multiple import statements or i can just have one import and group them in a in a parenthesis so you can see that this is my main package so we always need a main package for our code in the main package i have a main function which is my starting point for this application and in this application what i'm doing is i'm just i'm calling i have a method called setup server and i have this thing called a router so this is coming from the gen library from the gen library uh i just call the default which gives me the router and then i want to set up some routing on my uh onto my my local server so what i have here is there are two ways for me to do it so what i'm going to do here is i will set up a get so i will say router.get i'll give it a path and then i can either have a function directly in here right so in this case i'm saying my handler is a function that takes in the context and returns so the context will turn a json where the status will be okay and the response will be this right but you don't really want to do this everywhere right so what you will have is something like this where you have a get and you'll probably have post put patch all these you have the end point with maybe some query paths in here which i do like city state and state and then you have i have a handlers package which is up here that has a get weather that it gets called and then this one has get alerts for state this is a weather api by the way that returns some other information and when i set up my routes right next thing i do is i say router dot run and i get the port so in this case because i'm deploying to azure function i'm just looking up my local environment to see if i have this variable set and you can see i'm using the if val okay if ok exists i'm going to go ahead and return that right i'm going to return that that port otherwise if this doesn't exist which means either i am not in azure or i am not anywhere else i may have more here to see if i'm in aws or whatever else but here i'm only checking for function if not then just go ahead and start it on 8080 right so to run that to run that i can uh i hope you can see this can you guys see this um read it pretty easily or yeah it looks good okay now it i hope you can see it now because it's pretty big okay so this is the same file i was showing earlier so we have a few files we have the goda mod which is just the module that i showed you earlier uh the sum is kind of like the packages file where once you run the mod it brings in all the dependencies then the blue are the folders handlers model services and then i have a main.go file right so this is the same file that we just saw right you can see i'm using this because you don't have to have an ide but you can just use your terminal and all i'm going to say is go build and main.go so when i run this right and now if i open up this folder you can see that there is a main file that's in red that just got created or generated because i run the go command which is how it compiled that code for me and because i'm on a mac it ran it for arm or in this case i don't know what it will be and if i want to run it all i have to say go run main.go and you can see now my server is running and it's telling me that it's running and these are the three endpoints i have the slash api slash weather and all that so what i can do is in here i can say actually let's switch to a browser so i will go to localhost 8080 and i'll just say api and you can see this is what the slash api returns and if i say i want to see alerts for for my state for instance you see i get the response i get the whatever whatever the object is and we'll take a look at this so i get 19 count and then these are all the weather alerts coming back for my for my state and it's running locally as you can see so i can come in here and it'll tell you that these two were called and you know all the time that it took 437 milliseconds right so pretty straightforward we run it you know it gets the state and it goes from there"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:40:24",
        "seconds": 2424,
        "text": "you can see so i can come in here and it'll tell you that these two were called and you know all the time that it took 437 milliseconds right so pretty straightforward we run it you know it gets the state and it goes from there now if i look at the source code i have handlers for instance i have the alert handler that we just saw it it takes in a context right and then it looks for a parameter called state so if you remember in here i said that look for there will be a query parameter called or a path parameter called state and that's what it's looking for here and if it gets if it doesn't get it it returns a bad request if it gets it it returns the alerts right and what is alerts uh i call the alerts or the other and i'm calling another hand another package called services and i'm passing in that value in there and all these packages if you notice at the top this is called package handler this is just me structuring my code right in the handlers and and services and whatnot and the alert service which is here it has two constants it has that get alert method and remember because i have this one as lowercase this is not exported so you can get to this one this is the only method that is uppercase so this is the only one you can get in the service and i get the url structured for my code i call the http response i don't have to do and there is no ceremony here right i just call if you notice i just call http get pass in the the url and i get the value back here i use something called defer so when you use a defer that code gets run at the end of the code block so this is really used so if you're about to like you know if you're reading something or you're opening a socket or a connection and you want to be able to close it and you don't want to forget you just do it right away so in this case as soon as i get a response that is not bad i close my function body and if this gives me an error i just log it i don't like do anything with it and then i'm saying okay if the status code is is not okay then return the editor otherwise you turn the body and the error will be nil right so and then i just do some uh serializing and deserializing so in this case remember i talked about keeping it simple keeping it very lightweight i have an alert response dto or dao or whatever you want to call it but this is a response object that's coming back from the from the response from the http call and here instead of creating another model and then just throwing it out there i just create an inline struct and i just use that to deserialize my incoming object which is pretty neat so i just said hey there's an alert response that'll have updated that'll have alerts um and in here when when my actual model alert is here i'm setting the values to my alert the count and then the actual array of all the alerts that come back and this service then goes back to my handler which gets the response here and and then i get c dot json status is okay and the response is alert right so that's what we saw there is a more complicated one which is the weather right i'm not going to go in all the detail but it works exactly the same way but this one has a few things right so this one does it makes two calls first of all to it to a server that it needs to wait on so i couldn't just spin off a i couldn't just spin off a go routine and then like not wait for it so here what i did is i said okay i'm going to get the city from the given text because i'm using rj arcgis for this and then i want to get the location i get the coordinates and once i get the coordinates this check this out this is the the main meet of this function so i'm calling in six core routines to go get different items for a weather response get me the alerts the observations the hourly forecast the daily forecast the rain forecast and some other product and then i tell this wait group to wait for all of them to finish and when they're finished return my response object and in go everything gets passed by value there is no passing by reference but you can pass in the address right so you can pass in the pointer so if you notice i have my weather object initialized up here in line 38 and i'm just passing in the address to that to all of these go routines because go routines don't return value and inside my go routine they're just making calls to different services they're getting the response set and they're just saying okay i'm done so every time a go routine says i'm done this weight group count goes down to zero when it goes down to zero it returns so this is like you know a bunch of code here this is all in github so you can see it um when this one runs how does this work let's take a look so i'm gonna go ahead and run it again right so it's running and then we go to the browser and instead"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:45:25",
        "seconds": 2725,
        "text": "see it um when this one runs how does this work let's take a look so i'm gonna go ahead and run it again right so it's running and then we go to the browser and instead of pulling for alerts we pull for weather and we say boston uh or not i think it's running let's try katie no it's not running oh it is not running because if i look at the code i should get a 400 back because i'm using the arcgis map api which i don't have it configured in my um i don't think i have it configured in my ide well i do have it yep i have it so let's see what does the 400 yeah it says unauthorized api key for service not found um let's take a look oh sorry i'm gonna run it through my ide because my id knows about it and not cli okay so now let's go here and run it again we go to localhost weather and let's just say boston and we still didn't do it why oh sorry i have to stop this one first let's start this again there you go now it's running on port 8080 so now if i go and run to boston if i run it there you go so what i get back is i get the update id all these values and you can see i get the hourly forecast i get the daily forecast the rain chances and all these good stuff now what you'd probably notice is something that is here let me actually see um localhost alerts let's see you guys don't have any alerts so i'm just going to say texas so you see what happens this this object that's getting back has a property called updated then it has a property called count that it has a property that's an alerts array and that is here so i have embedded the same object in my weather response so my weather response alert property looks exactly the same right i named it active alerts but it has update count and then the alert right in which in your case is empty so um that's just a quick little tour of the go apis itself now how do we actually publish it to azure so to do that let's switch over to azure this is my function app so in in my case i did the setup of the functions app in the browser and i'm in the portal and you can see that currently i have two apis in here i have an alerts and a weather api so if i go to go let's just pull texas why not so if i go to that you will see i get this i don't know why i don't have the the nice ui but you get the point so this one returns the update the alert count etc running on on azure so what i'm gonna do is i'm actually gonna delete these two um do i want to delete them let's just delete them oh i can't touch it in here okay so let's take a look at how we actually deploy no worries so for me to deploy i have to do a few things so let's just go back to my easy function folder so in my easy function folder as you would imagine for those of you who are this is the azure group so i'm sure you guys are familiar with with how we deploy to azure function normally we have the function bindings right so we have a function called alerts and we pass in a state then we have a function called weather we pass in the city state these are all http triggers and then i have the host.json and i made a few changes here so first of all i said that my execution path is going to be something called api so whatever my executable is going to be is going to be named api and i removed my route prefix right normally out of the box you get slash api as there are prefix i remove that because i don't want that and this is where my function configuration live in this folder called azfunc and if we look at that folder right now we will see that it has just a few files right it has alerts folder make file and all these things so what i'm going to do is we will go in to um we will go back into the source folder where we have"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:50:31",
        "seconds": 3031,
        "text": "right it has alerts folder make file and all these things so what i'm going to do is we will go in to um we will go back into the source folder where we have this and and i'm going to make some changes i'm going to say make my so now i'm going to cross compile this build for linux to run on my on my function so i'm going to say make my go os to be linux and make my architecture to be am d64 then i'm going to say go build main.go and output into az.functions uh actually i have to say where it needs to go and then the output is going to be going to call it api so or is it the other way go build uh let me make sure what the syntax looks like so go build i'll have to do the output then the folder and the file okay so i have to say go build the output will be complete main comes after that okay cool build output in this directory which is the azure function and my file will be main.go and the name comes okay so i'm going to say the name of my file will be api so if i run this it will take a second and okay more than a second and there you go so now if i go back to my az folder you see that there is a new api file that's the actual function that will get deployed so now within my i'm i can see my host.json within my azure folder where my function configuration is i can deploy but before i do that let me finish up with this really fast so nope that's not what i wanted but let's just run through it really quick all right here so now when we are ready to actually deploy this i'm going to show you two different ways of doing that right first is the actual cli that i'm going to show you now and then the github actions because i'm sure you will not be doing this manually in your code right so this all all this code is here and i'll show you in a second but this is the main function that we will call right so if i go back in here if i say func azure function app and then the name of the app was go w xp api so you have to say publish the app name and then because okay so if you if you know azure functions needs the runtime so if it's net if it's linux what it is uh if it's python whatever language it is and in our case it's custom because uh currently on azure go and rust fall under custom so when i run this it should connect to my i don't know if i'm logged in to this it may scream that i'm not um but i am logged in which is great so you see it's deploying to my function uh to the portal and it's going to sync both my alerts and weather and there you go so now if i go back to my portal i hit refresh they should still be there and they still are so if i run this now hey sometimes there's service okay there you go so it's still running right it normally takes a minute or two for it to finish deployment but in this case it actually went right away which is which is pretty good um let's run it one more time just to make sure it's not um cached we'll learn different one there you go so it's working right but how does actually how can we do this with github actions so in github actions at the directory that i'll share with you at the end where you can see all this all this code that you are seeing right now is on github of course so you can play with it yourself i have two workflows one is every time i do a pull request all it does it just all it does it just runs a a build just to make sure that it builds and runs the test and then when it's done it uploads artifact doesn't really need to do that either but it does that but the main one is publish so in this in"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "00:55:34",
        "seconds": 3334,
        "text": "a build just to make sure that it builds and runs the test and then when it's done it uploads artifact doesn't really need to do that either but it does that but the main one is publish so in this in this action or my workflow every time i push to my main branch i'm setting up my environment variable so i've set up my os architecture my build output path so you guys remember it's a z function and then my artifact name right so i set all this up up here and then of course i run the job so first i have to say i'm running in ubuntu then go ahead and and set up my setup go so i'm going to set up go at 1.18 version and then i'm going to go and build this and to build it i'm going to run this command where first i change directory into source and then i run the same command that rain in in in my command prompt which is go os go architecture go build verbose so i can see what's going on output and the output is going to be the build output path slash artifact name and then main.go so what this step does it creates that file and when it creates it it places it in that ac function folder that what i do next is i just upload it right so here i'm using the upload artifact get github action and i'm saying name it the artifact name and then put everything that is in the build output folder so remember this is important that i'm seeing everything in this folder upload it and name it this artifact and of course i don't have tests running right now i'm in test to run right now but this is how i run the test and the next main important thing is publish now there are two ways to publish and i'll show you both first is first things first i download the artifact with the same name that i uploaded them to and i log into azure using my secret credentials and for those of you not familiar if you go to your repository and if you go to settings on your left there is a secret folder i mean secret option menu and if you go to actions this is where you can put your secrets for your github actions and i have a few i have the function name i have the publish profile and the azure credentials um going back to code i log in using those two things and then i run this functions action step and this is actually pretty cool i i didn't like it at first i don't know if i like it still because it's too much of a abstraction in black box for me but all i have to do is just give it the actual of app name and it knows where it is right now and it has all the um it has downloaded the artifact so it will upload this artifact straight to my azure account using the credentials that i provided it if you don't want to do that you can also do it manually which is right here i left it here as company so you know what it is for that what i do is instead of using that action i set up the cli tool so i just do what you would do on your local machine because github actions is passwordless which means you can run sudo commands without having to get a prompt for password so in here i set up the repository i set up i pull down the package for linux i do have update and then i just install the cli tools and then here i run the same exact uh command that i ran locally which is function azure function i publish the name of the app and custom and it does the same thing right so if i was to show you this in action i will go back in here i will just update my readme file and let's just make a change and we will save it now i could go up to actions and just rerun the last action but i wanted to show you how it actually works so this is a you can see the version number on this particular one is 20. i'm not versioning my stuff right now but what will happen is in my code you will see it it is going to set up go environment it is going to build all it will bring in all the dependencies that my code needs it will build it and then it will upload it uh to upload my whole az function folder uh with the built-in with the build binary of the api and it's doing that right now it's going to test there's nothing to test so we'll just quickly pass all this and you can see on the left build pass if you go to publish it is going to publish this as well now what happens is if something goes wrong here for example if you passed in the wrong"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "01:00:38",
        "seconds": 3638,
        "text": "pass all this and you can see on the left build pass if you go to publish it is going to publish this as well now what happens is if something goes wrong here for example if you passed in the wrong location for your artifacts or if you didn't pass in the runtime properly it will actually remove your functions from the from the portal or from from azure because they will not know what to push and your functions will just disappear and then you have to just push a new one for them to go back and get synced and here you see i logged in successfully i'm publishing based on that using the function action step or github action step from the marketplace so this is all available i didn't do this one myself uh it is publishing once it's done publishing it will log off so in my case if you notice i'm logging in and logging out manually into azure just just to be on the safe side and it is publishing i think it's done publishing and now if i go back to my portal and i do refresh you can see my functions are here and if i run them let's run them from texas because we have some here and there you go right so in here if you come in here and don't know exactly where to go and see all the latest deployments that just happened on this anyone on the call if you can tell me really quick fine if not then it's okay but we can look at that to see all the deployment that just happened on this particular one i don't see any maybe activity log oh there you go yeah there you go you can see that eight minutes ago it synced successfully by eight minutes 13 minutes and it tells you which subscription i was using and who did it so this is all my company profile so it's all coming in here right so that that is that is pretty much it now i do want to finish up um we did this we did this and then when it's all said and done you should see it there so quick recap why use go i know that we went through a lot but i hope what you noticed was how simple the language itself is and how easy it looks like you can pick up and work with it right it's it's if you're coming from c sharp it shouldn't be very very different it's pretty easy to to pick up so i hope you will play with it like consider it for your apis if you have a need for really performant apis that could run anywhere definitely consider uh you know looking at go as well so it's perfect it's a it's great for cross-platform any use cases uh easy to learn dev experience is performant it is coming up in it's it actually picked up steam in 2021 when i guess everybody was back to their working from home and realized that they needed more their workload on their systems got pushed to the limit so they realized they need to look at some more performant technology so go came back in the picture a little bit more so it picked up a steam in in 21 and there are a lot of now go language oh sorry conversations are on go about people learning go where to go learn go uh you know people the the jobs posting are more and more asking for back end goal as well so and it's easier to learn than rest at this point so i think and it's pretty cool i pulled some stats so you can see it's number four most wanted from 22 stack overflow survey if you don't if you don't like that survey don't add me i don't really care about this airway but i do read it every year it comes out and it gives me a good indication of what's going on and then it is one of the the top paying jobs as well because of all the demand so resources how can you actually get started really quick if you go to go.dev today they have a playground where you can start coding without installing anything just go to the website um why don't i show you so if you go to go.dev it'll take you here and if you go to slash play you can run go directly in the browser so it's pretty cool you can do a lot of the use case you can learn the whole the whole you can learn a lot of the concepts directly in here if you wanted to i wouldn't because you know if you work a lot on recorder and save it and come back to it then you'll lose all that but it's really good place for you to go and play around with it if you want to go i just see some of the codes that i was showing you do during the presentation if you go to tinyurl.com go snippets it will bring you to my gist that"
    },
    {
        "speaker": "",
        "title": "Deploy Your GO API to Azure Functions",
        "videoId": "1NcnkU403UE",
        "description": "This is a recording of the September 8, 2022 meeting.Do you want to build backend application but don’t like JavaScript? Let’s GO. GO is an open-source programming language with simplicity at its core. It is supported by Google is widely in use for backend and CLI applications with a growing ecosystem of communities, partners, and tools. It is easy to get started with GO and build amazing applications.Ok, so now you built your GO API and want to publish to Azure. In this session, we will take a tour of GO lang and explore a REST API built with GO and hosted it in Azure as Azure Function.About the speakerHussain Abbasi is the Head of Technology at ChaiOne. He is a content-creator, blogger, speaker, streamer, and software engineer with over a decade of experience developing mobile, web, cloud, and desktop applications.Hussain is a well-known community leader in the mobile development space. He is a co-organizer of Houston Xamarin User Group and the organizer for Houston Flutter User Group in Houston area and authors and contributes to several OSS projects.You can find his shenanigans at hussainabbasi.com. Or his blog at intelliAbb.com. You can find him on Twitter @HussainNAbbasi.",
        "start": "01:05:41",
        "seconds": 3941,
        "text": "if you want to go i just see some of the codes that i was showing you do during the presentation if you go to tinyurl.com go snippets it will bring you to my gist that i put together a while ago that talks to you about variables arrays map loop types generics i have a fibonacci calculator in there go routine channel and interface examples right so all this code is here uh just just look at it play with it i remember i was talking about circle radius and and square area and circle area et cetera so it's all in there if you want if you're interested if you're a javascript developer and you want to see how you can maybe use some of the go libraries within your uh browser and then my github repositories right there is called wasm samples and the one we just looked at is called go wx api wx usually stands for those of you who don't know wx stands for weather right so go by their api is there and for anything else you can find me on twitter that's my handle hussein and abbasi and my github and that's it thank you very much for uh coming along and and sticking it out for this long i will take any questions if you guys have at this point any questions how are we doing on time i guess i guess i would like to think that sure one of the promising things would go for me is the containers yes uh so if you notice uh even with net six we are in the dot net world we are coming to uh this new idea or the new way of doing this which is to minimal apis and minimize a lot of that boilerplate noise but go because it's built out of the gate has lightweight it still feels very light and yeah and yes if you noticed most of i shouldn't say this a lot of azure right nowadays runs on linux so i think we are we are in good hands we are not tied into a ecosystem at this point if no other questions um i would encourage you guys to just go go here copy paste this whole snippet into your vs code and once you install vs code copy paste it there and then just comment all these and then run one by one and see what's going on right how are the variables working how do the arrays work what happens in a map how does loop work struct vehicle we talked about all these things fibonacci number this is using a cache so it's super quick using my memoization this is a slower version where you know so you will see you know a lot of these examples are there how they work uh go routine this one has three go routines running you will learn running this code that they will always come back in different order but not always which tells you that there is no order to these whenever they finish they finish then channels you just play with that on your sending stuff to the channel receiving it back and then work with generics which is pretty fun which is right here i i'm really good at naming stuff so i call this edible you can add these things because you can also add a string right so if you pass in a string to edible two strings it will send send you by a concatenated string which is as useful as you can make it and there are some interface things and at the end uh yep that's all the interface work so a lot of stuff here just to get started and play with so yep that's it that's all going to go ahead and stop sharing all right well thank you for the presentation all right good job i actually see getting it getting it running and functions is something i just hadn't gotten to yet it's really cool thanks absolutely yeah that's that's one of the first things i did is how can i bring this to azure because most of my clients are in azure so if we are working with a more so we worked on a fire firefighter lms system that was that was being converted into go and they wanted performance and i was like how can i bring this to aws uh azure i mean and causing the war on aws and we are azure so that's why i started getting curious on go and azure and then there isn't a lot of documentation out there because go and rush kind of get lumped into the same support links but if you just play around with it long enough you'll get it awesome thanks and thanks everyone for coming thank you i'll get this posted up on the youtube channel probably tomorrow morning and put a link in the meetup as to where it's located great all right thanks everybody have a good night bye-bye bye goodnight thank you thanks susan all right "
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Pamela Fox: Building a RAG app to chat with your data. This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure. Json the data format thank you Jason for the introduction uh I do have the slides available for those who want to have a copy of the slides or follow along with them you should be able to get them from that speaker deck link so today we're going to talk about large language models briefly just to you know set the stage um for that terminology then go deep into rag which is retrieval augmented generation uh go and look at this open source rag chat app solution that can be deployed on as your talk about how to evaluate rag chat applications and talk about observability for rag chat applications on Azure so just to start off with talking about llms uh so llm stands for large language model it is a model that's so large that it achieves general purpose language understanding and generation so example I like to give is sentiment analysis which is you get a you know a sentence and you say whether it's positive or negative in the past what we would traditionally do is we' train a custom model with you know trained data that said here's a sentence it's positive here's a sentence it's negative and then what we would get is a model that could classify sentences as positive or negative and we would specifically use that Sate and now model when that's what we needed but with an llm we can just do this uh we don't have to specifically train the llm to know how to do it it just is able to do it because it's just seen so much data and been trained on such a large data set and one way you can think about the size of an llm is how how uh how many training operations it's had so the these graphs here are in turns of training flops which is floating operations per second I believe and what you see is that there's this jump when they've had 10 to the 24 training flops they suddenly achieve this ability to do really really well at these General purpose tasks and these are the classic ones that they do like modular arithmetic word in context Etc um so that this is observation they had is that if they threw enough data at it they threw enough compute at it then they you know achieve these general purpose models so you can there you can call them Universal models Foundation models large language models um but the point is that we can use them for a wide variety of tasks and that's really really exciting um and it's kind of like I don't know I feel like it's lowering the barrier for more folks to get involved with with uh Ai and using models because you know you think of a task you're like well maybe I can just use an llm to do it maybe I don't have to you know train one and learn how to do training well so there are lots of llms in used today ones that are both hosted on you know company infrastructure and also ones that are open source that you can even download to your computer and use uh so you know the hosted ones the big one of course uh are from open Ai and that's the GPT model like gp35 gbd4 whatever GPT is coming next uh Google is also in the game here you know it put out Palm was like a year ago and now it's put out Gemini and Gemini you know looks like it might be pretty impressive uh anthropic is a company I think they forked off of Open Ai and they recently put out the Claude 3 family which seems to be pretty powerful and then we've got the open model so there's a lot of open models coming from meta like uh the llama llama model uh and that one has kind of variety of sizes and then there's also this company mistro AI that's been putting out some models as well uh yeah I see a question from so yeah can you go back to the last slide and just want to understand when you say this um um like model scale training flops so what does it mean like mod AR arthamatic mod task nlu and word in context what does it mean these tasks that they get the models to do so mod arithmetic this is modular arithmetic so typically we wouldn't expect like a language model to be able to do modular arithmetic since it's not trained for math uh but you can see that its accuracy does jump to like 35% when it has been trained on a lat enough data just because it ends up seeing modular arithmetic a lot in the data um this one is multitask natural language understanding I don't remember exactly what that test test looks like um and then I don't remember what word into context looks like so I'd have to dig up the paper uh to remember what these what these tasks look like it's a good question thank you thank you so much uh yeah so and I see a good question about hallucinations so I'll certainly talk about that throughout it um so what we see is there's a variety of LMS so some of them are hosted and these are the like the most powerful ones you can really only use on someone else's infrastructure um unless you're willing to go through a lot of effort to figure out how to you know host one of these powerful and set up the GPU and all that stuff but you can totally get started running with these smaller models locally I recommend using olama"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:05:04",
        "seconds": 304,
        "text": "willing to go through a lot of effort to figure out how to you know host one of these powerful and set up the GPU and all that stuff but you can totally get started running with these smaller models locally I recommend using olama you can see I've got like a little llama up here uh and here I've got it running I typically have it running over here yeah so let's see emojis for Boston I always use it to generate emojis uh so this is with llama 2 so I just write a llama run llama 2 and what that does is that it pulls down the model if I don't have it already uh and then it lets me just chat with the model so here are some emojis to represent Boston so we get a building a park and a person walking they're pretty good ones I like to walk around Boston when I go there uh so I do recommend playing around with olama it's the easiest way to get started with these open models locally and it's just fun to have an llm in your terminal they're not as powerful as the models you'll definitely get more you know hallucinations um as you know Lucas was saying um but uh there's a lot you can do with it h you know especially if you just need a quick a quick Emoji quick poem that sort of thing so one thing that you might want to know about terminology wise is GPT what does that stand for it is generative pre-train Transformer that's what the open AI models are named after you'll also just generally people talk about he people talk about Transformer architecture so that architecture was actually first described in a research paper from the Google brain team so it's funny that you know open AI came up with the gvd models first but uh you know things happen uh so if you're interested in seeing how this architecture actually works and you like reading research papers uh do check out that paper that's where I got this diagram from um but basically this Transformer architecture m let uh was much better for language because of its ability to see multiple parts of the like kind of input the sentence at the same time so that's my very simp simplified and probably not quite correct uh you know understanding of the Transformer architecture there's more in the paper and there's also some great videos for f from folks that are actually machine learning experts that explain the attention architecture more there's also a fantastic videos from Andre karpathy who is a machine learning expert and he was just uh he was previously at open aai and at Tesla Ai and he's got a great talk state of GPT and then also he has a series where he builds GPT from scratch in code using python notebooks so that is a really cool Theory I still haven't made it through the whole series because it's a little intimidating to build entire tvt it takes quite a few hours but every time I watch his videos I I just learn so much so if you want to dig into how these you know how these GPT this transform architecture actually works that is what I recommend so how do we actually use these uh these GPT models from open AI uh one way you can do it is an Azure Studio I'm guessing some of you have already done that um so please you in the chat uh let me know what your experience so far has been in terms of using open AI as your open AI that sort of thing uh so there is this you know Studio that you can use you can get to it from the um from the portal now the first thing you need if you're going to use as your open AI is that you do have to fill out a form in order to get access and in that form you have to say what your usage your expected usage is going to be so that Microsoft can say like okay that sounds like a good responsible use of um of open Ai and then once you got it then you can deploy all these models you can see I've got quite a few I have quite a few deployments because I spend way too much time doing this stuff um so let's see I can go to my model deployments and then open those up in as your open AI Studio load load load oh here we go oh I'm just gonna all right so I'll go to as your opening I Studio there is also something called a your AI Studio which is different from a your open AI Studio I tend to only use a your open AI studio um but a your AI studio is where you'd go if you're you know using other models making your own machine learn models that sort of thing I think eventually they're going to merge the two but right now we've got two different Studios so this one's really fun just the chat playground it's just a you know just a wrapper for playing with the API so we can be like you know right haiku about Boston and it'll send it off and we can see Harbor City's charm Boston's history unfolds proud Spirit endures okay so that's cool but maybe we want to change the system message so how people find more you know you're AI assistant that uses so many emojis okay so I'll change the"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:10:08",
        "seconds": 608,
        "text": "see Harbor City's charm Boston's history unfolds proud Spirit endures okay so that's cool but maybe we want to change the system message so how people find more you know you're AI assistant that uses so many emojis okay so I'll change the system message I'll apply the changes and now I'm going to ask ask it to write a haiku about Boston again and there we go we can see a lot more emojis let's also we're talking about hallucinations we can say what is the weather in Boston and those of you who are in in Boston well there you go um it's still doing hus and it's G Gabby a range here so what is the temperature today I'm trying to get it to lie basically uh okay so sometimes it does this response where it says I'm sorry it's an AI I don't have real time data access so that's good uh it's you know it's better when the LM doesn't try to make something up but let's just try to force it so I'm going to change temperature to one and top P to one to try and increase its creativity level and we'll see yeah it still is refusing to answer that's good so sometimes you can get the llms to to uh make stuff up and uh depending on you know how it's been trained sometimes it won't do that for you all right so that's a little playground and you can also grab code from here so once you've played around with something you can actually grab the code uh you can get it in you know they've got different ones they've got curl C Python and Json I'm not sure what the Json is for I typically use Python and so most of the code you're going to see me using today is in Python so as you see here here is an example in Python uh so we pass in the conversation so when we're working with these chat tuned models so we call them like chat tuned models uh so like CH gp35 and gbd4 are chat tuned which means they expect their input to be to look like a conversation so we typically start off with a message which is the system prompt so it has roll system and then it has the system prompt and that gives it just overall tone format expectations uh and then we have the question from the user and then and we can also keep going so we could pass in you know multiple back and forth um so that the you know the chat model could see what messages happened before uh we can choose to stream the responses or just get the whole response back at once so llms can be really great you just saw we could get it to know write Haus and use poems and all that stuff uh but you know as Lucas was saying like you know there's uh it can make stuff up right and it can answer things incorrectly and why is that well one is that llms are have always have outdated public knowledge right because they train the llm you know on the internet up to a certain point and then nothing after that right so if we asked about something recent that happened it would you know it would have no idea uh the other thing about llms is that they do not have access to anything internal so if you know if you have data that's inside your internet there's no way that an llm is going to know anything about that so if you're trying to ask company specific data it's just not going to know right so those are you know the limitations we run into and then we try and figure out like how can we work around these limitations so there's you know three General techniques to incorporating domain knowledge the first technique is to do try to do prompt engineering this prompt engineering is only going to work if the data is inside their inside the weights somewhere right like let me see if I can do an example of this um so I'll say um write SQL Alchemy code uh that's a particular python package for SQL databases okay so yeah so it did this this is the old way of writing seal Alchemy code uh I'm going to see if I can get it I don't know actually if it's seen the 2.0 I think it has code using the declarative base C Class let's see if I can get it to fix itself oh it says squal 2.0 doesn't exist as of my knowledge so yeah unfortunately in this case it can't do it so what I was trying to show is the the fact that if if you know imagine there's you know two different versions of a library in an llm weight you can often get it to you know pick the most recent one if you're giving it a hint that that's what you're trying to get it to do right but that only works if it's in the weight somewhere right in this example it actually didn't even have anything in its you know in its training data at all so we couldn't get it to come out with the code so prompt engineering is generally not going"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:15:10",
        "seconds": 910,
        "text": "in the weight somewhere right in this example it actually didn't even have anything in its you know in its training data at all so we couldn't get it to come out with the code so prompt engineering is generally not going to be that helpful when we're trying to incorporate specific domain knowledge only helpful if it is actually somewhere in those weights and we're trying to steer it the next approach people talk about is fine-tuning that's where you actually are kind of training a subset of the weights and so you would repair like you know maybe thousand examples or or more and those examples would be you know examples of uh you know user questions and chat answer and in that way the llm could actually learn new skills permanently so it's a very it's a it's a you know effective way of getting an llm to you know update it's weight to learn something more however it is expensive right it's expensive to do the fine tuning and then it's more expensive to run uh to you know to use a fine tune model than to use a base model so I actually personally have not done any fine tuning myself I haven't felt the need but uh and and a lot of people have talked about where you know uh you could do fine tuning or you can just use the the the you know the most recent model and and that is generally going to be better so fine-tuning we like to consider a last resort because of the ex you know expense involved you know the time and all that stuff um so it is it is a tool in our toolkit but it's not the thing we should necessarily reach for immediately the technique that I like to use is retrieval augmented generation which is a way of just giving the llm the facts just in time right um you know for example with the SQL Alchemy one that I just showed if I you know wanted to make sure it really did um you know answer something correctly well I could just give it information I could just say like well you know um you know here write a model for a restaurant class based off this example right so I'm basically going to like give it current code and and see if it can learn how to do it yeah it got a little bit better there yeah uh so the idea here is that you know we're we're going to give the llm the information to answer a question based off the domain data and we're just get get going to give it to it at the point where it's answering the question so that it can see what we want to answer the question based off and it can still use its skills of answering questions on that provided data so I have one question if you don't mind previous so where does the few shot fit into in this um yeah that's a good question um yeah I should I should do like an updated version of this I actually I did talk about that in a presentation on um Friday uh so me find yeah ways to improve llm output so F shot examples uh so we could even do that in the playground too you can add examples and this shows the chat what responses you want uh so I would say F shot examples are the most useful for format they could also help like in this case with SEO Alchemy like it might be enough to get it to write the syntactically correct SEO Alchemy code but usually few shot examples is more about learning the format that you're looking for and less about the knowledge um because typically your F shot examples are going to be the same across all the questions but the knowledge for each question would actually be different um does that make sense yes so that means a fuse shot would be for the formatting and for the you would use the rag or fine tuning if it is knowledge based is it yeah yeah and I I can show examples because we do use few shots for our you know for for formatting to try and show the LM this is the kind of format we expect so we use fuse shots in combination with rag so it's definitely a good tool to use f shot examples especially when you're trying to get a particular format particular length that sort of thing um but it's uh I would say it's complimentary to rag got and and irres of which llm we use is that a same how we interact with the with the foundation models in terms of let's say the F shot is the way that we do it for GPT would it be the same for the clot um do they follow the same Pro you know similar way to interact with them yeah generally generally that would be similar um you know you know you see people talking online online about what prompt engineering and few shots they're doing for Claude and and other models there are some differences in terms of"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:20:12",
        "seconds": 1212,
        "text": "with them yeah generally generally that would be similar um you know you know you see people talking online online about what prompt engineering and few shots they're doing for Claude and and other models there are some differences in terms of um if you're going to do something with like function calling or Json output so there there's a a lot of people try to get the llms to Output structured data uh like if you're trying to get it to Output a Json that um you know like you pass it in news article and then you say output a Json that has the title of the article the top you know cities mentioned in the article and the top people mention the article right so doing like an any analysis to get Json out if you're trying to get Json out of an llm that actually is is going to vary based off the model because some llms have like specific uh kind of API endpoints in order to to get Json output because they've been they've tuned it for that uh and with like the open AI use the tools parameter to the API um H but not all the not all the API support that so the main difference I've seen so far is if you're trying to get structured output out of the llm the way you do that per model uh may vary okay thank youh all right so retrieval augmented generation let's dig into this so let's say we have this example here do my company perks cover underwater activities and I actually have I have this one open let's see is it over here there we go yeah I'll even try it again do my company perks cover underwater activities let me zoom zoom zoom so it is going off and trying to figure out the answer to this question and it should be doing it in and this one's this one is actually running locally okay so there we go we see underwater activity such as scuba diving are covered under the perks plus program now this is a chat that's specific for a fictional fictional company's data and it's managed to answer this question and it does that using retrieval augmented generation so how did this actually work so we get the user question and we use that to search a knowledge base right so this knowledge base it's either a search engine in this case it's as your AI search it could be a database we're searching some sort of SE search engine it could even be a numpy array actually like if you had a small enough amount of data it could even be like an inmemory array but you need to search your data somehow based off this user question in order to figure out what are the pieces of knowledge that could help an LM answer this question and then we take that you know we get that information back and we take that and the original user question we send it to llm and say hey answer this user's question based off this data and make sure you site your sources and then we get back this answer that says yes your perks do cover some under activities like scuba diving lessons so this is the general approach to rag is that we're getting the search documents back the search results back and we're passing both the user question and the documents to that llm call and we can actually see that here if we click on the thought process so first we uh you know we search using this query and we get back search results from as your AI search and these are Snippets from employee you know employee HR handbooks type stuff and we can see you know the page number and all that stuff so we get back these and then this is the actual conversation we send to the model so we have the system message and the system message says You must do it according to the data and the sources below then we have the user question and actually here is where you can see we do have few shots so we have an example of a question and sources and an example answer and that's to show it how to do citations right because we're trying to get citations in a particular format just trying to make it bigger bigger bigger right so we're saying like Okay this is an example this is how you answer this is you know how you give those citations and then and then we have the actual user question and the sources that we got back and these are just concatenated you know with new lines and that's it that is what we send to the llm so that is the heart of retrieval augmented generation is that you send the the information along with the question and the LM is able to look through that information in order to synthesize an answer have a question or okay can can I ask a question yeah so P how like what is this is this a python based um web UI you have developed and then how you have developed like what what you are actually trying to achieve"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "answer have a question or okay can can I ask a question yeah so P how like what is this is this a python based um web UI you have developed and then how you have developed like what what you are actually trying to achieve from this how you have developed this UI if you can explain that it will be really great yeah so I'll dive deeper into the actual code for this this is a this is all open source it's a react front end with a python back end and I will I'll I'll step through the code as part of this presentation in a bit sure thank youh all right so as we can see yeah yeah have one small question so when it comes to rag um and this might be just you know your experience but how do you balance the amount of data you're actually putting in either that Vector DB or you know I'm kind of trying to understand this because I've heard these scenarios where people throw in just mountains of PDF files in a vector DB does that then I get to the point like well can't I just search the vector DB and what do I need the llm for so I'm trying to understand the kind of like the balance between you know how much data you have in there or the quality of the data or does it even matter I mean you know for example in your case here you have the HR information do you just basically put the entire every single PDF file you possibly can find and you just scrape it and put it in the vector DB and you're pretty much going to be getting quality results or do you you know how do you balance all the splits or whatever comes in I'm just trying to get a better understanding of that if that kind of makes any sense yeah so here you can see these are the only bits of like chunks of documents uh so when we're doing rag on documents we do split up the documents uh into chunks that are about this this size here about like 500 Words uh so we we split up the documents into these chunks uh because the whole thing is that we don't want send too much I actually think that might be my next slide so okay okay okay I can hold us uh so yeah so as we see rag is beneficial okay so yeah let's talk about that search step and the what the data looks like right um so we need to get good results to the llm or we're not going to get a good answer and yeah another point is that what is the llm actually doing right the llm in this case it's synthesizing information so we're basically I think of brag is making search more accessible right so people they don't want to have to search and click through multiple documents and like synthesize information in the head so we are using an llm to synthesize information and present it to the user in a concise way um but really it's it's it's really like kind of just you know making a more friendly search interface and it turns out like people like people like having a more friendly search interface where they just feel like the answer is right there in front of them um but in fact like we do need to focus a lot on that search step because in order to get a good answer synthesize we need to have really good search results right if we if we give the llm garbage it's going to Output garbage um if we give it gold you know it it it it should you know output gold uh so we want to figure out how can we really make those you know those search results be really helpful for that LM so our general goal is to come up with a small number of searches uh search results that contain the answer uh we don't want to like we don't want to find too much information because if we send too much information to an llm it does tend to get a bit lost like either if we send too much information either it just won't find the answer at all because it'll kind of just ignore it if it if it's just too much being sent at it uh or if that if we send so much information that we kind of have conflicting answers in there and we have some information that's like misleading in there and doesn't actually answer the question the LM could get misled and answer the the thing wrongly right so we really want the search step to find the most relevant documents and nothing more uh and not too many documents right so in my example I'm only retrieving three documents between three to 10 would be the usual um so that's we we don't want to send too much this there's this paper here lost in the middle uh where they were you know looking at how many documents you could send and basically like as you sent more and more the accuracy went down because the llms would you know find it too noisy to find the answers in that large chunk of information uh so you can see here we only got the three document chunks back and uh and and you know these chunks contain the answer and they don't contain too much more that is that's the goal um as like you know how many documents do you throw into your search index I mean you do want to throw in everything that"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:30:22",
        "seconds": 1822,
        "text": "and uh and and you know these chunks contain the answer and they don't contain too much more that is that's the goal um as like you know how many documents do you throw into your search index I mean you do want to throw in everything that could possibly answer a question that a user would have I I I think that's that's true you just want to throw it in in a way that you're going to be able to to you know search well um on that data later uh because you don't want to just send your you know too much information at an LM so when we're doing the actual search uh we want to use the best search strategy for searching with the you know use your question uh these days everybody's talking about Vector search a vector search it means that you turn the user query into a vector and uh you know Vector using like the open AI uh embedding models and it basically like that Vector encodes all this kind of semantic stuff about what's what's in that text so if you had a user question about dogs then that would end up you know in this similarity space where it's similar to cats because dogs and cats are both pets so they are sem atically similar even though they're spelled completely differently right uh so you know this example here I asked about underwater activities but the word underwater is nowhere in the text at all instead the word scuba diving is in the text but underwater and scuba diving are both similar in the vector space so that's why everyone's talking about Vector search because it's a way that we can uh you know we can get results for things that are semantically similar even if they're spelled completely differently so we definitely want to do a vector search so that we can you know find those semantically similar things we still want to do a keyword search because Vector search is not good for some things and this is something I want to stress because there's been such an obsession with Vector search because we're like we're all like discovering it now that people are forgetting about keyword search but oop um but keyword search is still necessary for some stuff like if I search for like an exact you know number like you know what costs you know $1 19991 1999 is not going to do well in a vector search or if I search for an exact name like you know everything about hamla Susan Fox I want that to be done with a keyword search that's an exact name I don't want you know things that people that have names like me right I want Pamela Susan Fox so we still want to have keyword searches done as well so we need a search strategy that's going to do a vector search going to do a keyword search and then is going to combine those together right because you get both those results right so you search using your you your full text query you search using your vector query you get back results you need to somehow merge those results together you know remove duplicates figure out um you know which which scored higher and then you want to you know you need to have some sort of way of ranking the vector versus the keyword search so what uh people often do is they use a reranking model so this would be a machine learning model where you say hey here's the search results here's the user question could you please rerank these search results in the optimal way now this seems like a lot of work and it it is actually because I was actually trying to implement this this morning myself so typically we I use as your AI search because it just does all of this for you and it's very very good at it uh so I do recommend as your AI search but if you were going to do this on your own database then you know you have to implement it on on that database and you can often find examples of how to do that um but the thing I want to stress is that you want to get the best results and a small number of results and generally the way to do that is with a really good hybrid search so you whatever you are using as your search engine make sure that you can get good results from that using a hybrid search uh I see a question from Robert in the chat is there way to leverage a company ontology for vectors and tonies for keywords uh like we provide documents to the llms um yeah that's a good question when you just do the vectors you're generally going to use like the open AI models because they're quite they're quite good if you had your own ontology I mean one thing that's interesting that you could link into this isn't publicly out yet um but I think it should be out in the future this is called graph rag because it sounds like you know you've got an ontology ready uh so let me link to this here um and it actually like in order to use graph rag I think you have to actually Define an an antology and uh they they say it works it can work better for some some types of rag uh so it'll be interesting to see I haven't had a chance to play with it myself um yeah that's a good question um you could also do like custom waiting with res searches and stuff like that but I haven't dug much more into it beyond that uh rajes yeah I have a question suppose you have a millions of Records in a database then you are"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "custom waiting with res searches and stuff like that but I haven't dug much more into it beyond that uh rajes yeah I have a question suppose you have a millions of Records in a database then you are going to go through millions of record create a vector out of it and then merge the keyword I think then that case going to be very very slow uh for the model to search those many records isn't it so yes yeah yeah you're right so doing a Brute Force Vector search would be quite slow um what uh you're usually going to use an index either hnsw or IVF uh those are the two main ones uh like as your AI search uses hssw so you just tell it which kind of index to use and this does as you can see fast approximate nearest neighbor surch so it's using heris in order to be able to quickly search um across so this is the current one that's the most popular and that's supported really well there's also IVF and there's also I was even reading uh people are really experimenting with this space and how to how to do uh Vector search faster so this is an article from Nvidia about doing uh GPU powered Vector search so it is a very hot topic uh but you can generally get pretty good performance with hnsw and uh you can do it with Azure AI search you can do it with postgress um so you can use one of those indexing algorithms with whatever database you use I I was watching some videos nowadays people are talking about graph databases uh yeah I saw somebody post on LinkedIn about doing what is it like neo4j or graph databases with rag I didn't read into it to see what particular approaches they they were using uh but uh that is definitely something look into so I don't know Mindy if you have any videos or articles you want to put in the chat that would be very helpful all right uh and I do also recommend reading this blog post from the Azure AI search team uh so aka.ms rag relevance also just put it in chat this nice chat here and it really nicely demonstrates uh you know the differences between just doing Vector just doing keyword and doing you know hybrid and ranker and and you know for those of you interested in like you know how do you decide how to index documents this is just a really uh really fascinating article so what does it really look like to do a rag with hybrid search so this is just my diagram before but broken down a little bit more right so we get the user query we take that user query and first we actually send it to an embedding model like Ada 002 or even one of the new embedding models from open Ai and we get back that vector and so then we take the vector and the text and use both of them to do a hybrid search which will get back the merge results and then you know with those result results we send both the results uh and the user query to the large language model and get back the the answer so this is still actually even simpler than what we actually do in the app but I'll I'll talk about that soon um but as you can see there's various steps involved here in doing a proper rag with a hybrid search now another thing to think about is what is your rag searching uh is your rag searching documents or you know I would think of as unstructured data or is it searching like rows of an existing database right so imagine uh you know you have like a an online store and you wanted to have a rag where customers could ask questions about your store items right so those I think of as actually being two fairly different rag situations and a lot of times when people are talking about rag they're talking about rag on documents because that's I think where people are really like I don't know I think maybe because it's harder and that's where we tend to focus on it because it's you know it's it's you know trying to figure out how to ingest all those documents but you could also totally do rag on database rows and um and you can have a really com compelling experience with that too so do you have any articles I actually that's one of my um kind of a research item to do uh do you have any articles you could share on how to do database Rod uh yeah that's a good question um I was actually working on it this morning uh so I intend to put out"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:40:32",
        "seconds": 2432,
        "text": "um kind of a research item to do uh do you have any articles you could share on how to do database Rod uh yeah that's a good question um I was actually working on it this morning uh so I intend to put out various samples so you can see um post from this morning so the first thing I did was I implemented a hybrid search for postgress um you know postgress with PJ vector and so you can see the search right so I pass in a text and a vector and then I get back to results so if you can Implement hybrid search on your database um you know it means you need to have some sort of vector support with so with postgress I use PG Vector um various database extensions of different ways of storing vectors so hopefully there's one in your database of choice once you do that it was actually really easy just to swap it in to my um you know to the app that that I've been showing I just kind of substituted the Azure AI search call with the call to the uh hybrid search endpoint for the postgress database uh but I will be putting out uh some repos around this to make it easier for folks so I guess want to be clear so it's it's like you're able to scan the whole database schema and then ask questions in natural language or did you just okay so when I do I I said best shoes and that um that turns into a a hybrid search query on the well in this case just on the shoe table so I did have to decide what is this going to you know what Fields that's the thing you have to decide if you're going to be doing rag on database rows you have to figure out which what are your target columns like are you going to be actually searching across all the columns or just one column and when you make a vector are you going to make a vector for each of The Columns and like search on each of those vectors or what a lot of times people would do is you know they kind of you can do like stuff it so you you would concatenate all the relevant columns together uh and then compute the vector for that so you would still just for each row have a single a single column for the embedding for that row as long as it encoded all the stuff you thought would be semantically relevant so that's that's actually the decision that you have to make is uh you know how many how many embedding columns are you going to have and and what is your you know full Tech search going to search as well yeah this a great question and definitely something we need to talk more about and have more examples for uh so so yeah if you're doing database rows you do need to figure out a way to have Vector support um for the ability to have a vector column and to have efficient search right we were talking about indexing right so you need a database that has support for Vector indexes so you're looking for support for hnsw or IVF those are like the efficient Vector searches uh or just looking for a native Vector database um you know that's an option too so on aure uh the options we have here are you know uh for database rows you could do as your AI search if you wanted to copy the data over that's also an option if you're okay with having a copy of the data as your AI search can connect to various databases and and index it uh but then you'd have a copy of the data so you know if your data changes a lot you might not want to do that uh you can do as your post grass flexible server plus PG Vector you could do as your cosos to be plus their new Vector support you could use container app Services uh with these built-in Vector databases like milis quadrant or weate uh and of course you could use the open AI embedding models in order to actually you know compute that column so that's rag on database Rose and I haven't done that as much as saying like I only really did it this morning to make sure that you know to to kind of prove it um what I've spent much more time on is rag on documents which we can also think of as unstructured data so that's just whatever documents you have PDFs docs PowerPoint HTML markdown IM images all of those are things you could potentially uh you know ingest into a search engine but for that you do need an ingestion process that's going to take that document extract the data from it split it into good siiz chunks because remember we don't want to send too much information at an LM then you know compute vectors for each of those chunks and then store those so on Azure the best option for that is definitely a your AI search uh in combination with document intelligence for the raction and open AI embedding models for the vectorization uh so how would you actually build a rag chat app on Azure there are various Solutions ranging from no code to low code to high code my emphasis is always high code but I will show the no code and the low code"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:45:35",
        "seconds": 2735,
        "text": "vectorization uh so how would you actually build a rag chat app on Azure there are various Solutions ranging from no code to low code to high code my emphasis is always high code but I will show the no code and the low code options because hey if they get the job done that's great the no code option is co-pilot studio and you know is is really meant to be you know a user friendly way of setting up your own co-pilot so you can say like oh here's you know make a co-pilot based off of this blog right so I tried making one based off my blog and it'll you know it'll try to do all the ingestion and indexing for you and give you this chat interface now the thing about co- pilot studio is that I actually don't really know how it works behind the scenes right it is uh it's you know kind of a black box uh I do work at Microsoft but I don't I don't actually know how to like find the code Behind these things so I actually don't know how is it doing the ingestion how is it doing the searching I don't even know actually if it's using gp35 or gbd4 um I'm trying to ask around just to find out for my own edification but generally if you're going to use a you know a no code option like this it's you know you're not going to be able to have that much flexibility right you're not going to be able to really um you know extend it if you realize it's not working for your use cases uh so it's always good to start off with these things just to see does it work for your use case especially if you have like a really low stakes use case um but then you know keep in mind that you'll probably reach a wall now the next option is actually a really compelling option because it actually has some code that you can mess with and that's that as your AI open AI Studio on your data so I think I still have this open here yeah so you can actually go to this add your data Tab and add a data source and you can click you know as your AI search if you have an existing index or you can use blob storage Cosmos CB elastic search I think they're even adding pine cone you can specify a web address upload files so they're trying to figure out what are the common data sources that people want to use and make it easy to connect to them uh so it supports you know all sorts of documents because you can use aure I search uh you can upload documents to it so lots of documents uh it kind of supports databases in that you could connect your as your AI search index to a database um but I don't think it's really uh kind of I don't think it's really Geared for databases I think it's a little more Geared for for documents but uh but there is a cosmo actually I mean there is Cosmos D for  VOR so yeah so you could try that out for for that if you've got your data there and uh and yeah and how does it do the searching it's got lots of different search options right so even some non- aier ones like elastic search and you can choose whether you're going to use three you know 3335 or four so this is a pretty cool one because actually once you you can make it and you can deploy it entirely from the studio and if you want to extend it you can actually get the code for it from their repo so I believe that this you know this is the code that powers it so if you do deploy it and you like it you can try to actually change the code if you need to make some tweaks now there is still limitations to this because I'll I'll show the code um what is doing let me find the relevant bit of code Source uh trying to find the chat completion call so a lot of options here chat. completions do create okay send chat request okay I haven't looked through their code in a while um stram okay let's see yeah okay it's kind of hard to find it but um what it does is actually using a particular parameter to the chat completion yeah these are basically the parameters so it's actually telling the chat completion API like hey here's the elastic search index use this index and search it so and behind the scenes that as your chat completion API knows how to do this this is only on aure you can't do this with open AI um you know on open.com you can only do this on Azure right now at least uh so it's doing the search for you so if you if this works for you great if you end up needing more flexibility over like the searching step and like how it's actually combining the search result with the you know with the system prompt and the user message and and all that stuff then this you know this may not work for you so you may reach a wall if if you find you need to uh you need to extend the actual rag flow more because this basically is like rag orchestration as a service so it there's code going on behind the scenes that's figuring out how to get the search results and how to you"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:50:40",
        "seconds": 3040,
        "text": "if you find you need to uh you need to extend the actual rag flow more because this basically is like rag orchestration as a service so it there's code going on behind the scenes that's figuring out how to get the search results and how to you know how to answer a question based off the search results oh I see a question from Robert like what do you map it to from so you can map stuff like if you're doing like elastic search with you know with a your studio on your data you have to tell it what's the title column what's the URL column what's the content column what's the file name column so if you're you know if your data matches you know you know works with the assumptions they're making here like the assumptions here you can see is that you have a title and a URL and a file name and a Content so it's definitely assuming some sort of document-based rag but if if you're you know if that works for your rag use case then the as your opening eye on your data could work really well for you so lots of folks do start off in this ad data um and and deploy that and um and some of them you know stick with that and that works well for them uh and then if it doesn't then you can go to the full very high code uh solution and this is the one that I spend all my time on so I you know I know you know that on your data a little bit but I basically spend like way too much of my time on this on this repo here uh it came out in March of last year and it just became really super popular so you see it's got 5,000 Stars so it's actually the most popular aure sample in our aure samples repo so it's been deployed thousands of times so we've got lots of feedback from it we we're continually you know improving it you can check our releases to see you know the sort of things were changing um and it's all based off of feedback from you know a your developers as your customers so it's been a really great way to learn about how to make a rag chat application and see all the different ways people are trying to use rag chat apps and it is I would say the most flexible of all the options because uh you know it's it's open source and if something isn't working for you generally you can go in there and mess with it uh it is very much a high code situation like the the code is not necessarily simple we try to do that but it's not always going to work uh to make something simple but um you know it's very flexible and and that's can be the advantage of it so it currently it's geared for documents and for the search engine it's only as your AI search so that is certainly you know a limitation if you were trying to use like elastic search right um but generally aure AI search is the best way to search documents uh if you're you know using aure services and that's why uh we use aure AI search for the LM you can switch whatever you want uh so you can you know have these multi-turn chats you know whole conversations we've got user authentication buil in we've got Access Control built in so if you wanted some users to have access to different files than other users that you could do with this uh you can even use gbd4 with vision we have that as an experimental feature that you can turn on if you're interested in trying that out so a lot of the stuff are features that you can kind of turn on if you want to see if they you know if they work for you okay so now I'm going to dive into that solution so in order to deploy this you need an as your account and subscription uh you can use free account but it has an awful lot of limitations so usually better if not using a free account uh you do need access to as your openai or an open.com account you could use either of them you could even use olama if you really wanted I sometimes I do that just to see how the local models do but they don't do very well so I would recommend gbd3 5 or gbd4 uh you do need as your account permissions to be able to create the rback roles uh and to make the deployment so those are you know prerequisites to deploying uh and then to open the project you can use GitHub code spaces you can use VSS code with Dev containers we like to set up everything with a Dev container so that it's all all the requirements are set up for you or you can go ahead and set up a local environment if you enjoy doing that I do not and then you can deploy using the Azure developer CLI I don't know if you all have talked about the addd CLI before but it is by far my favorite way to deploy things to Azure uh basically what we do is we Define the infrastructure using bicep which is infrastructure as code files like terraform so we Define all the infrastructure in bicep that's just in the repo and that you know declares everything that needs to be provisioned and how they relate to each other and environment variables and all that stuff and then we just have to run you know ACD up in order to get everything provisioned and everything deployed uh in you know onto the platform of choice once it gets deployed what you end up with is is a bunch of azure services so for"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "00:55:43",
        "seconds": 3343,
        "text": "and then we just have to run you know ACD up in order to get everything provisioned and everything deployed uh in you know onto the platform of choice once it gets deployed what you end up with is is a bunch of azure services so for like the chat application itself that's on aure app service and it uses a your blob storage in order to render the documents and the citations uh it uses AZ your open AI for the embeddings and the large language model calls and it uses a your AI search for the searching we also do data ingestion in this repo and that one also uses all those Services as well as a your document intelligence so there's two ways that we do data ingestion so this is another opportunity we're going to talk more about data ingestion so if there's any additional questions uh I think from like George um this is a good opportunity to to ask them one question for data ingestion so if it's a document and it's unstructured I mean it's just text in a document so if you want to feed it text from your database I guess why would it need to have specific like vector indexing or anything special like that if you want to just you know all the fields of this one table you know are all the same type of text Data no different than you'd scrape it from like a document um so so you're wondering about scraping from a database yeah as data source yeah if you're using a database as a data source you do not need any of this right so I I probably still have my let me find my um here we go okay so if we were going to do you know um this this is like the code for my postgress hybrid search it's not perfect yet but but here I'm just doing uh you know so I just have like you know you you just need to have a database that has um you know you've got your columns here and then you've got an embedding and you have to decide whether that embedding is going to be the embedding of just like a single You Know Field like just the description or you could concatenate all these together and make it embedding based off that so that's probably what I would do is concatenate uh you know all like the text Fields together the things that kind of have semantic things in them concatenate in one thing generate the embedding based off that store that as an embedding column so you can see here like this is my schema um right so I've got all like my standard columns and then I've got a vector column for the embedding and then when I do the search I need to do the vector search with that column and then the keyword search uh right now I'm only searching one column but probably I should do that across multiple columns right and then I need to you know merge those results uh but yeah if you're working off a database you don't have to have all this fancy data ingestion you just really need to have uh you know ideally have an embedding column you could even just use I mean you can also just do it you could do just a full Tech search I I think you're you would be happier if you also had a vector search sech and a hybrid search on top um but you just need some way of searching your database based off a user query yeah that makes more sense okay thank you yep yeah great question all right so yeah so data ingestion this is really relevant to documents right imagine multi-page documents your HR documents that sort of thing right so we get the documents first thing we do is uh you know upload to blob storage actually that's even the last thing we do um uh so we get them to blob at some point just so we can and that's just so that when we have the actual app where we can um click on let me see so I'm going to click on I'm G to click on a bunch of citations and see which of them loads first because sometimes these PDFs can be a little low to SL to load okay there you see so it loaded the um this you know this PDF PDF here uh this one was this one is a rag based off my personal blog which is fun for me and so here you can see it actually loaded the HTML right uh so we you know we need these things stored somewhere so that we can uh you know show the citation so this is coming from blob storage and it's actually checking our um user authentication when it grabs it oh that one's going to be slow so we put them in Blob storage just so we can render citations um the next thing uh is that you know we have the documents and we need to extract data from them so uh we typically use aard document because it supports a ton of formats these days including docx and PowerPoint which was really huge for people when they added that earlier uh you know I think in the fall so it supports lots of documents even supports images it does OCR so it really tries to get as much text as it can get out of a document we do also have local parsers that we make available just because they can be cheaper or more customizable like for my blog I actually just use the local parser for HTML because I then I can just do some custom parsing for"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:00:47",
        "seconds": 3647,
        "text": "document we do also have local parsers that we make available just because they can be cheaper or more customizable like for my blog I actually just use the local parser for HTML because I then I can just do some custom parsing for HTML uh and uh leave off the parts of my blog I don't want like the comments uh but generally the you know approach is to use as your document intelligence because it's very good at document extraction now we have the text extracted for the whole document but we still need it in chunks because we can't send like a 10-page document to an llm or at least we shouldn't because it's going to get lost right it's going to be too noisy for it so then we split the data into chunks uh so we have all this you know python code that looks for sentence boundaries and also tries to you know split things appropriately so that they're a good um you know a good size to send to an llm uh there's lots of other splitting libraries out there like in Lang chain that you could use as well then once we have the chunks for each of the chunks we compute an embedding of that chunk and then finally we put them in as your AI search uh and I can show you once again the results right so this is actually just straight from a your AI search uh so this is what the index looks like so we can see the content and we can see the embedding we've got like an ID uh we've got scores that come back from the search that's only relevant you know that we don't store that that depends on the query uh we've got what page it came from and we also have access control related information if we're using access control like uh the user ID and user groups so this is a local script uh so this is actually like just in the repo um if you know if I wanted to ingest something right so I'll go ahead and run it just to show you also Jason you can remind me if I'm like going way too long there's lots of good questions I no you're fine okay let's see all right I'm just going to see if I can ingest something just to show you okay I'll go here and let's see what environment I'm in right now okay it's a good one okay let's see if my ingestion script is working at the moment I'm always doing so much hacking on this repo that you never quite know what state it's in but on my machine it's good on Main okay so just running the the script here and it's just setting up well first it has to set up the environment to bring in all the you know the AZ your document intelligence SDK and all the other things we use for for the extraction ingestion any questions as it's running so I have quick question in terms of the cost wise right you know like you were saying earlier when when we use the fine-tuning it's definitely more expensive because there are tokens involved and lot in the same thing would it be more expensive when we use Rack or is there a way we can reduce the cost using any kind of caching in it yeah that's good question um I don't think you could use caching of user questions because I think your user questions would be so um so different i' I'd be impressed users were were actually asking the same thing uh generally like ways to reduce cost well I'll say this what are the expensive things uh you know there's app service but app service actually isn't too expensive it can it can handle a fair bit um without getting too expensive as your AI search does cost uh a bit especially if you're going to have if you need multiple replicas for the amount of traffic you think you're going to get and especially if you use the semantic ranker which is the ranker which is actually you know the best thing to do is to use the ranker but both of those are the things that make it the most expenses if you increase the replicas and you do uh keep the semantic ranker enabled so if you want to decrease aure AI search cost you disable the semantic ranker and you keep it one replica if that works for your traffic levels uh the your other approach with Azure I search is you know to replace it with a you know with a you know a database search engine um you know like the post one I was showing but then you do have to reimplement everything that as your AI search comes built in and they are putting a lot of effort into rag because rag is such a use big use case for them right now uh but you know that's just a decision to make and the other big thing that costs well as your document intelligence does cost money and and uh it can it's a that can be a decent amount if you have a ton of documents so if you're trying to reduce cost there you can use a local parser and see if the quality is good enough it depends on your kind of document um I don't think it's"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:05:49",
        "seconds": 3949,
        "text": "decent amount if you have a ton of documents so if you're trying to reduce cost there you can use a local parser and see if the quality is good enough it depends on your kind of document um I don't think it's that the local ones that great for PDF but if you're doing HTML you could do a pretty good job parsing that H and then finally as your open AI cost money uh you that one you can't really reduce the cost except for just making sure you're not sending too much data right so it it's per token so the less you send the better right so if I do three search results that's generally going to be cheaper for me than doing uh you know five search results got it thank you and then velle asked uh does this service need GPU or CPU no this one doesn't because we're using azer open AI as like an API that we're hitting up uh so that's you know that's serve somewhere that has GPU nothing that we're doing requires a uh GPU we would need a GPO if we were running our own model uh but we're not running our own model for any of this all right so here you can see um that it did decide yeah it skipped a bunch of things because we'd already ined them then it decided to ingest this PDF so first it extracts the text then it splits it into sections then it uploaded the file and then it computed the embeding and then it stored it so that's just what the local script uh looks like now the other option we have is integrated vectorization this is something that's now built into as your AI search which is basically just doing everything we just saw but in the cloud hosted you know with uh you know geared for large you know large scale uses uh and it has a little it supports a little bit more um data sources right because as your AI search can be you can make indexers so it's basically making indexers and skill sets and tying them all together so you can have your indexer based off like blob storage or Cosmos Tob or whatever and as your AI search will you can run like a Cron job and basically like every five minutes it would check to see oh is there something new in Blob storage and then reindex it and only index the the things that have changed so if you use integrative vectorization you can take advantage of the indexer which can work well if you want to be able to like you know have it pulling off of some data source dynamically and only indexing the new stuff in that data source then it'll do the it'll do the data extraction and there I think it's just I think it is using document intelligence behind the scenes it'll do the chunking using a similar splitting algorithm it'll use the vectorization using your open AI deployment and then it'll index it but the big Advantage here is that you know it's doing it all it's doing it all the in the cloud and you can connect it to the indexers so that is an option to consider if you're using as your AI search uh and it's an option you can turn on in the repo that I've been showing okay so how does this code actually work okay so let's do a little code walk through just to see all right I'm actually going to go to the chat tab now because this one's more fun uh does all right so let's see actually let me go ahead and um and point put a breakpoint in let's see all right let's see can I do run okay all right I well I don't know if you're gonna want watch me do breako to can be a little slow all right I'll just I'll just put one breakpoint and then display so this is in vs code with the uh the python debugger uh I like to use the debugger when I can because I am very often debugging things so it'll it'll start up but basically what we have is a uh a front end that's in react so we have like you know this chat you know chat react stuff here and when we you know type in a question it's going to make a request to the chat API right so the SL chat and that goes to our you know python routes right so we look for Flash chat here where is it chat chat oh that went that went to the wrong place okay app.py many app.py okay okay so the frontend makes this request to the chat sends a post with the user message and the history and then sends that to our other Python and sometimes it streams it if we ask it to stream otherwise it'll just send it back all right so we should be running now so it say uh do company perks hover underwater activities it should let's see my chat retrieve yeah it should pop open the um I think it should pop open in the debugger are there libraries so you can do this from a c project yeah uh so if you want"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:11:00",
        "seconds": 4260,
        "text": "activities it should let's see my chat retrieve yeah it should pop open the um I think it should pop open in the debugger are there libraries so you can do this from a c project yeah uh so if you want this C equivalent of this product it is this repo here so uh the other Advocates have been trying to Port the python repo into other languages you know because the python repo is so popular uh the other ones aren't as popular yet but you can make them Popular by going into them I think Jason haven't you been I feel like Jason or maybe Jason's been on the JavaScript one I saw Jason committing to one of them yeah I I committed to the JavaScript I'll put the links and so I've reviewed the different ones on my blog site I'll put the links in the chat for people okay thanks Jason okay wait it's it's being too slow so anyway so I'll just show the the thought process okay so right so you know we go into the python H and now I just wanted to show the chat tab because it's a little it's actually more complex and I think it's interesting the way and it's more complex so this is thought process for the for the chat tab so what we see is the original user query and we actually used an llm in order to turn that search query into a good keyword query and now this might seem a little silly because all we did here is just remove the question mark But in other cases it actually makes really helpful um modifications especially based off of the history that gets passed in so that you so we get the generated query and then we use that to search and then we get back the results so uh let me good an example like so then I'm going to do a followup question like more I'm just GNA more that's all I'm going to say is more let's see how it does with the um search query generation here my hope is that it takes more and turns it into a a longer a longer query okay I think it did let's see okay I'm going to click on thought process okay great so the original user query was more the generated search query was sleep strategy so this is where it's really helpful to use this llm to turn the user query into a keyword search because if we had just passed more into our search engine what would we have gotten right we would have not gotten good results at all uh so we you know we ask it like hey turn this into a search query based off of the you know convers a history so the llm realizes like oh okay a good search query would actually be sleep strategy so it's actually going to just redo the Sleep strategy from before and then it's asking the llm down here it with the llm it's saying it tells it the question where it just says more right so the llm can see like oh you wanted more sleep strategies in addition to the ones before so when you are doing you know what we call like multi-turn conversations you know conversations whatever you want to call them when you have chat history you need to keep in mind that users are going to ask follow-up questions that are not going to be as well formed as their original question and you can use the llm in order to turn their followup question into a much better keyword query for your search index okay all right so I wanted to show that so you know there's the general architecture of the code and uh now our code is using you know python for the back end and it's just using the open AI SDK with the Azure you know document search SDK it's not using any fancy llm orchestration libraries and people always ask like why aren't you using Lang chain why aren't you using this why aren't you using that well part of the reason I'm not using any of those is because everybody has a different favorite library for Python and I'd have to pick one of them and I and then that would like alienate other people right so there are many popular rag orchestration libraries and you could totally use those as well you know whichever one works for you uh so the most popular ones in the open source world are Lang chain and llama index and both of them are available in multiple languages and then from Microsoft we've got Mantic kernel which is probably the most similar to linkchain and which is that's in Python and oh I should have said net that's really what it is is net we we'll fix that python and.net I don't think it's in typescript um I obviously haven't used it very much at all and then there's also Microsoft prompt flow and that's built into a your AI studio so it works really well if you're using as your AI studio and doing other machine learning model stuff so you can totally use these libraries uh you know I tend to not use any libraries because"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:16:02",
        "seconds": 4562,
        "text": "prompt flow and that's built into a your AI studio so it works really well if you're using as your AI studio and doing other machine learning model stuff so you can totally use these libraries uh you know I tend to not use any libraries because I like to work really you know really close to the metal H because things are changing all the time and I want to be able to take advantage of everything uh but these libraries do have a lot of advantages as well because they have like documented you know ways of doing things right so llama index for example it actually has a way of indexing into postgress and doing a hybrid search uh just already built in there so they've already got that that built in so definitely if you're you know looking to do search on documents and you're looking to do it with you know you know various um you know search backends check out llama index they have all these different retrievers all these different document pars there's lots and lots of options we also have more starter repository so we just talked about actually a bunch of them so the you know this python one we're trying to Port it into other languages they're they're never going to be exactly the same and generally the python one tends to have more more features or at least more experimental features because we're just working on it so much because it's so so popular but you know we're you know the get more more eyes and more developers uh interested in these then we can you know the teams can spend more and more time on them which would be great because we would like to have full featured rag applications for all languages so if your favorite thing is C definitely check out the C repo it's actually been around for quite a while um it it came out at a similar time as the python one so it's it's got a good number of features and then there's JavaScript that team is great and there's the Java one so those are definitely options for you and if you're seeing something missing in there in there those repos that you want just file an issue and let them know uh there's also uh the one that I showed earlier which is the code that powers as your AI Studio on your data uh so you can check out the code for that uh another one is chat co-pilot and this is a demonstration of semantic colel but it is actually really really cool it has collaborative chat which I think is just really fun um so just putting there especially for those of you who are doing net which is probably quite a bit I see a question will the demonstrated code still work with a free account even in some limited way what are the limitations yeah so that's all documented on let me see H yeah this AA I'll just place this okay yeah so I did try to figure out how to get it working on free and so you can get it on free and I talk about all the limitations here although I will say there is no form of free open aai you're going to have to pay for that somewhere whether that's on open.com you could even you can actually swap out AMA I I do have support for that in the repo I think I talked about that here yeah you can't locally you could use an opening eye compatible model good question all right okay so it is now 4:30 is this the time I meant to be over Jason sorry looking for the mute button um it is but uh if you can go ahead and go through this and I don't know say 15 minutes sure yeah so I won't do like the demo like demo stuff I'll just talk about this so okay so let's see you make a rag chat application and you want to know is it good right is it high quality right you can't just write unit test I mean you should write unit test for the features but you can't just write a a you know test to say yeah it's good to go you need to evaluate the answer quality right so you want to know are these rag answers correct relative to my knowledge base right uh are they clear and understandable usually uh and are they formatted in the desired manner so if you ask for citations in square brackets with file extensions that is exactly how the citation should come through right so that's the stuff we're looking for in our rag chat app answers right so here I have three different answers that came for the same question my favorite one is the bottom one because it answered the question correctly and it has the citation in the right format and that's what I'm looking for lots and lots of things affect the quality and that's what can make it kind of hard to you know to figure out how to improve uh improve quality right so the first thing is the search right we talked about search is really really important right so what search engine are you using are you cleaning up your query like what are your actual queries come in that they look look like are you using hybrid search um any other search options you're using how big is your data like how large are your chunks uh you know are do they overlap with each other how many search results are you returning these are all things that can affect the results and then finally we you know we pass things into the large language model so there the system prompt can affect things especially like whether"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:21:05",
        "seconds": 4865,
        "text": "you know are do they overlap with each other how many search results are you returning these are all things that can affect the results and then finally we you know we pass things into the large language model so there the system prompt can affect things especially like whether it uses citations or not uh the language of the prompt if you're doing something not in English you should actually write your prompt in that Lang Ang instead if you wanted to Output in that language uh how much conversation history you're passing in which model you're using has a huge effect generally qd4 is much it's like really it's just really good at things so um you know model definitely has effect I use gbd 35 a lot but I've definitely seen places where gbd4 was just nicer better more adherent to the instructions I'll say temperature can affect things all these parameters right so you know what do you do like first thing you do is just do manual experimentation right so in our you know in this repo um we can experiment using developer settings so we can you know override the system prompt here we can change the temperature we can change our search results we can do all these other you know changes to the search results and so we could just do manual experimentation just to get a feel for what changes when we change these settings so that's a good thing just to get some more intuition for how things are working but then what you really want to do is to do an automated evaluation once you think you've found settings that work well right if you if your manual tests are working well and you're like okay I think this is working well then you want to do an automated evaluation on a lot of um question answer periods to figure out is it really working well right across lots of questions and answers so the first thing you're going to need is ground truuth data that ground truth Theta is the ideal answer for a particular question so you generally want at least 200 ground truth question answer pairs uh you can use an llm to generate these question answer pairs but you should definitely curate them manually go through them make sure they're actually legit and um you know and grounded uh I have this script here okay so I have this repo AI rag chat evaluator let me uh P put this in the chat which everyone it'll let me click on there we go so this repo has a bunch of tools that I've made to make it easier to evaluate a rag chat app so one of them is a tool that generates ground truth data and it uses this as your AI uh evaluate SDK so this will generate data based off an Azure AI search index uh you could change it if you have a database instead you could just modify it uh and so you could you know generate that data look through it curate it uh if you've got your rag chat live you could add like thumbs up and thumbs down buttons to you know actual answers to find out which answers aren't working well for people and then you should add those questions with their correct answer to your ground truth data to make sure that you're evaluating according to the kind of questions and answers that users are getting now once you've got that ground truth data the next step is to evaluate right so the way we're actually going to do evaluation is hit up our you know our our current version of the app uh whether that's local or deployed or whatever but hit up the version we want to test with the question from the ground to Theta get the the you know the new answer and then we send you know the the new question you know the the current um answer for that question along with the ground truth answer for that question and we actually send that to gb4 and we ask gp4 to rate it and we say hey gbd4 from one to five how grounded was this answer from 1 to five how coherent was the answer from 1 to five how relevant is this answer and our prompt is a lot longer than that but the general idea is that we use GPT in order to evaluate GPT which is a funny thing to do but it actually does work quite well and there's a lot of research around it uh we can also do other calculate other metrics as well like look at how long it was look at whether it had citations look at whether the citation in the new answer match the citation in the ground truth answer that's actually my favorite metric and that we can just do you know with our python so then after we run those evaluations we can compare them so you can see here's a bunch of comparisons I was doing doing where I was playing around with different prompts uh there's lots of things you can change but in this case I was changing prompts and so I was looking at you know what was the groundedness and coherence and then you know which of them had citations because that's really important to me so I can look across the runs to get an idea for how well things are working and uh it can also compare answers between runs and say like okay well what was the answer like for this run versus this other run to try and get a feel for how things changed and yeah I'm going very fast through this part so as Jason said I do have a um a whole video about evaluating chat app and he linked to it there so thank you Jason okay so that's evaluation I definitely recommend doing it because you want to make sure you're putting out a you know a quality application that isn't making stuff up uh and the the uh you asked about hallucinations earlier I"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:26:05",
        "seconds": 5165,
        "text": "you Jason okay so that's evaluation I definitely recommend doing it because you want to make sure you're putting out a you know a quality application that isn't making stuff up uh and the the uh you asked about hallucinations earlier I have a recent I think my most recent blog post is actually about it yeah so I added a metric specifically well this isn't quite hallucinations this is just making sure the app says it doesn't know if something's just completely off topic for it that it shouldn't know so it's slightly different from huc naations and something it should know but this is also something that's really interesting that I've been digging into lately okay and just a few slides about observability for rag chat apps especially on azzer so the first thing you might want to do is integrate with Az your monitor because that's our standard way of you know uh tracing our apps on azir so you can use instrumentation libraries to send uh the open AI traces to application insights so this is how we do it in Python using this Library here and then when we look in Azure monitor we can you know see the nice little water flow and then click on the chat request and we can see like okay you know here's the parameters here's the actual prompt here's the question so we can actually see all that in as your monitor uh it's not perfect and we're trying to make some improvements to it but it's pretty good another thing you could use is an open source tool called Lane fuse and I really like it it is a um a you know it's a tool specifically for open Ai observability and it's also got evaluations and stuff and it's just a really nice UI uh so you know you have to um you know you can deploy that UI to to aser and I have a repo here where you can do that and then you just uh you know bring in their tracing like this and then you get this really really cool UI that's very focused on open AI uh usage so it's very helpful to see all your calls and see all the tokens they use and see how slow your gbd3 calls are versus your gbd4 and all that stuff and okay this is my final slide so uh yeah so if you're interested in this you can try creating a rag app uh you know and I pointed to the free instructions here so so that you're not spending money doing that and you can read about the limitations air you can try out the evaluation tools as well uh anytime you try these please do raise any issues I do see everything that comes in I can't always respond the the day that I see them but I try to respond to everything so that we can make things better and generally I recommend sharing your learning so like Jason has all these blog posts where he reviewed stuff like so if any of you blog or tweet or whatever please share what you learn about building a rag app because I think still early days for this and we still all have a lot to learn in terms of best practices and that's what I have awesome that was awesome any uh any other questions out there I think you got it all that was great that was uh that was uh really good I I've really gotten into the r stuff so the more that I uh see people present it who really know this stuff is it's just fantastic to be there so I think this was probably the most interactive session we've had in a very long time yeah you all had great great questions I love getting the questions because usually there's something afterwards where I'm like oh I really got to figure out a good answer to that question and then it gives me an excuse to dig into something I don't think they asked too many things you didn't have an answer to I have to try harder next time no I gota like export the chat awesome well I I think that's it Bill's going toh do a Hands-On thing after um so yeah all right well thank you everyone thanks yeah thanks pam pam thank you Pamela that was fantastic so quick question great can we get the recording of this session is it possible to share the recording yeah um it will be on our Boston Azure YouTube channel it's youtube.com Boston Azure isn't that right bill I think it's the full boss word yeah and um it'll probably be up there late tonight or B tomorrow morning sometime okay so so from meet up I should be able to access that right and no well we I believe we do have a link to the YouTube channel in the Meetup description so you should be able to find it yeah okay thank you cool all right okay bye everyone have a good night thank you thank you Bill are you gonna take over can you yeah I just I flipped on um sharing and it's I got to go set"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:31:10",
        "seconds": 5470,
        "text": "right okay bye everyone have a good night thank you thank you Bill are you gonna take over can you yeah I just I flipped on um sharing and it's I got to go set a permissions sorry folks give me a second let's see I have here um so let me share my screen why bills getting his duck R here so this is where we're at okay cool Phil's there Bill's got it cool um yeah so you can get the recording at uh youtube.com Boston Azure that'll have pelis stuff and um I'm going to transition um I can only share my um my web browser without having to configure something my apologies so I have a couple of slides I was going to share I'm going to speak to those um what I'm going to show here is a um we I'm I'm going to ask you to create a simple python app or a simple uh C app um per you know instructions I um I basically think you know how to do that that and I'm going to ask you to basically do that and then I have some code to uh to slam in to make it easier the goal of the workshop this mini Workshop is to see um if you've been doing this for a while the this might not be for you but if you're new to this and you you don't really know what the code looks like um my hope is that at the end of this you'll have the aha moment of wow I can do this in about 10 lines of meaningful code not everything Pamela did but you can actually create a program that can do something using the llm that a programmer just before this whole llm thing came on it was impossible to do no programmer was able to do this in you know before this this is a remarkable um change in just the way uh the way the the tools that we have access to as um as developers so I am sharing let's see I'm sharing in the chat two links um this is um okay so I just shared two links um I was also going to go through and show you how to do this that's going to be a little trickier now because like I'm having trouble sharing Beyond just my web browser uh but here's the the idea if you're a a python developer um go follow the python link you know which is which brings you here and if you're a net developer cop developer follow that one and there are directions at the top of each file basically create a folder and then um do do a couple of steps that are normal things to do if you're a python or. net developer and then replace or create the the file if it's cop you're going to replace program.cs with um with this file tells you to do that here um and if you're a python developer you're just going to create a file called hello ai. py and you know do the stuff mentioned here so these two links are in the teams chat um and after you do these few steps up here there's a there's a challenge that um um that you know once you have it running I'll I'll I'll speak to that so I I hope this only takes you know five minutes for folks or maybe 10 minutes for folks to to get running but if you have questions come off you know go on audio or uh post up in the um in the chat bill you want me to share anything and you can talk to it I had it all set up on my um uh it a command lines I you know I have windows open that um maybe in the metime I can I can see if I can even extend my permissions um I so no it'll be hard to give you something to to share Jason unless you wanted to follow along the lab and do that live okay I mean I can do that too meantime I'm going to go see if I can"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:36:14",
        "seconds": 5774,
        "text": "too meantime I'm going to go see if I can enhance my permissions here [Music] m I share mine until you get yours going Bill see this guy so let me take this here so got empty folder do this gu e all right clob or the content just copy and paste the code all right so here paste this guy save okay done it run okay that worked perfectly oh an interesting fact that fast cool if you um so I'll wait I'll wait till to proceed um I'll I'll talk a little more once everybody has this at least running I can do it so I try to put this code in the collab andun trying to run it think I'm just having some issues like configure environment for python no module name no open some those kind of er maybe I need to do few things before so you did the python one yeah I did the Google cab and did the python Google collab I'm not sure what that is yeah collab is the environment where you can run the python Cod um yeah I've heard of it I've never used it okay so let's try the python one where's the link that python [Music] say mac thing um or Linux you know uh thing my mistake you want to run activate um so it's probably just B activate on window po I can"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:41:27",
        "seconds": 6087,
        "text": "say mac thing um or Linux you know uh thing my mistake you want to run activate um so it's probably just B activate on window po I can do it in code if I don't have any luck let me look that one up that's I'm kind of handicapped when it comes to python so yeah this is the let me start over with this close CD MK oh it's activate do PS1 I think but it's do it well actually you you figured out um or or if you're onto something yeah I'm just going to do this so if I go here yeah I do dude trying to type sometimes challenge over okay so now close this welcome window so we'll take this what do you want this to be hello AI well you um there's more to the file than that unfortunately is there okay it's it's above the comments too so I would just do a control a and take the whole thing in all copy paste all right see what we got here so here we have this deployment okay so that's that so now we basically I think I already have these you might not need to do anything except just run it yeah actually it's true um let me just try to run it I could have done a notebook there a there we go different one um and this a uh yes George contributed a scripts activate command which maybe is the one that you need for po shell I probably should have opened the mic let you guys struggle through that but yeah just oh good I thought it was quick on the chat I was like oh well I know C SHP guys anyway so yeah me too try python I can fumble around and get most things working but slowly getting there okay so anybody um anybody have this working besides Jason either one and you hit the uh you keep score if you want to check the I put put a comment in there you could respond to you could click the check box no obligation but trying to have some way to track how people are doing all you got three of them now what do they look like next to each other python anybody have any struggles they want to vocalize who's got it you know my my struggle with these is always the cost right whenever you do any of these cloud computing especially these services like this I'm always very leery I mean I actually I'm working on a project right now where it's all local so our local CPU and GPU I got a local llama 2 model that I'm using um you know the stuff with an Azure is really awesome but do you have any indication or you know setting up like workflows like this the cost involved I mean I well th this one is um uh actually actually that's a good question I don't have a readymade answer for that uh my perception is this is not expensive um but um but if you add uh like the Azure AI search um you know the the it goes up to minimum of some number $100 a month okay uh you add a vector database you know the same thing this is using um if I could show my da uh Graphics here I made a beauti I had uh uh do 3 make me a nice uh uh visual um but um you know this is using the the tip of the tip of the iceberg and um this this just you're not using the the heavyweight uh tools yet not using"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:46:30",
        "seconds": 6390,
        "text": "but um you know this is using the the tip of the tip of the iceberg and um this this just you're not using the the heavyweight uh tools yet not using um um you know the the responsible AI um uh services to you know make sure your your data is safe the the the safety uh service and so forth yeah you're you're in the the cheap Zone here there are different approaches how you can minimize the cost obviously you can drive it to zero especially as you mentioned when you work with Cloud technologes um but you know you're using llama deployed on um your local machine you can deploy the servers so you you kind of escaping that cloud approach Al together so making it a little cheaper and then caching so you can cach the responses so you are not calling the service all the time if you are using something like Azure open AI um or maybe store most popular answers somewhere in um like a a database or something like that that's interesting I never thought about caching the responses that come back yeah so that's that's one uh that it depends what you're building right um so that that's one of the approaches how you can minimize the cost um and then you know something like rag you don't have in in some cases you don't have to call um Azure open AR or something like that at all so if you're um doing the search and then you're getting decent response from the search then you can escape that second and stop of calling them um llm or ji service alog together that's interesting I never thought you got me thinking about maybe cashing the common responses okay thank you no problem so I'm going to grab so does anybody have any struggles any struggles out there who's still here is is doing good so I'm going to grab the screen back and walk through a couple things here so um do you saw the output so I I assume I assume you can see your output and it basically shows um a prompt that appears I'm I'm let me zoom in on this code here that the code is essentially the same between Python and uh C so um this is the prompt that you're that is being sent to the um under the hood the open AI uh llm large language model and and this is the part that's you know magic it's producing a response that is uh unique text uh that you know a response that the kind of a response that was impossible before this um LM Revolution uh started year and a half ago that's like just amazing and if and um one of the things that I claim is if you look at the response there's something wrong wrong about it and I didn't want to spoil it give folks a chance to look at the response but when you look at the the response um um there's there's a lack of um grounding or or the opposite the other side of the grounding coin is uh hallucination of sorts happening in the response so um I'm suggesting that um a hint to help you U solve for that don't want to take a huge amount of time here but that that's that's the point and um this response setting the number of tokens we can talk about these um April 20th setting a prompt um scrolling up here creating this Azure open AI uh you know object and the rest of this is kind of boiler plate stuff um this is like 10 lines of code that that you're now able to do something that no software engineer could do for the first 75 years of the computer industry let's go back here how we doing um it ah so yay somebody declared a"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:51:33",
        "seconds": 6693,
        "text": "the first 75 years of the computer industry let's go back here how we doing um it ah so yay somebody declared a date buug and they fixed it good two people a couple people fix a date buug so um the the date buug if you haven't figured it out by now is actually Jason would you mind sharing again and showing um showing your uh your output sure just SEC let's see share this one the C output was here do you want to see the code or the output the output okay so H this was the python code either one is the output is down here and then up here is the um other one up at the top thank you so if folks look at that you're seeing similar stuff you know what today's date is because it's output as a debug message um and the prompt asks for something from some world history event from today's date and and it gives you one except with great confidence uh on March 18th 18 uh 1965 uh Soviets walked in space um but uh that great confidence is uh untethered from reality because that didn't happen on this day in history it happened on a different day and that's uh that's your llm hallucinating returning a confident result when it has no business doing that and the way to ground it is to do um basically rag this is this is exactly what Pamela was talking about except that with the rag um here it's a much simpler rag where the augmentation is simply the date so you don't have to make a network call to get the the uh the current current date you can just make you know call a a python library or a cop library to uh to get that then weave it into the prompt uh I'll leave that to your imagination how to do that you know on this day in history you know assuming this day is you know X or something like that would do fine which is date whatever you know choose your style and see if you get uh consistent results and if you do then that's that's the win and um and and that was the the goal is to uh to give you the the hands-on experience hopefully a couple of a house quiet group thank you Tony see I go here and if you've accomplished the the goal here and you want to try something different you can instead of just uh prompt engineering or or ragging to to get the date inserted in the in the prompt itself so that the respones um more accurate better grounded uh you can also say something like uh and return the results in French or translate the results to German uh you know append that to your prompt and see if that works I I tested it earlier with mandarin and it was"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "01:56:38",
        "seconds": 6998,
        "text": "German uh you know append that to your prompt and see if that works I I tested it earlier with mandarin and it was happy to do that and it also worked with pig latin um Mandarin didn't display on my my son was doing some testing on me um uh and um he realized that Mandarin didn't display well in some contexts on his windows box mine is I I'm using a Mac didn't have any trouble for me so your mileage if it's a different alphabet uh your mileage May VAR my response looks gibberish how many uh oh you didn't um no you got 250 tokens used all the tokens it ran out tokens I changed the temperature to two I thought the temperature only went up to one I goes two those people between one Veronica help what's going on yeah temperature can be more than one that one's a little better Al the the one above used all 250 tokens this one only used 50 so it hit some cognitive limit there when it ran out of tokens maybe I thought temperature was a was like a zero to one real number I guess you can scale it if way I know I've seen it from negatives to positives and stuff too but one concept going into junk at 1.7 how about 1.6 1.5 was good it's the top P that's you would want that's also gibberish starts off good it's getting tired it's passes bedtime so um SAR how to fix the date so the the the challenge is that um oops somebody um weighed in Tony so um Yep this this looks like a python solution I don't know which one you're using sadar yes I'm using B okay so T Tony's solution how to do it basically you just want to uh Wordsmith the prompt to also in normal English uh declare what today's date is and that becomes part of the information that the llm uses and again that's a very simple form of rag I see I see Conor so the initial one you're not actually passing what today is on purpose that's the bug that's the the challenge the the my My Hope was people would notice the you know discover for themselves that there's a hallucination there that you ask for today to something today and it gives you something you know in September and then something in June and you know and so forth because it has no concept of the day that's a hallucination then you ground it using rag you know rag light I guess simple Rag by just inserting the date like that let's up with that Jason you you were playing with the uh the temperature can you explain to the to the room what what that um what that means yeah so the temperature is what you see most demos change was it I just passed it fine temperature okay so I guess this is the top pie"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "02:01:42",
        "seconds": 7302,
        "text": "you see most demos change was it I just passed it fine temperature okay so I guess this is the top pie H interesting um the temp here so this is a temperature it's a float it's between zero and two but it typically uh is explained as in it is a spectrum of creativity that you want in the response so a lot of rag Solutions are geared to zero because that you don't want creativity but if you're say doing um writing of some sort say fiction writing you would want to get gaug it closer to two the defaults one right middle of the road a lot of the rag systems will be zero or up to maybe3 but not much more than that that I've seen anyways not saying they all are so this is the one I want nuc nucleus sampling factor is a different one and yeah so here if it's set then temperature is kind of um ignored it's going to be one of the other but this one is geared more toward the sampling here and it's between 0 and one sorry what was the question where's it at on the bottom down here yeah so for co-pilot or chat the creative balanced precise is that basically the temperature yeah sense and then the co-pilot in like word and Outlook have the same idea don't they I don't have those running so I've only seen demos yeah I don't have those either but they should they they're all based on um the same approach um if Pam was sh in both top PE and then the temperature um most people just use temperature um but if you want it extra creative you can adjust both top p and um the temperature cool yeah you kind of just have to play with it see what works for [Music] you I'll mention that in the code um there's a comment up the the top uh that says um do not do this in real code it's a terrible idea uh because I in order to simplify this mini Workshop rather than externalizing the the the variables like the API key value um I burned them in so I'm going to roll those I'm going to roll that key at some point after after we hang up so your your onepage uh AI machine will will uh cease to work at that point good idea actually prepared um a a a bash version a Powershell version a command version and I struggled with it and I ended up I still have them but I ended up uh doing this just to just to simplify and uh I I don't know how much it simplified it but probably at least a little well does anybody um um than thank you"
    },
    {
        "speaker": "",
        "title": "Pamela Fox: Building a RAG app to chat with your data",
        "videoId": "3Zh9MEuyTQo",
        "description": "This is a recording of the March 28, 2024 meeting.One of the most popular use cases for generative AI is RAG (Retrieval-Augmented-Generation), a technique that feeds context to an LLM (large language model) so that it can answer questions according to sources. Thousands of developers have deployed RAG applications to chat with their data, both for internal enterprise data (like HR or support) and external public data (like government or retail). In this talk, I'll show how to build a RAG with Azure technology, like Azure AI search and Azure OpenAI, and share best practices for data ingestion, orchestration, and evaluation.Pamela FoxPamela Fox is a Cloud Advocate in Python at Microsoft. Previously, she was a lecturer for UC Berkeley and the creator of the computer programming curriculum for Khan Academy. She has founded GDI chapters globally and develops curriculum for GDI.Slides: https://speakerdeck.com/pamelafox/building-a-rag-app-to-chat-with-your-data-on-azure",
        "start": "02:06:47",
        "seconds": 7607,
        "text": "up uh doing this just to just to simplify and uh I I don't know how much it simplified it but probably at least a little well does anybody um um than thank you all for for attending I hope this was uh useful for those of you newer to the to the uh Azure AI world uh does anybody have any uh closing questions yeah this is great thank you and H how many tokens does the open asure support like um I know normally they would charge right but in this case um is it is it free for to use a or how how long we can use this if I keep running it well I'm going to roll the credentials after this uh call ends so we'll stop working I I I see you know five minutes uh it actually isn't free uh but it's not terribly expensive this is tied to my personal credit card okay but it's it's not like it's not a lot of money to do what we did that's if you look in the comments you'll see I put a comment to not raise the max tokens above 250 so you could go you know everybody could go crazy and try to do a lot of stuff um but you know this felt like a this is experimental for for myself and uh roner and Jason and because we have to also figure out how to do what we going to whatever we're going to do on the Azure um day you know the full day event on April 20th how do we light up this for everybody because it's not an easily available service so um I'll check the the numbers later and see if this cost me more than a dollar I I don't expect it it will though I'd expect it to be pennies if anything so I hope that's that's the best answer I have at the moment oh thank you I really appreciate that I I did run it some sometimes so didn't realize that's the case sorry about that sorry I I think the volumes were at um and it's kind of in 10 people left or something Veronica or Jason do either of you have any ideas how to like what this exercise that we did for this um mini Workshop um given parameters that we were using and the the volume that we were pumping into that would you expect that to not even be a penny or any idea it should be really cheap I'd say less than a quarter um more than a penny though all right yeah uh what is actually hold on I can bring up the pricing open AI pricing it's um it's like it's kind of like reminds me of storage was like per thousand type stuff uh so is it gp4 or 35 it's a 35 turbo5 tur of course this isn't the pricing page uh let's see this is the this doesn't tell me the model pricing uh that's for open a I um think Azure is charging something on top of it are they so Azure open AI model pricing now this one  this thing can't see because of the bar at the top this guy okay so per thousand token so for heading to 50 well see these input output but it does add up but not a lot I mean th tokens if you cap it at 250 and you hit the cap every time four of those you're at this much so time up by you'd have to have like a 100 before you'd hit five I I'll check the uh I I actually have the cost analysis window popped up on the Azure side and I'll say I don't know how much latency there is before it catches up it takes a while yeah I use that in my demo the um but I mean this is a a good thing to point out I mean look how much price difference there is between GPT T4 with 32k and turbo I mean it's huge this is a scent one penny for 100 or a th tokens out and then so you could easily yeah right but I was watching a video actually a couple videos from the guys over Lang chain and they've been doing testing on the context window basically finding I think they call it needle and hay stack so they put like I forget how many needles they were doing needles so they put it something in the context window that they're passing they put were putting like one to seven they did multiple tests to see how often it would find those four things and it other test showed that the larger the window was the more often it paid attention to the end of the context it would sometimes lose things at the beginning of the context so yeah it's all interesting stuff anyways so you did mention that you are going to have some kind of a workshop in the future like is is it to uh open to everyone sure I can answer that sure yeah it's open to everyone so we're this is a um an event that Veronica and Jason and myself have put on a bunch of times over the years where we've been doing it for more than 10 years where we have an all day uh free usually vendor sponsored so we can do food and and such um at nerd in Cambridge Massachusetts uh where uh you show up with a laptop or you know we we'll we'll uh we'll publish a page that describes all this but show up at usually it's around 8:30 or 9 or something and at the at the site and you bring your laptop like I mentioned and we code we do stuff there's a usually a an interwoven set of talks like like the Pamela talk that you just heard um as a you know one example there might be a talk like that and then there'd be um a hands-on experience after that to take advantage of the information there and then you know uh you repeat that three four five six times during the day you know new topic new lab new topic new live that kind of thing and at the end of the day um you uh you leave presumably Having learned a bunch more about Azure you know this is the Boston Azure group but we're um um we're we're expecting to have a heavy AI emphasis on um on this particular workshop on April 20th well that's great I would love to I'm in New Jersey but I would love to come there and join it love to have you great we so watch the Meetup space there'll be a sign up um soon um we like uh we we only found out about this uh quite this is quite recently this late breaking news so we have a couple of details to square away now that we know we have space but we'll we'll get a sign up form out there and um if you should you know assuming you get Meetup notifications that should um should let you know great thank you so much yeah welcome have you been to any in-person uh Boston Azure or North Boston Azure events no no I I haven't come to any Boston a events but I did go to some in New York New York City ah very cool oh welcome thank you any other um questions out there folks we let everybody go sounds good have a good night okay thanks for staying late all uh I'm tired you are too good night everybody Forest gum what's he say I'm tired I'm gonna go home now that's how I feel that's what I'm gonna two and a half hours this is great thank you guys thank you very much take care thanks everybody thank you okay "
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide. This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade. back then but you don't need help with azure now you're you're you've been helping people uh learn their azure skills and uh become you know pretty deep azure expert so it's really um it's really great to be able to tap you from all the way in uh texas for a uh for an event uh so the the the other side of the covet coin is uh this is nice to be able to have the uh uh speakers come from anywhere so uh without further ado um join me in welcoming uh duck over to you sir thank you sir appreciate it um you know i i will tell you that by far some of the most fond memories i have is taking the train or the bus um down to boston for the day to go and hang out with the tech community down there go to a meet-up do something at nerd those were my salad days and i wouldn't trade it for a thing and it's a large part of the success that i've been able to have so i'm in no small part i thank the community for helping me get to where i am so as bill had indicated my name is doug van der weid i'm a director of infant information technology at avanade avenatti is a joint venture of microsoft and accenture we are about 50 000 people worldwide they're trying to hire another 20 000 people in the next two years um we are always hiring microsoft talent so if you're kind of bored in your role today if you know anything about the microsoft stack if you have knowledge around dynamics or sharepoint or anything like that and you think you'd like to learn more about avanade feel free to reach out to me i have been working in azure for about 10 years as bill noted um i got started at my old newspaper group um we got 50 000 worth of azure credits as part of a store simple deal and uh ever since that moment i became an azure developer um my actual steel set goes back quite a time i came up through the ranks as a.net and sql server open source developer um for quite some time as bill indicated i'm originally from maine i've been texas for the last five years and i have a bunch of uh certifications as well so just so you know um you're fine i have a general understanding of which end of azure pounds of the nail as we go through this uh pro uh the thing that i really want to talk about today is uh is setting up some of why we're why we're going to have this conversation on azure policy and uh using uh automation to enforce a tagging strategy and i think the first thing uh that you need to understand in order to get to why this is important is that uh is the concept of governance right and governance is ultimately the ability to be able to identify measure and control all the assets you have deployed so what is the you know it's things like uh what is this thing where is it in the world what does it do who owns it who controls it what relies upon this thing what does it cost is it operating efficiently so on and so forth all of the things that go into making sure that i'm not being wasteful either in terms of science in terms of um cost or being wasteful in terms of effort also things along the lines of who's going to pay for all of this how are we going to uh and how are we going to make sure that we're doing this as well as we can that's governance in a nutshell and it's especially true that in large organizations governance is a is a significant challenge for them um usually speaking a large it organization and by this i mean like a fortune 500 fortune 100 company um they tend to be in multiple clouds so if they're going to be in azure they're probably going to be in aws um they probably have colos someplace so they have data centers somewhere out there they're running private clouds um they may be using vmware uh they may have rack space presence so on and so forth and when they are in azure they tend to be using multiple subscriptions they have very complex subscription hierarchies sometimes they have subscriptions that are specific for dev tests uh sometimes they have subscriptions that are broken out for regional concerns or by business unit sometimes they have they use the hub and spoke model where certain shared services and certain central networking assets are in subscriptions and everything branches off from there oh and i should mention this as well folks um if you have any questions feel free to interrupt me at any point or go ahead and electronically raise your hand i'll try to keep an eye on that and answer any questions you might have the another thing that tends to be true of most large it organizations most organizations that are broad in terms of their total operational footprint you know multiple divisions across the world that sort of thing they all tend to use what's called a chargeback model and what that means is the operational cost of their ikea states the actual cost of delivering the it services that they're using in azure and other places gets built back to a specific to a specific business unit so that business unit has an i.t budget and you they need some means to"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:05:04",
        "seconds": 304,
        "text": "states the actual cost of delivering the it services that they're using in azure and other places gets built back to a specific to a specific business unit so that business unit has an i.t budget and you they need some means to track what the spend against that it budget is that they can charge the business unit and make sure that business unit is isn't exceeding the capacity they've been allotted also in in most large it operations you tend to see that that the model that they use for operating is an i.t servicing model so the it department doesn't actually own anything in the ita state they don't own the computers they don't own the data center they don't own the cloud presence they're not ultimately even really responsible for any of that stuff the decision of what gets created and what gets bought and where it goes and all those other things they might be an advisor but they're not a decider the business units decide what kind of it they're going to have what kind of programs they're going to run how those programs are going to be hosted where they're going to be hosted um so the itu unit is really just a servicing organization they keep the lights on they're they're basically digital janitors as it were right they're there to maintain the inventory to keep things running to enforce you know some guard rails um to you know impose discipline on the operations but ultimately what gets done in the i t world doesn't really belong to the iep department in most large organizations it belongs to the specific business units and then finally and this is where this question of azure policy and tagging comes in most large organizations have a lot of different tools for a lot of different solutions right so uh so seems security incident and event management itsm uh it service management itil um information technology information cmdb configuration management ipam ip management they have all these different tools that do different things for them in terms of you know being able to control their uh being able to control their environments as well as monitor them it is the very rare large organization for example that uses azure monitor as its soul meets as its sole pane of glass to look at azure um generally speaking they want to have a unified pane of glass they're using something like grafana or they're using something like um you know something like that to have a much broader implementation of their monitoring solutions and their learning solutions um they will have very complex implementations of servicenow for example and everything so everything that they need to know has to basically come into everything that they're doing in the it world regardless of where it is if it's an aws if it's an azure if it's on in vmware it's some co-location facility or data or data center they own all that information generally speaking needs to report to the same places so they have the ability to see everything in one place in terms of their operations and i'm sorry i've lost focus on my uh advancer let me get that back all right so that's why tagging comes in so tagging for those who aren't familiar with tagging in azure it's basically key value pairs that can be assigned to most assets there are a few assets in azure that you can't tag but for the most part pretty much anything you're going to encounter that racks a charge is going to be something you can tag and a tag is basically a means of storing metadata about a resource that's useful for understanding its context the real value in tagging at the end of the day especially for large organizations is that using azure native tools using tools you can build yourself bespoke tools or using third-party tool sets such as servicenow and the like you can usually retrieve the tags on an asset when you're trying to call for that resource so i can set up an integration for example in servicenow that or some other catalog service that basically says when i pull the information about this particular virtual machine for example tell me the tags are on that virtual machine and when when i do that i'm doing it probably through the rest api that azure has and i'm getting that information back and i'm able to store it and therefore i can use those tags to help catalog that item for various business concerns i might have the real value of tags at the end of the day is that they exist outside of and therefore they extend the subscription and resource group hierarchy right also management groups and for those who are familiar very large organizations when they buy azure they don't buy pay-as-you-go subscriptions they tend to have enterprise agreements with microsoft and what an enterprise agreement is is it's a way for that large organization to pay for all their microsoft stuff in one place so all their office 365 all of their dynamics um all of their sql server licenses all of their windows desktop licenses and all their azure stuff tends to be part of what's called an enterprise agreement which is all all rolled up price that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:10:09",
        "seconds": 609,
        "text": "their office 365 all of their dynamics um all of their sql server licenses all of their windows desktop licenses and all their azure stuff tends to be part of what's called an enterprise agreement which is all all rolled up price that microsoft gives that customer as part of that process there's additional reporting planes called departments and accounts that they can use as well but again the beauty of a tag is it exists outside all of these hierarchical solutions so um from you know it's it's basically enterprise agreement department account then subscription then resource group tags can be on tags would live outside that ecosystem and therefore they extend um the ability to track assets because i don't have to worry about where they are in that logical hierarchy so we know what governance is now it's the ability to keep control over your stuff especially to understand what it is where why it's there what it's supposed to be doing for you who owns it etc etc we've established that it is difficult to keep a wrassle on that especially if you are a large organization there's stuff everywhere in multiple different types of places and they need all that information to report to external systems so our ability to govern those assets especially for large organizations this can be a challenge and there's some ways that most people tend to solve that problem at least in the shortlist at least as a smaller organization right so we can have a naming standard and depending upon how we name things that name can tell us where that asset is in the world what its purpose is uh what kind of thing it is if it's a virtual machine if it's a network that sort of thing we can use subscriptions as well to group our assets by purpose or business unit right so theoretically we can have a subscription for example that maybe our subscription strategy is every application we have goes to a particular subscription maybe we have a strategy that's a hub spoke again we have a central subscription for all shared services and then every other department gets its own subscription or every other geographical area gets its own subscriptions all the stuff in east u.s is in one subscription and all the stuff in west u.s is in another and typically we see resource groups used to manage assets that are on the same life cycle so any solution any workload any application that i have that's running in azure it's very typical that all the things that are necessary to provide that application the databases the virtual machines the networks the firewalls so on and so forth all tend to live in one or two resource groups that are related to that particular solution and finally again we can use regions regional separations to help uh structure business units but but the challenge with that approach especially as you get larger especially as you become a bigger organization is it doesn't scale well right um the challenge you you if you're gonna have it you know there's a lot of enterprises out there that have hundreds if not thousands of applications you can't have hundreds or thousands of subscriptions it just becomes unmanageable um there are tons of organizations out there that are deploying all the time they can't have every single asset um that's related to a particularly large organizat operation for example like perhaps their inner source re their enterprise re planning uh solution uh you know something that they're using to basically allocate staff and in materials that's probably too broad too large a thing for them to put in a single resource group they need multiple resource groups because there's too many moving parts they can't define it as a single deployment same thing is true of regional approaches some organizations um they have multiple regions for one particular business unit one business unit may very well span the globe so again what tangy does because it's outside of these restrictions it's outside of these hierarchies tagging allows us to identify the what assets are doing without being restricted to any of these logical hierarchies that that exist such as regions resource groups subscriptions and even naming of assets or naming conventions so what are the kinds of tags we tend to see large organizations specifically but organizations in general what kind of tags do they tend to put on assets um there's actually some guidance on the doc site for azure um under their um under their uh framework um part which i'll try to get links to um for you in the in the meetup that talks about typical tags that are advised for most organizations but typically what you'll see in a large organization is specifically a cost center tag most again especially any organization that has a chargeback model that says hey business unit you're financially responsible for everything we deploy on your behalf and azure you need to pay for that thing it has to come off your budget um by far the most easy way to keep track of that is to simply assign a cost center a tag to an asset so that they you know who's racking that charge same thing is true for most organizations to have an owner the owners again especially depending upon how broad an application is"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:15:12",
        "seconds": 912,
        "text": "of that is to simply assign a cost center a tag to an asset so that they you know who's racking that charge same thing is true for most organizations to have an owner the owners again especially depending upon how broad an application is it's not unusual for a single application to have multiple people who own parts of that application there may be a db team that owns the underlying database uh databases for example in the webs in the website there may be another team that owns the firewall there may be another team in the networking concerns there may be another team that is responsible for actually providing the web servers there may be another team that's actually responsible for the devops part of pushing the code there there may be multiple teams with multiple moving parts that all are part of a single application and therefore having an owner tag on individual assets helps keep straight which team owns this part of this solution you'll see versions you'll see um termination dates especially for assets that are put out there some organizations will intentionally tag assets for a particular termination date and automate the process of destroying them most are going to apply a business criticality tag they want to make sure that they can audit any mission critical system is being backed up or is being uh supported in a way that the business can continue to run if there's an incident almost all of them also use a data classification tag almost all of them say hey we want to make absolutely certain that we are able to identify this information systems that are holding confidential information or personally identifiable information so that um in the event of a data breach we can quickly identify places that we need to lock down the summary of this is the next large organization that was 100 tagging coverage on all of its assets will be the first i've talked with dozens of businesses extremely large organizations every single year none of them have this right okay and that's not a bad thing the reason why none of them have it right in short is because there's no efficient means of enforcing both the presence and the quality of a tag in azure for example one of the challenges in azure is that tags are case sensitive so if i spell owner with a capital o in one place an owner with a lowercase o in another place those are two different keys in the azure tagging world and so therefore it may look to me like i've got better coverage than i do but in truth when i query i need to make sure that my case sensitivity and my spacing sensitivity are addressed in the name in the key of that tag so i can actually pull all the information i'm expecting and then again additionally the challenge is for most of the things without some means of insisting that the tag be there a tag is not required to deploy an asset manager an asset can be deployed without tags and what tends to happen is even with the best of intents organizations even highly automated organizations don't have a means of saying oops you forgot the tag that's where azure policy comes in so what is azure policy azure policy is basically a way to allow you to enforce and audit deployment compliance for azure assets so is this thing that i'm putting in azure correctly configured according to my business rules and my technical requirements that's what azure policy does it is is it audits or views the deployment as it happens and it ensures that the asset as it's being deployed complies with those requirements that you set out a manager policy can be applied in multiple scopes so it can be applied to a management group for those who aren't familiar management groups are basically a way to associate both identity or role-based access control and policies to multiple subscriptions at once it's also possible to apply a policy directly to a subscription that's what we'll be doing today in our demo it's also possible to apply a policy at the resource group level we can further uh group our policies together to a common outcome such as an initiative and i'll talk a little bit about more about that in just a minute then finally there's multiple means of enforcement available to you in an azure policy one thing you can do is just outright reject the deployment hey user you forgot to add this tag or you gave me a tag value that's incorrect i'm going to reject the deployment outright go back and try again another thing i can do is i can say well you sent me this deployment it does not have a cost center tag on it so i'm going to automatically assign a generic cost center tag to it so at least i have something may not be right but at least i'll have something that looks correct and then finally you think you can do is you can audit that deployment so you can have the policy say i just deployed this person just deployed this virtual machine i went ahead and created it they did forget to give me a cost center tag now what i'm going to do is tell mom i'm going to send off a message to a queue i'm going to raise the fact to raise an alarm that basically says hey when this guy deployed this asset he forgot to add that tag so what are some typical azure policies that you see out there"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:20:15",
        "seconds": 1215,
        "text": "going to send off a message to a queue i'm going to raise the fact to raise an alarm that basically says hey when this guy deployed this asset he forgot to add that tag so what are some typical azure policies that you see out there very common for most organizations is that there's a regional restriction right we're not going to allow you to deploy this virtual machine to south africa because we don't do business in south africa also very common is policies that say don't deploy expensive skus right so you cannot go out and deploy that giant n c or m series vm uh with 64 cores because it costs a thousand dollars a minute a thousand dollars an hour to run we're just not going to let you make those things you can for example enforce encryption at rest so maybe you have some sql databases you don't you you want to deploy those databases um you want to make sure that everything that you have is all that data is encrypted at rest by default um you could certainly create a policy that says anytime you create a new sql server pass service make sure that encryption at rest is turned on and then the other thing you can as well do as well is for all your public endpoints uh force enforce https so no hdb traffic to that public endpoint it has to come over via https um more advanced stuff is uh ensuring that your virtual machines are set for backups either that the a backup agent is present on the vm or it's actually using the azure backup solution requiring network security groups anytime a new subnet is created so you can't just come out and boldly create a new subnet if you create a new subnet it has to have a network security group associated with it same thing is true for um again providing certain default settings so maybe uh not necessarily a tag default value but maybe for example one of the things you want to do is say anytime that a new network security group is created it needs to have a specific role a specific rule in place that rule needs to block any traffic on 33.89 um and you want to insist on that rule being present in the nsg you can go ahead and create a policy that basically says and if you don't see a rule for 33.89 that's a deny rule you will automatically add that deny rule for 33.89 and then again uh as we talked about here you can check for certain tags as we look at today's demo one of the things we'll be able to see and i'll be able to show you is there's a long list of built-in best practice policies that are already present in every azure subscription most of them are in audit which is why you tend not to run up against them and see them as a bad thing but i can show you what some of those policies are and how you can turn them into enforcement policies to prevent uh some potentially dangerous practices okay that's a lot of stuff i'm going to take a quick pause anybody have any questions before we start talking about the nuts and bolts of what we're going to be looking at today for actual hands-on keyboard stuff all right okay so what are the parts of azure of an azure policy well the first thing you have to have is definition that is what is the condition that needs to be met and what do you want to do to ensure that that condition is met every single time you deploy an asset the next thing you need to do is provide the definition in some cases you need to provide values that describe what's allowed so for example you may very well have and what we'll be looking at today in our demo is we're going to be applying a cost center tag to our assets when they get deployed and we're going to restrict the possible values of that tag to only certain values so that's a definition object the values that are allowed is one of the definition objects that you would supply the next thing is an assignment so you have a policy that is going to require a particular state we have the allowed values for that particular state now we need to assign that we need to assign that policy and give at a specific scope so we need to take the policy definition that we defined that then needs to be assigned to either a management group a subscription or a resource group that's called the assignment there are also initiatives as we described before initiatives are grouping of policy definitions for assignment purposes so for example i may have multiple policies that define the kinds of tags that i need to have on an asset i need to have four or five different required tags every single asset needs to have them i would probably define that in four or five different policies and then i would group those together in an initiative that would be my tagging policy initiative there is the ability to make exclusions so another thing i can do is define i want this policy to apply except in these particular cases and basically you can create an exclusion there for that excludes specific assets from policy definition when it's after it's been assigned finally there's a remediation so i've been speaking about policies as um runtime solutions right that every single time i'm going to make a deployment i can use a policy to ensure that that deployment is compliant with my rules and requirements as defined in my policies but i can also create what's called a remediation and what a"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "runtime solutions right that every single time i'm going to make a deployment i can use a policy to ensure that that deployment is compliant with my rules and requirements as defined in my policies but i can also create what's called a remediation and what a remediation does is it says it is possible that somehow it's certainly possible that prior to implementing the policy you have some assets that are not compliant they do not comply with the policy that you've just defined you may have a bunch of stuff in azure already for example that doesn't have a cost center tag a remediation plan allows you to basically say for those assets that are already existing i want you to go and apply this solution this fix to all of the things that don't comply with this new policy it's also theoretically possible although it shouldn't happen it does occasionally happen that through one way or another you're you see some configuration drift on your assets that azure policy doesn't catch because it's not technically a redeployment especially true with virtual machines sometimes you add things to virtual machines or make changes to them internally that have a fundamental effect on their overall configuration that tends to make them drift you can use a remediation plan also to spot this kind of weird drift that doesn't completely fall into the definition of a redeployment all right so what i'm going to do is show you now how to deploy an azure policy from a powershell um i also mean in a template um i wanted to do this with azure devops but my azure devops uh instance ate my homework um so we're gonna be doing this uh the old-fashioned way um with powershell and arm templates i also do recognize that microsoft would like people to start using bicep um i actually kind of like bicep it's very yummly if you work a lot in azure devops you will like the fact that bicep is pretty ambi um the challenge i have is that i haven't worked with it enough to do this quickly and i didn't give myself enough time to do the demo so arm templates and powershell it is what we're looking at on screen right now is basically an arm template and this arm template is going to define the policy so this is a policy definition arm template and as you can see i've got the schema set for this subscription deployment template scope so i'm going to be putting this right at um right at the subscription level normally i would do this at a management group level and i don't want to get overly nuanced about why i like management groups over subscriptions but if we have time we can have that conversation normally i put this in a management group for this demo i'm going to be doing it at the subscription level um as you can see the cleverly just named uh microsoft authorization policy definitions is the scope is the type of thing we're going to be deploying i'm going to give it the name of required tag billing identifier normally i would not put this in a template i would pass it in as a parameter um again for this demo i'm just going to go ahead and give it a hard-coded name the api version tells um the api which version of this definition to use was it creates a thing these are just basically a friendly name for required billing identifier tag you'll see that just a moment i have to specify if this is a custom policy because it is a policy that i wrote um this description is very helpful you can see it in the portal i'll show that to you in a bit the other thing is that um it's also going to have a category so cat you can categorize um your individual policies with um this thing in this case um i actually stole this from another project i was working on for a customer that had a bunch of stuff they wanted to make they wanted to put policies on one of the things they wanted was required tags having this category piece is something you can filter on in the portal it's really helpful for seeing what's in effect and what isn't in effect this mode index basically means um i forget i forget the exact definition but basically in the index mode is telling um the deployment listen what you're going to do is go and iterate all of the items that this can be applied to and you're going to make sure that it applies to them that's an oversimplification of what it does but good enough for now finally i'm passing into as parameters um this bill id value it's going to be an array and basically what it's saying is when i get a bill id when you provide the billing code id for this uh tag it's going to be have to be one of these three values you can't provide me anything else so here's where we actually create the rule it's a simple if statement and what it basically says if any of these conditions are true then i'm going to deny the deployment okay so if any of these things are true then i'm going to deny the deployment outright in this case i'm saying there has to be a tag with the key of billing identifier if that's not present i'm going to reject the deployment the other thing i'm going to reject the deployment for is if the tag name billing identifier doesn't have a value that's in this list okay any questions about this template before we move on and actually try to use it okey-dokey all right so i'm gonna go ahead and fire up powershell um normally i would do this in the cloud shell"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:30:21",
        "seconds": 1821,
        "text": "identifier doesn't have a value that's in this list okay any questions about this template before we move on and actually try to use it okey-dokey all right so i'm gonna go ahead and fire up powershell um normally i would do this in the cloud shell but for some reason i can't copy paste in the cloud shell today um or at the very least it's decided it's not gonna be nice to me about it uh so we will be using good old console powershell and i will big in so you can see what this looks like okay so the first thing i'm going to do is log in a z account i know there's a lot of different ways to log into an azure account i am using the az module for this um i believe there's a replacement on the horizon i might be wrong about that um but definitely don't use azure rm that module is no longer with us so uh and again i do know there's more than one way to log into azure uh to azure with this thing i'm using again login az account just because it's familiar to me so it'll take just a moment while i get prompted to uh log in all right i'm going to log in with my personal account i don't actually know any of my passwords so i have to go look it up bear with me just a moment i use lastpass by the way to um to record record my passwords i don't know what you guys use but i absolutely adore this thing um it couldn't get a thing done without it so let me go back over here paste that in and i'm gonna have to go ahead and enter my um my code so that is right here oh thank you for asking though all right seven three five seven two four all right and it should dump me in and i should be logged in okay i'm also going to cheat and copy down the individual codes i will give you guys this information as well so the first thing i want to do is i want to go ahead and set a variable that contains the subscription id i'm going to use because i'm going to need that later in this process so i set a variable sub id that's just going to contain the guide that you see right here uh for this thing did i do that right no that's the wrong good i need this one right here well that's the tenant id i suppose this is the id of my azure tenant that's the correct sub id my apologies okay so the next thing i need to do is um normally i would not do this but um if you have more than one azure subscription this is a really useful commandlet um you can then set your context to be this particular subscription so i'm going to set a z context i'm being very specific in this case that this is the subscription i want to use okay next thing i want to do is go ahead and add that template that we were just looking at i have that template saved in an azure storage account that's publicly accessible i'm just going to go ahead and run the new az subscription deployment commandlet which i'll show you before i execute it bear with me all right new az subscription deployment is telling azure i want to go ahead and deploy at the subscription level um i have to provide a location even though this is even though policies are not location based they'll apply to the entire subscription regardless of where assets are located but as you know you can't run a deployment without specifying a region that you're going to deploy to then finally i'm just giving the template uri of the template that i was just showing you so when i hit return it'll take just a few seconds and azure's going to go ahead and create that uh go ahead and create that for me and it's going to spit out basically information about that policy so what i want to do now is look in the portal we're going to look at azure policy in this case i'm going to look at the definitions oh by the way um getting into the azure policy piece getting into this view to be able to manipulate anything in here you need fairly advanced privileges it wouldn't hurt to be an owner if you're a contributor you may or may not have certain uh you may or may not have certain permissions that are necessary to be able to look at this stuff but what i'm going to do right this case i'm going to sort by type and you can see i now have a custom policy named require billing identifier tag and when i click on that i can see the full definition of the policy it looks very much like what i was just talking about again um in this case i need to have a tag that's named billing identifier on a those that tag not only needs to be presents but the values that are in it need to be one of these allowed values let me be real clear about this in the case of making a requirement almost always you need to have one of these any of statements it's very rare that you can pass to this thing just a list of values than say the the value that you're providing this tag have to be present usually azure policy is going to interpret that as the tag is optional but if you provide the tag it can only be one of these values without both these statements you can't have a required tag but if i"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "providing this tag have to be present usually azure policy is going to interpret that as the tag is optional but if you provide the tag it can only be one of these values without both these statements you can't have a required tag but if i got rid of this statement saying that the field needs to be present if i went and deployed something without a billing identifier tag it would accept that if i deployed something with a billing identifier tag that was said abc123 it would reject it okay let me back up one all right so there's our policy it's available but it's not being applied let me show you that so i'm going to come over here to the storage account i'm going to create a storage account i'm going to name the storage account uh we'll use create a new resource group we'll call boston azure [Music] and we'll give this storage account the name of just some random stuff that should do it um i guess not we'll go back there that should take care of it you can see that i can scroll all the way through this even past tags to review and create and i'm going to run my final validation and i pass but i just created a policy that says hey i want these i want this tag this billing identifier tag on this asset and it has to be one of these values the reason that it doesn't work yet is because i haven't assigned it a scope i haven't set its assignment so that's going to be our next task so let me come back up here and go back into my commandments and back into powershell okay so now i need to go ahead and create the policy assignment to do that my automation routine and i realize that i'm running this by hand but normally i would do this if i was going to automate this either with azure automation um which runs powershell scripts for you or with a devops pipeline so um first thing i got to do is i just created this policy i need to get that policy definition so i can actually assign it so i'm going to set the value of the policy to be this and if i go ahead and write output i get back the same information when i got it back so this is an object with these uh param with these um uh values uh parameters and values right okay so now what i want to do is uh go ahead and set the values that can be accepted i know i did that in the policy but for some reason when you create the assignment um the assignment allows you to override the allowed values so i could create a subset of the old i could create a policy with a broad set of a lot values i could then create an assignment that only allows a subset of those values so i could have one subscription that says you can give me any billing code i could have another subscription that this applies to but and say in this one you can only use the billing codes that are appropriate to a particular department or something and use the same policy but a narrower definition of allowed values so in this case i need to create an array of all the allowed values that's what that bill ids variable is and finally i'm ready to go ahead and assign the policy so now what i'm going to do is again run this commandlet i could also do this with template i have a template that i can show you that does this um but i i prefer to do it this way um and this is how i would normally do it with it with an azure automation solution is i'm not just going to go ahead and run a policy assignment this policy assignment is going to go ahead and uh pull the policy definition so that policy variable that we just set that's going to basically that's telling it this is the policy i want to assign scope tells me i'm going to assign it to this particular subscription at the subscription level and the policy parameter object again is those uh values this these particular values that i'm going to allow uh to be passed in so i hit return bingo i've got an assignment if i go back into the portal and i look at policy again i can now see i have assignments there's my assignment okay in this particular case what it's telling me is i'm going to have to have a there's going to be a parameter provided it's bill id it's got to be one of those values that i specified and then it's going to basically deny directly any deployment to the subscription that doesn't have one of those tags let me show you how this actually works when we try to actually use it so now i'm going to go back and create a storage account again again in this case i will call this story i'll just get some random gibberish for a name i'm going to go next to advanced next uh-oh my tags are not showing up there it should show me his errors right there next data protection next tags this should actually not this should not have happened of course this is how you know it's a live demo is that it didn't actually work correctly oh no it didn't it failed okay so what should actually have happened here let me refresh because maybe it's just the portal model normally what will happen here when you try to come and create a storage account is immediately after you provide this basic information you should see a"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:40:28",
        "seconds": 2428,
        "text": "so what should actually have happened here let me refresh because maybe it's just the portal model normally what will happen here when you try to come and create a storage account is immediately after you provide this basic information you should see a little red dot here appear next to tags and it should tell you that hey you've got to apply tags it's a requirement on this deployment but we'll go over right over here we'll get right through and you'll see that i get a validation fail and the reason why it's validating failed is because it's disallowed by policy right and i can actually come over here and click on the policy and see the policy that i'm violating if i were using devops or some other solution to pump uh or to pipe this information into or to pipe this particular uh request into azure there's a strong possibility um i would not get any warning in advance that's why i would want to run some sort of test on it before i actually execute it but in this case if i come over here and i type in billing identifier let me make sure that i've got that correct um i just want to make sure that i've got the name of the uh the key of this correct before i get going it's going to be billing identifier capital b capital i so in this case i'm going to go ahead and provide billing identifier provide a value in this case um i know that one of the values i have to provide is this is one of the values i can provide actually let me provide a wrong value first so let's go ahead and call that like that and i'll go ahead and review and create and you'll see i fail again and in this case the reason i failed is because i provided a bad value so what i'll do this time is go back one more step and this time we'll provide an actual value that's allowed so if i review and create oh i don't know why i'm not passing my validations i'm sorry you have to fix the name you missed oh i didn't miss that there you go that's the reason why there you go yep you're correct so actually yeah i don't know why i can't spell identifier correctly probably because i'm not wearing my reading glasses there we go there we go yeah so in this case let's go ahead and again and take that off just so they still have the wrong name when i validate it shouldn't have passed but um maybe because um actually i think in this case it will pass but it will pass but when i try to create it will fail um because i don't have a correct value so it's it's passing because in this case i have oh because it actually did take it so if i come back here and rotate this entirely there we go yeah fails again this time if i pass in a correct value it will pass me and i can go ahead and create that object so that's basically in a nutshell how i would begin the approach that's the that's the nuts and bolts of how applying a policy to azure can allow me to ensure that a tag with a particular key and a particular set of values is allowed what can policy do and not do out of the box okay policy out of the box can require the presence of a configuration variable that can be again a tag um it can be a uh it could be a particular region it can be a particular skew that sort of thing it can also restrict configuration inputs to of specific values like we just described you can place a default configuration value where value is not provided so for example one of the things i could in theory do is say um [Music] if you don't have a cost center tag i'm going to apply this default cost center to you and finally i can overwrite a provided configuration value with a default value so i can for example say i don't care what you gave me for the value of um of cost center because you're deploying to this particular subscription you will take a cost center that's associated with that subscription what policy can't do natively is provide you with an option list so you saw before that i said there are three different values that you can pass in as a billing identifier for this particular asset uh what i can't do what it won't do for you is like populate in the portal a pull down list of just those values so it won't generate for you even even at deployment time a list of values that are available to you to supply it's also not good at complex if then statements so for example if one of the things i wanted to do is say well if you're deploying to east u.s and this is a dsv3 series vm that you're deploying then you need to give it a tag with a particular value that's too complex for azure policy out of the box to execute the other thing you can't do is restrict configuration inputs to a range right so one of the things you can't say is well you got to have this tag called serial number and that number has to be"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:45:33",
        "seconds": 2733,
        "text": "azure policy out of the box to execute the other thing you can't do is restrict configuration inputs to a range right so one of the things you can't say is well you got to have this tag called serial number and that number has to be somewhere between 1 and a hundred that's not something that um azure a policy can do it can't evaluate things as being in the middle of a range so how do you get there how do you typically work around those limitations most commonly if you're using you're going to use something like azure devops right and what azure devops is going to do is it's going to collect your runtime arguments usually from some sort of configuration file um and that is for example if you're using terraform you're going to get that from your terraform config or from your state file if you're using just powershell or arm templates you may have a flat file or csv or something like that or excel file or even a database that you might be pulling that information from the other thing you can do with something like azure devops is pull from a content from a configuration management database uh from an itsm system like servicenow or from other apis right so you could actually say go give me some information third party service that and i will apply tags according to that uh if you're using powershell scripts and to a lesser degree azure automation generally speaking you'll be prompted for that of course the challenge with azure automation is while it's running powershell scripts for you it you can't really take user input um so you would need to have uh some sort of config file or the like but basically when you're using partial scripts of the like you can just write your powershell in a manner that the user is going to prompt with that information is is user input when executing something automation my opinion is yes others may disagree and we can have a fulsome conversation on that if you'd like finally azure functions are logic apps um azure functions uh more so but logic apps to some degree are useful for solving the complex if-then interpretation right i'm saying when i have i'm deploying to east u.s and it's a dsv3 vm and it has this particular port open then or i want you to do some other thing right that is something that an azure function can do for you quite easily same thing is true if you're pulling from external databases or other data sources um azure functions and logic apps are really good at that and saying hey go get me some information spill it into a very spill it into an object for me so i can pull out the various parts i need in order to inform this uh in order to inform this deployment very useful with that um and that's basically what uh it that's basically you see them using the helping level it's very seldom you will see an azure function used solely to deploy things although i have seen that use case i actually helped a client at one point they uh what they basically did was a stand-up boutique websites um for their customers any single time that they onboarded them um and they had a completely automated solution to provision everything we used an azure function to do that they basically just pushed a button and the function went and deployed everything that they needed uh including point c point code from the right place and all that sort of stuff so you can see functions and even logic apps occasionally running stand-alone deployment solutions more typically they're used to support especially things like azure devops in terms of configuration so to recap what we talked about today large organizations face significant challenges when they're trying to govern their resources um in in the public cloud tagging is almost always and this is true not just of azure but also of aws and like it tends to be the most effective control plane for understanding and identifying assets especially if you're a large organization with stuff everywhere very few organizations have sufficient tagging coverage to really be effectively to be able to effectively govern their assets that's where azure policy come in azure policy when applied correctly and as part of your deployment process can really ensure that your tags are present and that they comply with your guidelines now finally deployment automation is typically required for this to work it's very seldom very rare that you're going to be have that you're going to be able to make an azure policy work if you're just uh freehanding it um in either in the portal or with ad hoc powershell scripts look who you're looking at again i would never actually generally speaking i would never recall what we were looking at with the powershell scripts executed by hand as a mature process but i would plug that into a pipeline a devops pipeline or even an azure automation account and consider that a fairly mature solution to the problem that is all this presentation i had for you guys i am happy to go over anything specific i am happy to uh pop back into the portal and talk about uh policy and how it works i did promise you that i would look at that we could look at the predefined uh solute uh policies in azure and we can do that as well but i'll pause here take any feedback or questions you've got so doug i uh hopefully other folks will come off um off mute and and speak as um as they have questions i i have a comment question uh in the what used to"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "well but i'll pause here take any feedback or questions you've got so doug i uh hopefully other folks will come off um off mute and and speak as um as they have questions i i have a comment question uh in the what used to be known as the azure security center which is now microsoft defender for cloud that's also a you do you want to say anything about its use of policies yeah absolutely so you can see yeah so azure security so if you look at your policies you go to your azure subscription any of them really um especially if you got a p if you got to pay a pay-as-you-go subscription one that you like to play around in your little sandbox like you will see in there um this asc default um paul initiative right and this is an initiative it's a grouping of policies and you'll be able to see that in this um and this is what bill's talking about the azure security center slash defender slash whatever microsoft has decided it should be branded this week comes with a number of predefined policies and these policies are informed by an organization called the uh i think it's called the coalition for internet security cis um they have a bunch of guidelines for what a reliable safe cloud environment looks like and these policies are so the policies that you see in the asc default uh configuration initiative and policy is based on those and it contains things like for example um enable threat uh detection capabilities if we look at that policy for example one of the things you'll see is that it says hey you should totally be using azure defender um and you don't have it enabled on this subscription well okay great hint i'll go back and take a look at that and see what i can do about getting that fixed another thing but more commonly you'll see things along the lines of um well let's take a look um secure cloud services with network controls right which in this case it says we're compliant right in this case the reason why i'm secure i have secure network controls is i don't have any networks but in this particular case what it's saying is you should have private endpoints for any azure service that supports private link in order to be able to provide public private access to the resource and you should disable or restrict public access network uh public service uh access to the public access to the service um i i take a little bit of umbrage at that that's not always true but it's a good guideline it is generally true that if you're going to be in a network environment you should probably be protecting your stuff from public access especially if it's not meant to be public um but i'm also a big believer as an old school developer a big believer in apis and microservices and public endpoints and identity is the new control plane and all that other stuff we can i i'll talk your damn air off about that so don't get me started um yeah so there are a bunch of policies that are here in azure that are available to you the thing you'll notice again when we look at them um under the assignments uh when we look at how those policies are assigned you'll see by far most of them are either disabled or they are in audit if not exist mode or they're in audit mode on and if not exist mode basically says um for example in this case one of the things they're saying is you shouldn't use management well not that one that's not a great uh example but let's okay so like here's one this is basically if you're going to deploy a virtual machine scale set or a virtual machine to azure it should be it should have the agent the log analytics agent installed on it so that azure security center can monitor it that's probably a good piece of advice but from not for every organization some organizations like to use third-party tools semantic or the like to monitor their assets and and keep track of their strength you know keep track of how well they're running and and um you know whether or not they're secure um audit if not exist basically says well okay if you deploy this virtual machine and it doesn't have a log analytics agent on it for the purpose of azure security center i'm just going to make a note i'm just going to stick a note off someplace and again one of the things that that note can do is surface a event so i can capture the fact that this virtual machine was deployed without the azure security center agent i can get i can get that hooked via the event hub through the event hub in turn i can trigger some sort of automated workflow that says something like well go put the agent on it or say something like well go send go send a note to mom and intel on this machine for coming here coming here without uh the stuff it's supposed to have uh that sort of thing um most organizations again um this is probably not you know you could change the mode of this from audit if not exist to deny um you would probably create quite a few enemies um in your it staff and your user base especially if you change audit policies to deny policies right off the bat it's very often the case that um would that people mean well um but they don't have the"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "00:55:39",
        "seconds": 3339,
        "text": "quite a few enemies um in your it staff and your user base especially if you change audit policies to deny policies right off the bat it's very often the case that um would that people mean well um but they don't have the maturity of the ability to deploy assets that are 100 percent um compliant especially if they've a new policy so what most organizations do is implement a policy with audit and you can see where that paul where the violations come [Music] basically by looking at this compliance report so in this case i can see i've got some stuff that's non-compliant if i click on it i can see right here one of the things that are not compliant i can actually drill in and it will tell me the assets um that are not compliant um so it's uh and i believe it is uh i think it's right here so there's a way to actually pull this information as well i don't remember it off the top of my head but you can pull the information from this of the assets that are not compliant especially you'll see that most of these things that i'm not complying with right now are high level you you know this data protection one you don't have any sort of um you don't have any sort of implementation of a firewall or any other sort of data data exfiltration monitoring on your subscription well that's true but that's because i don't have anything in it so um again i can identify that the assets are non-compliant um i can see what's not there and i can actually go ahead and see the things that are not correct and do something about them from here it's actually easier to do this from the security center itself so and doug thank you that was that was excellent um bringing the context there what is the mechanism through which uh azure allows this all these uh policies to be grouped as a unit because they're all under this asc default thing yeah so that's an initiative so when we look at so when we look at policies again that's basically what's called an initiative in this particular case um i'll go back over here to um definitions um in this case what i'll do is i will filter down for initiatives so um and when i do that i should see come on give me the initiative oh so here's the initiative it's like four i'm sorry didn't mean to click on that so for example here's an initiative that is the nist sp 800 171 r2 initiative this basically implements all of the recommendations that are in the nist 800 171 recommendation again you'll see that most of them in this case are in audit mode we do have a couple that are in modify mode in other words what it will do is it will automatically apply um a system manage identity um on a virtual machine that doesn't have any for example right um the in this particular case the assignment right here of asc default contains all of these initiatives so when i create these initiatives these groupings of all my policies i then assign them to the subscription it is this asc default assignment that contains all of these policies so in each one of these initiatives is a policy or in each one of these initiatives multiple policies within this assignment are multiple initiatives so they appear grouped as a single thing even though they're all interrelated or rather even though they are all addressing different requirements of my governance plan and so just like uh like you can assign an individual policy create a policy assignment to a to some resource scope like a subscription as you would you wouldn't you could um uh apply the initiative with the same mechanism yes absolutely so and i can do that um typically the way i would do that if i was automating the solution end to end right so if was automating this end to end um let's suppose i'm using azure devops if i'm using the raw devops product out of the box um and i'm not going to bring in any third-party tools the way i would do that assignment both create the policy add the policy to an initiative and then um apply the initiative with an assignment to a subscription or a management group of the like the way i would do that is with powershell so in azure devops i would basically call a worker agent it would that worker agent in turn would run powershell and it would pull from get um it would pull from github or some other repo source all of my templates and use powershell to execute them that's typically the way i would do it natively in azure devops increasingly and this is a pro tip if you take nothing else away from this com from this conversation uh take this um increasingly what you are seeing organizations especially large organizations want to do is use terraform terraform is extremely popular especially with large organizations and the primary reason why it's popular is because theoretically i can describe anything anywhere using terraform so i can describe in terraform what a virtual machine looks like in aws what it looks like in vmware what it looks like in azure what it looks like in gcp uh google cloud platform i can describe"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:00:43",
        "seconds": 3643,
        "text": "anything anywhere using terraform so i can describe in terraform what a virtual machine looks like in aws what it looks like in vmware what it looks like in azure what it looks like in gcp uh google cloud platform i can describe it i can use a description in terraform a module that describes a virtual machine and theoretically therefore based upon that one basic description be able to deploy it anywhere i want in any public cloud any private cloud and on-premises as with most things that are described that way it's uh you know be careful of the snake oil you're buying i wouldn't call terraform snake oil but i would say that rumors of its cross-platform support are exaggerated um like all things um there are nuances and tricks not everything that terraform can do is supported in azure in aws for example you could do some things in aws that you can't do in azure and vice versa um more but that notwithstanding it's that's a question of maturity and it's very clear to me that the market the it market especially the high end it market the fortune 500s out there have identified terraform as basically the next the best thing since kubernetes so you know how you can't swing a cat without hitting somebody who wants you to have kubernetes skills the next big thing the thing that if you wanted to learn a skill you would be able to start pretty much asking whatever you want for price i would say is terraform if you are a skilled terraform developer if you demonstrate that you can write modules and configuration files and get them to execute well in a pipeline you are going to have a job for a while yet um so if anybody out there is looking for a skill to get skilled up on that they think is going to be in high demand and you don't particularly think much of kubernetes i would really really recommend looking into terraform it is a very hot commodity right now i see a hand raised but so i would use terraform or something like that if i was going to deploy these as well to answer your question directly i see a hand raised but unfortunately i can't see whose name that is so my apologies oh looks like it's uh jeffrey hi there um i had a question mainly on tagging strategy versus your topic feel free to stop but um one of the things that we're trying to do is you know rely on tags to uh specify you know network access between you know one resource or another um do you have any experience with that and maybe can talk about um any you know potential pitfalls or caveats that you've run into in you know any of your your deployments sure absolutely so if i understand if i understand what you're trying to achieve correctly what you're saying is asset a i want to know i want to know the network relationship between this thing over here and that thing over there so i want to know um for this asset over here that's network connected what is its connectivity to virtual machine a what is its connectivity virtual machine b do i have that right or yep okay yeah typically i would not recommend i would not recommend using tagging to solve that problem um now keep in mind there's a there's a twenty dollar solution there's a five dollar solution and there's a fifty cent solution um the challenge with using a tag to i think you could do it don't don't get me wrong yes you could say um i'm going to define a network group i'm going to where i'm going to define a group of assets that should be able to communicate to each other and i want to tag them so that i have visibility into the fact that they should be able to speak to each other absolutely you could achieve that with tagging my concern would be that that is um that's a configuration variable really um and i think you need to be careful using tags to specify what the configuration on an asset should be um that's typically the solution i would have toward that and i want to be real clear that this is will be real clear this is a consultant speaking to you not a guy who's actually got to do it typically the advice that you would get from a consultant like me is for that sort of traceability what is the network connectivity between device a and device b i want to do that in a configuration management database of some sort i want to have that in my servicenow catalog i want to have that in something else that's tracking what the correct configuration of that asset should be and if i'm using something like terraform or the like i can actually have a supporting file that describes that right so i can i can have in the deployment solution not necessarily on the asset itself but the deployment solution some sort of record as well that indicates virtual machine a should be able to speak to virtual machine b so that i would say is so i would say that that solution the make a note of it and stick it in the spreadsheet is the 50 cent solution right um i don't know is that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:05:45",
        "seconds": 3945,
        "text": "virtual machine a should be able to speak to virtual machine b so that i would say is so i would say that that solution the make a note of it and stick it in the spreadsheet is the 50 cent solution right um i don't know is that that's that's largely unmanageable the challenge with that is it comes out of date very quickly more typically the solution that i see organizations use to address network connectivity is some sort of net flow mapper there are a number of tools that can do that um but so if the challenge is if the challenge is i need to validate that virtual machine a can speak to virtual machine b and my azure presence typically the way i would audit that is with network watcher um in in the azure tool network watcher and just make sure that i can actually do it and actually see the latency and that sort of thing and set up some sort of alert you might have that network watcher um maybe pumping some of its telemetry to log analytics or the like or doing something along those lines so if my concern is i don't want virtual machine a to stop talking to virtual machine b or i don't want any network changes to affect their ability to communicate with each other i would then set up log analytics to basically capture when those two machines aren't capable of speaking to each other anymore via receiving telemetry from network watcher and then i would basically create a logic app or the like that would surface to me an email saying hey virtual machine a can't talk to virtual machine be as of this particular date and that would tell me okay i need to go and look at my deployments somewhere around that time to see who screwed up the network that's the five dollar solution the 50 solution would be to use something like an ipam solution um so using a full-fledged ip address management solution that includes things like dns management um and that sort of thing i forget the name of the one that everybody uses um anybody if you know the name of the thing that i'm thinking about it's something or other one or i forget it's called ipam ip address management a lot of this particular solution i'm thinking of includes things like dns routing uh and actual network latency management tools like that have the ability to also audit um the ability the ability of it has the ability to audit network change you can use to all that said one of if what you're really saying is what i really want is to ensure that my networks are not changing without me knowing about it that there's no changes to the network without somebody being alerted to it or a test being triggered the way to do that and i guess i would call this the 10 solution it's probably the way i would really recommend doing this is saying on everything i'm going to create a uh i'm going to create a policy and what the policy is going to do is it's going to watch for any time or i'm going to create a yeah i'm gonna create an event trigger i'm actually gonna watch the activity log in azure i'm gonna have it raise any single time and i could do this with policy or i could just do it with the event grid i'm sorry with the with the event grid in azure i'm gonna watch for any off the off the activity log i'm going to watch for any time that somebody makes a change to a network security group or deletes or changes a subnet and and if that change takes place i'm going to audit whether or not it affects that change that network security group change or that subnet change affects either virtual machine a or virtual machine b these two machines that have to speak to each other and if that happens i'm going to do one of two things if i'm super sophisticated i'm gonna kick off some sort of pain test i'm gonna go ahead and kick off some sort of test that's gonna say hey virtual machine a make sure you can still talk to virtual machine b and vice versa and if you guys can't talk to each other let me know alternative would be i'm just going to go ahead and send somebody an email and say hey johnny just changed the network security group rules for the subnet that virtual machine b lives on you might want to go look and see make sure that virtual machine b can still talk to virtual machine sorry i didn't want to interrupt you but um the big the big thing i'm trying to get at is like you know the cloud's supposed to be dynamic um if i have resources that are being spun up and spun down via like nsgs they can understand tags and you know we want to be able to spin up new resources apply the tags and have the nsd rules apply to those resources sure yeah absolutely yeah so that is a very i think that's an interesting automation case right i think you can make an automation case for that so if it's if it's i've got a not necessarily a fungible environment but it's an environment in which i'm bringing things up and occasionally getting rid of them and what i want to do is make sure that i can provide at the time that i execute the provisioning of that virtual machine for example i want to make sure that the network is completely ready for that asset to come and then i may need to provide certain custom network rules to that asset yes absolutely in that case that makes sense if you if you can especially if you can narrow the configurations to say a dozen or fifteen if you could narrow um the required configuration on that"
    },
    {
        "speaker": "",
        "title": "Build Your Tagging Strategy with Azure Policy and Automation with Doug Vanderweide",
        "videoId": "4ebXt0iMiEU",
        "description": "This is a recording of the November 16, 2021 virtual meeting.Build Your Tagging Strategy With Azure Policy and AutomationAbstract: A solid tagging strategy is essential to proper Azure governance. But that's often easier said than done -- especially for existing subscriptions. Using Azure Policy, with a little help from additional automation tooling, we can not only ensure our assets comply with a tagging strategy, we can remediate noncompliant assets, and help our team select the correct values for those tags.## SPEAKER BIODoug VanderweideAzure SME, Blogger and Cloud Architect | Director at Avanade",
        "start": "01:10:48",
        "seconds": 4248,
        "text": "provide certain custom network rules to that asset yes absolutely in that case that makes sense if you if you can especially if you can narrow the configurations to say a dozen or fifteen if you could narrow um the required configuration on that asset to you know a manageable number of templates basically it's very easy to say at run time when i deploy this asset i want something to inspect the asset to pull the tag off of it to identify to pull the tag off it that says what its networking rules should be or what rules i should apply to the nsg as a result of this machine showing up and then i want some routine some sort of service to go and make those changes that's a very clear case for a logic app and that's a very clear case for the event grid so what i would do in that case is i wouldn't necessarily use i wouldn't necessarily use a policy although theoretically you could use a policy to do this as well um i would actually say i'm going to have a logic app the logic app is going to listen for any single time that i create a virtual machine in that particular create a virtual machine it's going to go ahead grab that virtual machine's definition pull the tag on it that tells me what the network configuration should be it's going to identify the correct it's going to identify that correct network security group and it's going to modify it i might not actually be able to do that with a logic app now i think about it but i could definitely do it with a function so i might do it with a function instead just because it's a little more flexible but yes there's absolutely an automation solution you can do there and i might be wrong about this but again depending upon how you do it you theoretically could use that same methodology to call azure devops so you could actually maybe even have a devops routine that responds to a web hook that gets fired off by the fact that the machine happens and the value in that is you have it right there in your total deployment pipeline so the same pipeline you use to deploy the virtual machine you could use to manage the network settings as well completely automated based entirely upon the tag that you associated with a virtual machine that tells it what network configuration to apply all right thank you it's complicated um you know that you know if you want i can you know i can quote you that but it's going to be six figures so it would take it would take some time to do that it'd be it'd be a couple months of project for somebody who knew what he was doing looks like there's a question in there um just solo wins question mark from uh edgar i'm not sure i i understand what that is maybe yeah my apologies yeah so solo wins is a um it's a it's a software program um arguably the most popular software program that's used what's called itsm so it service management so as we all know um something breaks there's got to be a ticketing system of some sort right for example there's got to be some means of being notified that a change or a break or something like that happened and some sort of means of auditing the resolution of that request so um when you call you know when somebody calls the help desk help this guy answers solo wins is basically the database into which he enters your ticket and he tracks whether he tracks the resolution of that um solarwinds is more sophisticated than that it has additional things in it but basically when i'm talking about solarwinds i'm talking about arguably the most popular solution for tracking i.t incidents and managing them and keeping record of them and identifying what they're used for um again the reason i keep repeating solar winds is because everybody uses solarwinds um if you get out there are other solutions but much like there are other ways to do containers everybody uses docker much like there are many ways to manage container instances but everybody uses kubernetes there are many itsm systems out there but everybody uses solarwinds awesome any any further questions for doug sure yeah i would agree edgar solarwinds has many problems um and it is uh the worst thing you can do to solo wins is try to make it better um i am yet to meet the organization that's customized solar winds that wound up with what they were bargaining for um but again um you know it's what everybody uses so um while it's painful at least it's painful for everyone so um the brand is also unfortunately uh tarnished due to uh one of the most notorious uh data breaches ever data breach didn't do them any favors either agreed yeah um it you know it is it you know there are better i would argue there are better programs out there too um and certainly it is you know for most organizations especially that aren't enormous enterprise orgs solarwinds is probably overkill you don't need all the things it can do um generally speaking you'll be better off using something much simpler but again i just promise you that if you go and talk to any of the logos if you see any organization with more than 50 people on the it team um i've got five dollars that says they probably use solar winds or at the very least are at the very least used to use it right on okay well uh left call here i guess um in just a couple of reminders one is um if you so you should definitely follow doug's advice about policy and tagging they work nicely together and that will help you from being an example in our december first talk about azure security problems uh so we look forward to seeing you all on our if you're interested on december 1st that's the last event of 2021 and the video of doug's excellent talk will be posted soon it usually shows up the next day and you'll be able to find it at youtube.com boston azure great thanks doug this was fantastic you you took a a a a topic that has a lot of loose ends to it brought it together in a really coherent way and uh really uh uh gave us a great explanation many thanks thank you all appreciate your time take care everybody good night "
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Monitor Azure Resources with Kusto Query Language with Taiob Ali. This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.. okay we are recording um and i just want to introduce our big friend uh he already uh presented at boris uh north boston azure and boston azure user groups in person and virtually um tayo valley he is a microsoft data platform mvp he's also a data solutions architect he is a public speaker and just amazing person um so i just want to introduce him and pass the virtual mic to him okay thank you thank you veronica and bill for you know inviting me again uh this has been few times that i spoke to the combined group and also your group in nerd and also jason's group in burlington so thanks to everybody those who joined because you know things are a little bit difficult for everyone right you know working remote children's are home uh what not right and then after working a whole day and then you know uh spending the evening uh to listening to me it's not a you know easy thing to commit so i admire your uh you know your dedication and uh so i'm going to shut down the camera for now and i'll bring it back for q a uh so you know it's a small group so you know i'm not monitoring the chat actively so very can stop me anytime uh if it is okay you cannot mute ask me question i'm okay with it uh you know i'm not too too formal or i don't need to be and um i also noticed that the next month's speaker uh hassan i met him a few times he actually came to speak at boston sql saturday i was in wyo uh before the pandemic uh awesome speaker so you want to sign up uh you know for the next month's meeting for this for this group uh so let's move on i only have few slides uh most of it uh probably 80 to 85 percent will be demo and you know my goal is not to really teach you how to write kql because if you're familiar with you know i know some of you personally you are way better developer than me so if you know t-sql or some other programming language kusto is a very easy language to understand i will try to show you some bells and whistles so you can appreciate that as bill was saying you know how the azure business is expanding worldwide um you know and bill was just saying that you know average twenty five thousand dollars spend uh can get to that limit and i know at least my company is using manifold more than that so it's going to just grow and as you are expanding right you know you need to monitor your resources and and for me that was the reason that you know i i started looking at it so i'll try to you know show you a couple of things that you can take all this uh and hopefully put it into use and and i'll also show you if you really you know do not know anything about this language i'll also try to show you a couple of uh you know sources or resource and couple of just basic syntax that where you can start and build up learning this language so let's let's move on not sure if it's just me but are you um uh sharing your screen i'm probably not so that's a good point thank you bill so just give me a minute should be there show a screen why it's not giving me that option now okay i got it so screen two you should be able to see it now okay great yes thank you bill uh for reminding me uh so as again you know i'm not gonna read about myself if you just take a note on the things on the left side you can contact me if you know any questions comments any feedback after this event you can use any of this linkedin twitter email a contact page from my blog post uh please do contact me and i'm i'll always respond you know hopefully within two days uh but you are i'll guarantee that you know you will get a response and if i don't know that's okay you know i know people are smarter than me so that's a good thing i can go back you know i can go to them with your questions and get a feedback and and send it to you so you know at least i can do that so if i don't know the answer so let's uh just talk about a little bit you know what is this this custo right and and"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "send it to you so you know at least i can do that so if i don't know the answer so let's uh just talk about a little bit you know what is this this custo right and and where it came from uh so kusto it's a it's a language also there's acousto engine so don't get confused with these two things the name can be confusing um one thing of the bet is uh whatever you're going to use crystal for it's going to be only read-only so it's a read-only request and we look at the schema a little bit it also follow a hierarchy uh it's all column story index uh pre indexed for you and the goal is to when you have huge amount of data terabytes or petabytes how you can quickly get uh insight out of it right that was kind of the primary need of microsoft in 2014 um you know when azure was you know expanding they were building big data centers so microsoft had to internally monitor all their resources right all the hardware all the cooling power and whatnot so they had this challenge right they're collecting all these logs metrics what did they do with this how did they quickly know in real time what's happening so you know microsoft has r d facility big in israel and it was actually a grassroot project incubation project in israel uh into the rnd center and from there you know they came up with this language again to fast and scalable log you know to get the telemetry analytics and in 2016 this became the back end for application insight i personally do not work with application insights they're a team in my company where i work full time they do use it i know that for sure and in 2018 it was in public preview uh was announced in the uh ignite in 2018 and in 2019 uh in february in the ignite uh it became ga and so there are two things um i do not personally use there is a service called azure data explorer that's a total uh full place service that you can use you can dump your data into the into that service and you can use custom query language to extract data from there you can do that and i'll show you some of that what i use primarily is against log analytics workspace and we'll talk about that also a little bit that how i use it and why do i use it so i just took it from microsoft documentation i put the url on the right side just so you know that you know i did not made this slide by myself so you know i've been doing this uh you know working with sql server for a while and i had pretty good grasp on for my on-prem infrastructure i knew if any server goes down any host goes down anything out of ordinary cpu memory you know number of batches per second queries what not but as i started you know moving stuff to cloud primarily into azure sql database i needed something similar right i want to know when things are out of ordinary and i also wanted to do one thing is you know today i might be having i'm not going to give you exact number you know say smaller number of resources on-prem uh sorry in the cloud but down the road if i have hundreds and hundreds of those right at your sql database managed instance as your synapse what not how do i scale this thing out right how do i not you know keep doing the same thing over and over right i wanted to set this up one time make sure i can scale it out and doesn't matter how many of those resources i have you know it should do the same for me so i looked at couple of things you know i looked at in a couple of solutions uh in writing powershell into notebooks and all that and at the end i figured out for me at least uh log analytics workspace which you see here on the right side under the analyze you know blade that worked you know best for me so out of you know azure synapse as your sql server or pretty much any kind of azure resource because you know i gave this stock internally at my company for folks to for network folks to manage their searches and routers and all that right um and and and other groups because they all can send their metrics and logs to log analytics workspace and what does that do for you once you have that microsoft already has predefined schema for all kind of resources and nowadays actually you can install agent and send your on-premise uh resources logs and matrixes also to log analytics workspace so it's all in one place and azure"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "that do for you once you have that microsoft already has predefined schema for all kind of resources and nowadays actually you can install agent and send your on-premise uh resources logs and matrixes also to log analytics workspace so it's all in one place and azure monitor actually work on top of that and from there you can do whatever you want like in my case we use servicenow and i know you know bill was talking about like bill has a team in india and there's you know she can't join from south india i also have offshore team in pune and they're 24 by 7. so i use service now so from log analytics workspace i can write custom query language and whatever i want to get alerted on i can send a call to the service now and generate a ticket and it will land into there into the ticket queue and there are other stuff you can do you can use web hooks you can send a phone call you can send pager you can send notification to your teams app also and you know if you're just using matrix you know matrix is some we call this like uh it's a you know single time and a single matrix right and microsoft also you know in azure you have metric explorer they will do it for you but if you have to do it for each resource individually like for each azure sql adapter you go and have to do this over and over which you don't want to right you just want to send everything in one place and um you know query from there now is it the only destination no you can send your matrix and log analytics logs to a storage account you can also send it to event hub and it's actually recommended if you need to keep this for a longer period don't use log analytics send it to a storage account it'll be a lot cheaper but uh you know you can keep whatever you need to you know to look at your trend and and alert send those to log analytics uh one other thing is microsoft also has built-in solutions so if you see on the under the insights bled on the top right side there's something called additional solutions so these solutions are built in so if i'm sending azure sql data to log analytics i can enable those solutions turn it on i don't have to do anything and behind the scene microsoft is going to aggregate all data and you know graph it for me and i can drill down and find my problems very quickly um if you don't want to write any query you can have all these built-in solutions but if you want to go more granular and more specific alerts like dynamic alarms right i don't want to know when cpu is 90 i want to know if cpu is more than x number of percent compared to the last week at the same time right week by week day by day you can do all those with custom query language and get alerted so that's the one of the reason that i started looking at this uh you know these are a couple of other things that you know you can use with security center application inside windows defender i talked about it so you know everywhere pretty much every azure resource uh you can use this so now you know folks like me who came from a database background we've been working with t-sql i'm like you know okay now you you have to learn another language right uh why can't i use t sql so if you are using azure data explorer there is certain things you can do with t sql though it's not recommended but with azure monitor you cannot uh you really cannot do anything with t sql so you have to use custom query language and this is a quote from microsoft documentation and i kind of highlighted that you know microsoft also recommend even if you use data explorer uh use use custo instead of t sql where can i learn or how can i learn so go to my reference slide at the end and there are three different demo environments uh i'm going to use the top one today and i'm going to use another one that i'll show you so this demo um data collections are happening around the clock so microsoft actually pushing data to this demo um you know like data stores continuously as a you know for demo purpose so if you just have a portal account you do not need to spend any money uh you can log into this and you can start writing uh you know queries and i'll show you that and there are also some of the queries are saved for you so you can go and look at those and start from there recently you know i use a azure data studio a lot if you do not know this is a cross-platform tool um i wouldn't say similar to management studio is a lot richer but in certain extent it's not as rich as management studio when it comes to purely sql server uh so with azure studio it's a extension base uh we use it a lot you can use uh you know different languages and now actually there are menus that you can switch between management studio and azure data explorer so there has been two things been released recently um the the top one you know is called kql magic this is really not extension this is a kind of it's the extension of python kernel uh that once you enable it and i'll show you this in demo uh it gets you all the modules that you need"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:15:10",
        "seconds": 910,
        "text": "magic this is really not extension this is a kind of it's the extension of python kernel uh that once you enable it and i'll show you this in demo uh it gets you all the modules that you need and then you can actually write a python uh notebook uh using cousteau query language so um and i'll show you some of the examples how you can do it and the bottom one is actually a pure extension in azure data studio that microsoft released this will uh and and with this you can also you can have just a pure kql current notebook using couster kernel within azure data studio and today it's primarily done for azure data explorer but i also show you a workaround that how you can connect to your directory to your log analytics workspace it's not pretty but you know there is a someone at microsoft that i i talk julie she's in that team i talked to her all the time i was talking to her this morning um you know it's in the pipeline it's not in nda or anything i'm not giving you any insight scope but very soon you know there will be native uh connect connectivity to directly to log analytics workspace and then you will be able to you know pull your data and bring it to azure data studio and do more uh you know built-in visualization with the there is another extension called sendance which you can download so you can you know get this kql queries run those and and you know produce graph within azure data studio uh very powerful so those are some of the stuff in the pipeline and coming uh these are you know i put bunch of references uh i'm not going to talk about this only one thing the the second bullet point uh it's a gentleman called robert robert kane uh he has a four-hour pluralsight course on custom query language and this was actually sponsored by most probably microsoft so even if you do not have a paid account if you just have an account in poorer's site they have a bunch of courses that you really do not have to have a paid account because other companies sponsor those courses so this is one of those so you can do it you do not have to you know pay anything this is a nice course if you really want to get into the syntax from very basic to advanced level i would highly recommend some other stuff that i read in preparation for this course or you know over you know whenever i use it and that's all i have so i'm going to go to demo uh i'll primarily be using portal azure sql database and azure data studio this is the version i'm going to use and so i'm just going to take a pause and see if any questions comments at this time before i switch to demo i don't see any comments in the chat but if anyone has a question feel free to amuse yourself okay so i'm going to move on if if someone has anything please uh you know speak up or i i'm also watching the chat so so let's move on uh i'm not going to run this script right now the reason i'm running you know there's no reason for you to sit down here and watch me running this it takes about five to eight minutes uh i already uploaded this in my github repo which i'll show you and what it does i'll show you in portal what it did for us and then i'll let me bring this so running that script created some of these resources so let me go back to dashboard it created a azure sql server which is just a logical container uh and a sample azure sql database and a log analytics workspace that's all was done from that script that i showed you and also i did something within the log analytics workspace but before i go there i want to show you something else so whenever i deploy a azure sql database in production um you know i do a bunch of things at my work but i'm not going to show you all those i'm just going to show you just for the sake of this so as you can see here i'm under diagnostics it is saying that i already have this setup and it is going to this log analytics workspace so if i go to edit settings as i said you have three options you can send your log analytics storage account event hub and i'm sending all these logs now do you need to send all this i don't know it's up to you right you have to decide you know what you want to collect what you want to you know monitor what you want to alert on but just"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "i don't know it's up to you right you have to decide you know what you want to collect what you want to you know monitor what you want to alert on but just for demo purpose you know i'm sending all this to this log analytics workspace now let me close this i'm not sure if i understand yep okay now over here if i go to logs so all this data is being fed it and it's being you know automatically uh is being loaded into this tables and if i have you know other kind of data that you know i keep sending uh i do not have to do any of this here it will automatically get sorted out predefined uh schema it will get loaded it will get indexed and all that for me to to run queries now one thing i'm going to show you just for demo purpose what i did here i have one lrt enabled i call it found deadlock a lot and you know this is a very simple i'm just trying to give you a concept as i said before and you can you know take it as much you know as far as you want and as complex as you need so what i'm saying here that if i have a metric named deadlock if the count is greater than zero triggered this alert and you know i know i have overlap here i'm saying you know check for last 30 minutes but i'm running this every 15 minutes i'm going to get two alerts for same one i get that but i'm just doing it you know just picked up some numbers here and there's something called action group so i have action group called notify dba deadlock this is going to send an email sms and a voice call now you know do i want to get call at the middle of the night for every deadlock probably no you know again i said you know you have to decide this for yourself i have a subject line for email and you know i have a description i put a cv 83 here what does this cpa mean it really doesn't mean anything in this case but there are some apps that i know like i was just talking about servicenow you can create template in servicenow and you can look for text so if it says that okay it's coming with the cb 83 text then i'm going to do this i'm just going to send the email if i coming with the severity one i'm going to page someone if i'm coming with cv82 probably i'm going to do this so you know just an example so now i have this setup right so i don't need to save it because it's all said before now let's do a deadlock you know create a deadlock just for demo purpose and see what happen okay so i should have a what happened to mine okay similar deadlock and i'm doing this against this demo server that you saw on the dashboard that i just created on against that demo database so before i do this let me make sure i connect to this this is azure sql database and in edge or you cannot use the statement use database name so you always have to be in the right context of the database without your sql so and this is a very you know simple uh that if you if you you know google online how to create a deadlock you will see this probably thousands of examples so i'm just creating two tables and just having two rows of data and this is a common trick that you can do you use do a begin trend you're beginning a transaction you're not committing or anything you leave this open go to another window oops i didn't mean that run this here this will keep running i'm going to come here and now one of those should get deadlocked yep so as you see now a deadlock happened right so within five or seven minutes i kept my phone purposely on it should ring i'll also get a sms"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "those should get deadlocked yep so as you see now a deadlock happened right so within five or seven minutes i kept my phone purposely on it should ring i'll also get a sms i'll get an email um i'll show you uh once you get those but i'm not gonna you know i'm gonna move on so this is a very you know quick example but what i wanted to show it is that now i have this alert set up right for this condition as you saw that i didn't have a server name there or a database name right it's going to do for everything now you know this is probably not production ready right if you have you know a different tier of applications you might want to group those and do it in a different way you might have different log analytics workspace for different tier and based on that you can decide how you want to do that so you can take this concept and now you know write your queries and get alerted for anything you want to and get notified in any way you want like that was kind of my my goal of showing this that you can you know this is very you know scalable uh you know doesn't matter how many resources you are you are monitoring so i'm just going to close all this we don't need anymore uh so this script is there you know it will do everything for you there is only one place that you want to make sure that the one in the github i didn't put my of course my phone number and my email address you want to change that when you otherwise you can pretty much run this as is one other place you need to keep it careful is your subscription id that i have no idea and then at the end i have this one line code that's going to clean up so if you want to save your money make sure you delete this because i could build everything in one resource group so it's a very easy to clean up so there are two things that i talked about kql magic and these are also in in the github repo you can you can download so i actually downloaded this from here i didn't change much as you can see this is still using a python kernel and this is first time when you do this you need to install kql magic um and if you already have it installed uh you can always run this if there's a newer version to upgrade you can do that and then you load this into this notebook and then once you're done now i can actually connect to a azure data explorer i can give the tenant name cluster name and the database name and i need to do that authentications okay so you're connected now and now because i'm in a python kernel i can say you know person person kql that it knows that i'm using kql i can directly query the data here and if you have the other extension sentence uh you can also uh put this you know in in in in graph format uh and and we'll we'll see some of this or you can directly do this here if you say render time chart uh so we're looking at a storm event uh you know summarized by count and you can create a time chart right here you can do a pie chart by looking at the same you know similar data now as i said i personally do not work with azure data explorer um sorry i do not use uh you know the the service i mostly use with the you know the the log analytics workspace so uh this is another one like you know i was telling you about this this demo uh workspace in my slide uh you can connect through this um you know you same workspace application key and then the alias i'm not gonna run this but you can do that now you can also connect to the log analytics workspace directly this was a little bit tricky microsoft documentation was"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "but you can do that now you can also connect to the log analytics workspace directly this was a little bit tricky microsoft documentation was not very clear so i put a url here there is a gentleman named dennis he's a microsoft mvp he wrote extensively how to get this work and so there are a couple of different ways i'm not going to use this one because you know i have to create secret and change bunch of things so i don't want to but if you go to this article it will explain and then you can take this string that i have and you can just change the values and get it worked but there is another way you can you can do this as i'm doing it right here now this is directly connecting to the log analytics workspace that you saw in the portal that i i created okay so you're connected now and now i'm actually running this against this this localities workspace the one that i created not the microsoft's demo or anything it's directly getting the data i'm not sure yet if the deadlock landed there or no probably not yet but we can try another query let me let me bring that one in you can also look at from the matrix if you don't see it in diagnostics it land in two different places yep so 23 1847 yep this one so this is the one we just did right so uh it's there uh i also you know there are some more urls that if you want to you know read further and do some more stuff you can do that uh the next notebook it's a little bit about this is now not using a python kernel you can directly go and use custom and for this one what it's using it's using this extension called kql this is still in preview just so you know now with this one i can directly connect to a cluster from here and once i'm connected then it's and as you see here i do not have any person person kql because now i'm in acoustic kernel so i can directly write in crystal query language there's another one now these are as you see i'm connecting to a sample from microsoft right now how can i connect to the log analytics workspace and query the way i showed it in the other place it's very messy if i take this just give me a minute so let me see if i can put in a notepad and show you the whole thing now it is not ctrl shift and copy so as you hear my phone ringing this is actually uh about the deadlock i also got a text message and i'm gonna also try to show you the email so anyway uh so this is not pretty you have to you know create this whole string and then you have to put your query at the end um but again you know this has been still in preview so microsoft is actively actually building on this and i i think this is going to go away and you should be able to you know go to your connection string window and"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "still in preview so microsoft is actively actually building on this and i i think this is going to go away and you should be able to you know go to your connection string window and be able to connect your log analytics workspace pretty quickly i mean this works but you know you're not going to for every query you don't want to you know copy the whole thing and put your query then as you can see that we can get results but it's still it's not a you know i don't think so it's ready for you know for for prime time yet i want to show you that email that i received so let me get it in the different window and then because it's my personal email address so just give me a minute so you got a i got an email from that from the deadlock and i just want to show you that so you know i'm not going to read the whole thing but as you can see cb 83 this is the utc interval 30 minute and it actually gives you the you know the whole details uh about the you know the resources that was involved into the deadlock uh so i just wanted to okay so any questions so far otherwise i'm just going to go and show you a couple of syntaxes and you know run few things okay so someone has a question that pricing model for queries against localities workspace i think on my resource page i have a url because i don't remember every time you know there is a uh how much it cost and and all that uh there's definitely a price uh uh also in your log analytics workspace if you are keeping um over you know when it first came out you could not keep anything older than 30 days it will automatically get punched now you can actually customize what things you want to keep for how long um and i think there is a certain gigs are free for long entities workspace and after that you have to pay per gig and for uh you know for the period that you keep it um so you have to you know the more you keep and the longer you keep you pay more money also the queries yep okay so i have let me show you this i have the six queries i wrote those uh using visual studio code just so you know it gives me all the syntax error and all that but uh you can open this in pretty much any place i am not going to you know go through everything but they are also in my github repo uh i'm going to show you a couple of things out of these six queries but not not every operator because it's just going to get too boring and like i said at the beginning some of you are way better developer than me so i don't need to teach you every syntax of of this of this language the first one i'm not as i said i'm using one of those demo data collections to show you this but this is pretty much same as what you see in the portal so you know the look and feel is pretty same so i just want you to you know i'm just going to show you a couple of things to get around in the portal when you go into log analytics workspace so on the left you see your collections as you as i said few times these are all predefined right i'm speaking very loosely you can consider each one of these as a database these are your tables within the tables these are your columns right this is kind of i have a hierarchy same as a relational database on the left side you see the symbols telling you the data type right and on each one of these even without knowing anything if you click this it gives you a preview of your data and you can also click this and it will take the query show you what query was ran behind the scene to give you this data also gives you some ideas right what is this collection about right it's about virtual machines and this data is also being used by built-in solutions for azure monitor for vm so if you open that solution that solution actually use some data from this table so you know give you"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "and this data is also being used by built-in solutions for azure monitor for vm so if you open that solution that solution actually use some data from this table so you know give you some ideas one thing i'll probably mention few times if you just run this or if you see both of my queries i do not have any predicate with date time right for how long i'm looking at like how far back i'm going be careful with it especially if you're doing aggregation you might get caught with this i did few times by default it will always show you 24 hours last 24 hours for everything if you do a count you do some aggregation always for last 24 hours and by default it only gives you the first first 10 000 records so just keep these two things in mind last 24 hours and 10 000 records there is a query explorer if you want to save your queries and share with your teams you can use this uh under the saved queries if you go to purse site the course that i was talking to you as telling you before by robert kane all of his queries from that through a site is bundled here so you do not have to even start from scratch you can just open this and you start running those and you know see how he did this and if you go step by step from m1 to m8 he goes from very basic and build some complex queries so this is a good place for you if you want to get started it also gives you some link for getting started online courses and all that and what else i can tell you okay so let's let's let's look at few things and please i'm also monitoring the chat so if you have any question you know like i said you're a small group so please stop me because from here everything is available for you so i do not have to kill myself or kill yourself you know make you bored you know to to get this finished so the main purpose of this uh let me make this a little bit bigger and press f11 so you get a little bit more real estate uh one thing primarily we will be using this to search stuff right as i said these are all read-only queries we want to find this stuff means we'll be searching now i'll start with something negative you know you might not like me for that so do not do this as i said you know do not run this saying that search cpu means go to every database every table every column all rows and find the cpu case insensitive right so not a good thing for you to do if you have large collection it might take some you know longer time plus you'll be probably paying for some compute this one i'm restricting right now i'm saying just look at this table as your matrix again i'm looking at all columns case insensitive sorry case yes case insensitive if i want it to be case sensitive i need to mention this that i want the case sensitive search now this is a finally i'm restricting myself now i'm saying within azure matrix look at the column name named metric name and give me this again i'll mention that as you see here showing the first 10 000 which i told you it will always do that and time ranges last 24 hours i can do exact search with equal equal i can search for two different things with the end operator now this is first time i'm saying as you can see a time generated and notice this as soon as i click here [Music] bill is that a comment for me or no say someone else sorry yeah it was uh it seemed like it might be so jim o'neill was one who asked the question about the pricing and that one seemed to be uh pricing related uh if it has to do with cpu credits but i'm not actually sure yeah uh no i was just i i didn't mean i was just searching you know just to show exact search so um if you see that you know if i come here see this automatically says that"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:45:32",
        "seconds": 2732,
        "text": "i'm not actually sure yeah uh no i was just i i didn't mean i was just searching you know just to show exact search so um if you see that you know if i come here see this automatically says that it's last 24 hours here now you can see that it changed to set inquiry right now here i'm saying that just give me for last one hour right and it says that my time range is set in in the query but again within the last one hour i have more than ten thousand records and it's gonna only show me the first ten thousand i can do a wire and and one thing is unusual here uh it's giving me that alert again so let me just mute my phone so i don't get okay you can use three where clause this is something uh you know i don't know many uh programming language you know some of you probably know a lot more than me i'm primarily a t sql based and a little bit of c sharp but in t sql i cannot have this this will give me a syntax error i cannot have three word clauses but here you can do that or you can replace this by hand both works and there all you see as you can see is pipeline so it's going to take this reduce this then reduce the radius so it's always better uh if you have a if you're restricting it by time i would put that at the top so reducing your set um like you know if you work with sql server i'm sorry to bring you know sql server example that's what i work most if you're looking at a execution plan you always try to reduce your data set at the beginning of the query right on the right side of the plan so the rest of the plan has to work with the smaller data set you don't want to work with millions of said and at the end you know put a filter that uh you know reduce the set from one million to a thousand right you want to if you can do it at the beginning of the query that's better so here is the same deal if you are addressing your time range uh you know you want to do it first i i don't know if you bring it down you know someone asked me uh is it clever enough to do that before right um i you know these things doesn't have any query plan or stuff i cannot see behind the scenes so i really don't know if you know sql server i could tell you exactly what's the order of the operation but here i do not have that inside yet this is a syntax that you can use if you're searching in the all the columns there is some support for regular expressions i just wanted to mention that so you can run this and see that you know you can use it uh take and limit is synonyms so it's just a you know just give me the top 10. um keep in mind we always alert people when you're using top statement without order by uh you have no guarantee um though you keep seeing the same result set uh sometimes people think that you know there is order it's really not it's just bringing it you know what's in the memory is serving you the same data because that pages are already in the memory but there's really no order it's just a random 10. you can have a bunch of where clauses and then at the end you can decide when to just see top 10. count obvious is going to count it you can again combine count with other predicates obvious summarize this is pretty much what we call in sql t sql or or sql is a group by so i can do account group by metric name and i can also as you can see this column name is not very friendly it's count underscore i can give it a friendly name if i want to that also works now count by metric name uh i can group by with multiple columns i can also have aggregate functions so i do have a group by here but i'm also using a max value so for each one do a count also give me the maximum value for each bucket as an extra column i can do that i like this one bin it does a group by but then it also slice it you know based on what i'm passing here so what i mean by that here i'm saying you know do this per day now if i'm trying to troubleshoot this something you know select per hour so when did this thing change now it's going to give me per hour and then i can you know put this in a chart right and if i see a deviation probably will tell me when things start going wrong and you know if i do not like this i'm not sure the minute is the right syntax probably m i can slice and dice it every 15 minute chart it go"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:50:32",
        "seconds": 3032,
        "text": "tell me when things start going wrong and you know if i do not like this i'm not sure the minute is the right syntax probably m i can slice and dice it every 15 minute chart it go to more granular right as you can see you can see a pattern here probably so bean is a very you know powerful for troubleshooting i can also have calculated columns here i'm saying you know give me the headroom total minus average um so 312 is kind of weird for you know for for for a cpu i don't know it's because probably like it has four core uh that's a possibility i'm really not sure uh you can do project so what does that mean like you know we always say uh you know do not use select star right because if your schema change behind the scene you don't know always put your column names uh here's something so they're a bunch of columns that by default whenever you're looking at any collections it gives you certain columns but there are a lot more columns and if you do not want to you know if you do not want the default ones you want some particular ones you can just say give me these column names means it's basically saying select this this this column name from this collection so it's just going to give you those column names and you can combine project uh you know with a calculated column and give it a you know your your own name and what i'm showing here is even though i'm using a calculated column here with headroom total and average it shows total average and my headroom right so if i go to the right i'm showing total average and also headroom but if i say i do not want to see total on average i just want to see headroom so i can bring this up and in my project i just have headroom not the total end average and i can do that there's something called project away which is very interesting that that that t sql doesn't have something like this uh what it does it's saying give me all the columns except this so i don't know equivalent you know i haven't seen one uh which is which is new to me so projectile is saying give me all columns accept this uh distinct i'm not going to run this it's similar to any other language just give me the distinct values you can do a sample distinct so this is like no order uh just give me random 10 distinct values out of this collection you can do this in t sql but it's just two different keyword or two different operators but here you know they have a built-in one okay this is a top 20 by now i have a you know order so means i'm going to get you know definite result right it's like deterministic not not not random sort same you know very obvious now one thing you'll see this with these collections a lot of time there will be columns with json there will be columns with xml uh there will be columns in different format and some of those uh are not you know pretty to look at or pretty to query on right or when you are sending your alert uh to the person who is looking at the alert if you send like a whole big xml or or a json uh probably not very useful to them so you can parse some of those data and uh so i'll show you a couple of examples here uh no this is this is not doing that so yeah okay so parse number one i wrote two of these because recently i've been noticing that microsoft is not sending data to the event collection yep there is no data there so it stopped recently so i just wrote something and i know i'm getting ahead i did not explain what is let let is pretty much declaring a variable type you know table one column with the string data type i have couple of other examples how to use let but for this one as you can see i'm putting all these you know key value pairs right adding those into this column but then i don't want to send this data like this and i want to you know pivot this or or twist it to a to a column and and and you know put those values there and there i can use parse and then i can project those names so if i run this it will be more clear as you can see here now i have resource name total slice slice number i have this in each column and now i"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "00:55:36",
        "seconds": 3336,
        "text": "project those names so if i run this it will be more clear as you can see here now i have resource name total slice slice number i have this in each column and now i can you know have further query if i want to look you know if i'm looking for anything that i want to alert on you can do that uh between um i wrote this one interesting because they also have a you know i don't know if not between is a t-sql syntax but here you can use this symbol and say you know i want to between this and i do not want between this so uh two dynamic if you have a json column type you can use two dynamic and you can only extract the key value pairs that you want so look at this column extended property right so if we just run this and try to right here extended property as you can see right i have this compromised host username and all this and i do not want you know all of this data i just want to get resource type service id i just want to get this for alert name and time generator so i can get this by two dynamic uh and i put this into an array and then i can get those the one that i want i can extract those and now i'm getting only those key value pairs that i want in a column it's similar you know i have xml i have all these data i do not want all this i just want some particular you know key value pairs i can use parsex ml and get those extracted i put bunch of print statement with datetime because all of these collections will you know starts with the datetime column so if you want to present your daytime in a different way you want to parse it and whatnot so i just you know put a couple of examples here uh and then again you know like you can all kind of you know values from the date time column if you need this uh i know if some of your you know using without you know using data warehouse i'm sure you probably have a table something similar for daytime series and then you can use it to you know to do a bunch of things i'm going to take a detour here just to show you that i showed you i think couple of charts uh using the azure data studio i just want to show it here again and that you know these are built in you can use render column chart time chart you can also do it from the portal i showed you a few times so again you know i think and there's also you know some feature i think is built in here that you can change your chart type and stuff uh and if you do not want that if you just want data you can just do this it will give you your you know their data there um so these are some of the examples number three this is these are also a little bit advanced aggregation uh i'm not going to bore you with this uh you can read those by yourself and and you know just just run those and you'll see and i put for each one also each operator i also put url for microsoft documentation for everyone so if you want to read more see more examples please go to these urls and you will see it uh this is a couple of examples as i was saying with the let uh so again as you know we just saw that the event collection is not populated so i'm not going to use this but i have another one that that you can you can run and see declaring variables and you know stepping through these i'm not going to read this but this one is a little bit interesting so especially um let me get a little bit more real estate so especially if you came from t sql background we know that by default when you're joining two tables you get a inner join right if you do not say what kind of join it is and then of course you can do our join left outer join right outer join and what not uh kql by default does not do an inner"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "01:00:40",
        "seconds": 3640,
        "text": "say what kind of join it is and then of course you can do our join left outer join right outer join and what not uh kql by default does not do an inner join and that was a surprise for me so just to show you this on the left side just keep a note that i have twice april right so i'm doing a left table right table i didn't have to say that the join kind is inner unique because that's default i just said it to make clear that this is doing a inner unique so if i run this we got five rows we only got april once on the left side if you do a inner join which is default in t sql or in sql in general see that i got april twice okay so just bear in mind if you are doing a join between two tables uh keep that in mind uh just to show you another example the power of you know late statement so i'm looking at some cpu and memory data i'm putting those into two different data set and then i'm using both in the in the third one i mean it's not obvious always that you know just for demo purpose i'm looking at you know a correlation between cpu uh and memory can can i uh ask a question about that yes go ahead great thanks uh uh i was waiting for an example and i'm not sure this one is one that uses two tables oh this is correlating across um i'm sorry i didn't read it fast enough the first time i don't think my question quite applies here yet uh but these are both off the we'll call the perf table yeah you probably i think your question will lead to can we do a cross to database and i'm talking database here very loose term metaphorically yeah yeah yeah yeah that's possible that's possible i probably do not have an example here but i think if you go to that query explorer in plural site probably in m7 or m8 you will see bunch couple of examples cool thanks i'll check it out yep these are pretty there's something still not available in log analytics workspace but i'm pretty confident that it will be coming soon that is if i'm querying the same data set over and over right do i go to and fetch those every time so right now this is available in azure data explorer what you can do so let me get out of this come here if you are using this as a service you have this materialize function you get i think par i don't remember the cache size is a five gig i know that but there is a i think it's power uh not log entries workspace um i i have to go through i i'm following the right term uh so it's it's you know you get five gig and uh here if you see that i'm just giving it a name random set and i'm going to put this data into this and then i'm using it three times so it doesn't have to go back and fetch this data three times right you can it's a caching mechanism so that's available and as you can see i did it three times and if you go to this url there's more examples uh here it is getting it from the storm event collection and you know it's going to do a count and summaries and then it's putting it into the detailed data and now it's then you are using it and then you are joining to itself you know to look at uh you know some more data so you you can do this there are some some caching mechanisms uh built in there i will commit to all of you that i do not work with any of the machine learning stuff but some of you are probably doing it so for you folks uh you probably know these algorithms you know they're very common basket is one and auto cluster and i think basket is you know we all know you know retail industry probably use it all the"
    },
    {
        "speaker": "",
        "title": "Monitor Azure Resources with Kusto Query Language with Taiob Ali",
        "videoId": "6u-yWHNBCAg",
        "description": "This is a recording of the January 28, 2021 virtual meeting.Monitor Azure Resources with Kusto Query Language Need to Monitor Any Azure Resource? Must Learn Kusto Query Language.Kusto is a service for storing and running interactive analytics over Big Data. Kusto was designed from scratch to be a “big data” repository for Azure and easy to query using Kusto Query Language (KQL). As we make progress in our migration to the cloud, we are learning new ways to monitor and alert on resources and services. Microsoft has consolidated many services under the umbrella of ‘Azure Monitor.’ Whether you are ‘detecting and diagnose issues across applications and dependencies,’ ‘correlate infrastructure issues with Azure Monitor for VMs,’ ‘drill into your SQL database monitoring data with Log Analytics’ you will be using ‘Azure Monitor.’ Azure Monitor uses a version of the KQL used by Azure Data Explorer that is suitable for simple log queries but also includes advanced functionality such as aggregations, joins, and smart analytics. Going forward, the KQL must be your primary resource for querying the Azure Monitor log. In this 95% demo session, I will show you some ‘getting started’ tips and a few sophisticated queries using KQL. I will do a live demo, generating an alert using KQL. At the end of this session, beginners will have a solid knowledge about KQL that they can build upon by themselves; others will also learn many advance operators, including machine learning ones. Come and learn about the future of monitoring and investigations of Azure services.Taiob Ali, Microsoft Data Platform MVP, is an accomplished technical leader with a proven record of success. During his last 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, including massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning. Taiob is currently working at “GMO LLC” as Data Solutions Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences. He is a board member of New England SQL Server User Group, DBA Virtual Group and organizer of Boston SQL Saturday.",
        "start": "01:05:43",
        "seconds": 3943,
        "text": "you know they're very common basket is one and auto cluster and i think basket is you know we all know you know retail industry probably use it all the time right uh they're trying to find out you know what things they should put beside bread what things they should put beside you know bread or egg or whatnot right during christmas they want to figure out you know what are the things they put it together what are the things they put in the front what in the background they're always using this algorithm so these algorithms are actually available using with custom query language without doing anything you just evaluate and then you you know give your algorithm name and if you have a threshold you pass that and i again as i said you know i copied this from this example but if you go to this url uh you know there are other ones that you can read uh what are the algorithms they you know is allowed as of today so you you can just use those as as is so if you can see this one you know these are a couple of you know security events uh if you want to see that you know what kind of you know event id you are getting and you know how frequently you are getting what percent of this of your total and if you change this number um you know you you the weight of your groupings are going to change as you see now we shrinked it right if you want to go you know see like more smaller buckets uh you change this now you're going to you know see a larger result set again like you know just as an example this is telling me about my patching uh you know how much in compliance what are installed what not and if i want to say no this is you know very high level i want to give me more granular you can change that and you can see those i do not use this i'll be honest i just thought i'm going to mention it in case if some of you are using this machine learning algorithms so the last thing can you export this data right because uh for whatever reason right you might need that so if i run this so i should have used this now i have this data i can come here i can save it export to csv i can do a bunch of stuff so if you are into power bi i will just show you something this will be the last demo and before you know when i get this talk last time actually you had to do this query to power bi and then what do you do i have to go and get an advanced you know data source and paste all this right it comes with your source your your your cluster name and all that and luckily you do not have to do that anymore so power bi now have a connector for this hopefully help i should have given the query i did not okay let me go and get my inquiry system events you can bring you know all the data you can write your query you can filter it uh you know i'm again i'm not a power bi person uh but i just thought you know i'm just going to mention it in case if some of you are working on uh you can now directly bring this data and then you know build your dashboard share it send the links to people whatever you need to do so that's all i have before i go back to my slide let me just show you one more thing because i mentioned this few times and i can send this to no this is not my account just give me a minute i just want to show you where the where you can find everything and i i can definitely send this to veronica bill and jason if they want to you know put it somewhere or send you another email with this but where am i now okay i did refresh this just two hours ago as you can see so everything is here so if you just go you know sql worldwide and then presentation under this uh download play with it you don't need to ask me you know whatever you need to do feel free so that's it so i do not have anything else i'm just going to bring up my i'm just going to bring up my contact page again in case if anyone yeah so that's all i have um you know let me know if you have any question comments um if you you know when you download stuff if you can you know if you think of anything just send me a note and as i said you know if i do not know the answer i'll try to find it for you uh just keep an eye on the azure data in azure data studio there's going to be a bunch of kql extension is going to uh i think expand there's going to be a lot of you know good work is being done hopefully one day we can just directly connect to log analytics workspace without all these hoops and you know pull down data and do visualization there so so uh that was uh fantastic uh does anybody have any questions like to lob at him before we wrap this up okay well i guess everything was 100 crystal clear to everybody as usual uh uh that that was great and and you do you do a fantastic job of just making it so easy to continue the the quest after you leave because this the rich set of resources is you know just so uh well thought out and complete so appreciate that you've launched us all any of us who want to dig in further into uh cousteau made it easy uh last last uh last chance for a uh for a question you can come off mute if you like or you can text it uh well uh we'll wait a few seconds in case that happens i'll mention uh that two not two weeks from tonight um uh about almost four weeks from tonight on tuesday today's thursday the next meeting is on a tuesday february 23rd we have uh how does uh azuma azure cosmos db work under the hood hassan savran will be our uh guest uh speaker there so that's the next one to sign up and we have the number of other ones coming online after that as always follow us on you know meet up and you'll "
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:06:11",
        "seconds": 371,
        "text": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?. This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.. so again welcome welcome back to Boston Asia this our second virtual event we're trying to adjust to coronavirus just like everybody else but and hopefully well-well figure out how to get over all the technical difficulties a little bit at a time I'm here I'm joined by Jason Haley who's earth boy she already heard and Veronica calls Nicola who between the three of us we do most of the running of the Boston Azure and North Boston Azure groups and we're joining forces for this while we're in virtual mode and our hope is to have an event like this every couple of weeks we had one two weeks ago and we have one planned for like it's not exactly two weeks in tonight but 13 days from tonight so on a Wednesday and then we have another one queued up after that we're gonna try and keep it going whereas I mentioned the technical difficulties which is always fun as we you know shift into a new delivery approach so if you have feedback for us you know of course reach out use coding out loud at gmail.com for me and you can reach us on Twitter you can see our twitter handles here but for the groups at least it's actually putting out the greatest way to reach us personally though I'll think about that at the end well actually in slack is a great way to reach out just know that that's what I was about to talk about next so we're trying we're meeting with new technologies of course we have teams and there's a chat feature on teams you can ask questions on teams but we also want to experiment with use of slack as a side channel during the meeting so if you join the Boston as your slack and you see the pulley the bitly link is on screen it's a bi t ly slash and then all lowercase be a slack short for Boston I just lock if you follow that link you can with a couple of clicks you can get an invitation to the Boston measures like project and then once you're in there you can go to a slack Channel that's name - just for tonight which is called it's a it's called Dom it and I think I've thrown the name there that's called meeting - 30 - APR - 2020 I'll have to fix that and then so you can I'll be in there Veronica or Jason the three of us will be kind of running in the background with well our guest speaker is doing his thing and so you know comments on the meeting how it's going if you have questions we can queue them up and maybe answer some of them etc so it's our you know we're still try to figure this out that's our that's our side channel so it could join slack just to notice you know if you do ask a question you may show up on the video recording of this this is being recorded and we do plan to publish to the youtubes we're not sure every talk will be published it depends on certain things but there's the possibility that if you have a question in there you may appear there so just FYI be warned all right so without okay good all my points here without further ado let me switch into introduction mode here we're we're very glad to welcome back to Boston as er into North Boston outer he's a repeat visitor here and we have a slide here for him this is Toyo Holly and he's a sequel MVP and he enlightened us in the past about remember one of his excellent talks was on dr with Azure sequel DB and he has expertise in many areas and we're fortunate enough here tonight to hear him about sequel agents and what do you do when when you don't have one so I'll let I'll let him you know further introduce himself and join me in giving a warm virtual welcome to our second ever virtual speaker table ally will do it golf clap thing and hand it over to you sir thank you Bill I think you're just saying Veronica for hosting me and I think this is the third time I'll be presenting to one of the group I drove in once I think I presented to the Jetsons one other one other time in Cambridge so but thank you for hosting me again so let me share my screen"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:11:15",
        "seconds": 675,
        "text": "presenting to one of the group I drove in once I think I presented to the Jetsons one other one other time in Cambridge so but thank you for hosting me again so let me share my screen it looks like there's a lag between yeah you're good there's definitely a lag between if you're watching a live video versus what you see on your teams there's like a 20 second delay yes I'm just gonna wait for the screen to come up but I can start and I thanks others for joining and you know pad yourself in the back because you know after a whole day of work I know its current situation you're working from home with a lot of challenges with children you know home has become a playground a school workplace office and then you know you were hanging out at 6 p.m. which you know you should be you should be proud of yourself at least you know there's no I think about it and I have four here at home to take care of my wife and I both work and so it's not easy so we'll be talking about logistical database and as bill said what do you do when we do not have a secure agent and this was a challenge for me it's still a challenge that I haven't solved all my problems as am I getting to Azure cloud slowly you know I'm figuring out things so I thought you know some of the options that I figured out and I played with I'm going to share those that might help your journey to cloud a little bit easier so we'll probably talk for about 20 minutes and then the rest of the time I will show you demo you know between different options so one of the question I get when I you know talk about this people will ask me and I ask that to Microsoft long time ago I remember you know why bother with this why can't I just spin up managed instance where I have sequel server agent and if you look at the pricing the way they priced the edge of sequel database and a managed instance so to get the same compute and same storage in a managed instance you will be probably paying twice and Microsoft knew about that and that's how they priced it because they don't expect everyone to move from on-prem to managed instance so but you know if you can afford the money go for it and then you do not need many of the stuff that I'm going to show you but you know if you're like me work for a company that has a fixed budget trying to save money then some of this will help you out okay so we will have a problem with the slides because you know I'm I move to the next slide but you guys can't see it so I'm just gonna talk about that and when the slide comes you know we are we did it say it's the nuisance I understand but I think that's the fact of the technology that we are using today so a little bit about myself the next slide and I don't want to spend much time if you want to take any note is my contact if I do not answer anything if you have comments or if you are to follow up further you can use any of this method LinkedIn Twitter email me you I have a contact page on my website you can use that and I can assure you that you know I'll get back to you probably within two days max so why do you use sequel server agent you know I always try to avoid business logic to run by sequel server agent because there are other enterprises scheduler that people can use like I work for a financial industry a financial investment management firm we get a lot of feed you know every day like lot of data a lot of raw data from different places and they need to get processed overnight for the fund managers to look in the morning so we use something called tidal and if they need to run some key signal I you know I help them write it but I rather you know Enterprise a scheduler schedule so in that case if those fail is because I do not know all the logics of the business so someone else you know from the expert we the application can look at it because for me the only reason I look at it is it fail and I have to wake them up so why not you know they get that out at the first you know in the first place so some of"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:16:18",
        "seconds": 978,
        "text": "because for me the only reason I look at it is it fail and I have to wake them up so why not you know they get that out at the first you know in the first place so some of this stuff that I put here that I use sequel server agent on prim or I have been using for many years I listed those and if you are moving to add your sequel database I think many of this is still valid right if I have a long-running query that if I you know if I see my average for last week was X and now if we're running if it's running 1.5 X on the same time of the day of the week I want to know if I have an important process that's blocked by something and it's time-sensitive I want to know I might want to party all data in batches index maintenance you know nowadays it's a people have very strong opinion you can see in the public blog even some of the Microsoft engineers are coming against it so it's up to you you know you might have a case that you might have to do indexed materials you might be on the other side of the fence but definitely updated status updated stats is a big thing and I'll show you a couple of demo that we still need to do even though we move to edge of sequel database so how do we achieve this while you are on Prem it was pretty easy for us right we write the code either integral or PowerShell we go to sequel server schedule it and forget about it we set up some alert if it fails you know we can get a lock so very simple now I'm moving to add your secret database we don't have that option so what I'm going to talk about is most of the people today in the cloud journey either probably in a hybrid mode and what I mean by that they still probably have some hardware some secure server running on Prem and some in cloud and some people might say now when I talk to people yes we moved in six months hundred percent and when you ask them a further question what model you are using most of them will say that I'm using a is model and when I say is is infrastructure-as-a-service means you get the VM from Microsoft but you still can decide what OS you want and what version of sequel server one you know what patches you want to put it and you know you do not take care of the hardware directly but you take care of your operating system you take care of your sequel server version so if you look like as in on-premise equals never so if you still have those around you can leverage those and we'll talk about it and if you're a hundred percent cloud then you do not have the option you know some of the option that I'm going to show you but for those folks I'll show you some of the options that are totally you know cloud services so let's talk about some example what can we do on Prem if you are using on-premise sequel server we can create a link server pointing to as your secret database and once we have the links are established we can do pretty much anything we do with on Prem sequel server so if I have a link server I can collect information from there I can have sequel server agent jobs pointing to that now if you have many of those right if you have hundreds of thousands of logistical database you have to create a link server for each one and that might not be ideal right to maintain all those eager those through those might not be a easy task then PowerShell can come handy because in PowerShell with different modules now you can look through objects pretty easy so I can a bunch of link servers and I can put them in object and loop through those and do whatever I want to do so that can solve one problem other way you can do a combination of PowerShell and you can use Windows a scheduler and if you you can use an on-prem host or you can use I as VM with Windows the scheduler you can schedule a date and time or any frequency one and you can call a partial function what that PowerShell code or your own fashion can go through all your as your secure database and do whatever you want all you can use the third-party scheduler like I say title there are other ones you might be using you can leverage those using your link server pointing to your sequel database I already talked about is model so it really doesn't change much so but one poor admission that I saw some of the people use this solution say you have few hundred edge of secret database and you"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:21:23",
        "seconds": 1283,
        "text": "already talked about is model so it really doesn't change much so but one poor admission that I saw some of the people use this solution say you have few hundred edge of secret database and you really your company's goal is to go to you know either pass or in sales model but not a nice model and when I say pass means platform-as-a-service means you do not get a hardware you do not control your OS you do not control your secure server version you get the sequel server engine and you just and you get compute and you work with it so if that's your company's model you can always spin up a single VM install a sequel server and use that agent pointing to all other edge of sequel database and do your work do your maintenance do whatever you need to do that can be a solution the last one is the pass so if you do not have anything and you were dead against that I do not want to use any on-premise and I don't have anything we do not want to use honest model and you're totally into pairs so there are automation which is a service itself as your function yourself a service elastic job agent is a combination you still use the edge of secure database because for elastic job agent to work you need it you need add your sequel database to host your metadata and I'll show that and web jobs so I'm not going to talk about web jobs you know I myself is not a developer you know not a full-time developer but I have seen that people using word jobs to solve some of these problems I just mentioned it but I'm going to show demo on the top three in pass model and if you want to know that you know what out of all these solutions that I'm talking about what resembles like our on-prem MSD be right so MSD be Database kind of holds all your metadata about your sequence every agent all your job definitions job schedules and all that elastic job agents looks pretty similar and actually I think Microsoft copied some of the code that go against them is TV and I'll show you some of those objects that created once you turn that on and they look pretty similar to what we see on Prem today so I talked about link server the next slide is coming up it's going to show you a picture that you know how you can design this so it's no different than adding a link server today to our on-premise sequel server that it point to a different sequel server in this case you'll be pointing to cloud to your address secure database and then you know it's pretty much same as what you do on Prem today and the next slide I'm talking about a combination of PowerShell and Windows the scheduler so I'm going to skip this slide you guys will probably see it for a second and because I'm going to demo this so the next we're going to talk about agile automation and then audio as well as your automation itself is a service as I said before if the cloud-based and you do not need to maintain any hardware for it you do not need to acquire any hardware you do not even need to acquire any compute power it's all you know it's all built-in for you as a package and the primary component of automation is a run book and today you can run him you can write a run book using PowerShell or Python and if you go to the PS gallery which you can do it from the GUI and from the portal which I'll show you there's a PowerShell gallery and you can actually import many one books that people already wrote and share there and you know you can import it to your automation account and you can modify or you can write it from scratch and also you can write graphical run books which if you ask me that something similar to like if you created SSI packages you can drag drop different objects and you know glue them together you can do something like that you know if you do not want to start writing from scratch and I'm not going to go into details into run book types but if you go to this route I definitely will argue - look at this - major difference between a powershell run book and a PowerShell workflow run book and the main difference is partial workflow run books can"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:26:26",
        "seconds": 1586,
        "text": "route I definitely will argue - look at this - major difference between a powershell run book and a PowerShell workflow run book and the main difference is partial workflow run books can keep its status so if it fails you can restart from that point it knows where it is and but a PowerShell workflow it does not preserve its state so if it fails you have to start from the beginning you can also like I said you can also have Python and books you can schedule run books one problem with the scheduling runbook that I find if you have a time-critical sequence every agent job that you want to start at a certain hour minute and second this would be a problem for you because once you trigger a run book to run it goes into queue it acquires the compute and then it is start running so you really cannot pinpoint to that exact second in run books you can share a lot of resources like crucial certificates connections you create those ones many different run books can share those there is source control integration there is run as account you can create and then you can take that account and you can give it privilege at a different level you can give it to individualize your sequel database you can give it your resource group you can even give it as a subscription level so you do not have to give it to all the resources under a subscription I'm not going to talk about this very fair interested look up a Jewess run book can also manage your on-prem resources so today if you are setting this up you can even come back to on Prem and manage some of your on-prem resources like your VMs your patching you know some of your compliance requirement you can manage using the run books you so okay let me so you have a lark so I'm just going to read you know what I'm looking at my slide so with a as you're out Commissioner can do a couple of things you know definitely you can you know Schedule E repetitive jobs can save as you know time and money because you know you don't you don't have to do the same thing over and over you can also you know maintain your patching so like your Windows Linux systems or if you hybrid environments by runbook you can do you know do those tasks - so next I will talk about function apps and when I first look at the function apps as your first app is itself a service I was not encouraged because you know before they ignite last year I could not use PowerShell in edge of function apps so but in ignite you know they announced and I'm going to show you a demo today how we can use PowerShell pointing to edge of sequel database and we can do a updated stats or you can reveal the index using a function and one function ops first you know I looked at it there are a couple of limitations like as you can see on the screen the max runtime was 10 minutes and you also didn't know you could not reserve compute for yourself so every time you trigger a function you have to wait it goes to a queue same as that you know you run books before it is start running now with the premium service you can resolve your own compute and those will be reserved for you of course you'll be paying for those but the good part is you do not have to wait as soon as you trigger you run it is going to go on the computer and he's gonna run and language was it can use c-sharp Java JavaScript Python and PowerShell again it has continuous integration with github DevOps you know so you know whatever source control you are using it will work with those so the next slide I'm talking about few of the stuff that was announced in 2019 in ignite and I think the big thing is they're guaranteed pre-warm instances to avert cold start and you"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:31:28",
        "seconds": 1888,
        "text": "those so the next slide I'm talking about few of the stuff that was announced in 2019 in ignite and I think the big thing is they're guaranteed pre-warm instances to avert cold start and you can have up to 60 minutes of runtime and automatic management of the dependencies and what I mean by that so if you have a partial function or you you're sorry your function is depending on a selective EA tools which is a very famous open source free library for managing you know sequel server assets and you wrote a function that dependent on a version that's not dependent on any version say you want to get the new version when they release it you do not have to do anything it will automatically get the new version for you but if you are a version dependent and say like just pick an example you get a minor version dependents a 3.8 and you mentioned that in your code it will not update and if you say I am NOT dependent on minor version I am only depending on the major version and you can say 3 dot is star anytime a new minor version get released your function app will automatically manage those so you do not have to manage the dependencies which is pretty cool so one thing when you first write a function and you run it for first time you will see that the runtime is they'll be longer because it's really getting all the dependencies and setting this up for you so next we'll talk about elastic job agent and it has two components so what first you need a elastic database you need to add your sequel database and Microsoft has some recommendation I put a URL at the end you know what size of obstacle database you should get minimum and that database will save you metadata Sol your job definitions your targets and you can also write your output into the same edge of circle database say like if I'm collecting like all my other sequel database size I want to collect that you know frequent interval to check my growth I can bring that data and write it so you can write it there or you can write it to a different in your DBA warehouse and in my demo I will show you that I'll have two database one is for my job metadata and I'll have a warehouse or I'm going to write on the outputs so what can be a target for your elastic jobs your target can be a single as your sequel database your target can be a logical server means all the databases belong to that logical server you can have a elastic poll so every database in the realistic pool will be a target so you can have a job that will go and run against all as your sequel database belong to that elastic poll so in your job DB database you clear your login you create credentials then you take those skills and your targets and you give them appropriate permission or privilege say for example you are just reading then they need to be a part of the DB data reader group member of their group if they have to write something modify something so you are is the same as on Prem right if you want to account to do something it has to have the right permissions so exactly the same concept so I get on the right side of this slide I show you the four major component we talked about you need a job agent will show that target group job database and your jobs and you can also schedule jobs and the next slide I just copy pasted from books online I have the URL at the bottom is just giving seven examples of different combinations of target what your target can be so one thing I didn't mention when I talked about target I can have a target of elastic pool or a add your sequel a logical server and I mentioned that all databases will be member of the you know of the target so you can exclude also so you can say okay go against this elastic poll but exclude db2 as you can see on the third you know on the left side on the third one there is a red X it's saying that do not deploy my code against db2 the next"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:36:33",
        "seconds": 2193,
        "text": "but exclude db2 as you can see on the third you know on the left side on the third one there is a red X it's saying that do not deploy my code against db2 the next slide I'm showing that some of the tables views and disturb procs that we created when you turn on your elastic job agent and if you see some of these like on the third block you will see that it says SV star job that's pitstop job is the update job they are pretty similar what we have today on premium is DB right we can go open SSMS and we can set a star job and we can give a job limit it starts so so and and and if you look at the code they are pretty similar to what we have on Prem today I'm going to move to demo I'm done with the slide so for demo I'm using 2019 on Prem sequel server it's eu4 I'm using SSMS management studio 18.5 the latest version of a Visual Studio code to show you some of the PowerShell and partial core 7.0 bill is probably a good time to take any questions if there are before I move to demo excellent idea so I I don't think we have any questions queued up in on the team's streaming side I'm jumping over the slack stick quick look I'm curious you mentioned this question for me that you're you know you just mentioned the tools that you're using I'm wondering if you have any experience with Azure data studio which seems to be a computer you know competing offering our newer offering than the sequel server management studio yes it's a good question so I've been I been started using Azure data studio mainly for notebooks so some of the you know I find it it's really helpful you know if I have to send a piece of code with few line of simple data you know I don't have to send a thousand rows see if I understand the query with the ten rows of data I can package it with some comments and send it to people I haven't explored if any of this will be I be I'll be able to do with that and I also think that in a long run probably in a year or two we will see a merger of management studio and Azure data studio today it's not there there are very specific use cases that when you should use what especially for you know for us who are operational DBAs one challenge is with the execution plan I know sentry one has a plug-in I think there is a little bit more work to do so I don't know if I'm answering your question but I haven't explored to mimic any functional gear sico server agent with with agile sequestered your translator question directly okay yeah thanks for the context and I'll remind the audience that you're welcome to drop so there are no questions at this time if you have questions folks please either drop them in the slack in the meeting specific Channel or directly in the teams and we'll pick them up at the next table so back to you Tori oh sure and you know we'll have some pause and I'll be running stuff against cloud you know there's certain times we just have to give it if you know a few seconds and I can answer those questions during that time so great will so we'll show it take that taking that out so I'll feel free to if there's a like a time-sensitive question on context I'll interview at a pause sure so one thing I did again you know there's a lag between my screen and your what are you things okay so before you know we started the meeting I ran this whole setup code and just so you know all of this code and slide I'll send the link to Jason our bill after this meeting and you can download as is do whatever you need you don't need to ask me feel free to use it if you have any feedback send me you know to improve them I'm very open about it so I ran all this code that you see on this it takes about 30 plus minute and what it did it catered to as your sequel server bunch of databases and you know loaded some data I and because I do not think it's that prepared for me"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:41:39",
        "seconds": 2499,
        "text": "it catered to as your sequel server bunch of databases and you know loaded some data I and because I do not think it's that prepared for me to you know keep you guys here and show that I'm running this so this is pretty much set up and what I did I put everything in a resource group and this is a good practice if you are not you know working with Azure for a while you put everything in a resource group at the end I just go and remove the resource group that way I do not have to go and delete every resource the manual is just a good you know good housekeeping especially if you have limited money you know this can you know your money can you can expect it a lot you know if you you know delete your stuff after you're done so as I talked about the first one we're going to talk about using linked server so I'll start the demo when you guys see the screen and here I'm using a on Prem 2019 cycle server we'd see you for and what this is skip is going to do before we do anything I'm going to be creating a DBA database on Prem and I'm just going to appear their small table to save my database sizes and I'm gonna pull this database size for my edge of sequel database in cloud I wish this was the lag was a little bit less but just period me so you guys are looking at a recording right now because I have another computer I logged in as a attendee so I already then that is script and you're kind of looking at a recording right now so I'll probably do the next part so as you saw I peered at that table and next I'm creating a link server and this link server is pointing to a vertical database what I just created with my setup script you so this is pointing to my ug demo target server which is in in the cloud and using that link server let me run the script first then when it comes down you guys should talk it's probably a better way so now I'm running this script using the link server going to cloud and getting the database size and I saved it locally so now I'm looking at the result as you can see that look at the local time you know I converted the UTC to local just so you can see we just collected this now you might say that you know I do not want to bring the data to my own pram I just want to use the link server I want to keep it in the cloud within my addressable database so next I'm going to show that so what I'm doing now I'm connecting to my critical database and I'm creating a similar table into that database where I'm going to collect the size two you so here I'm connecting there I'm creating this table you cannot use the user statement so you always have to be in the right database context when you're using management studio for addressing of database so now I created that table now I'm switching back I'll be switching back to on Prem you so what I'm going what are we doing here I created that table in logistical database but now I'll be using the link server from one Prem round this physical it will grab"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:46:43",
        "seconds": 2803,
        "text": "created that table in logistical database but now I'll be using the link server from one Prem round this physical it will grab the size but it would save it in cloud over there within the same database and we can look at that you you as you you will see that table I'm going to show you in a minute so I I restore adventure words from the sample back up as a sample database and I created that table but from one pre-miranda size collection of the size and it was saved into this table now you know we are only dealing with one database so it's easy for us but as you can see that in this instance itself I have for edge of sequel databases and if I want to collect the same from all four I have to have falling server and I have to go through those you know which I do not find very nice to you know to do that way because eventually I'll end up with hundreds of links server so what I did the next solution I'm going to show you using a PowerShell function we're going to use the same query that we used from SSMS to collect the size we'll be using the same thing but you we will go to our resource group and using a loop we look at every as your sequel database that belong to that resource group so you'll go through every other secure database every other secure server go to every other sequel database and collect the same information and here I'm scoping it to a research group sequel agent demo but you can take it one level up you can go to your subscription also so let's run this and sorry okay so I'm running this now it should go through all those databases collect the size and save it in my local instance you so let me run it I know it goes a little bit behind so I'm going to come back to management studio and if I run the look at the result you know the same table you can see the time is 1854 let me read for you guys to see that so from that partial function is wrote into this table and as you can see the time frame and now I have data for all the tables so it went through the both server as you can see different server name and went through every database got the size and pulled it into my local instance and saved it there now if I have to schedule something I'm not going to be sitting into my PowerShell console and run it manually every time so what I can do that exact PowerShell code that we just ran using a windows task scheduler I can schedule it and in that"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:51:46",
        "seconds": 3106,
        "text": "do that exact PowerShell code that we just ran using a windows task scheduler I can schedule it and in that way it will run whenever I want you know once a day or whatever frequency I won also I can go there and run it manually and we can do this in an on-prem windows host or with the iris VM so as you can see this job is actually calling a PowerShell function that we just saw and if I click the action now you see that it's calling partial or Exe and it will call that that piece of code that we just ran from visual studio code and you can see their status now it's running and once it finishes if we go to the management studio you will see a bunch of new records with 1856 our time stamp means it collected another round of you know sizes for their circle database now I'm just showing you an example of collecting the size you know I'm sure you're not you know that excited I were just collecting the size of your databases but you can replace my code with anything that you know you want to do and you know it will perform be updated stats and you want to part your data you know whatever you want to do so next we were moved to add your automation before I do that and show you in management studio two things that in the job database you currently we do not have any tables because I've only created the database name job database but I haven't turned on the elastic job agent so you will see that there's no turbo right now also under the stirrup receiver there is nothing and I'm going to turn that on you I'm gonna use PowerShell to turn a realistic job agent and then we'll come back to the management studio and we'll see all the objects that you're created you you it's taking a look okay it's done bill I know we have some pauses so if you see any question you're gonna stop me especially the lag I have more positive than I expected right hon yep we're monitoring and [Music] don't have an ear to report at this point sure you so you know you will see very soon that under the table you will see a bunch of new tables got created also under the stirred procedure you know the products that I showed you before in the slide all those will show up and now we are ready to clear jobs create our target"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "00:56:50",
        "seconds": 3410,
        "text": "before in the slide all those will show up and now we are ready to clear jobs create our target groups and do whatever we want so I'm gonna keep this here and in the interest of time and reduce some of the lag I'm also going to start setting up our add your automation account and it's the strip that I will be running from PowerShell and once you have a automation account created then you can start creating your own book and schedule those ran works also so this is the script which you know you will get when villain just send you the link so this already got created so we'll go to the portal for first time and see what we have there so you created automation account name you still showing up here yet you eugie demo tool you you okay start a mission icon got created you'll see there on the screen in few seconds I'm just going to wait for it to come up and once it's there we'll go to run book and I created a demo run book and I'm going to edit this because I do not want to type and the whole thing right now so I have the code right here I'm just going to use that code and again I did not run I did not write this from scratch as I was telling you I downloaded this from the gallery and I actually get carried I kept the you know it was eaten by Microsoft employees and in 2014 I downloaded and then modified it a few times based on what I needed and as you can see here they're a bunch of variables that I'm gonna declare and just for this demo purpose as I said fragmentation percent is 20 so if in the database there is a table name test revealed if there is an index that fragmented more than 20 percent it will do a defrag and it will bring it down now again I said you know people have very strong opinion about index maintenance if that's something you do not want to do that's fine but you can take this framework and you can replace your code with whatever we need you need so now I'm going to set up a test table in one of our agile sequel database and we will see that it's different it's fragmented and we'll use the run book to to fix it so here I have a database name test run book dB I'm just creating a table inserting one thousand rows so I'm connecting here to my Azure SQL database"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "01:02:00",
        "seconds": 3720,
        "text": "so here I have a database name test run book dB I'm just creating a table inserting one thousand rows so I'm connecting here to my Azure SQL database let me repeat that so there's a database name here test run book DB cheering it's small table one thousand rows and then I'm gonna update it again with some other value and we'll see a fragmentation of our 40% now you can see there is 39.8 and will go to the portal execute that run book we'll come back here and see if this got fixed and though we are correcting 3s SMS we are actually connecting to our single database everything happening in cloud so we saved our run book I'm going to a test thing and this is a good thing that you know you can write your ronbo you can save and you can test all from one place and as was as I was saying before when I was running my slides as you can see it skewed right now so I really do not have a control up-to-the-second that I wanna run it right now you know I'm kind of dependent on you know this to get on a computer resource and to get completed and now you see completed so there was a lag between when I press the Run button and when it is started it goes to Q then run and then get completed so now if we go back and check the fragmentation with the code that we used before we'll see that it's down less than a percent so if I like and after my test I can now go and schedule this for whatever time I want to run this so you're done with this I think our last thing is our sickle-cell very elastic agent that we set up so we're going to play with that I think I'm not going to run through all the demos because you'll get the code and you can run it by yourself or what I did on this piece of code I did set up all the permissions before the session started because they are pretty simple one as you can see I'm just kidding login you know I'm adding those into the role member I'm creating credentials and giving them access to all my targets so I'll not run those code where I'm going to start is from line 81 or line 84 I already ran the permission setups so here as I said I'm creating a way let it drop there then I can explain so right now to do anything I need to be connected to my job database because all these store products that I'm gonna run they only reside in jobs server in the job database I mean the server name can be anything I just gave it a name just so it's obvious for us and you always have to have the right database context because you cannot use they use a statement here so now I added a target group we can see that our target group it's a server now I'm adding a job here and I'm putting the traditional names my server name and hard to put down put now I can look at the job definition in you know in Java steps and I also started the job it's the same T cyclists mr. job and I can also go and look at the job status and well after I start the job I can go and look at a job status whether its sister running I succeeded failed you know it's an awaiting a state as you will see here that even though I ran one job but it"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "01:07:04",
        "seconds": 4024,
        "text": "look at a job status whether its sister running I succeeded failed you know it's an awaiting a state as you will see here that even though I ran one job but it shows that you know there are six rows because one is your job and then it clear daily steps because it's working through all the sequels all the databases in my target group and they all succeeded and I wrote the result into another database name Divya warehouse so we'll go and look at the result they are see if we did what it's supposed to do you and in this style in this example I'm really not collecting database size anymore so there are two DMVs that come with every other sequel database the colored performance metrics so your CPU IO and everything the one one only keeps it for 15 minute I think the generality is every few seconds and the other one keeps it for over an hour so this will be a good one if you have a performance issue you might want to collect it for you know for a few minutes and see what's going on as you can see that you know if you're into the into the warehouse so in this you know in the code I have other target groups I have elastic pool and and other stuff so I'm not going to run through this because they're pretty much the same concept you create a target group you create your job and then you can schedule your job or you can run it see their status and then you can go to the warehouse and you know look at your target now do you need our house no as I said before I can write it into the same database it's up to you whatever is your you know your test so I'm gonna skip running this I put enough comment that you should be able to go and you know run this by yourself and if you have any question again like reach out to me you so next we will talk about function apps and function up again if so it itself a service so but you can leverage this to maintain your agile sequel databases and one good thing is and I'm not going to explain this in detail I recently put this in a blog post how you can use the so it's a service it has its own identity you can take this identity and you can give that identity make it a user in your Roger sequel databases and give it proper privilege so when you run your functions you can get a token and use that token to do your stuff and what is the advantage that you do not have to pass a username password inside your function or you do not have to keep it in your source control so what I did here I set all this up before that but I also gave you you know with the court set when you get the code you will get a full set of code for this function and I put enough comment that you should be able to use it so as you can see this function app name is vast and as your demo and when I enabled that setting what it does it clears the active directory object with the same name and what you were seeing in the screen right now I can go to my other secret database and I already did that on the test run book dB I said cleared user Boston edger demo from external provider means it's the ad account and I gave it a DB owner make it a member of DB owner now I make it a DB owner you don't have to depending on what you're doing you can make it a member of other groups and now in my function if I go down and I wrote comments you know how you can use managed service identity and I put three URLs you can read about it there"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "01:12:08",
        "seconds": 4328,
        "text": "in my function if I go down and I wrote comments you know how you can use managed service identity and I put three URLs you can read about it there are some tutorials and also have a blog post that talks in detail about this so now what I'm doing here I'm going in getting a token and I am using their token in my connection string you know pointing to that as your signal server to the database and using that token I will go and altering that's all on the test rebuild database and I know you know you're not going to go and reveal all the indexes like this I'm sure you will have some criteria but if this is just a sample you can replace that piece of key sequel with anything you want to do so I'll go back to our demo database that and I'm going to create more and I'll fragment that index more and this time you will see a 98% percent fragmentation then I'll go and run the that I wrote and we'll expect that that function will fix the fragmentation so now you can see that I'm running that updated statement and I'm checking the fragmentation on their Azure sequel database on the table and it's 98% fragmented and we'll go and run that function that you saw the code I put it as a function here and I'm expecting that function to fix their fragmentation and you can also schedule this these functions you don't have to come here and write it and run it every time you can schedule it like our sequence of agent jobs you so it's done you can see at the bottom now we'll come here we'll check the fragmentation again and it should show that it's zero so I'm going to go back to the slide I'm done with the demo is this a good time to inject a question sure it's the perfect time okay great if I if I need to have a schedule that creates a backup of my database and I want to store it somewhere like blob storage for compliance reasons and maybe want to you know a permanent immutable copy there what would be the best way to do that so now as your secret database you cannot take it back up the way today we take backup on Prem Microsoft create backups for us automatically there are two different type of backups one is point in time one is the long-term point in time it can go up to 35 days max as of today for a long time you can go up to 10 years if you need more than 10 years you can reach out to Microsoft to make some arrangement just for your you know your subscription or your resource what you can do if you really need something there's something called backpack you can look at that that's really not a backup you really spitting out all the objects and saving it and you can deploy it against you know or you can restore a shell you can clear the shell land and deployed against that so I don't know if that will answer your question but even for complex reason like I told you I work for a financial industry very highly regulated up to 35 days I can get your point in time with automated backup and now you have long-term refresh and backups setup that I can go back up to ten years okay so whoever asked that question do you have any follow-ups please let me know but I'll make sense to me Toyo thank you for for that let's see if there any others it's a big question about I guess it's kind of back up related to but any comments about the uses of geo replication as a that's really all it is asking I don't know if you could mention"
    },
    {
        "speaker": "",
        "title": "Taiob Ali - Azure SQL Database - Where is my SQL Agent?",
        "videoId": "7IpL_uEGwcI",
        "description": "This is a recording of the April 30, 2020 virtual meetingYou migrate your on-premise SQL Database to cloud, taking advantage of the PaaS offering of Azure SQL Database. You heard the promise of spinning up databases on demand and being able to scale up resources during high peak and scale down when not in use. You also want to make sure you are performing integrity checks, index defragmentation, and statistics updates when necessary. There is no SQL Agent, so how do you automate your jobs? Do you have time to do this manually each time? No. There are different options available to automate these long-running, manual, error-prone, and frequently repeated tasks to increase reliability, efficiency.In this demo intensive session, I will show you different options on how to automate these tasks. Some of these solutions use on-prem infrastructure and services in Azure, which are conveniently encapsulated within the collective Azure portal experience.At the end of this session, you will have a solid understanding of how to automate SQL Server Maintenance tasks, including replacing SQL Agent functionality with multiple options.SPEAKER BIOTaiob Ali, MVP Data Platform, is an accomplished technical leader with a proven record of success. For 14 years, he has worked with the Microsoft Data Platform and MongoDB both on-premise and cloud. His experience includes all three major business sectors: finance, e-commerce, and healthcare. Taiob has hands-on experience in managing large database projects, massive data migration, intricate process design, testing and deployment, performance tuning, long term capacity planning.Taiob is currently working at “GMO LLC” as a Database Solution Manager, focusing on cloud migration, automation, improving, and streamlining operational workflow. He is a regular speaker at local and virtual PASS chapters, SQL Saturdays, and Azure conferences.",
        "start": "01:17:18",
        "seconds": 4638,
        "text": "it's a big question about I guess it's kind of back up related to but any comments about the uses of geo replication as a that's really all it is asking I don't know if you could mention a little bit about that I guess yeah wait sure that was the other talk that you were talking at the beginning that I gave to your user group is a high availability solution right so or a disaster recovery right so or can be both right so it depends on your requirement so today when you spin up a single database by default you get three copies but you are not guaranteed to get three copies doesn't guarantee you data center redundancy so if you want data center redundancy you can have so the term is not coming in my head there's a squat some group you will still be within a region but Microsoft will guarantee you that your three copies are three in three different data center which has different power different cooling so you have data center redundancy but you still do not have region redundancy so what will happen if all the data center of Microsoft that belongs to a region like a leased us to central us or East us is not available and you need that kind of redundancy for your business then yes you can set up always own availability group it's pretty much the same concept as on-prem and you can failover to a different region and now Microsoft also recently released availability group set so you can have multiple as your sequel database though they are all you know individual databases sitting in a shell of a logical server but you can group them dependent you know pile app so if you so like before this if I have three apps depending on three there if I have a tab that depending on three other secure database I have to fail over these three independently and that might bring some inconsistency on my app for transaction now I can create a group and fill them over as a group and you can also have a little only replica like we have on Prem so you get two URLs and like on Prem we have listener over there you actually get two URL once you put both URL in your connection string you do not have to do anything during your failover it will automatically find out who is primary and you read write you write traffic will go to primary you can send yuri traffic to your to your read node in a different region I don't know if that answers your question if you want to know more ping me I might have that whole slide deck that I gave into Bill's group I can send that to you there are I think the the the title of the talk was a disaster recovery for hadr or disaster recovery for or high availability for as your Sigma database you know I had a couple of other options that I talked about talked about that might you know because this all comes with a cost right like I have apps or I'm sure you guys have that our business say you know if it's down for 24 hours now we are okay with its internal app or we can rebuild it from scratch so you know we can run our processes again and we can rebuild so for those apps we are not doing you know like the whole region redundancy we are happy with the data center redundancy so it all depends what you need so we can we can definitely talk about that excellent thank you I got the thumb up indicator so I think that that clarified the question and there's one final question here is you've shown number of different techniques for replacing the functionality that your sequel agent would handle and you've shown different automation approaches you personally have a preference of functions or vs. run books for example like what's your go-to yeah so my go-to was a adhirata machine before they ignite 2019 like I said because you know I'm not a c-sharp developer I'll just commit that upfront you know I can write it sequel pretty good I can write PowerShell and that's how I do most of my you know monitoring alerting long-term trending so when they you know they declared that PowerShell is going to be supported especially the security model that I talked about managed identity I think this will be you know my my go-to solution okay fantastic thank you Toria that there clears the question queue so I'm not gonna talk about this slide you just been up I'm sure you guys looking at it so again so it's basically all I'm saying it's multiple options say you know it said you can have hybrid approach multiple language you know you limitations you know what's your strong point where you are comfortable where you company need you know think about all those and one thing you want to you know think through the way even you know as you're monitoring is a big part of this right monitoring alerting it all come as a package the way I'm trying to you know design for myself today you know I cannot give you exact number I have you know I don't have numbers in hundred of secure database I'm in tens twenties but I'm trying to design this in a way that after one year to eighty five hundred or more than a hundred or two hundred I can still scale this I do not have to redesign so just keep that in mind before you make a final decision but play with all you know some people totally comfortable with the elastic job agent to give you an example but why I did not say that as my go-to choice because it doesn't suffer partial today you know and that's a kind of a showstopper for me because I have many many scripts that use partial and you know with the DVR tools and all that so so that's why I looked at it it look you know pretty appealing because in everything look like as on prime but you know I got I didn't like it because I couldn't use this so I created a another slide with all the resources if you click one of these it will take you to a URL is either a Microsoft documentation or you know most of these are Microsoft documentation that I found helpful and you know can give you more details then a one-hour talk and so here's that slide and then you know the next slide will talk about my contacts again affinity I think reach out to me I'd be happy to answer and you know thank you all for attending and thank you Jason Veronica bill for hosting me for third time I do not take this as guaranteed and I appreciate that well if this was a live in-person event I would I would stand up and lead a on applause but we you know audience can't can't speak back to us here today so on behalf of the audience you know so virtual applause back to you Toyota this was a very informative I I've been using Azure and sequel TV for a long time and out of the the prior talk that you gave in this one I picked up a number of things I wasn't aware of so it's educational for me which is a bonus and on behalf of Veronica and Jason and myself we thank you for for coming and educating us for the third time over I'll look forward to having you back in the future the question queue is currently empty if folks have them please blast them in there pretty quickly where we're gonna go in the wrap-up mode here and just so that just to recap in a little less than two weeks on Wednesday May 13th that's a Wednesday not a Thursday Wednesday May 13th at 6 p.m. Eastern Time we have Kevin Griffin who will be talking about 21st century background services with Azure logic apps and add your functions and you'll see the description of that appear in the meetup pages so you can read more about that there but hope to see you in in a couple weeks then we have another one that's scheduled for a fortnight after that and we'll get that posted as well so thanks everybody for attending stay safe out there and once again big THANK YOU toyou appreciate the talk good night everybody stay safe and to no time over now oh Claire "
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:00:13",
        "seconds": 13,
        "text": "Udai Ramachandran: Azure Private Link. This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.. yes you can speak it loudly blow into their ignition so be a lot of topics in the past that we're trying to do more topics upcoming months so you can check it out oh okay so okay i'm going to pick it up for that but yeah now i'll speak up yeah so here is the azure cosmos tv that i'm giving the training visit from the comment box so you can visit these lots of training and the certification program so one of the certification programs that i'm also delivering for microsoft so you can check it out i'm going to start my presentation so today's topic we're going to talk about the azure project link any of the use of supervising no yes you do yeah how you doing so he's the favorite link okay um so that's the topic that we can talk today this is a little bit about me and i'm there for ramachandran shortly called me today so i work for a company called like kimi nasi sigo i'm also responsible for security privacy and compliance that i will come together briefly um i want microsoft azure meps of january 2022 and i've been working the cloud for about 10 plus years uh focused on all three cloud training you know mostly focused on the microsoft but i have a particular experience on other cloud and we built a lot of sas product which stands in a multi-cloud environment it's primarily focused on the cloud and dotnet and that's my personal page today dot io you can talk about the little bit about virtual network basics but we are not going to spend all the time on understanding the virtual network but this topic needs some basic understanding of the network so which we i know we will assume that we all know and then we're going to dive into our private endpoint yeah then we can talk about the private link and then preventing services in some of the use case scenario some diagrams how we can use it and then i would bring a real scenario real-world scenario that i have been using with my customers um then we will do something about our customers so this is the virtual network basics you know we all know virtual networks are the basic new service networks creating the network and when you get a network you need a subnets you can define one or more subnets then you need a nic network interface then you need a network security group you know how you want to flow your traffic then you will have uh you know nat and source map and then you will have a load balance and then you have an express route if you want to connect back to your on-prem service right so those are the basics of eventually everything is a pretty big topic but we're going to assume a high level we know these topics right so now to dive into a service input to enable a service endpoint we need a return so you you if you create any services it can be a platform as a service like um you know azure storage or cosmos tv and as web apps you name it any service that runs on the platform systems by default when you create it's publicly exposed right so you control the axis by using the original if you can't figure okay it is not public endpoint i'm going to enable this to the particular return so any surveys are virtual machines that configured or belongs to that virtual network can only access right so service endpoint is nothing but you making that as a private in a microsoft network but still your platform services are populated so you create a storage account it's still going to have a public import if you have a consumer's degree student have a public impact they are exposed to the public someone knows that you are they can try to kill it but they may not get cleaned access but they can still see that this is a protecting point service and point you know secures that by using the general so those kind of security that service endpoint enables is also important to understand if you have a web app that's running in non-service end points you will also get the outcome um because of these so there is a 150 outdoor connection you can go from any web instance but if you don't have that personal network enabled on a service in point you hit that threshold so fast and then your application try to look so so a lot of people realizing not realizing right so that 150 will hit a very fast say for example you request a page that the page makes see like a 10 connection to a cosmos db"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:05:16",
        "seconds": 316,
        "text": "then your application try to look so so a lot of people realizing not realizing right so that 150 will hit a very fast say for example you request a page that the page makes see like a 10 connection to a cosmos db file connection to ready another file connection to storage now that one page is now enabled to turn the output so we have like a 20 year across to coming in 400 outdoor technicians now only 150 connections data time is allowed everything else is used to resolve the problem it is always recommended to go through the current network points so you don't have the religion right but still you will get into some sort of limit of memory or cpu but at least it dissolves that that outbound issues it also secures your service to the private but still those platforms cost more than that they are exposed to the internet but you you control the access and that's where the private endpoints coming right so the private endpoints you bring the services into a private time so now you create a storage if you create a storage account you look for the industry lookup of the storage that console is going to have a public eye but once you enable the private endpoint that storage account now will have the private type so if you pivot um you know a cidr range you say 10.0 dot whatever the range you assign is going to be one of the id within the solution right so you bring every any services it used to be you know like a few services two years ago but if you look at it now almost all the services you can enable the primitive so you bring all your platforms your service into private uh you know but you can gain that access into uh you know you can bring a lot of hybrid scenarios like connecting to on-premises um using the express route or you can use the ms express and then you can bring the private express route and so on right so and it is also a single direction meaning that you only go from a one direction you have platforms and services on a certain network you have the another network they're trying to connect using the private endpoints but it is just one direction not the reverse system invoke the other other side of it um you can have multiple private endpoints created using the private link resource and we will see in a demo when you see that demo it definitely makes sense it can use the same are different um subnets or you can use the same on different virtual networks you can expose this into another virtual networks or another regions you can also expose things into another subject so that's the concept of now coming to a private link so if you look at the service endpoints the service endpoint means the same exact thing but the services are public the private endpoint brings all the services in good private the private link what it does is enables the platform to communicate to the services that are hosted in the private the year three council to get service endpoint which is you securing your platforms and services to connect securely using the virtual network or configure ip address but the services are exposed to apartment private endpoint makes all the services to have private ipr it's not a topic at five years but you will have the dns but those dns is not exposed to the public they are assigned to a private ipa so in order to expose to the public you need a public id right but in this case they don't ascend here uh public ideas they only what private line link does is it runs on the private endpoints but it enables the platform that you can communicate to the services that are posted using the trading points so that's the concept but now this private link can connect to the private services privately posted to on premises or to another network or to under the subscripts so if jay has another subscription that running on his machine i have two services that running as a private end point in my subscription i can create a private link service and give it a thing he can still communicate to my service secure because my service is running private this service is coming in private but now we provide a link i exposed to him and then i approve that link and now he can connect to my private service over the microsoft i'm not going to go to the property the cool thing about microsoft network is it's you know very fast so key benefits are you know there is a two concept here you know the private link is a platform that uses the private endpoint um there is another concept called consumer consumer is nothing but who is consuming that credit links right so as it is the provider if we create a private link then we are the consumer if i am creating a private link as a service and giving to somebody else and those guys are with our girls are the consumer but i am the provider okay so that's the concept consumer privately connected to your service by using the credit and private endpoint provider render the service um you know by by using the private link or private privileged so i when i create a private link link microsoft users might provide when i give"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:10:20",
        "seconds": 620,
        "text": "that's the concept consumer privately connected to your service by using the credit and private endpoint provider render the service um you know by by using the private link or private privileged so i when i create a private link link microsoft users might provide when i give my all the you know services that run begin the load balancing i give it to somebody else and i become a provider somebody else consume my services so there are key benefits you know privately access services on the as a platform um you can expose the on-premise network and connect um data leakage right so this is very important data leakage is very important so if you are not protecting those services private now i can go to my home network and i can close to the service and trying to export it by making that as a private private but nobody can access the data outside of my network now i have more control who is accessing the data so once i bring everything into a print date now i have to you know nobody can access to it i'm not going to add that ip address but everything is a private but what we do in the secure networks we bring everything to the private in order to access the data some reason you want to query we provide them another it should be concept so they have to get in the console by using the password script they can do a lot of copy paste getting their return machine and then they access it now if this gives a more control nobody can connect using the connection screen from outside of the network but they have to come into a network they have to get into the virtual machine then they need to connect to the data source but now we have a lot more control over them so when we have a compliance requirement like assad those compliances it is very important that the data is not expected nobody is seeing the data they are copying it taking home right these things provides an extreme security of your money very simple to set up global reach um extend your own services if i have my services i want to expose my private ip yes i can do that that's not the private link services um you know it uses the approval every time you create a private link somebody needs to that approved by default if we have a full contributor rights it's going to pull it by default or you have our back enable it's going to upgrade if not then it will always come back to the next one or to upgrade they're not they're not sell for true but based on your outback role as you create it's going to approve or waiting for them so here is the private link over so if you look at this diagram there is a two way you can make the workflow working for you one is the manual other one is automatic so i am the owner of my subscription so it's it's going to upgrade for an automatically but if i have someone delicate as a you know different role then they will create the link then i will have to go and upload it so if you look at this case consumer is i'm going to assume that my subscription is a consumer me as a consumer as a platform as a services provider right so say these are the providers for example you know cosmos db storage or anything you know radius cache or you name it um so now you create a private end point right and once you create the private end point it's going to see send to the request to approve or reject as i said before and i belongs to the owner road it's always going to approve it otherwise it's going to put them in a queue for someone to approach it so you know you approve it and are rejected based on the decision it's sending back to the client okay software authenticated then the credit link services that's how the privilege now the private link service is coming so private link services you package your private link that using the load balancer so you can bring the load balancer that can be using the public front-end ip or private fundamental when you say private prototyping you have a website running behind the you know internal load balancer so you're always going to have a private type because you don't want to expose that to the public cloud now you want to package that as a solution and sell it to somebody else now private link service is the platform that enables them now you create you you you create a private link service and then it gives the id of the preventing service from the other person another another subscript is not necessarily the same another person another subscription they they create the privilege endpoint again and then they use the id that you passed once they put the id passed in you know then it knows what the id is you can manipulate that id it's out of created id and it's going to send a request for the provider to acquire a reject so once you approve they will be able to communicate back to your your internal services that the package is part of the private link services okay so if you look at the private link service workflow over here so you can enable that back to on from services by using the express route um it can be you know you know ms express and then you can use a private private express route for the faster network and you create all those things over there right so if you look at it on the on the left hand side we have the clear the"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:15:22",
        "seconds": 922,
        "text": "know you know ms express and then you can use a private private express route for the faster network and you create all those things over there right so if you look at it on the on the left hand side we have the clear the you know so subnet so we have the services created over there right now the provider says take the provider network on the right hand side so provider network they create all those things and then they exposed it over here they they they're going to they're going to create that endpoint using the private link services how they can securely communicate right so the right hand side is the provider who created that endpoints run a lot of services running behind that endpoint they exposed to the public ip as a internal front-end ips one night to 168 how they can be able to communicate to that ip and resolution that privately when you hear the pivot link service it's also things in that stud map can be a static iphone you can fix it or it can be dynamic it can it can assign one form that's that's a high level so you create the provider creates all the services i have an end point that i am running behind my services i create a private link services then i give it to a consumer the consumer informs it and then the approaching scene or software chain is up to then they can work on it and they can also connect back to their own concerns because they have a express router over here they can so this is how you bring your hand from your consumer services in the cloud and then your provider services now how the private link services workflow works i think we already talked about it but you know say i'm the provider right so i create a virtual machine and then that virtual machine it can be a virtual missions or it can be a virtual mission skills right so and then it has to be part of the load balance that load balancer can again be an internal or copycat and it also can use a basic or standard but in this case the ipr trust that you assign has to follow the standard ipo okay once you created that um slb and then you you create a alien so once you create the link service it's going to give you the id and then the other side the consumer is going to take that id you you know you give in to the id to the consumer the consumer is going to take the id creates the end point he puts it over there then there you will get a reject you know request that you want to upload decline once you approve the request then they should be able to consume the connection okay so here is some use any questions so far there is three concepts you have to understand service endpoint private and point preventing and privileged services composed of those uh the key difference is service and find is a public services the platform necessities are public you can control the access through the uh you know your mutual networks or some restricted ips private endpoint is everything is fun now you you securely access into the private service by using the private link once you have the private link you want to expose the credit link into a market then you create the credit links let's look at the use case how it works so in this case um very simple use case which generator workloads with the custom dns right so you have the vm over here so if you look at how this pro works um the vm you know you you have a connection to you are talking to a sql azure database called ac sql one database windows.net that that is your public dms but that's hosted in a private ips they are not going to be assigned optical right so since it's a private dns it's also a sense the private university you're going to use the connection string acsp one database.windows.net but the microsoft resolves that and puts into their backline and then resolves okay this is pointing to the pivot network and then sending back to the other side so do you have to set up all the the dns entries no you don't have to you can fill it up but they they you know you have to create this but the names you can pick it up are there they can um not awesome yeah i'll show you the theme um so you you know it responds and it talks to the you know this is the iso dns ip address 168 190 129 16. you see you see it on the all the diagrams that we we have it so here is the vm that bm is going to talk to the sql server right so you have the connection string ac sql one database windows.net so if the request goes in look at it as a dns now it comes back okay i got it that resolved as a private link.database.windows.net okay now it's come back okay there is a private link and then it resorts at iphone 10.5.0.5. let's call it communicate so you send the packet to uh ac sql database.windows.net and then it gets into the microsoft backbone network and it resolves what it is and then it knows that is pointing to so a question on that one today so for that to for that configuration to all work um that means they're wrapping this so you have the v-net consumer zero one yeah um so you have the v-net and then you've had to connect"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:20:28",
        "seconds": 1228,
        "text": "so a question on that one today so for that to for that configuration to all work um that means they're wrapping this so you have the v-net consumer zero one yeah um so you have the v-net and then you've had to connect the sql server into the v-net so that means that in order to get to the sql server you have to connect to the v-net to communicate to it it's all it's all in part of it yeah so there's no way to not to get to that sql server without going through the jump machine or uh so you have you have to have the service that connecting to the secret part of that yeah ah if it's a different between it then you have to make a feeling got it okay so if you don't bearing it then you have been at one the service exists you have been a two which is a different uh cider rate right you want to expose the service to that another dinner then you have to make the feeding one and then you also have to enable on the privately also in a demo the privately i'm going to expose this into that peanut if you are like a 10 winner running in a 10 different regions you will have to expose this private link into all ten minutes then only it can connect so now it's another example over here you know custom dns server so if you look at it there is a two regions over here right so we don't want that whatever you are just talking you have unit one on the one region being a two on the two regions how they know that there is a sequel as you can you know sitting in a another region or common region or one of those two regions right the same exact diagram when you when this goes through these you know region one it resolves the same exact way so i'm finding it you're giving the dna public dns name it resorts to the private dns then it results to the private ip okay then it communicates back same exact thing happening on the other side it resolves the topic cleaners with private dns and then it gives the private ip to company but if you look at it over here there is a winner right so this sequel as you're sitting on a v-net over here and a different subnet but here is another v-net on the 10.10.0 here is the wiener transit 10.20.0 but sequel as it is sitting on a 10.5 so those three sitting on a three different enable the period so that it knows okay that is to sell these things strongly so here's a third example how you can talk to an entrepreneur assistant right without a custom dns problem like a dedicated dns formula so if you look at it over here the number one in link is from going from the on-premises mission okay look for the dns forwarder okay you know um i'm going to i need a connection to ac sql database windows.net it's going to look up the dns as the dns looked up as he said all the diagram will have that then it's going to resolve to the private link then it's going to resolve to the ip address of it and then returning back to that machine then it uses the express valve to communicate back to that right and then it putting back into that microsoft one now the same thing you know same exact thing but now you have the internal dns cell right so you know the previous diagram you did not have internal dns server but now you have the internal usb dns so now your virtual machine is going to go back to the internal dns server then receives the same input oh internal dns server is going to attack back to the international dns forwarder it resolves that okay rarities and then come back over here then it gives us the express route okay connect to the pivot link now here's a scenario five um the the difference is uh spoke model right so if you if you have the private network uh sorry on-prem network over here then it goes to the dns forwarder resolves everything but if you look at it over here there is a client bespoke so the one goes to the dns forwarder and also you know let's go to the client scope model here too so this is the 10.0.0 and that pi dot 0 over here but we have the clearing enabled over time right so there's another vm that's sitting on the somewhere in the cloud okay so what they're explaining is you are on connection how it works but in the same exact connection how it consumed from the cloud asp so this is this one is coming from the cloud this one is coming from the on-prem but the flow is remain same when it comes to the cloud it's going to go back to the dns forward or resolve and then give me what it is then i'm going to connect back to the sequel and from and go from on-premises just go back in as forward and give me you know give me that address and instantly use the express route to communicate tactics so how do you"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:25:30",
        "seconds": 1530,
        "text": "and from and go from on-premises just go back in as forward and give me you know give me that address and instantly use the express route to communicate tactics so how do you verify the private link are you really enabled right so you're going to you're going to type you know every service has the public indian class right so you're going to say it has to look up that service name you know it will never give you the private public id it's going to give you the privilege once you see that private ip address means it's a private it's not export to the public internet you have to have that network and everything created properly to communicate um you can also use the name resolver or you can use the tcp ping so that will show you how you see the public ip address then you are not configuring correctly or something um if you see the private ip address here's the new contributor so here is the demo scenario that you're going to want i'm going to walk you through today um so if you take this scenario we have a two regions region a and region b right i call it as eastern test uh for the region a i call it as a primary region and i also call it as a data residency because that's where my army data is and then data region b i call it as the jio which is mainly for the high availability and the traffic receiver from the closest proximity but i also have a services running over there um it's optional you know we may have a storage account but in this case we're going to have the storage account on radish cache and keyword but all the other services are options but this is one scenario that we can call a higher value right so if you look at it how these two knows how to communicate you have to create a private link you have to enter the claim so if you do all those things you you expose you you enable the pairing and then you expose the private link on both network then the both network can see each other they can they can start communicating to the success so region b can connect to region a services vice versa on a failover on a real no otherwise they can talk to their own services region detox all right let's look at some demos here i think i'm going to set it again yeah i've seen the room seen my bald head in the video so i have a resource group here um i know i i think i can walk you through all the v-net creation but if i walk through everything that i created here it will take approximately if i spend some time in creating anything uh but as i said before we could assume that we have some knowledge of creating the first thing what you do you create a virtual network i'm not going to complete it but i'll walk through a few steps and then you're going to set up the idr range so if you say i already took the two three and everything so you can say that zero dot whatever was there and then equal 16 which is 250 then you define a subnet in this case you're going to define a more in in our example today we define the multiple subnets one subnet for the database uh like a data other subnet for the virtual machine that we want to see what is going on so nobody can access it outside we do need to access some point inside so we have a virtual machine on subnet and then we have all the websites posting on another subject so submit three then we created two subnets for the function app and then web app to communicate as output you also need outbound connections so that if the function i'm trying to outcome to any of your fielding services they can output connection right so and then you pick the range so which is going to return 0.4 over here so i say then i start 1.0 expands for so 24 is the last one"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:30:36",
        "seconds": 1836,
        "text": "right so and then you pick the range so which is going to return 0.4 over here so i say then i start 1.0 expands for so 24 is the last one he said 32 it's fully done and 16 is you get a 25 up here and then 255 up here and you have to get it then you get a 250 payout here 255 here and then the multiplier okay but in this case no we create uh one subnet for web add it and then you keep adding whatever subnet you want say subnet for data define it you got it right so what's the servicing point at the bottom of that do you use that after the fact already see that on the subnet yeah oh yeah your interview is after the fact so when you create a when you create a subnet you tell them what part you're getting option a you can select the subnet over here say for example i create a subnet called data yes data right i can say i'm going to use data for the storage keyword based keyword answer data i'm going to select the cosmos db because i know that sounds great and then in our examples so you get the point but yeah either you can ascend it here or you can assign it in the services and every private thing but we are not going to complete so it doesn't have um and then go to the security you know you can do tds protection on firewall so that's how you create that so i'm going back to my already created virtual networks if i look back to my um you know private link demo eur stands for users and then i have another v-net demo wu stands for uh rest of this right so if you look at my east us over here one for data one for web on for another other one for function app i want out so whenever you you bring those uh web app function app you need out too because they are by tagging right so uh and then the s net um for the vms where i have some literature machines so we can see whether we are able to come in the same exact setup that we did for the best uh us okay so if i look at the subnets i have just but in this case the range is conducted because you can use that here these are another civil rights but it can be any different or 192 or 169 whatever okay so that's a virtual network um so we saw the virtual network these are the subnets right now let's look at the uh you know how we enable the service inputs then we will talk about to talk about your private point so i'm going to pick up the service maybe a storage account over here so let's take this sort of story when i enable a service in pond i go back to my networking um if i say disabled right i'm disabled completely private i'm disabled so if i go back to my private end points i have created a three private entities but in the service endpoints i shouldn't be having these credit reports i remove all the payment points my storage account will still have public id in this case i've added a private endpoints so it's all gone the you know storage account provides a multiple services right it provides a block it's provides a table it works and cue it for its files and so on right so if you want to bring you know they are different endpoints they are not the same anymore take and it's the same and equalizer.windows.net if you take a cosmos follow the customer's new task force but when you go to the storage account it has the block.net table.net2.window.net so you will have to repeat that creation for every sentence so in this case if you look at it i get a private endpoint for the block so look"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:35:41",
        "seconds": 2141,
        "text": "it has the block.net table.net2.window.net so you will have to repeat that creation for every sentence so in this case if you look at it i get a private endpoint for the block so look at it over here right you know so let's enable uh let's go back to this service uh i click on the network so if you look at it it's all network if you do this one enable from the selected virtual network and ip address then you are going to get into the services that's your service if you do this now you're completely removing that now you are stepped one step before you go into the privilege right so that you know that that's all you do let's go back to this um if i go check this name space over doctor one services then all of us are so this runs on results right so that's the public evidence right so that is not a private address it's a topic idea well thanks very much so now we go back to the networking and we create the you know you know we will disable it you know we will have to disable it in order to get interpreted network so we'll disable it uh unfortunately i can disable network so you go back to the private endpoint connection but you can create i already created for those three services if you want to create more then you can create so i'm going to put some name over here link and i'm going to say files dash uh you can have that link running in it that's not necessarily very historic because then you're going to communicate with the other network you can enable that link that's a platform so if you look at it over here i'm going to select the file service right and then i go back to the next tab now i pick the virtual network um it's going to give me the network based on the region that i selected so in this video i'm going to show you the subnets and then the subnet i'm going to select the data so i'm going to aggregate all the data services if you have a application security group how it's growing to our information applications and you can do that but this is a different concept they are not going to talk about it today and then it comes back to the dns right so this is where it creates that you ask your question here we need to configure that so it uses a dns okay that creates a new dns um so here is the thing that i want you to understand once you clear our one region it's going to do that right private link.file.com right our favorite link computer block it's going to private link that block.com but if you go to another region what will happen we're going to have a conflict right so yeah so if you when i was doing this very first time last year same time around the same time it was so you're not going to complete it and then you know you go to a tag and then review uh and then create it so that's how you create the pivot pivot in favorite endpoints for any given symbol so once you click on the private endpoint uh the few things to understand here is the dns configuration so if you look at the dns configuration this is your dns right but when you're going to communicate you are not going to say uh your connection string is not going to have a private link because it knows that the connection string is complete um that runs on the iprescenda 2.2.4 this is your network interface it creates it automatically if you look at it again gives you the ip address configuration in the network security group how it's configured there is no secretive configuration private service but if you have i know if you want to add some some services to be configured then you can do that look at the dns server i just moved there it's immediate from the virtual network that's what this clean so let's go back to um the services here right so this is this is our service right so block.windows.com so let's go back"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:40:43",
        "seconds": 2443,
        "text": "the services here right so this is this is our service right so block.windows.com so let's go back to what this services so this results address the i settings were a question okay that's right so this is resolving to aliases of that alias and it's pointing to the public ideas right but i'm not sure why this is if you look at it over here it says the true aliases i'm not sure why it's showing there but we will get into the virtual machine that's the private private let's go back so we configured that storage at on that's the same way we configure any service that we want so let's pick up another service called uh it's called a cosmos db for example go back to the cosmos tv you click on the firewall and virtual network uh you know you do the selecting the selected networks the first thing because you can do all networks right and then you go to the private endpoint connections and then you create a private endpoint so this is the question when you creating the services there was service name so if you follow this blade the very next screen will be for example i'm going to say something and go and explore the source then here that i have to select this source type so i have to select the cross motion okay that's the resources you are selecting so you enable the uh private links that go back to the third endpoints right so third end point add the private endpoint again as i said before private link is in a platform that uses the private info if you go back to the storage and not store it maybe a search index just an example so back to my search index over here again the same concept before you go to networking now you disable the public access first and then you go back to the private access and then you add one right so if you look at it it will tell you which network it's running um right so this is extended product seven um so here it is it is using the attender dot whatever name i gave it and then it adds a private link and then comes over now let's go back to uh web app or function"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:45:50",
        "seconds": 2750,
        "text": "so here it is it is using the attender dot whatever name i gave it and then it adds a private link and then comes over now let's go back to uh web app or function app so now we have the web app that running on the private network we have function after running on the preview we're all going to communicate these services and one of the service that i run this also belongs to another network that thomas on the best test sites if i look at it over here this this storage account they go back to my network um if you look at i completely disabled it but when i have the private network here so i have the approved network if you look at it that has a different iq okay so this is going to have one that's confirmation i also have two virtual machines one on the east running on the east which will network other one on the best running on the westminster before we dive into browsing that let me show you one other thing look at it on the function app okay let's take this one right the function so there is a requirement here if you want the function app to be a pivot favorite endpoint support it cannot be a consumption it has to be premium consumption plan you know you use it you pay only when you use it and then it scales you pay for it right for premium plan you will have to pay at least one instance function but then it will scale out you know as you scale scalar will pay for it for at least one instance if you're running one to pay whatever that size would be one instance of javascript this private endpoint you can only enable on premium i also enable on the remote look at the v-net integration it uses that you know 10.2 because it runs on the east network okay uh it runs on the subnet function you saw but while creating it last you what outbound subnet what you know what is the input subnet and everything you'll have to say because it's an app where it's going to communicate for the outgoing you know how it's going to take the inbound everything class um what i did here i put this function app behind the network so it only runs and it takes all the data all the bindings from the services that are running within the network are the network that experience so we enter the pivot end point we enable the unit content so if you did that same setup on a web app i'm going to when the web app's not visible to public network you have to use you set up the same thing on the web app the web app is not public but you are not going to receive it from the top it's also your facebook but if you use the latest trendo premium you can put all your web app in the private thing in tier let you connect privately to your button it can now route to your privately hosted one so you cannot directly access the web app but now you can go through the at that point even his service your web app cannot be the dividend point your web app can be a service input i mean because all the other services belongs to the same services network and you know if you have a services running on another destination you're already appearing enabled so you can now talk to all these things but once you enable the private endpoint to work with that now that the web app cannot be exposed to the outside to do that you have to go to the premium front door services and there they support um the back and full services part of the private endpoints instead of service endpoint now you select the pavilion points now they can come back to those so if you take a web app in in this demo i disabled it but you know you can also enable it back here so we have the private endpoint i need to turn it on once i turn it off this will click on the services [Music] but but you still have to put them in uh peanut indication so that it can reach out all the time so that's running over here so now let's go back and then one"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:50:55",
        "seconds": 3055,
        "text": "but but you still have to put them in uh peanut indication so that it can reach out all the time so that's running over here so now let's go back and then one other thing that i forgot to show you so if you go back to the d network look at the hearing so you can see that i'm talking to w uh this is this network is talking to a period uh with this [Music] yeah okay so that is done now let's go back to um go back to our services and we have a lot of services running on the private environment let's try to browse on opposition right so if i go back to go back to say storage account for example i mean you see a lot of links over here they are created as you paid a private name if you go back to this service over here you yes try to browse this endpoint of containment taking cloud i don't have access to it yeah i know i can access it the same thing happens with the cosmos tv for example any services in this case i put all the services go back to the data explorer come until the data explorer after that will tell you but i do have that i guess you can see more details in the bottom you can see you know either you requested that i theaters to access it or you know completely not so it depends on the problem now if you are running uh in a secure website everything is a private which is great but you do need something to access the data but you don't want to give that access to my topic ideas you want to control it within certain ideas in my case is what we do we control everything to go through a one virtual machine so what people do is that is enabled by just in time access whenever people want to connect they will have a customer now we know who is going to get into the team right so first level article is done once they get into the vm there is a diagnostic article you can enable all the submissions now you know who is accessing what okay so you have full control if somebody's trying to run a query copy the data you know they are trying to run after you talk to them here so you need to secure the data you really want to be able to meet the confined system now let's remote into vm i'm still able to connect this vm because this vm only enabled me the service input i did not enable the private account so you don't have to connect the vpn to get to it if i do a private endpoint then i have to yeah but i only enable the service input that's cool that's that's useful yeah because i need something to get into them right yeah this is like a jump post and then from there you can connect to that private endpoint yeah but then you have to whitelist that jump host address yeah because otherwise how it would know that this is a good job uh no because it's part of the part of the same one so i like that so this is this is what we do you know if you want you know this also needs to compliance people are working from everywhere everywhere you want to give access to your person how you give access to the person so you have the course running in a used us let them connect with this machine and they can access the data from business so if you look at the audit lock and the audit lab is going to say wherever this vm is that's where the access happened these actions never happen outside of it so there is a lot of compliance is required you will have to follow all those things so you can if i look at it and i install the azure storage explorer so i can look at the aka cloud here uh that's my container but now i don't know how am i able to see the data right so it's the same same container i was not able to do also so i have some"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "00:55:59",
        "seconds": 3359,
        "text": "at the aka cloud here uh that's my container but now i don't know how am i able to see the data right so it's the same same container i was not able to do also so i have some data i added something now how this overall functionality wise work put a very little demo here um you know i have a function app working on the yeast network which is this as soon as i file a copy over here my functionality of the data and move it to the west network which is also your pivot right so i have two storage account one runs on the east the other one runs on the best but whenever i copy your files over here there is a function app watching for the binding and it takes that stream and then move it to the investment so let's go back and i had a small files i can upload this file from outside i have to come into the post so i'm going to copy this file we also do this for our product because we were trying to use the um flop replica where the figure takes a long time yeah and then another problem is everything else can there is only one right the family can be right one region can be right every other regions can only be agreed that adds a latency when you're trying to connect say from india to a server that's located in the knees it has a huge lattice to come back so we will have to enable right on every regions through metadata and then they all limit some some of the events like our files based on the metadata we want to replicate the same pipeline so if the india region for example writing the file right primary can be the viewers but now it takes that file monitoring and then to take it back to all the services but now every host is the right course so from the metadata it knows no need to replicate back to the sender because there is some metadata there is it came from that link so you skip that so distributed processing yeah processing because to do a highly scalable performance system you have to run everything everywhere even the search indexes because in such index they don't give you a multi rank and it they only can give you a false dollar and a higher balance within a one region that goes down now you have a latency to replicate it back to other needs that's the one problem second problem is if you have a compute running in everywhere your search index can only know one reason now there's latency attached it has to come all the way from the traffic to reach this one so what we do is we distribute so we have one cluster running as the data comes in we use the cosmos multiply after their data comes in it runs the multiple search indexes on every region even if the one region is gone there is a typical search indexes pick it up but that provides you a we don't rely on the simple cat we don't rely on that because the microsoft person will have but the all the other cats are evil but there is a transgender happening more frequent but microsoft you need to handle the transfer that's impossible because i go right into one brief and there is a huge latency coming to right now one treatment because there is only one primary right but everything else is a replica but those replica on a high frequent mode like a highly thought mode it's going to have power more trans may take like five minutes to address the terms and we have a problem so you change the design we are not going to use that model this is expensive tool we throw small caches area now if you we use a condor once you hit the front door if it connects to the yeast most likely you connect it to the mixture never going to come out of east until there is a significant you know disaster companies i connected to uh west for example uh i'm i'm traveling to california i'm connected to the west 99 percent of them connect to the west because i'm there maybe i'm flying now but four hours later i may be connected to a different region but when i'm actively working i'm connecting the treatment so why do i have to route back to a centralized account why not i throw small cash in every region we solve the problem a lot of these little time problems by throwing a crystal things so this is one example so let me copy this file over here and it depends on everybody's scenario and requirements exactly uh i that happened so now my storage accounts are sitting in a private end"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "01:01:02",
        "seconds": 3662,
        "text": "and it depends on everybody's scenario and requirements exactly uh i that happened so now my storage accounts are sitting in a private end point my function i'm sitting in a private end point my storage accounts are sitting in two different virtual networks my function i'm sitting in a one which one how they were able to come perfectly fine that's but now if you look at the you know the services over here let's look at investment of this one now it tells you the ik addresses right but this is the dns book of service okay which you were talking about the diagram please always i have the dns it went and looked at it okay i see this but that now pointing to 10.3.2.4 and visit here is so if you look at the yeast one now that's another one is a three this one is a 10. so we kept that the two is the data on both sides and then we but as you can see this is running on the private right right so somebody trying to keep these now they're never able to reach this so now going back to the demo so let's re-talk about the web app right so here is the web um this is what we can access because i put that up into a private input go back to this mission over here are the mission from this perfectly able to find you know find it but now i still want to use these services but i don't want to be in the private and private network i want to expose this endpoint to the public that's where you're going to scale down to the service this so if i had two web apps one web app is say the front end another web app is really just apis could i put the api one private yeah keep the other one yeah because you your public one in the private on the same network are in a different network period yeah and now database it has nothing to do to go on service endpoint or get export right because it is going to be hit only by the application side so you expose your web app because that's where the clients are gonna hit and then you hit me up yeah now i remove the pivot and find brought on the service and fine now i'm able to perform but if you want to keep this entire your your property can find website and then do the api everything behind the scene then you have to use the front door premium it is a printout premium with asc not with the app you have to use the uh app service environment series will be slightly expensive that's how you use security but that comes another problem because you want to deploy multiply it and you have to go into the network and do all that that's why we don't keep it that way we are fine but what we do"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "01:06:05",
        "seconds": 3965,
        "text": "that that's why we don't keep it that way we are fine but what we do is we expose that as a public still when we use the pivot uh front door or we set the header only the front door can read you do that by using the by using the access restriction you go to the access registration go to uh you go to access restriction and then you add a little still exposed to this to a public or only the finder can uh build a request otherwise you're gonna follow through okay now let's go back to our private links so you saw the service and find them these are the private environments now you can talk about the private links and it's the last one right so if you look uh now in order to create a private link service you have to have a load balancer at load balance it can be a internal load balancer or a public load balance once you bring a load balancer it only supports the consumer only that concept uh i'm not going to explain how to create those things instead of what we do we will look at one of the load balancer okay so if i look at this road balancing now while creating the load balancer um of series or internationals um and then the tier can be original so then you go back now you do internal and the ip configuration is going to give you internal rates so it's like the next one and then you add the front and id configuration you give some name select the network based on the region is selected you know that you pick your uh it's going to fix tightly done liking this case right so i say add then i go back to the back end here and complete it and you can do all the configurations like the that must have a standard complicated is yeah it's kind of strange uh but you get the concept you add the machine or you have the scale set and"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Private Link",
        "videoId": "AJ-hxVHohjE",
        "description": "This is a recording of the May 26, 2022 meeting.Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. This session will deep dive into the following topics:  Private Endpoints  Private LinksAbout toe speaker:Udaiappa Ramachandran (Udai - https://udai.io) is the CTO at Akumina, a Microsoft Azure MVP, Cloud Expert, Organizer of the New Hampshire Cloud .NET User Group, and Speaker.",
        "start": "01:11:12",
        "seconds": 4272,
        "text": "yeah it's kind of strange uh but you get the concept you add the machine or you have the scale set and then you complete it right so that's why you create the load balancer once you have the load balancer means then you already put a vm that you could assume that you can't create a site in this go back to the some names go back to outbound settings uh now you have to pick up the load balancer which i'm going to be selecting something that will select you select it you have to create a new load balancer but i have created how do you get the console you complete this step and then the access security which is going to give you three steps uh it's technically uh anonymous uh anybody can access or access those who have the id or what they provided is or they are bragging okay so once you complete it's going to create a favorite thing so what it looks like when it creates a private thing for example you go back over here once you create it this is what you see the alias that you need is this you need to copy you copy this one and then when you create the step pass it will tell you do you want to allow any substitute i can say all subscriptions and anybody can see so you can go and see receive research or i can say um yes and upload required means if i give this id to you you go back to your old subscription so i'm going to switch to my android subscription over substitution um i have runs on another subscription is i was trying to browse this from this subscription over here which is completely different different any questions so far oh that's good i mean yeah this is called region one region two and then appearing very nice video over here internet conference two this has been really helpful yeah i've been using this now this is a critical point you're in a sas company right you have to secure everything right right no no i don't know from the customers right and we also uh technology company for technology company when you work with the customers you need to suggest just enterprise architecture and this is one of the really best layered approach from the security side and then you should be able to produce evidence and then have like confidence that things are secured at the same time scalability performance all those things are ground zero reality no matter what you have to face it's uh you know it's not hard it's very easy i'm trying to with the script for everything for in a software service module one time you said it already thank you so much man i will stop this morning "
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Derek Smith: Protecting Your critical Applications with Azure Front Door. This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/. uh to be here and thank you for having me uh i believe you saw me speak at the omaha user group if i remember correctly um so a good good group of folks over there but uh very happy to be here very happy to talk to you today um about the azure front door service and kind of uh what i'm seeing out there in space interacting with both clients that i work with as well as fellow users from that picture so a little there we go um so specifically uh we're focusing in on uh critical applications and the reason why i say critical applications is more often than not we're seeing organizations uh start to kind of pull back the uh i don't say the shackles but uh pull back the restraints on uh critical applications being uh left in an on-prem environment and even if they are still in an on-prem environment there are ways to leverage protections that are cloud-native and cloud-friendly even for those applications that for whatever reason we can't take them from an on-prem service so whether they live in the cloud they live in a different cloud they live on-prem we're going to talk about how we can secure these critical applications with our azure front door service now the main premise behind this is really around sre uh and obviously google originally coined the term site reliability engineering and i think initially uh as i think with most things people kind of scratched their heads and they they looked at it and they're like well you know we have h.a we have dr like that there's we don't need this term we don't need this buzzword and so really um in true cloud fashion you know whoever tends to invent uh these new processes or these new paradigms tends to be the only person actually operating in them for a little while and then what happens is people leave that organization and they go out and they either start up their own company or they go join new ventures and they're like hey we were doing this cool thing over here why don't we try it here and right and it just kind of becomes this kind of spider web of a of a thing and it it builds that momentum and eventually becomes mainstream from a cloud practice perspective so what we've started to see out there in the last i don't know probably a year and a half probably even less than that is that sre really is growing and and i think the ultimate reason behind that is we know that at any given point in time there could be challenges around getting our application uh to have access um there are you know attack vectors coming at us from all over the place uh certainly the cloud has opened that up uh even larger but even beyond that um there's just so much that's out there uh in the web today and and we're not even talking about either web 2.0 or even web 3.0 um we'll just talk about you know the traditional web itself but as we um put more and more out there we're accessing more and more on our mobile phones and um we're mobile we've we've been at home for the most part for the better half of the last two years and we've needed things to be delivered to us in a very consumable fashion so companies have really had to shift their application architectures especially their critical ones into a more relia liable and web friendly format and so we've seen a lot of organizations finally start to ditch the monolithic architecture model and start to decouple these and so as they've started to do this they really needed that structure around how do we focus in on the overall infrastructure to support this new micro service environment what type of tooling do we need uh and you know where are those people to best help us implement this going forward so we've seen we saw this huge uptick probably about 18 months ago of companies looking for sre right whether they knew things around cicd or incident response or observability things of that nature right sres became a very uh hot item within the labor market and i think if you were to try and go out there today and try to find an sre if you're not offering them you know north of 300 000 a year i'm not sure you're going to lure one away so they are very in demand right now and the reason is because of this wave"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:05:05",
        "seconds": 305,
        "text": "if you're not offering them you know north of 300 000 a year i'm not sure you're going to lure one away so they are very in demand right now and the reason is because of this wave of sre we've seen companies start to adopt the netflix testing model right you're seeing azure even come out with a service specifically around chaos engineering and chaos testing to make sure the applications are resilient and have that automated resiliency capability built in by the way that azure chaos studios and public preview but cool service to go check out and i'll drop the link in the chat after this is over but um ultimately the the whole premise behind this is with this explosion of applications right and we've seen huge adoption of these practices specifically around some of those key areas right application delivery response incident response monitoring observability and even things like pre-mortems and postmortems and how do we take those introspectives those are being adopted at a very high rate and it's becoming even more mainstream a recent studies uh conducted show that within the next 12 to 24 months right the next one to two years roughly eighty percent or probably a little bit over than that of organizations plan on either maturing their sre practices if they've already started them or to start adopting them right 80 that's huge all right think of all the organization you know large organizations even probably medium-sized organizations throughout the world right eighty percent of them are gonna start adopting these practices and so that's gonna be a huge demand and uptick in people who are very skilled in things like application delivery sre overall engineering devops devsecops things of that nature so the the amount of i think a wave of work from a cloud native perspective is just going to keep building and ultimately what's driving some of these adoptions are things around the desire to have some some very i think what we would consider basic things but i think as we've all interacted in the cloud world it is a challenge at times um how do we get better monitoring and alerting right we do our best to monitor and alert what we can but i think from a overall operations perspective you know it takes effort takes time to set all of that up you need to make sure you're understanding what you need to monitor and what you want to be alerted back to you and without interactions from you know the product owners and the devs right it's really hard to i think everybody to kind of agree upon what are the the things to make sure that you should be monitoring and alerting on from an overall uh application perspective and i think that also speaks to keeping all of the stakeholders right product ops devs and business all on the same page because more often than not uh those four groups are a tree branch right they're all splitting off and going in some direction and they're not all kind of going on the same path at times and so that can be a real challenge and so organizations are starting to recognize hey i need to start uh bringing all of these groups together and really have um a clear focused mission out for each of these stakeholders right and we're seeing companies start to adopt better devops uh practices around that having what's known as this cloud center of excellence and and kind of having a single voice that's kind of keeping all of these together everybody's on the same page and they're all driving towards the same goal and i think once we can align the business and all the various groups into that then how the how do we measure the overall user happiness and what i mean by user happiness is is our end user whether it's a client or our own internal employees happy with the application how many times have you yourself walked around your company way back in the day it feels like and been like ah yeah this application crashed again you know gotta do this gotta do that um i personally was just traveling uh two weeks ago uh flying out to um for work and was at the check-in counter uh before i to board my plane and you know the application for onboarding everybody and you know checking them in you know crashed the ticket uh counters machine and so they had to reboot it right and their happiness was not very happy on top of having a huge long line of people right so how are we measuring that how do we delivering uh"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:10:09",
        "seconds": 609,
        "text": "machine and so they had to reboot it right and their happiness was not very happy on top of having a huge long line of people right so how are we measuring that how do we delivering uh better end user happiness so that when they're happy and they're like yes everything is working this is moving at a a a pace that you know i expect it to or the pace of how i perform my job right then i can exude that same happiness to those around me right there's a lot of studies about that sort of uh infectious happiness right if you've got a bunch of happy clients or happy end users within your organization right it kind of spreads and kind of uplifts the whole group or the you know your whole client base uh from that stance so how do we measure that and there's a key ways to do that from an sre perspective but we'll talk about how we fit that in into our particular use case how do we improve prioritization of work right we need to understand the service health right so as i'm looking at my application and the various services that i'm talking to do i have a way to um look at that service health and prioritize the work to improve the different aspects of my application we see automating toil so how do we work through our backlog how do we simplify our complexity from a micro service perspective and then how do we avoid financial penalties of breaching slas that we've set to our customers or our end users right if i'm operating an application right i'm sure i have some type of service level agreement that my application will be up and running for a certain period of time so how are we working with our infrastructure how do we work with a service from the cloud providers to help make sure that we're maintaining those slas and avoiding those financial penalties now the funny thing is about uh of all these drivers that we see right and there's seven of them most of the teams plan on measuring um their service level objectives with three main types and it should hopefully this doesn't come as a surprise if it does we can talk about it user facing services right so basically our user facing applications our apis and compute platforms so container orchestration kubernetes infrastructure the service vms so hopefully none of those come as a surprise to you right basically everything that we have our applications our workloads our services running on are the three main service types that most organizations plan on measuring so how does this fit into azure front door how does azure front door help solve some of my sre challenges and it helps to kind of look at this uh decision tree that microsoft put together about all of the different load balancing services and the reason is sre ultimately is a reliability model so as organizations decide to make their applications more reliable more available i'm probably placing my application in different regions i'm maybe placing them in different clouds i'm placing them on prem so that if one region or one cloud provider has some sort of failure some sort of interruption that's okay i still have my application running on-prem or over in google cloud or in aws or in a different azure region it really doesn't matter where it lives but if i'm following that sre model which we've seen now everything is pointing to where that's where organizations are going i need some way to take all of those instances of my service my application my api whatever it may be and make it available to my end user or my client in a very unified and simplistic way right how do i improve their end user happiness so it's important to look at well is my application web-based or is it not well if it's not great typically we're going to look at either azure's load balancer offering or if it is is internet facing but not in a layer 7 http or https nature i may look at something like azure traffic manager however if it is a web-based application right and then we ask ourselves okay do we use something like an azure application gateway or do we use our azure front door and really it boils down to is this a regional based deployment which is kind of great for some smaller applications and maybe our user base our end users are only located in one particular area or we're not concerned with any sort of outage but typically we we are right and our our user base ends up being a"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:15:12",
        "seconds": 912,
        "text": "our user base our end users are only located in one particular area or we're not concerned with any sort of outage but typically we we are right and our our user base ends up being a lot broader than we think and so this is where azure front door really comes in and helps shine because it is global it is multi-region it can literally it can touch anything that hasn't a public accessible endpoint and then that's whether it's a public ip address or even a publicly addressable dns right if i can recursively figure out from a dns perspective where it is then i can leverage azure front door to reach out to that service endpoint and one of the reasons why front door is preferred over traffic manager and i do get this question probably quite a few for quite a lot surprisingly is traffic manager is dns based and that's great but we have that pesky time to live situation to worry about right and it only because it only works at that domain level um there is a delay you know even if you set the time to live down to super low right there's this delay that can happen from a failure perspective so if we need to swap over to a different region or to a different instance um there's gonna be some downtime and this is where front door similarly doesn't have that same issue the reason is is because front door is a part of microsoft's global delivery network so imagine uh microsoft's entire global delivery network and all those little points of presence that you connect into um from a content delivery network perspective excuse me uh azure front door is available in all of those and you can go to a a website on microsoft docs and you can see all of the cities where all those various points of presence are and azure front door has a hook in every single one of those and so your application is cached and each one of those points are present so if an instance fails say in east us2 for example i have another potential instance in say easy west or east u.s 3 or central u.s or north central right immediately available because it's cached in that application delivery network for me right to help accelerate my application being there so this is really what makes azure front door the preferred service from a critical application perspective now a funny note um and i'm sure everybody's hand probably is go up i'm sure everyone here uses office 365 or microsoft 365. um any guesses on what service actually fronts that sas delivery yep azure front door so you've been using front door if you've consumed any part of office 365 for the last decade right so can you think of a time when office 365 has really truly gone down i can't it's been a really long time so that's right so the very service that um we're talking about leveraging today is a very service that pretty much most of microsoft's customers right have been leveraging for the better you know part of a decade and it's funny when i hear people like oh well you know i'm not sure about front door all that stuff and when i give them that story about office 65 they're like oh right because it sounds new it sounds kind of unheard of but when you put it in the context of hey it's what we microsoft has been using for their own service especially something like office 365 um it becomes you know far less uh i don't want to say the term cloudy but right it becomes more demystified so uh what specifically is azure front door right azure front door is a global scalable entry point right and it uses all of microsoft's right cdn global edge network right to create a very fast secure and widely scalable web-based application and how they do this again they put everything in all those various points of presence is through uh anycast capability right so accelerating that application performance using that tcp based uh anycast protocol now when we talk about those critical applications part of one of the drivers is to help secure or help monitor the service health of our various micro services that make up our application and front door has a very intelligent health probe for monitoring all of those back-end resources right so as we're talking about sre and that monitoring capability what are the things that people think about and drive them towards making sure they have a reliable model right"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:20:15",
        "seconds": 1215,
        "text": "all of those back-end resources right so as we're talking about sre and that monitoring capability what are the things that people think about and drive them towards making sure they have a reliable model right so making sure that health probe is monitoring all of your back end resources for health for availability to service your end users to make sure that they're happy just like the application gateway it does support url path-based routing for requests so you can use a single front door to host multiple various web applications you do not need to limit it to one to one it's one to many from a hosting perspective now uh it would behoove me not to talk about some of the improvements that have been made to front door front door as itself has been kind of a standalone service for the last couple of years however microsoft did recently release two new skus what they call azure front door standard and azure front door premium and essentially what these new additions have done is combined front door with the web application firewall which it did technically have in the past but it added now this new component of the azure content delivery network and the reason being is we've seen a lot of microservice applications api best applications right being uh more used to deliver content to deliver video to deliver audio to deliver images to deliver something right documents you name it in front door initially wasn't really optimized for this type of application uh workload while it did sit on the same network as cdn it didn't actually leverage some of the capabilities that cd had offered it so um the team really went to work and to figure out how to bring those services together and the result is these two new skus now the standard sku again content delivery optimized um whether it's either static content or dynamic right doesn't matter you still get that global load balancing you still get your ssl offloading um the domain and certificate management capability you also get enhanced traffic analytics right so as i'm looking at monitoring my application right the alerting capabilities i need that traffic analytics to help tell me what's going on how how much traffic is funneling to a certain url path maybe this url path or how many users are staying on this particular static content versus maybe going over to this other static content over here so i get all of those enhanced traffic analytic capabilities um and then it includes uh those uh basic security capabilities that the azure waff will offer you now on top of that the premium sku adds in um some additional capabilities right so we now have enhanced uh waft capabilities so there are additional services and things that you can do from a premium perspective with the waff that you cannot do with the standard sku you also get bot protection so we all know love and uh hate those pesky little bots uh as in terms of bypassing some of our web stuff so instead of doing the captcha and all those other things the azure front door premium actually has built-in bot protection right to make sure we can discern who's a real user versus who is a bot user my favorite feature from a premium perspective is the private link support right so if i want uh my origin to be from a private link perspective have all of my services not be public facing right we talked about earlier how front door can hit any public facing whether it be ip or dns space right well premium can hit anything as long as it has that private link capability so even if my service is on prem or in some other cloud and it's a private ip address well front door premium can't get to it so long as there is a private link connection to that service into my azure environment where my azure front door premium is being hosted and then there's also some integrations with microsoft threat intelligence and security analytics again enhancing that security capability uh to make sure that we are securing our api or our web application or our static website or whatever it may be with the most up-to-date threat intelligence and security capabilities that microsoft has to offer so uh to create our fantastic front door um i'm not going to walk you through a terraform or a bicep uh code unfortunately um but if"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "threat intelligence and security capabilities that microsoft has to offer so uh to create our fantastic front door um i'm not going to walk you through a terraform or a bicep uh code unfortunately um but if you do want to try that out i can make some recommendations on where to get started with those but from a traditional standpoint we'll just talk about how you set this up in the portal and then we'll jump into a demo that i have set up to explore the front door now uh pretty straightforward we just need to go and type in front door to go ahead and add our front door host obviously this does need to be a globally unique hostname because it is a global service and it comes with that nice lovely azurefd.net url that obviously no one will keep you'll change it to some custom domain for you but because of that reason it does need to have a global unique name we'll go ahead and add a backend pool again a back-end pool can be whatever we want it to be as long as it is accessible from the front door service right if it's the traditional front door service it has to be public facing or front door standard so fully qualified domain name public ip um located anywhere doesn't even have to be in azure it is front door premium right as long as it's connected to the private link service we can access it via private ip it doesn't have to be public ip uh so once we add the backend pool it will then create the routing rule um that will map front door uh to your back end pool now when we configure our routing rules um this will look eerily familiar uh for those of you who have set up as your application gateway um what's a little bit different is the routing rules within front door are composed of two major parts what they refer to as the left-hand side and the right-hand side so the front door uh what it does at first it matches the incoming request to the left-hand side of the route so think uh https www.microsoft.com right and then on the right hand side right i'm looking for how to process that request um right so left hand i need to match what's coming in right so what's the protocol http or https what's the host right www.microsoft.com or star.microsoft.com or whatever and then what is that path right so slash docs slash you name it right and then right hand side we're doing how to process that request whether uh caching is enabled or not or where we route it from a specific um perspective or do we redirect it to some other location um so those two marry up together from a routing perspective now uh in configuring our uh backend targets again we can choose the type of backend host that we have there are some that do auto-populate for us so if we are connected to something like an app service or a vm that's hosted in azure those are much easier to obviously set up that shouldn't go without saying if you're hosting it in azure but we still can connect to other things but if you'll notice from our window here we select the type that we're looking for if it's something hosted in azure you're going to pick the azure subscription that it's in and then it'll hopefully auto populate that back-end hostname for you if it's something that's not hosted in azure you'll have to specify that back-end hostname as well as what that host header is going to look at and then you'll define what its http and https ports are and then you'll assign a priority and a weight to that backend target now we talked about the front door service having a fairly robust health probe service and it absolutely does right so we can uh use health probes in two different methods we can either use the get method meaning we can retrieve what information in the form uh that we request via the request uri so we can request information about our application so if our application has the configuration of based on certain telemetry from a health perspective right we can use a get method to go ahead and retrieve all of that data and source it in the azure front door blade and then we can also use the head method which is um it's very similar to get uh but um the server cannot return a message body in the response right so almost identical but"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "blade and then we can also use the head method which is um it's very similar to get uh but um the server cannot return a message body in the response right so almost identical but slightly different typically i will recommend that you use the head method because most applications tend not to have a message body in the response anyways but if you have an older application and you haven't quite refactored it to a certain extent get the get method will be preferable for some of those legacy web-based applications but otherwise most refactored or modern applications are going to use the head method and so that's the one that's set up by default now our front door does have ssl offloading or and and ssl encryption capabilities as well so we can add in yes yeah before we get too uh far afield uh there's a question from irene she's wondering um if you could explain more about what our a what are the uh priority and weight values oh i think they were on the couple sides ago got it right up here priority and weight okay um so priority has to deal with uh from a host selection right so if i am routing to a back end target right and i have obviously multiple instances of my application located whatever i uh setting a priority value and setting a weight value helps determine the intelligence of how a end user or a client is routed to a particular application so azure front door like traffic manager has various routing methods and you can select either priority you can select weight or you can select by geo so that's where the the priority and weight uh weight value comes in so as you're adding your back-end pool you assign a priority right do i deem this particular service to be priority number one and then this next one's gonna be priority two priority three so it's to help feed into front door from a routing intelligence perspective hey which one is kind of the first one that i want from our priority perspective and which one's number two number three right and so on and so forth so as it's routing users and determining who should go where right if i select a priority based routing method um the priority value same thing with weight right so depending on the weight that you assign right so 50 so 50 weight will go to this application you know 60 70 right so depending on the weight that you assign to each back-end host that'll determine from a routing perspective where front door will send your clients or end users so that's ultimately where when you see this uh configuring your back end target those values come in it's purely from a routing intelligence perspective that answer your question there irene yeah perfect yeah a lot of similarities between a traffic manager and front door at least from a routing perspective um so if you're familiar with how traffic manager you create the traffic manager profiles and determine how to route your dns uh dns based uh traffic right you have the the different profile methods you can select front door almost identical to that the only difference is it has path-based capabilities where traffic manager is a little bit more less specific it's at the domain level all right so ssl and ns end-to-end ssl encryption capabilities again we can create uh either http or http to https redirect rules much like we could with our application gateways so if we do obviously want none of our users going to http we'll redirect them to our https we'll create a specific handle for that https traffic and then we can either offload that ssl traffic on our front door service much like we can with our application gateway right but we can do it at a global scale and obviously front door auto scales automatically in the back end that's nothing that you have to worry about from a scale unit perspective the front door service handles all of that for you a little more manual with the application gateway from a regional perspective but with front door because of its global scale capabilities you don't have to worry about all the various uh scale units both in region and from a global perspective or you can do end-to-end ssl if you want to make sure that the encryption handles goes all the"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:35:27",
        "seconds": 2127,
        "text": "various uh scale units both in region and from a global perspective or you can do end-to-end ssl if you want to make sure that the encryption handles goes all the way through to your application all right demo time i've set up a nice little demo environment for us to take a look at so first thing i'm going to do is i'm going to go up here i'm going to walk through oops door so you'll notice i do have one created already uh the reason being is it'll take a little bit of time to set one up so i will just walk through how to create one and then we'll go into the one that's already built here so a little bit different you can select different options right so you have the classic offerings right so the clasp they now refer to the original front door as classic uh same thing with cdn so you'll see that you have cdn standard classic uh and the other third-party offerings from verizon and occamy or you have the newer ones which is the standard and the premium you can either do a quick create or you can do custom so depending on your level of skill and and setting things up from a front door perspective you can either get started with a very simplified deployment and take essentially all of the defaults settings or if you need to heavily customize specify different you know domains various origin groups right and define all the different routes to connect to them and the various web policies to assign to each one of those you'll do custom create option from there uh we're going to take the quick create option um so you're going to pick your resource group name again needs to be something that is globally unique to the environment so we will call this door zero zero one again uh tier we have our standard we have our premium you'll notice when i do select premium private link comes up as an option all right and you can see all the different origin types right so i can pick storage accounts a different cloud service app service static web app right api app gateway public ip i can even select a traffic manager uh spring cloud is now in their containers or i can even select custom right i can define the host name as a you know something i host from a public dns perspective i have app services right so i can pick and then if i want to ensure that that connection is not public right so from front door to my origin right if i want it to be a private link service i can go ahead and select that option and then i need to specify those methods i'm not going to enable private link for now so we're going to call my endpoint name all right so you see my nice little endpoint hostnames getting updated here to something incredibly ugly but uh caching all right absolutely do want to enable that again um right we want to cache our static content in the application delivery network right so for fast failover so i can choose different query caching behaviors right so i can either ignore the query string or i can use it i can use ignore specified ones or i can include specified ones i can enable compression if i need to uh whack policies right so if i've got a graph policy that i want to set up i can create a whap policy and maybe i don't want bots in there right so go ahead and create that create my customized waff policy and that's it now for her to hit uh review and create and actually create it does obviously take a little bit of time to set that up so we're"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:40:35",
        "seconds": 2435,
        "text": "create my customized waff policy and that's it now for her to hit uh review and create and actually create it does obviously take a little bit of time to set that up so we're not going to get to that button because lo and behold i have one already available to us so uh welcome to our azure front door now you'll see two different uh setting options here i have my front door designer and then i have the various web application firewall policies that are associated uh with my front door front ends right or multiple front ends depending on how many you are hosting in my demo environment i just have one at the moment but if i were to add additional front ends right i can add additional waft policies per front end right depending maybe i have one web application that needs certain rule sets where maybe another one needs a different setup uh the front door designer this should look eerily familiar if any of you have touched uh azure logic apps so kind of similar design right i have my various front front-ends or domains that are tied to back-end pools and then uh tied into my routing rules so if i want to go ahead and add a new custom right hostname i can i can add that in here and i can enable that i can specify my tls version just i if you change it off 1.2 shame on you um do that um you can specify whether or not you want front door to manage that certificate for you or you can use your own and it'll tell you specifically how to do that so you will need a service principle within azure active directory and then the front door service is going to need permission um into a azure key vault so yes that own certificate needs to be hosted inside of azure keyboard and then you will have to grant front door permission to those secrets inside of your key vault via the policy service i know that there is a new rbac model within azure key vault for setting up permissions um front door doesn't currently love that right now but i know it's something they're working on fixing so you're gonna have to use the access policy method and making sure that that this uh added microsoft azure dot front door service principle has the get secret permission uh web application firewall and you can enable that you can set up a policy and if you want session affinity right so making sure that user sessions are mapped to the same application back end right so we can enable that or we can disable that from a custom perspective backend pools again we can choose our type app service cloud service storage right app gateway just a public ip address right traffic manager or some custom host as long as i know that ip or fully qualified domain name i can reach it so again it doesn't have to be hosted here in azure i can literally host it wherever i want there's just a more simplistic setup uh if something is in azure versus somewhere else but still very capable uh to host that service here regardless uh michael i would love tls 1.3 also um i have not heard anything about when they're going to add that in there um but i'm sure it's it's in the backlog to be added uh so that is the front door designer uh web application firewall again i do have this enabled on here so you can see i've got my policy uh set up for this environment um i can remove the policy or i can apply it so you can see right there i can hit add so if i set up a front end and i didn't initially apply a waf policy but i want to come back and do it later i absolutely can do that i can just go in here i'll select my new front end um you know hit apply policy i'll select the policy that i want it uh to for it to apply to and then go ahead and hit save so again each front end can have a different policy you do not have to apply a uniform policy uh to all of your various front ends"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:45:37",
        "seconds": 2737,
        "text": "so again each front end can have a different policy you do not have to apply a uniform policy uh to all of your various front ends so a lot of uh granularity from the security perspective rule engine again i can customize how i want uh my front door to process so i can just call this test01 and call this rule name and demo right so i can specify how i want the front door to process certain things so if i want to look for a specific request header a header name has let's just say microsoft and contains change that to uh boston right i can to lower case i can do uppercase right so i can specify any number of different rules all right so all of these rules are if then statements and delete that and we'll discard our little rule here but as you can see i can specify yes that's fine but i can customize how any specific http requests are handled at the edge right so it gives me more control over how i'm routing various things to my application or applications uh depending on what i'm hosting from a front door perspective now uh alerting oops that's not what i wanted i wanted metrics all right so i have all my nice little standard metric rules now the the fun thing is is i can now send all of my front door data into my log analytics workspace which i do have one configured so if you go down here and i'm looking for my traffic analytics insights so i don't currently have not really anybody's hitting my front end so i really have a ton of data to show you from this perspective see if any logs really have been generated out of the environment but uh in a more functional environment or is more active environment you'll see a lot more data from a traffic analytics perspective being sourced into your log analytics workspace uh but you'll see that all of that is being sent directly in here but uh we can take a look at a number of different things we can see how many requests per hour right what the firewall is seeing in terms of host the path that it's taking what rule what action it was given we can see all the request errors by host and by path or maybe by user right so maybe a particular user is having issues with our application right so we can go in and take a look at request errors by that user agent or maybe something is getting blocked so we have a lot of different alerting options available to us within the front door service as you'll notice all of my traffic is fairly uneventful at the moment but hey my health probes are 100 i'm totally available so um that is all of our fun demo inside of the azure environment all righty so uh that wraps it up for azure front door and securing your critical applications as you start to expand your resiliency practices within your business or your client customers businesses so i will open it up for any questions that you may have thanks derek there is one um text comment from michael meyer who just says uh i want tls 1.3 yeah i saw that okay yeah yeah yeah i would love tls 1.3 as"
    },
    {
        "speaker": "",
        "title": "Derek Smith: Protecting Your critical Applications with Azure Front Door",
        "videoId": "dJ2olMCX7QU",
        "description": "This is a recording of the April 12, 2022 virtual meeting.As enterprises continue to adopt SRE practices within their application stacks, it's becoming ever more critical to secure these applications at scale. Designing the right application architecture secured by AFD to solve business challenges around security and end-user experience.About the speaker:Derek Smith works as a Director of Cloud Strategic Alliances and Brand at Trace3. As part of the Cloud + Azure Team, he engages with clients to help transform their business applications, operations and initiatives to the Azure Public Cloud. Additionally, Derek also regularly serves within the Azure Community as a Mentor, Public Speaker, Content Creator, and Enthusiast for all things Azure Public Cloud.Twitter: @ConsidercloudDSLinkedIn: linkedin.com/in/considercloudwithderek/",
        "start": "00:50:49",
        "seconds": 3049,
        "text": "that you may have thanks derek there is one um text comment from michael meyer who just says uh i want tls 1.3 yeah i saw that okay yeah yeah yeah i would love tls 1.3 as well i know it's been a requested feature of the product team um so i would bet a lot of money that it's in their backlog to add tls 1.3 i don't unfortunately have any answers on when it is coming but i assure you it's definitely something that they are working on it's fine if uh if folks have a question if you want to go off mute feel free to do so and pose your question verbally i i have a question while we're waiting derek um what have you seen uh or do you have any um any sense or visibility into the uptick in the in the customer market for azure front doors so you mentioned that office has been using it for quite a while and the way you described it it sounded like they had built out the infrastructure for office and they said well this is a solution that lots of customers could use so they productized it uh do you know how well it's doing um it's surprisingly enough it's probably at least it was a fairly literally little use service i think initially and i think a lot of that had to do with uh a the pricing around it and b its lack of content awareness and content delivery capabilities i think as organizations scaled out certain applications right and i talk about i'm going to use netflix as kind of like the the ivory tower that we stand on from a resiliency perspective right as as more people went towards that direction right that's kind of where classic front door struggled uh from a service perspective so i think that's what we saw in response to that there was a lot of user feedback uh partner feedback to the front door team being like hey we really need this capability because that's essentially a lot of the objections they were getting is if i wanted to put front door in front of my application right how am i delivering that static content that dynamic content and making sure that front door services that in a meaningful fashion and that's something that office never really i think truly exposed as part of the service right because a lot of the content that it's you know surfacing is you know email and things of that nature so it wasn't very dynamic in nature um i don't think a ton of people were using office 365 for you know image delivery or video delivery or you know concept content changing from that perspective so i think in response to that right um that's where now we see the new standard and premium skus and and we certainly started seeing more people recognize from a resiliency perspective hey we need to put um something in front of this so i've seen a lot of fortune we'll say 100 clients start to adopt front door in front of major applications that i would say everybody in this audience today if you have a mobile phone you're probably using some of these apps they're actually being fronted by front door today i can think of an active engagement that my company's working on now i can't name the client obviously but they're that's one of the things we're working on is their critical mobile application um and it's now being fronted by front door because it's obviously deployed globally from their perspective so yeah a lot of i'm hoping that you know as we've hit the 100 level right then we'll start trickling down into 500 and you know and lower and lower so i think pricing wise it's gotten better now with the standard and premium sku differentiation and i think the addition of cdn has really helped pacify a lot of the original objections to people onboarding front door so definitely i think the trajectory as i think hopefully my slides have highlighted right it's just going to go up right along with the sre adoption yeah yeah thanks that's really interesting you were talking about um well microsoft has been historically they've been really good at listening to customers and been adopting based on your real usage patterns and that sounds like what you're describing there and um uh over covid of course the use of teams increased uh you know pretty substantially i don't know what the numbers are maybe it went up you know unless you're going somewhere multiple didn't go up 10 yeah it went way up so um so i i'm guessing based on your description that that really exercised uh azure front door quite a bit and took advantage of it for he was saying you know image delivery that's an example yeah i mean that's yeah so originally right i think even though skype for business and i'm sure people are groaning right skype for business was um was a i don't know i don't say 50 50 adoption rate right either people did adopt it and they kind of liked it or they didn't um and i know the original people brought over from skype were never really big fans of of skype for business and so that's kind of yeah uh so when teams kind of came around right there was this you know big energy like oh yeah like we've we've kind of rectified you know the the earlier step child and so i think based on its current use and and how classic front door was designed there was really no issue and then like you said uh covet hit and all of a sudden this absolutely monumental spike in this data happened and classic front door was just no longer a sufficient solution and it's not you know without that event i don't think i mean we microsoft may have eventually realized that issue i just don't think they would have realized it as soon as as it did so i think literally almost 12 months to the day later is when standard and premium were announced right after covet hit i think they announced it in february of 2021 sometimes not working great together uh yeah it's not perfect um but yeah that's when those new skus were announced and they really took into account like hey we need to optimize you know image delivery video content delivery all of the dynamic capabilities that right the tick tocks of the world the instagram stories the facebook video right you name it uh whatsapp right we can go on and on on all the different very popular app services that leverage some type of dynamic facing content capability and so that's really where the new front door was targeted around um so yeah definitely i think you know covid was kind of the the biggest customer that sprang into microsoft's lab to address that that change um so and uh derek you very conveniently uh did include a slide that shows the uptick in teams usage because of covet it's on your questions slide there oh yeah right to the moon yeah okay well let me see uh uh there were no written questions uh any and if you're uh anybody wants to come off mute please do now do so now okay so um thank you uh derek this was uh excellent uh always informative very very nice to have you everybody can um uh find this usually we have it the royal we jason usually posts it the next day on youtube so you should be able to find it at uh youtube.com boston azure and like i said it should be you within 24 hours let's say that usually and um we have a couple of other talks in the queue but we haven't officially published anything so watch the usual the usual uh places for for updates uh once again uh thanks uh derek smith and thanks everybody for joining and we'll we'll see you all next time stay safe out there thanks for having me everybody take care you "
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Working with Azure SQL for Azure DevOps. This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/. I'll share my screen and let me know if you can see it okay yeah I can see it um which one are you seeing I'm seeing you on the left and Olympia on the right so let me let me share my screen because I think that I'm having issues with that hold on permissions just to set it setting is flagging me to share hold on privacy sorry I didn't test that my mistake well a third person came up that was an l [Music] okay there we go there you go rock and roll your mic is cutting out now sorry I left there you go okay so it's nice to be here with you I am not going to delay it a little more so today we'll discuss a little bit about Azure devops for CI CD pipelines with Azure SQL I'm Carlos Lopez I'm cloud data engineer uh I'm Microsoft MBP data platforms so that's my credentials um this is me this is my site this is a little bit of uh me so I'm a blogger speaker a local community leader so for Guatemala so we chat a little bit about that you can find me later if you want we can discuss whatever you you you have if you have any questions please let me know ah I'm happy to answer so for today uh we can discuss a little bit about devops the perspective uh we will focus on the plan the develop deliver and operate but mostly on the develop and deliver faces because uh for us at data Engineers we focus more into Data so that's on the develop the script part and the deliver to infrastructures code for example so basically that's my main concerns for this uh for today so the other uh for the developed phases and the liver faces we will discuss it in a little bit of demo about describing the scenario of the devops for us as Azure SQL Engineers because what we'll work is for with Azure SQL right so let's talk a little bit of devil devops like a cycle for data that's not for data this is the classical Loop so this is for everyone so when we see the classical Loop we see devops cycle we think cicd process so right away something we already have we we take for granted that this is something cultural as well that is requiring to in our company so basically we this is cultural this is infrastructure this is this is software that that involves the company but uh we have to be uh with the understanding that we uh This concerns us all and for example we need to know uh for us a little bit of agile yeah um developer developing faces we need to use know about user stories uh to do categorization for example uh to do for for example we need to know a little bit of uh scrum uh estimation to do the story points for example for Fibonacci to to to uh to Mark the story points for example uh so basically that's not us to be like a scrum Master but we need to know so that's that's why I I put the the classical loop as part of uh us all so as being part of it we need to know the the Sprint planning the daily the standout the Sprint review and Sprint retrospective uh we need we need to be there in in all the process so for us to as data Engineers changing our"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:05:06",
        "seconds": 306,
        "text": "the Sprint planning the daily the standout the Sprint review and Sprint retrospective uh we need we need to be there in in all the process so for us to as data Engineers changing our our uh from Idol for example I come from from from knowing Idol changing to to devops that's a different culture so and how to uh Embrace that uh as the SQL developers but in we're not just SQL developers we have to do to be a DBA as well so everything is here but uh the the scope has been changed so the environment has changed so that is why this is important mentioning that uh the classical the the devops is um then we we have to understand the culture because it changes from how to to integrate and how to deliver right so basically that's uh that's what I wanted to show you with this picture and now if you see the difference I'm just going to return a little bit the difference is uh the loop changes uh this is the classical look for for for the books but this is how Azure devops cycle it is for for the product for the product we have uh four phases we have plan we have developed deliver and operate this is how how it works for for the design uh Azure devops cycle not that it's different but it's just uh the culture for for the Microsoft uh tool right for the infrastructure to work how the philosophy of the the tool works so and it provides a variety of services so that they can plan and we can work we can collaborate and we can code as a team right to build and deploy software and services that that's the main idea to develop and deploy Services right so most of the devops teams rely on several tools and build custom tool chains for each face and application life cycles so when we look at devops classical Loop we that we see before the diagram we imagine now that we are analyzing the devops uh followed by Microsoft the the product so a we will focus as I mentioned earlier that in the develop and deliver phases because that is where the the construction of the infrastructure as code that we will see to con to build the SQL server or the the server itself will uh will we will focus on that so basically that's that in that phases so that is just to to let you know that that is the the diagram so I'm not going to school you on on epics and user stories and all but this is like the the the the flow from the that we are used to uh to go from devops right from scrums using an epic and feature user stories and tasks issuing books uh for example uh and tasks but uh this is just to mention because in Azure devops you can do everything on that so basically that's just mentioning because that is part of the the tooling right so we are going to go to configuring the Azure devops itself so right now we will discuss a little bit about the agents in the Pipelines and the tool itself has um uh this um uh machines because they're they're if you see it like uh there are virtual machines that lets you run your your your agent which is the connection to the pipeline software that lets you to do whatever task you are asking them to do that's basically the agent so you have two two ways to do it you have uh Microsoft self-hosted agent uh I'm sorry a Microsoft hosted agent which runs in the Azure platform that's paid and you have this self-hosted agent that is uh that can be whatever machine you have on your on your house or or whatever you it it can be your laptop we will see it in I can show you that I'm already running a self-hosted agent just to to let you know it so you can see what it is and how it looks like so you can choose it from whatever you like Linux Windows Mac OS myself I'm running Mac OS so whatever you choose is fine so the only thing that it does is that it connects to the Azure devops and to your account and allows them"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:10:12",
        "seconds": 612,
        "text": "Windows Mac OS myself I'm running Mac OS so whatever you choose is fine so the only thing that it does is that it connects to the Azure devops and to your account and allows them to know what is the machine that is uh connecting to the service that is running so that's everything that it does and it is a pull uh a service that is continually running and as long as you keep the connection alive or the virtual machine alive it will run your pipeline so it is made to for you for to you to run your Pipelines so that's their purpose and here it is where you choose it and how do you and what you choose on it so here are some expects specs for the self-hosted agents this is the the images that you have uh these are the yaml files that you can VM images that you can choose from uh these are the specs and as you can see there are I I took this like eight months or something like that so that's a little bit old but you can choose whatever you like that are different OS versioning so that's good for you um so uh continuing on self-hosted agents the process is really simple you have to create a path which is personal access token where you can you have to um create a new token and then you will be asked we will you will have a URL uh in in a well I'm sorry you will generate a token that you will copy and you will be asked to put it when you are running your bash or your or your terminal all your Powershell um terminal and you will be asked to be to put the place the token so when you put your user account URL and the token you will activate your software and and this is the portal and you will see if it active like that like this so that is what I was saying this is your organization this is the name this is the how you configured if you wanted you you want that path token expires how many times you you want to to get them to live uh which [Music] um what what is the access roles that you want to give them the to the scope that you want to give to the to your path and then when that is created that uh token you you will generate that uh that script so with that you you can paste it right now so basically that's when you uh put your your login credentials you you will ask your token and then you can run it and then it will connect to the server and it will run so that I I took the liberty to take a little bit of time to explain you about this because that I think it's a good option for you if you are trying to test Azure devops for the first time so you can run self-hosted agent and so you are not um build with the uh hosted Agents from the Azure so that's a good notice on that so you can test that so basically that's how how it looks like and you you will see your your agent run running there okay so I don't know if there is if there are any questions please let me know or I can answer so they cannot I I'm not I don't have any issues if if there are so uh I'm sorry I jump a little bit so now we will overview uh the the Pipelines what they are and and what are their benefits right against uh the different we are talking about pipelines as part of the CI CD right because this is the process that uh this is this is the software that allows you to control the delivering the the shipping and the delivering uh faces so basically what you do is um you're changing methodologies right so you're changing the ways that you do your software so with that the overview of this is that uh the platform and the language are independent so with that is this is a plus because you are not language dependent or in interoperability you have different type of repositories you you can integrate it with different software that there is in the market with the the biggest one the name it jit GitHub or whatever you you like there is so basically"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:15:18",
        "seconds": 918,
        "text": "of repositories you you can integrate it with different software that there is in the market with the the biggest one the name it jit GitHub or whatever you you like there is so basically um that's that's a good and the platform and language independent which means you can build code on every platform using Code based on what you want on your needs right on on the environment that you are it can be integrated with different repositories as I told you before uh report like GitHub uh Enterprise beat bucket and so on uh you have a lot of lots of extensions standards and Community Driven standards so they're available for you to build your code handling custom tasks so that's good and allows you to deploy your code into different Cloud vendors that's something good as well because not all we we think that everything is on Microsoft but there is not it allows you to connect to the different Cloud vendors but at the end uh you have to have your Azure devops so license so so there is a little bit of uh well you are part of the Azure devops and you you this is more if you want to integrate with other uh Cloud solutions that you need to communicate so that's a good solution to integrate clouds right not just the the Azure known uh you can work with containerized applications such as Docker you can use all the the Azure infrastructure with Azure container registry or kubernetes if you like so basically that's um integrating you a lot of solutions to to deliver right so it allows you to to create a lot for infrastructure I mean so let's return a little bit to databases so we talked that we needed to create code now we're that we're not seeing that databases as as hard objects we are saying more like the code of the databases so the assets is the code so in this um in this methodology if you if you will we think we need to think that we need to uh be very careful with all the code and the versioning because it is delivering fast but well but uh we have to control what we have so basically this is the objects to check on the database and why we have to be very careful with the with this is because of the the versioning because every time we ship and deliver we are every time that we are doing pushing requests we are creating new versioning we are creating every time that we um integrate and create new versioning of the stabilizing applications we are changing the database as well as part of the objects so right now we have to think of how we have to think that the scripts are the most important things that uh that database have I know that the data is important but the problem is that we're seeing uh not the problem we are in this scope we're seeing the database for migrations uh and for migration um methodology so in the migration when you are migrating a database you are always doing some changes ddl changes or DML changes to the database so every time that we integrate a new version or doing a PR we're doing something to the database because it will run there unless we you say that we're not going to do it but we need to be very careful that everything is on the latest version so what we need to think is in the all all these objects right list collection data data sorry I I shortened the word data dictionaries ddl for all the definitions if this is the latest version that we have and that doesn't have any bugs in it that doesn't create that we we might create some bugs every time that we create that we create integrate a new version right so we need to be very careful that this is the stable version as well as the DML that creates all the yeah and the definitions that we're introducing so when we're seeing all these objects we're thinking in infrastructure as a code model so that is why we're thinking database into this model and therefore we need a language capable to manage or handle this infrastructure so this is the the database"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:20:22",
        "seconds": 1222,
        "text": "in infrastructure as a code model so that is why we're thinking database into this model and therefore we need a language capable to manage or handle this infrastructure so this is the the database as uh database developer every time that is running the the the life cycle to integrate something or to push something to the repository for example but what about when we are trying to create new servers when we are trying to create uh to deliver uh create new databases or clone a server so that is when we need another kind of language and that's that can be because it is not the only one we can use yamu and we can create infrastructure as code and we can manage that into our our pipelines so what can we do with it um I think that I I lost you a little bit bit um bear with me with a little bit these are the tools that you can use when when you're trying to uh manage your databases you you can use it everything from Visual Studio code you can use it through Azure data Studio you can use Powershell and to control your Azure uh infrastructure right and for and also you can use it for your logical uh database tasks right for red gay SQL search and SQL prompt to see the differences in in the objects that we were discussing a little bit uh you can use everything right now right here to to see The Logical work for the PVA for the database sorry so um I'm sorry about confusing you with this part of the the yaml I think that we'll see it in a few slides so bear with me there so um again as I was saying uh since you are seeing the database as Scripts that be that can affect the database every time that uh uh pipeline is implemented you have to have best practices to to see what what you have to control so basically your most important task is to control your versioning the code control versioning you have to see the object level history you have to control the inside of that object that how they how they change and to do a code analysis rule to implement code analysis rules for example if you're if you're having uh some team members and and that happens to me this week I I have I have a new SQL Dev um which is a junior Dev so how can I pass all that I I the devs and I have have um already know by because we are in the company for more than one year for example so or we have a document for that but when when you left uh I knew a new SQL Dev alone and you could expect them hey to this store procedure and give it to me in a week when you see this the store procedure he will implement the naming differently because he he thinks differently right so doing a code analysis rules implementing a code analysis rules into your pipeline that's a good idea for example and uh the naming the formatting the the the managing the versioning that's the important thing that you have to do I know that everything that I have uh discussed right now is uh a SQL Dev perspective or a database Dev perspective but that's part of the job right so we need to be sure that that works fine so how can you do it you can use for example I put two examples that I'm trying to use right now I I'm using Flyway Community version to to use the the part of the code control versioning for example or you can use the SQL fluff which is on a personal open source tool to run your code analysis rules that are tools that may help you or assess you while you are using another uh uh while you're doing your daily job so that that may help you so that's just uh uh suggestions so I know that we're discussing a lot of data migrations but this is because um you know that's the one of the approaches that can be done when you are doing when you're doing Azure pipelines that's uh the a possibility or a way to do"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:25:25",
        "seconds": 1525,
        "text": "um you know that's the one of the approaches that can be done when you are doing when you're doing Azure pipelines that's uh the a possibility or a way to do it so you have to be um at least uh open to to know that this will happen in some time that in some environments they may change to use for example Entity framework which is my case they do everything on uh in.net core and they Implement in in Entity framework to do this shipping to the pr and integrate into the uh Azure devops for example and doing the pipelines the other can be uh Flyway and or you can do use another right now but uh these are just examples or uh what you can do right so what what is the purpose of of this um migrations on how this will be or can be integrated with devops so at the end Azure devops is the complete uh software that allows you to to execute whatever job you you put them but at the end what you are trying to see is that database as as a software and instead of looking your virtual machines uh actual um how do you say this um your um on-prem databases that may change that um scope might change so I'm just giving you a different scenario that can uh imply to a different methodology of using an orm or object relay relay the relationship manager right so I don't know if object relational mapping sorry um so I don't know if if you have a any experience about that I don't know if this is the the idea that you were expecting on this session but I just wanted to let you um a little bit of you know a splash of what can can be done with that so um the deployment scenario now we are returning to the infrastructure scone right now do we we change it from the data definition layer and all the the database code so right now we're uh talking about infrastructures code and thinking in creating the SQL Server itself to the Azure Azure environment you can have it in your repositories for example you can uh push it to the your yaml code which is the language I told you before that is the markup language used for infrastructure as code this is a uh an old uh code but it is used to implement it for the infrastructure as code for declarative implementations and there you can trigger pipelines to execute and deploy your uh Azure sqls or in this case in this case for me Azure sqls but you can Implement whatever you like you can create uh Cosmos DB that's that's the beauty of infrastructure as code you can Implement whatever object you have you you wanted to to build right so for us right now it's that databases rmdbs right so I hope that I I haven't uh lose you there so if you have any questions please let me know this is a pipeline this is yamo and this is um this is the code how you are putting a little bits of code using uh yamo in your pipeline when you are defining your your structure here I'm using a bad reference because I'm putting my subscription here I'm trusting you here so um no worries it was already uh do it doesn't work so no worries um this is the the Asher uh Azure CLI code to uh run your creation for your machines first the first line we will see it a little bit later but first you have to Define your uh Resource Group so this is the line that creates the resource Group this is the line that creates the SQL Server as uh SQL Azure SQL and here is when you create your Azure DB SQL general purpose with license and with uh service object basic with all your capabilities that you allowed it and and I I put the the model as serverless so this is"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:30:35",
        "seconds": 1835,
        "text": "create your Azure DB SQL general purpose with license and with uh service object basic with all your capabilities that you allowed it and and I I put the the model as serverless so this is an Azure SQL serverless SQL Server database sorry okay in a in our SQL Server so this is basically uh the yaml structure that you can use and as you can see you can Implement whatever task you like so this is a this is a way to do infrastructure as code to create and a SQL Server so to configure the Azure DB into a pipeline will will try to do this kind of example to develop build and publish the the model to develop the the SQL database right so basically um this is when you are creating something that you have you have your T SQL you put it in your develop faces you you have your DAC pack you build it into your backpack the model if you have your.net core or dotnet Visual Studio you can build it there and you can publish into your into your um environment so basically uh we will do a little bit of workflow to do the the creation of the database into the plate upload the changes to the SQL Server so this is what we'll do and I hope that it works right now so um I know that we're mixing a little bit but since Azure Azure devops has a lot of to offer here are a little um some of samples to do for example code analysis a code and testing and this is some some tools that can help you guidelines for when you're doing some some part of the testing in your in your SQL code in your normal normal SQL code but I hope that this helps you if not you can use Flyway as I mentioned you can use SQL fluff and that's that's another way to do it so uh here I leave the materials to do it here I'll uh this is a really good solution complete solution that he did here uh I recommend this to you for you uh here are some Azure SQL documentation the the front end page and where every concept is uh supported here are the talks related to the pipelines agents the yaml files and the agent posts that we discussed how to integrate it to the GitHub repository and how to continue on the Azure um SQL Ms docs learning path to do the Azure SQL workshop for example that's a really good way to start in your Azure sequels if you if you haven't been able to do um Azure SQL serverless solutions for example uh you can go from scratch and do it everything there so this is the code sample that I did for the for this demo so I leave it in my GitHub so you can if you want to I use it in another session so I leave it the same name of the folder so I can not mess up there so let's go to the demo right now part of the demo sorry because I had an issue with my my credentials um yeah some hours ago I think that someone reject my Recreation so I don't I think that I I'm not going to be able to execute the pipeline itself but I'm going to give you all the roadmap to it so um I don't know if we're are we good with the questions or can I can I continue I'd definitely like to see like the actual pipelines like I'm curious to see like like within the UI like your your actual as CLI scripts and like how you're running the migrations and how you're actually preparing them I guess we'll go to the study yeah sure okay okay I will I will continue then um if there are any uh because I I didn't have any the complete solution because I just did some examples uh as you're referring I I didn't have the time to complete everything but uh I give the roadmap so I'll go to the um the edit the the pipeline see all right and explain a little bit because it was just a explanate explanatory to do the SQL creation so basically this is the assistant to do the the yaml there uh here the test to execute sorry for that uh oh this"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:35:42",
        "seconds": 2142,
        "text": "just a explanate explanatory to do the SQL creation so basically this is the assistant to do the the yaml there uh here the test to execute sorry for that uh oh this this can uh scare you a little bit so this is the the VM to execute the pull for the uh the creation for the task and here here is some some step to do the first creation of The Logical server I use variable instead here of using it for to get my Azure subscription uh this is the type of the script that I'm running and these are the the lines that I'm executing first I'm doing the Azure SQL command to create the resource resource I'm explaining the resource Group I'm creating the SQL Server here and I'm putting the logical name as you can see everything is the variable that I'm using so I'm replacing instead of leaving the hard code of every single line that I'm using here okay so instead of um using the resource Group name like put right here I use a variable instead of using the name of the SQL Server itself I'm putting a variable which is getting uh which is simply a text that is getting my name right whatever I I put there so this is the same for the admin user uh [Music] this is the essay password this is the essay user that I'm giving and this is the password right so this is the essay I'm creating the SQL Server here and then I'm adding uh and admin to the group to the SQL Server right this is the the instruction to give to create that into the the SQL Server and then I'm creating a firewall rule this is the name of the firewall Rule and these are the the IPS that I'm given right now none so that is the that is the actual inline execution so if you want to add more you can use this assistant and you can specify that you want an Azure CLI when you do that it will create more yaml instructions to create a new task it will um here you will specify the resource management connection that you are using so you can give your subscription that you are authorized to use when I do that it will fail because I have any uh issue with my account when you execute here when you do this you can specify which one are you selecting depending on the environment that you're using from a case I will use shell and then in the script path you can use whatever you like inline script or script path if you use the script path then you are attaching the the the the the the script if not then you are inlining the code that you are doing so what what I did is copy and paste of the code of the the [Music] um Azure CLI code directly to here and you can code paste it here and it will create your your new new lines so when you do that it will create the code here right since I didn't put anything then it is blank but basically the inline script is the part of where where I put it here so let's continue the second part is creating the the elastic pool for the actual Azure SQL elastic pool and database so the first line um creates uh sends the command that says Azure CLI SQL elastic pool create with the resource Group that we are specifying The Logical SQL server name the elastic pool name that we're putting a general purpose and for example I'm using Gen 5 this can also be put a variable instead of putting there and then now the number of CPUs that you're using so I'm using one and that is another variable you can choose where you can see the variables you can see it right here variables and you can see who your variables are you can add more and these are the names that you're putting right"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:40:45",
        "seconds": 2445,
        "text": "where you can see the variables you can see it right here variables and you can see who your variables are you can add more and these are the names that you're putting right so that's a way to to manage your security there so um I think that I explained the resource Group the elastic pool okay so then I create another SQL DB explaining the resource Group the SQL Server the name and the elastic pool that I just created in the uh bulb line so basically that is what it does that that is the the script there and leave that is the the one the the that I wanted to show you let me see if I have another a little bit more complex to do I think as it feels the same let me see on the repo okay SQL Server you point home yeah I have the complete one here which is the create The Logical file then creates it the idea I don't want you I really don't want to bore you with all what it does but this is what uh what it builds the the deck pack for the SQL project so this is the other yaml file that I have that uh pulls up with the Articles from the backpack in the SQL database project that um there is already on on to to generate this deployment so basically these are the tasks with the complete one so this is the the the one I showed you this is just uh explanatory uh which is just a simple script and this is the complete uh the whole meat and potatoes so that's um the the part of the pipelines so also here is the the solutions food that I use I use the data warehouse for example using the worldwide importer solution to do the the fact tables and know the script so I put the the solution of the table so I can integrate that into the project so that is the the idea but the problem is since I cannot run it I it will fail because when I do when you go to the Pipelines and you execute let's see if I can show you the problem um runs I'll retain then I'll see it when I run it manually you'll see that it will fail because it will take whatever I have and since my credential is is not allowing me it will it will fail so sorry for that I'm sorry it's okay we believe you okay so I just wanted to show you the settings the project settings then so this is the part when you can integrate your pro your project to your GitHub for example you see I have you can see you can use the get the normal kit or you can use the GitHub so here's the connection you you trust and you can use your personal GitHub to connect this is the project configuration this is where you can set your it either iterations uh Sprints you can see your you can configure your uh all your configuration for your team um all your security for the team how you're you're going to manage your your backlog how you're going to manage your user story these are the boards this is the part of the boards and as well as the permission the themes and how you're going to integrate it with that here is the part with the the agent polls that we were discussing here this is the cell phone self-hosted agent and here is the hosted agent in in azure so when you see the self-hosted agent as I uh I think I I don't have it right here I already it's not running now let's see um there is there is where you you run your self-hosted agent and or your azure uh hosted agent that run that fail Okay so the problem is that why do you need the um uh self-hosted agent or or why do you want a Microsoft hosted agent is because of this if you have a self-hosted you can do two parallel jobs uh three one one free parallel job and these are this you have to be very"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:45:48",
        "seconds": 2748,
        "text": "want a Microsoft hosted agent is because of this if you have a self-hosted you can do two parallel jobs uh three one one free parallel job and these are this you have to be very careful on what you need depending on what is your solution this is what you have and the minutes per month that you have for one parallel job for example so that depends on how you want to go so with self-hosted agent uh well you're not um you're not build so that's a good way to start right so that is what I wanted to show you I think the other is the service connection here this is the the one when you connect your service to your Azure resource manager you know one you might want to select that so when you do that this is all the options that you have you have a lot of options where you can integrate it to your infrastructure as code when you uh connected to yourself to your subscription it will get your details from from your account and you will specify the resource Group that where you want to deploy your objects the service connection name that you will put for your tests and the description of what it does and granting permissions to the pipelines and I'm doing this because every pipeline I want to to have access to when I do the same thing this is here okay so in your in your case you are good to go and this will save and you will have a connection and all the pipelines that you execute will execute with the subscription that you specified here so um okay so this is what I wanted to show you I will return to the slides I think I have another one no I think that's it that's it for my side these are my um social network if you want to hang out or you can discuss whatever you want I can show show whatever example I have if you if you want to test please ping me don't worry ah so glad to help I really I'm really happy to be here with you and I don't know if you have any questions or you want to talk a little bit about something or something wasn't clear please let me know I want to hear about uh bad things that have happened to you because I'm assuming you're doing this in production right so like what kind of like Lessons Learned did you take away from this like for example I'm terrified of doing database migrations through automation like this because what if it drops a column and oh crap I can't get that back you know it happens it happens and it already happened because the problem is first not everything that or my experience is not everything that the software does is automated you have to be very careful with the tool for example for Entity framework um if you don't import uh then it has uh the Caps naming and there was an issue with uh the naming of the file and it was a some developer left a blank space there it didn't import it when when the the build was made so for example when we did uh uh push to PR and did a new versioning and when we we integrated it was uh a maintenance for to run all changing the options for the indexes for example that was the that that was the problem so it didn't run all the scripts it just run three or four because the fourth line in the Entity framework had a a small line in there so even with all these uh tooling that we have we need to have we need to have documentation that's we we cannot live without without it because we need to know what what we're doing the other is uh since the other bad example that happened to me a lot this I think that it was on December or November November was that we were executing uh new scripts for uh store procedures to do that does the report and which I changed [Music] um uh date times or something like that in the store procedures so when I when I created this store procedure uh these um changed um the problem was that the report our reports are in um in some how do you um um"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:50:52",
        "seconds": 3052,
        "text": "the store procedures so when I when I created this store procedure uh these um changed um the problem was that the report our reports are in um in some how do you um um how do you say this um it was deployed into into our portal but this is a container running kubernetes so when we execute this new version with the different uh uh date formatting it it wasn't accepted by the the portal so it failed badly and it was because like a local issue yeah yeah and the problem is since we the problem is that the the we shipped and the version of the the container for the for the pot for the kubernetes spot when they created they created with the different uh type format for the dates so it was completely different and everything was ugly and you know it was bad and it was because the SQL Server uh store procedure had daytime offset time of uh uh data type and the the front end uh it is it is in node.js with uh something tool like I think um that managed the the dates so it was a different kind of date that it handled so it it screwed all the dates so I uh the problem there it was that I didn't have a code analysis rule that will help me to say hey everything that goes from store procedure to the front that need to be date time only not daytime offset for example so that will help me so that is why I started to use SQL fluff uh to do the code analysis review and also you need a peer review with a with a teammate of yours that shows you hey you you did it but there so that are some of the uh um I don't know how to say um um experiences that I have in a in some uh quite a few months so that is why I put you here that code control versioning is the most important thing that you need to have for your asset because basically every time that you do a new run you are replacing objects or creating new objects to the database and that will affect it even if if it is you can say well let's see uh we will have a baseline of uh our SQL Server Azure SQL Server we will destroy the that container and we'll create a new Azure SQL with with that Baseline and we'll start from scratch yeah but you lose two days so instead of doing that if you have your control versioning and you have your your code analysis rules you have your verification and everything you you will you it will assess you the other is Monitor uh you you have to monitor your your changes right so that's very important the after and the before and after the year changes so that helps you to understand your infrastructure how you how you left it ah do you wanna I I have another right right now I have another story that I had [Music] um we uh we use Azure SQL serverless database and we have um I think is that is that the one that turns off after inactivity right okay that one that was puts in outer pause so the problem is that the in the end you're getting to the problem the problem was that we we were implementing in into production with Azure with several Solutions and I told them no that that is not a good idea we need to have uh at least we we need to move to another tier so they said no let's go with what we have okay and we we went and the problem is that that when you put Auto pause you cannot put if you don't want Autobots it will auto pass because it's serverless and after um two hours uh it put in in pause and all the connections were lost and they wanted to like connect again you know it and it was the transactional scenario so all the all the typesetters were mad and well we need to we needed to change it to to a different tier and and it was like a cost solution because every everything um was better when we change it from to to"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "00:55:56",
        "seconds": 3356,
        "text": "and well we need to we needed to change it to to a different tier and and it was like a cost solution because every everything um was better when we change it from to to our um uh other other tier for SQL server but that cost a little bit uh more but you know that's the cost you have to to to take care right so you have to think that first before doing anything so that's one of the the problems I have with the with this infrastructure but you have to be very careful with the architecture that you're trying to implement every time in every uh solution that you're trying to implement right if if this fits to your scenario this is more uh this this infrastructure is is designed for Loosely coupled Solutions where you need to have containers and and this architecture is good every every architecture is good but depends on the environment that you're trying to implement right this is just a scope and a glance and depends on what you need and that is what you do right if the virtual machines is yours and helps you that is the the way to do it but um in a way that you can decouple but for a bit not doing a hundred percent uh differently right you have to test everything that you do to decouple and try to implement new architectures but not all at once I think that's my experience so I don't know uh that's that's what I have uh lived for uh that's my experience from shifting from a DBA from a traditional DBA doing uh from on-prem to to the cloud databases but but it's good you know right now I'm the the good part though because in every everything is good and there's some some bright sides um you get to see a lot of different technology which is not being able to do with other um uh with the with uh virtual machines for example that it's a little hard to do you know you have to implement something differently yeah so this is this is another way so this opens your world to to a whole lot of possibilities so this is really really good to do if you want to shift to this Paradigm so I really uh even if I I it hurts a little bit to the start I I think it's it's really good to to do the shifting it's it gives you a glance of to a new different world to do in the data right so you were saying that you had an issue or you you are scared if you do something in your yeah my co-workers want me to shift to like EF core migrations for example I still write them by hand we don't use Azure devops to run them we just we but we do sort we do have it in Source control and we run it through a tool called DB up which is just a simple right tool right just yeah there's personal point for the code right the the the the Paradigm that allows you that's what you're getting at yeah yeah exactly that is why I I wanted to like say 50 50 scenario because the good thing about what is tested for more than 10 years I think more than 15 I think uh Source control versioning works right having your object level history works for your on-prem data database scenario that we are used to do so how the way is how to implement this uh with this uh with this new technology so I think that for example I'm trying to this uh um this Flyway because it has this kind of uh solution so not that because I I cannot move to MTT framework I cannot move from my Entity framework to flyboy but it allows me to use the monitor from flyweight personally to see what what are the the changes not to implement just to see anyway in the same for SQL floss I connect SQL fluff to see the the different the code analysis rules so it can help me to assess me before I implement it in the in the Pipelines right like disconnected not connected right so I know that a little step in a middle step is not like integrated step but can help you because you imagine that you have like 20 scripts daily that you want to that you"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "01:00:59",
        "seconds": 3659,
        "text": "so I know that a little step in a middle step is not like integrated step but can help you because you imagine that you have like 20 scripts daily that you want to that you want to see each for each object I I really with versioning I know that you you can go in versioning each one but at the end you're going to miss one so you need to have something automated that at least this SQL fluff gives you a report so with that report you can see the differences faster so that helps me I don't know I mean at least locally so um that's I what I think um it is a good um way to do it the other is I put here uh this is a little bit older but it works this um uh what was what was it the code analysis example for the SQL Server rules that that's old but it works um an older other I had like it was smell sickle smells something I had this over here I think in the documentation if not I can give it to you but this is all all tools but it helps you to do your your SQL checks before to verifying this code that you're testing soon well that's my experience at the moment I think uh I think Nate had a question as well okay yeah Carlos I was interested in um what happened does did this does this tooling uh help you to be able to revert so if you're doing a a release and you're uh releasing code and you're releasing database updates um and you find out there's something wrong that you have to revert um uh yes does it give you the um a good option to be able yeah that option yes they do Entity framework no Entity framework no but Flyway yes it it for the paid version it has the option to revert the changes and it advised you so it lets you okay all right so it'll change the schema right is that whatever right right right right right reverted back to what it was before yeah released and is that kind of majority of what you use you consider a database migration right is a new release of um software with the database changes with it right yeah cool cool yeah I hope that uh I know that uh not everything on orms are like you know in in the there are not a like a lot of documentation out there because this is like I have like five years or something like that it's not a long long time but I think that at the end uh this will be the scenario that we'll see in the next five more more often so I think that at least worth trying right at the end I know it is stable because it is not like something like fails every time because it is not Entity framework at least it works the only thing is that it's a for example uh for Entity framework it's a little bit uh slower I think that it it that is the word it is slow but and it has a lot of parameter options that you have to be very careful and where you have to for example when you shift something um the output that it gives you you have to like control the handle control the the output the solution interface with the database for example the the error that for example is there is a some kind of error in the script that you're putting in the Entity framework and you have to detail then the you can detail the number of codes the error codes that you will display in your log so you have to be like a tweak a little bit there in the Entity framework plus it is a little bit slow not that slower but it's compared with Flyway I think it's a little bit slower but um it works it works and it's Microsoft so you are fully Microsoft integrated there so that's a good thing you have all the tooling to use Visual Studio code visual studio um 2019 I use and um so um depending on on what you have uh it gives you all the Microsoft tooling so it it helps you so um when you when you talk about these two tools you're talking about any using any framework to do the migration is that correct yeah"
    },
    {
        "speaker": "",
        "title": "Working with Azure SQL for Azure DevOps",
        "videoId": "drm7kWsVRxw",
        "description": "This is a recording of the February 28, 2023 virtual meetup.In this session we will work on Azure SQL as a data platform working interacting in collaboration with different teams in Azure DevOps accelerating the value of your workflow. Implementing DevOps practice helps organizations to develop and deliver faster products, maintaining stability and confidence, increasing confidence in the applications they build, and achieving business goals faster.In this session we can explore the use of tools and platforms like Visual Studio, Azure Data Studio, Git and Azure DevOps for a modern platform in the data ops role using with DevOps practice in Azure SQL.With the combination of these platforms, we can experience the integration of the data world into the DevOps culture providing tools for the data engineer to support the process of delivering applications. Carlos LopezMicrosoft Data Platform MVP Senior Database Administrator MCPGuatemala SQL User Group community leader,Cloud Database Engineer.Experienced in multi-platform databases on RDBMS MS SQL Server, Azure SQL DB, Oracle, MySQL, No SQL experienced in MongoDB as well.Experienced in large-scale relational databases management support, passionate about K8S and Docker container tech-oriented to development and data platform.Advanced Linux user, Gentoo distro fan since v.1.4.In his spare time, Carlos is an enthusiastic swimmer and runner.Website: https://www.muppity.net/Twitter: https://twitter.com/carloslopezsql/",
        "start": "01:06:03",
        "seconds": 3963,
        "text": "gives you all the Microsoft tooling so it it helps you so um when you when you talk about these two tools you're talking about any using any framework to do the migration is that correct yeah to the immigration and then fly away you can also do it and imply why it looks like it has versioning so you could go back to the correct correct sorry sorry if I can misguide you there yeah flyweight the difference is that fly away not the um the paid version not the uh Community version has the the possibility to revert back the changes that you did in do does the comparison of the changes and advise you it each step that you're doing in the integration so that is what helps you that is I think that is a cool thing that Flyway has and it is good because I think not because I'm doing uh promotion here but Redgate has a lot of experience doing uh with SQL server in so it has a lot of tooling so they integrate those tools into that Flyway solution so that is why it's a little robust I think in that that way so that is why they have all these advisors uh um to to give you support when you're into implementing that is what I think I was going to ask you Carlos which databases were supported by Fly Away Flyway but I I found it it's a SQL Server Oracle postgres and it looks like MySQL is in the works for at least some features so that's a pretty uh that's a very good uh set of uh DBS to cover yeah and they are doing I think that they're doing Cosmos something like that and they're doing something else but yeah the main ones are are there they're doing uh Cosmos for postgres which came out uh last year you know so they are integrating to that I don't know how much if if they compare it to Usher compared to SQL at least how much they have integrated that but they say that they have it so that's good to know that's another option cool so um does anybody else have uh any questions for Carlos before we uh let him go back to Guatemala because okay one quick one uh of like uh so as far as um when you're starting a new project do you export a a deck pack file to get started and and create your your project and then use either Flyway or anything framework to uh do the pushing yeah I do but uh first I do uh let's see if I have it here huh let's see uh it's not that but uh what I do is I I get my DAC pack I backpack sorry because backpack is for for the code um I do my backpack uh and I go with the backpack and I put it into into my local container in my machine so what I do is I do all the coding in my in my computer my like local sandbox and then I I push it back into the into the code to the to do the testing in the in the sandbox in the in the Enterprise sandbox which is azure SQL serverless so I go and get pushed to it and I test it there so one it's but but this is a a local git not the the the the main the main git this is just for the devs and then I just then I go in when it's ready well you can eat that you can implement it to the solution but still I need to test it with the with the database developer team so when when that's done then I can move it to to the main solution which is other other kid right well and that backpack processes just wants to set it up and then you maintain it within the project exactly awesome cool okay so I'll stop sharing so um well let me uh let me jump in here and uh give you a real big uh thank you Carlos I was uh enlightening and a lot of good questions thank you everybody who who joined in and you can watch for the recording soon usually it gets posted the next day and it'll be at youtube.com Boston azure and watch the usual spaces on Meetup for uh the we have a bunch of I think we have seven more virtual talks lined up we just have to slot them in and as we talked about up front uh before Carlos started speaking we had the um we have two in-person events that were we're planning out right now one of them which would be the uh Local Edition Boston area edition of the global Azure boot camp on Saturday May uh 13th so I hope to see you all in person soon and uh thank you big thank you again Carlos and um until next time thank you take care have a good day thank you Carlos thank you Carlos goodbye bye thank you bye foreign "
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints. This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.. screen can you see my slide deck i can see it oh good okay excellent okay well thanks very much jason bill veronica for having me thank you all for showing up tonight or today wherever you are in the world this is going to be on azure blueprints and the learning objectives i have for us i've prepared about an hour's worth of content and at any point in time you have any questions let me know and jason definitely feel free to stop me because i got a couple monitors here and it can be difficult to see a scrolling chat screen i want to spend just a couple minutes with the slides i want to do 90 of this presentation in demo mode but i want to make sure we understand the business use case of azure blueprints and the high level workflow and you'll find i think that if you've already done work with azure resource manager deployment templates and if you've worked with azure policy for example you're well on your way to mastering azure blueprints by the end of this session you'll understand how to create deploy and track blueprints in a number of different ways i want to make sure that we cover not only the azure portal which is normally the introductory approach but also how to do the same in azure powershell azure cli and then how we can integrate azure blueprints into azure devops pipelines all right arino well let's see what do we have here session materials right the session materials are in github in particular the short url is tim w dot info forward slash azb and if you go out there you'll find um well it's just a simple repo that's got the slide doc and the supporting files from the session a lot of good goodies in there i think azb stands for azure blueprints whoops i'm presenting on my home computer which is a mac and i very very rarely present on a mac so i'm kind of clumsy i'm not even entirely sure you can hear or see me i hope that it's the case otherwise i'll be presenting to myself and to my cat all right hopefully you see a screen that says azure blueprints and what i want to call your attention to is the sneaky little word preview as azure azure blueprints has been in public preview status for literally years now to the point where if you've taken any of the azure certification exams blueprints is on most of them and i don't know if you know this but microsoft worldwide learning has a policy where they don't cover public preview features of course i asked them what the heck's going on with blueprints and their response was well blueprints is a mature enough product to where we include it so take that for what it's worth but i also whoops sorry about the slides i wanted to call this out here that of course the preview terms of use state that they're provided as is with all faults and as available and are excluded from slas and warranties now if you do find something in the azure blogs maybe the blueprints product team is providing production support if that's true let us know because i don't know that to be the case there's the traditional disclaimer that under normal circumstances public preview means you're on your own the problem statements that go into azure blueprints are as follows how do we track our deployments i know everything that's deployed in azure is recorded in json and you can get to those files and the resource groups and your subscriptions but how do we more granularly control those deployments we might have a golden deployment of a virtual network but now we need to deploy that and number of times yes we can fetch the json but we've got different people with different versions of these json files we need consistency in our infrastructure you might ask well well we're we're doing infrastructure as code and azure devops what else do you want well how about layering beyond just the json deployment templates you might have issues with taxonomic tag inconsistencies missing tags misspelled tags this kind of stuff you might have deployments that get snuck out to unauthorized regions there's the question of role-based access control and least privileged security how can you make sure that you're on top of that your security and compliance professionals are probably most concerned with that and then maybe you're not yet at the point of infrastructure as code and keeping your infrastructure alongside your applications in a pipeline but you need to do that how can we solve these problems it's quite a few headaches and i think i really love to know some of the background at microsoft about what their opinion of blueprints are because it's a pretty cool product very cool actually and i think that i'm going to make a strong case on how useful it can be for you and it seems to have gotten enough pickup at microsoft to where it's nicely documented across the board in the portal the"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "that i'm going to make a strong case on how useful it can be for you and it seems to have gotten enough pickup at microsoft to where it's nicely documented across the board in the portal the rest api definitions seem pretty complete to me the powershell the cli support all that's pretty robust yet it remains in preview and at least the portal experience is a little bit non-optimal more on that in a moment the things that we can do with azure blueprint definitions are the resource groups of course that's the fundamental deployment unit in azure after all you can deploy anything and an arm template as i'm sure you know but we can also layer in our back role assignments and azure policy in other words the picture here is that we can create entire deployment environments instead of just a one-off virtual machine or virtual network or aks cluster whatever it is you can define the entire environment of the deployment and track it end to end we therefore are ensuring consistency in our infrastructure deployments and as i'm going to teach you we do have a fair fairly good integration at this point with azure devops build and release pipelines the workflow as i said earlier is similar to existing azure technologies particularly azure blueprints you start your azure excuse me azure policy where in an azure policy you have your draft of your policy and then you publish your policy and then assign it it's the same exact thing with azure blueprints your blueprint starts its life cycle as a collection of json documents that you draft work on collaborate with your teammates potentially then when you're ready to start using a blueprint you publish it as a version and then the idea is over time you'll have potentially a library of blueprint versions and you may need version 1.5 for this environment or version 2.0 for the other environment etc the assignment i don't really like that word myself it's a little confusing in a way assignment is simply an instance of the deployment where you take a published blueprint and you tell azure resource manager to go ahead and deploy it and then as i said you can track those deployments using all of your traditional azure tools from log analytics to monitor etc blueprints also bring to the table a pretty darn powerful locking mechanism i don't know if you're familiar with resource locks in azure where you can apply read only or do not delete locks at different scopes i don't know if you can do it at the subscription scope but you certainly can do locks at the resource group and resource levels but here in blueprints it's actually much more powerful when you assign a blueprint you can optionally attach a read only or do not delete lock to the entire environment and you can look at the blueprint as basically being a protector a protection layer over that entire environment and what you'll see in a moment is that azure will put a deny our back permission on at that scope so if it's at the resource group scope everything inside it might be protected against the delete operation let's say and it's a deny and you might have got if you've got experience working with role-based access control in azure you know that ordinarily we people we human beings can't do anything with deny assignments that can cause problems where you've got the question of permissions inheritance flowing down through resource groups to resources and you want to do an override normally in a windows world you might consider a deny which would always overcome and allow at that same level but anyway you're going to see that blueprints make use of a very special azure security principle that i didn't know existed before i learned about blueprints where nobody including owners i don't care if you're a global administrator an azure id nobody can overcome the lock and that's by design because the idea is you'll be doing all of your life cycle management of the blueprint in the blueprint definition it's kind of a paradigm change you know for example in azure ad you have the privileged identity management or pim product if you've heard of that and microsoft would like us for instead of doing our role-based access control you know at the resource level or in azure a.d microsoft wants us to use pim to do all of our our back similarly for infrastructure life cycle i think microsoft is trying to gently steer us toward blueprints ready for a demo let me dump out a powerpoint i think we'll begin at the beginning we'll continue to the end and then we'll be done to quote alice's and adventures in wonderland here we are in the azure"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:10:11",
        "seconds": 611,
        "text": "ready for a demo let me dump out a powerpoint i think we'll begin at the beginning we'll continue to the end and then we'll be done to quote alice's and adventures in wonderland here we are in the azure portal and i'm going to head on over first to the blueprints area and once again if you're familiar with azure policy we have a very similar metaphor here we've got our collection of definitions and our collection of assignments it's pretty bare bones at least policy has a whole section for monitoring and tracking this doesn't yet that's that goes to what i said earlier to where this is a strange product and as much as microsoft seems to feel it's pretty important and now they've given the instruction that they've got to have powershell and cli support and all this other stuff but yet it still seems unfinished in some ways and it is here right over here preview whatever it's another discussion but we'll start by taking a look at the built-in definitions of course you can create your own definitions from scratch you can build upon the existing templates that microsoft gives you so we can hit create blueprint here and we'll see there's a blank blueprint template what you'd expect starting from scratch and then there's a collection of samples these are pretty interesting and i want to draw your attention to there's really three categories that i see here there's just the basic starter one the simplest one i found is this basic networking one that defines the deployment of a virtual network a subnet and a network security group that's the one that we'll proceed with in a moment but you also see several pre-built templates that are aligned to different compliance certifications fad ramp hipaa i'm sure that there's gdpr in here there's iso 27001 etc and that can give you a good head start because if you're wrestling with those kind of certifications you're probably wondering if you're newish to azure well what what knobs do i need to twiddle what switches do i need to flip to make sure that my infrastructure is going to pass those audits so that's the purpose of those templates my understanding is that these templates all come from microsoft's own full-time cloud solution architects and probably by extension in the microsoft partner network as well so those are two of the three categories of templates the third that i see come again from the azure solution architect community if you're familiar with the cloud adoption framework that microsoft publishes they have a foundation template they've got a migration landing zone template these again can save you potentially a lot of time and give you some really good tips and tricks and it's just a baseline environment to start with you can also go out to github if we do a search for github azure blueprints you can get all of the source code from those by going out to it looks like the repo is azure and then azure dash blueprints i actually cloned that for you in the the presentation files that i'm sharing with you again the short url if you want to go out there now is tim w dot info slash azb and what i did is cloned that entire repo in here of course i give attribution but let me see no it's the wrong one where the heck is it azure blueprints repo yeah i think it's in there like the old prego pasta sauce commercial it's in there there's a lot of stuff in there for sure including that repo but anyway let's come back to the portal let's go back to the correct page and let's select the basic networking v-net so we can kick the tires and see just the high level of how this works let's call this boston reference v-net how's that and optional description and then again very similar to azure policy we scope or place the definition at a particular level and we can do either management group or subscription here so we can choose our i'm going to choose my sponsorship subscription and scope it there this is going to be where the blueprint is available of course the benefit of the management group is that it's the level above subscription so you'd then have the blueprint be available to end number of subscriptions because this is all json anyway and i'm going to show you some ways to integrate this with source code control it's really trivial to keep your blueprint definitions out of azure at least initially and then just deploy them into whatever environment you need them to be visible at hope that makes sense let's go to the next step and the individual components of an azure blueprint are called artifacts and as you can see in the user interface you can scope your artifacts at the subscription or the resource group scope and we've got in this definition as i said you've got a resource group definition an nsg and"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:15:13",
        "seconds": 913,
        "text": "and as you can see in the user interface you can scope your artifacts at the subscription or the resource group scope and we've got in this definition as i said you've got a resource group definition an nsg and a v-net so the icons tell us that we've got first this resource group and then the paper references an arm template and then we'll see that there's a couple other artifact types that we can choose from all right so the artifact type for the resource group you might be wondering here now is this going to define a new or an existing resource group that speaks to the item potency of azure resource manager which defaults to an incremental deployment mode by default so if you define a resource group here that's called boston let's say and there's already one when you assign it it's going to leave it alone unless you do a force a complete rather than an incremental but incremental is the default so what you're going to see here is depending upon the type of artifact there's going to be a display name and then the actual resource name when you deploy it and as you can see if you're familiar with built-in functions and resource manager templates you can use some of those like in this case we're doing a concatenation to grab the resource name prefix parameter and then we're going to add rg to the end of it and notice here that you can specify that the value should either be hard coded in the blueprint or it should be specified when the blueprint is assigned if you want it to be more flexible then you probably want to choose this flag here and just make sure to name the resource group when you assign it resource group's going to need a location again you can either hard code that or say that this value should be specified and then there's just a convenience factor here where you can put in some tags whatever okay so this is the portal experience we're trucking on along here as i said we've got an artifact type of arm template so if we select what's in this starter template here it's defining v-net and one subnet and then this is where i meant that this is a little bit non-optimized best case scenario you're going to have all of your definitions and source code control and i did ask the blueprints team over a year ago hey just in case you haven't been suggested this it would be awesome to be able to dip into azure devops or any repository from here instead of having to do an import operation where you can pull the file manually from your system let's say or even worse do a control a control v to copy and paste and they took the suggestion they said it's on their roadmap again it's kind of been a strange situation i don't know if the pandemics come into play i suspect between yumi and the wall here that that jedi project the huge contract with the u.s federal government might shift shifted some priorities somewhere i don't know that's just speculation so we've got just a regular old garden variety template here and then the parameters show up in the gui here and the interface is either you specify them when it's assigned or you can hard code to do an override so the the resource manager template is defining the nsg and the v-net and then we can hit add artifact and as i said there's a couple other options here we can choose role assignment for example to pre-populate role assignments simple as that now just i want you to think for a second about how this might benefit your company i mean if you do work as a cloud solution provider or a managed service provider you might have blueprints that define a landing zone or an ideal environment for your client and you may want to basically scaffold the entire thing your best practices as far as the deployment definitions azure policy definitions and role-based assignment definitions which could include custom roles not just built-in roles so for example we might choose here from our role collection there's a virtual network or maybe it's just called network contributor let's see yeah there's a network contributor built-in role and we want we might want to make sure that we have an entry for that here and once again same song and dance about when to populate it and then lastly we can come back here and choose policy assignment and here we can choose custom or built-in and then we can just filter the list it's a little bit sluggish over here again if you're not familiar with azure policy these are json documents that you can use to enforce whatever it is you need to enforce governance wise whether you need to ensure that tags are present that you're using only allowed azure regions that you're enforcing only"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "policy these are json documents that you can use to enforce whatever it is you need to enforce governance wise whether you need to ensure that tags are present that you're using only allowed azure regions that you're enforcing only certain skus or stock keeping units of resources whatever that's a whole other subject but notice that you can grab individual policies and bring those in or more conveniently chances are if you're using azure policy to any degree you've rolled up collected or related policies into one or more initiative definitions and you can bring those in that just as a convenience factor let me just search for what might be nice inherit if i can type inherit i'm not looking at the right tab here inherit a tag from the resource group if missing how's that so let's grab that guy click add okay there you go so once you've finished horsing around here and structuring your blueprint you're ready to move to the next step let's save this as a draft and then it's going to get stored at the scope that we chose to store it at which in my case as you can see on the right the definition location field is my sponsorship subscription so this is an unpublished draft that you presumably would work with your team until it's just right and then when you're ready to do publication you can simply select it in the azure portal and you can edit or delete but you can also publish the blueprint which is going to make it ready for use you have to give it a version and that version and of course would be up to your team and what you want you've got some change notes which you can get to through azure log on analytics using kql queries etc if you need to retrieve that in the future and once you've got it published after this is again a little jarring we have to come up here yeah it says that it succeeded but you ever notice that that sometimes when you do an operation in azure it keeps you at that page you're like wait a minute what actually happened here so let's step back one and we can see now we've got our boston reference v-net latest version is 1.0 good deal we shouldn't have any assignments yet nope we don't so the last thing we can do now is actually conduct a deployment using that published version so let's go back into the published boston reference v-net and to do a deployment it's called an assignment so let's assign the blueprint we've got our subscription scope where it lives let's give it a name assignment boston that's fine i'll make sure to choose my home region let's see here east u.s like i said you may have over time a library of multiple versions and you can pick whichever one you want and then here's that bit about locking that i was telling you the default is not to lock but you can also do just protect against deletion you know how inactive directory local a.d you create an organizational unit you've got that flag protect against accidental deletion that's what this reminds me of you've got do not delete and you also have read only now be careful with that because that's exactly what it says you can't make a single change to that resource does say that not all resource type due to caching locks may take up to 30 minutes there's some legalese going on here let's choose the do not delete lock assignment and then azure is going to need a security context to do the deployment nowadays we have these handy dandy managed identities and a system assigned identity is one that azure will auto create in your azure ad tenant user assigned is a standalone one that you can create yourself in the portal by browsing over to the identities blade identities managed identities blade you can create your own the main difference is that system assigned azure will create it and dispose of it automatically as it needs to whereas the user assigned you control its life cycle now notice here that by clicking a sign with the system designed identity azure blueprints will create an a service principal identity that has owner access to the subscription so it can properly do the deployment and then check this out we will automatically remove this accent access when the assignment process is finished pretty cool all right and then there's the time consuming piece of filling out the parameter values so depending upon how you've defined your parameters in your source artifacts and how you want those specified that is either hard-coded or provided assignment we can add those values here and this will respect any defaults and any allowed value arrays that you've included in your json so resource group name i'll call this boston ug rg for our network"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "hard-coded or provided assignment we can add those values here and this will respect any defaults and any allowed value arrays that you've included in your json so resource group name i'll call this boston ug rg for our network contributor this is going to tap into our azure ad tenant i'll grab a fictional user actually better yet check this out i'm going to add bill zach who's here with us now and he's in the tenant tag name inherit a name what was the name of that tag i think it was location so i'll make sure that all of the resources that deploy into that resource group pick up the tag from the resource group i'll accept the defaults for the virtual network and the nsg definition looks like it doesn't have any parameters so i'll complete the assignment here now again this isn't a test to bring up the old whatever that's from this is actually going to conduct the deployment as you would expect and again the ui kind of just bombs out here but let's see let me refresh my portal let's go to assigned yeah so it looks like it's in waiting status so let's see if we click into the detail what it shows us here view activity log okay that's helpful yeah it's in a waiting status but at any rate it should all else being equal create that resource group and then create the rest of the artifacts but i'm looking forward to showing you that locking mechanism like i mentioned so the idea is that from now on if we have any maintenance to do on that infrastructure we're not going to want to go to the boston user group and start horsing around with the v-net there in fact depending on the lock that you choose you won't be able to you'll want to do all of your maintenance in the context of the blueprint so you would come back to the blueprints ui or your source code wherever the underlying files are and we could let's see if we go to our assignment we can update the assignment that's what you would do and then you optionally can go right back to the draft level and go through the publish assignment workflow iteratively however you want to do that again i want you to think of the azure blueprint as a strong protection layer on top of those resources such that the locks are going to prevent deletions or changes across the board the if you reassign the blueprint it's going to replace anything that was deleted let's say that we did this assignment without any kind of locking and one of your colleagues not you i understand but one of your colleagues were to make a change that you didn't want delete and update whatever it is the next time you could reassign the the um blueprint and just like item potency incremental mode deployments may or may not remove the change but it would make sure that anything that was deleted gets re-established based on the blueprint definition if that makes sense now the workflow if you wanted to delete this it looks like it completed good deal the way that you would remove this like let's say that this entire environment you wanted to get rid of which i actually will at the end of this session i'm not going to necessarily be in fact i'm not going to be able to delete look here it says cannot delete it shows the lock state right there we're going to have that i'm going to have to come in here and unassign the blueprint the unassignment i envision it in my head is that contact that protector that's on top of those resources when you do an unassigned operation it's like you're lifting that protection and then the resources are essentially unmanaged and then you can do whatever you want with them up to your level of our back privilege okay all right so i wanted to jump out to that resource group so let's jump out there and let's um let me show you what that deny assignment looks like that what the how the lock actually is manifested here so if we go to access control i am and go to deny assignments we see something here normally unless you're using blueprints this is totally empty all the time isn't it because it says that deny assignments block users from performing specific actions even if you have a corresponding allow but at this time the only way that you can add your own deny assignments is to use blueprints well here we are and we've got a deny assignment here at the scope but look who it's given to this is that special identity all principles that's analogous to the everyone identity that we have in windows in local active directory so that's going to affect everybody no matter what"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "but look who it's given to this is that special identity all principles that's analogous to the everyone identity that we have in windows in local active directory so that's going to affect everybody no matter what your privilege pretty powerful so let's say let's go into the blueprint and let's go into the subnet definition and just for grins i'll attempt to delete it of course again this again is bringing up that unfinished aspect that i've mentioned a few times this is obviously a bug it should give you a graceful dialogue that you might have expected to see in another context and the notification it should give you you know this operation is disallowed by a lock etc not a crash screen but that's what we get so again to finish this graphical bit the idea going forward now is that we can come back and modify the assignment we can do an unassign in fact we can get to that from the context menu here we can do an either an update or an unassigned are you sure you want to remove this assignment now look i want to call this out all resources created by the blueprint will remain so that answers the possible question when you do an unassignment is that going to whack those resources no not at all it just lifts that protection layer that the blueprint has on it so once that's it's going to say provisioning state deleting and it looks kind of scary but again it's not going the actual resources aren't going to go away that boston resource group should remain standing in my subscription questions comments concerns curiosities thus far anyone bueller anyone i don't think so yet okay let's turn our attention now to the conference files and look at azure blueprints from a more automative um standpoint because you know let's face it the portal's all well and good if you're learning certainly and even after the fact if you just know exactly what you need to do in and out fast that's good but for repeatability we want to look at automation and as i said at the beginning of the presentation blueprints pretty well covered with the other abstractions over the azure resource manager api so let's see where do i want to start first let's see what's this guy doing getting started with azure blueprints okay yeah this is fine so there's a powershell file in the in the files i've shared called warner azure blueprints and just as a side note i'm using a font called operator mono i there's a really cool course called vs pro it's called vs code.pro this dude trainer technical trainer put together this collection of vs code tips and tricks is worth the money for me it was think it was like 40 or 50 bucks usd but he recommended using another font and i like cascadia code a lot but i like operator an operator does this cool kind of cursive when you do a comment anyway assuming that you've installed the azure powershell modules which you probably know this you could just do an install module you don't do that install module az to bring down those modules now interestingly i don't think azure blueprint comes down when you do that though i think you'll have to do that separately i've got the code here in any case so make sure your azure powershell is installed we can do connect ac account or log in az account authenticate into your subscription you may need to set your context if you've got more than one subscription and then just make sure you could do a get module but otherwise you can grab the az blueprint module from the powershell gallery as you can see on line 12 here that is microsoft's official module for az blueprint and then we could for instance do something like get command from the module az dot blueprint boy it's awkward typing on this mac keyboard let's run that in my terminal there's not a whole lot of commands as you can see here very small number but they really cover the main ground right i mean what do we have here new az blueprint so we're going to see that there's going to be a json definition for the blueprint itself and then as you start to plug in artifacts to do this programmatically with powershell new az blueprint artifact pretty straightforward when it's time to publish the blueprint to a version we've got an appropriate command and then the assignment where is that set a z blueprint assignment right so pretty straightforward garden variety powershell as far as that goes"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:35:27",
        "seconds": 2127,
        "text": "straightforward when it's time to publish the blueprint to a version we've got an appropriate command and then the assignment where is that set a z blueprint assignment right so pretty straightforward garden variety powershell as far as that goes all right let's see here okay what am i doing get a reference to a sample blueprint object okay so it looks like here on line 16 i'm creating a variable to create a new blueprint definition assuming that i have the source on my system do i yeah i have a basic networking blueprint here and i think this is probably the same code that we were working with in azure but it's the same idea what you're going to have in your source code or on your local system in your blueprint project you want a folder for the blueprint and then inside there the blueprint definition itself needs to be called from what i understand blueprint.json and it's just pretty garden variety json format as you can see and we've got the artifact subfolder that you'll populate and these can have any names these are going to be the different artifact types arm templates i think you can even do an arm template parameter file then you'd have potentially one or more than one for your rbac role definitions and your azure policies that these have weird good names again this is definitely one i downloaded directly from the portal so you can see here we've got json with a kind of policy assignment and this is defining a resource id of one of my policy definitions uh i got this code again from just doing a download or an export from the portal and it's a little bit ugly with those goods if i did this manually i would use more friendly names but it's just meant there's several other examples in here that you can take a look at you know the drill modify to suit your needs let me go back to the file here yeah so to define a new blueprint give it a friendly name and then you path out to your blueprint.json file right and then i stored that as a variable because we're then going to plug the artifacts into that blueprint definition as you can see the next several examples new az blueprint artifact are going to plug those different json files into the blueprint definition then easy peasy when it's time to publish again just pass in the blueprint object and give it a version number and blueprint assignment anything special there the assignment name and then the assignment file oh that's kind of different i'm not sure what that's all about let's see if i can grab that blueprintassignment.json what's this doing here it looks like it's more or less a manifest that ties in the blueprint id the blueprint definition okay this must be where you provide your parameters i haven't gotten really really deep into this as you can tell which is why i'm being a little more tentative with my language yeah so this looks like the programmatic equivalent of what we did in the portal during assignment where you're plugging in any values that need to be supplied at run time or at go time okay and then i finish off here with remove az blueprint assignment i got the sample code from the docs and you'll notice again i'm not a plagiarist i always give my attributions on line four you can see a link that'll take you to the doc tutorial that this code came from all righty let's see so that's that what do i want to show next here i've got blueprints.ps1 is this any yeah this is a little bit different what this is doing is for example how to grab a blueprint from azure and bring it down to your system so any of those samples i know you can go to github but maybe let's say that one of your colleagues already published to azure and you don't have access to his or her source files i'm just trying to come up with an example off the top of my head there's a couple commands bookend commandlets in that az blueprint library we've got export az blueprint with artifact and import blueprint with artifact i get them confused here let's see input because and it's kind of backwards isn't it well not really if you think about azure being your source of truth for your blueprints i guess export makes sense we'll use export az blueprint with artifact where you want to grab a blueprint from azure and bring it down to your system so on line 14 i'm i'm creating a variable that's going to grab a reference to an existing blueprint in my subscription that's presumably what's happening on line 14 and then on 16 let me shrink this guy up here and then on line 16 we're doing export az blueprint with artifact just specifying there's my blueprint i want it to come down to my local"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:40:31",
        "seconds": 2431,
        "text": "and then on 16 let me shrink this guy up here and then on line 16 we're doing export az blueprint with artifact just specifying there's my blueprint i want it to come down to my local wherever i am in the terminal and if there's multiple published versions grab this version that's it and then the opposite effect would be import az blueprint with artifact push the sample blueprint to azure as a draft look that's kind of a handy command because we're able to take an entire folder so instead of horsing around with that manifest file that we looked at a few minutes ago i'm a little confused now honestly let's make sure that this export command is in that module because yeah it is they're here okay but i'm just thinking out loud now what the difference is between this and doing a oh okay we're sending it up as a draft i guess that would be the difference okay makes sense i hope this is making some semblance of sense uh all right let me see trucking on i don't have any sample code for azure cli but i did verify before we started tonight if i do a search for azure blueprints azure cli that there is a context a command context in the azure command line interface called az blueprint and it looks like policy create role yeah so they're doing their own thing you know that's been the situation with the azure cli isn't it i consider the app at the azure cli almost like an apple apple computer where they kind of march to the beat of their own drummer all right next if you want to go right down to the ground floor so to speak remember that everything in azure resource manager comes down to that fabric of rest api definitions we can of course interact with the azure blueprint product family using rest api directly and this is some code that i borrowed from the docs that uses power shells and abstraction but you know you could use your sdk or postman for that matter the general process here is pretty garden variety what this is showing us is first we're authenticating into azure as usual and then we need to get a bearer token or an api token that will attach to every request that we make to to the api so on line 12 it looks like we're building first of all they our identity and azure programmatically and then grabbing that token and then it's just walking through creating the authorization header and then i've got a bunch of examples here of making predominantly put calls into the api to create a blueprint to add artifacts to the blueprint to publish all the same stuff it's just these are the actual underlying naked rest api calls so the authorization header is going to have your api key and the body of the message is going to be the json itself i didn't include the json here but if you want to look at sample it's actually elsewhere in this collection of files i've shared and it's also in the the link of the tutorial itself all right next on our trolley ride let's take a look at some of the extensions in azure devops considering that you want to put your blueprint files in source code control and maybe ultimately integrate this into your continuous integration continuous deployment pipelines so let me go to that let me go to my organization and actually let me bring out my favorites because there's another repo i want to show you another project i want to show you let's see here show favorites bar always there's a microsoft engineer named paul toller he's australian and he kindly gave me a permission actually shared all of his source files for this project here's what happens here's how i find it found it i did a google search quite a while ago for azure blueprints azure devops and paul toller wrote a really nice linkedin article he posted it there for some reason where he walked through and he actually did quite a bit of work himself i think he wrote the azure blueprints um well he wrote a powershell module that does azure blueprints slash azure devops integration sorry about this ah i think i'm okay and he created a public azure devops project that showcases integration of azure blueprints in a build release pipeline context so all that's to say to give you the cliff notes version in the course files that i've shared or in the session files i"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:45:34",
        "seconds": 2734,
        "text": "showcases integration of azure blueprints in a build release pipeline context so all that's to say to give you the cliff notes version in the course files that i've shared or in the session files i created a folder in there called paultoller where i dumped all of the assets that he shared with me and gave me permission to share with you and also in the course files in the blueprints learning references document there's a markdown file that i created for you and i've just tried to summarize the most important links that come up in this discussion some docs links of course i give you a link to the microsoft azure blueprint definitions at github and then some of the specific extensions the azure blueprint powershell module paul's own az.devops.blueprint powershell module that's in the powershell gallery and then there's an azure devops and azure blueprints pipeline task that you can import as an extension into your azure devops project and then i give you links to paul's original linkedin article as well as to that azure devops public project and lastly another microsoft person named jim britt wrote his own powershell script module and you might want to look at that as an alternative to microsoft's own daisy blueprints it just does imports and exports i understand it's particularly useful when you want to download azure based blueprints and maybe it gives them in a slightly better format than just using that export command i don't know i haven't tested that but anyway what we've got here if i come back to the portal in my project i've created a project called azure blueprints if we go over to azure repos first there's good news and there's bad news in terms of this integration with azure blueprints and azure devops pipelines the good news is that it it's here and it works the bad news is i don't know if you're going to be able to do it if you're using the classic build pipelines the gui ones it's the eighth the azure blueprints task is only for the yaml pipeline experience which is really again speaking of themes where microsoft wants us all to go in the future to define your build and release processes in yaml format makes sense because you're putting the pipeline definition in source code right alongside your infrastructure which could be blueprint and right alongside your application's code base itself it's all in there which is kind of cool so let me see here what do i have in my pipeline script file yeah this is just starting let me see if i can zoom in a little bit just some initial little bit of work i did before i realized i needed more from paul and i gave all that in the conference files i didn't have time to put it all in here yet of course but let me just share my thinking with you what's going on here so in your build pipeline for example we've got this azure powershell task and i got that from the extension gallery azure blueprints task yeah here it is right here neil peterson wrote this one and this like i said is yamo only but there's two things that you can do here there's a blueprint creation and the blueprint publishing there's two things that you can do in here so it looks like in this case what's this actually doing well it's using my azure subscription service this is doing some different stuff actually it looks like this is doing pester testing and that's actually a good conversational point so just thinking off the top of my head here you might want to have your infrastructure defined as a blueprint definition and then using those azure blueprint tasks and also perhaps the inline script capability you could use pester for example to do unit testing on those json files make sure that they exist make sure that they're valid they um they what's that term that validate yeah and then once your testing is finished you can call that other task to do an assignment i think i've got some of that visible in my pipeline let me see let's see here let me go down to the bottom and add a new task let me search my task library for blueprint yeah there it is so if you go to the gallery and you import that as your blueprint as your devops task set you'll get two new tasks that you can incorporate into your pipelines as i said one for creating the blueprint the"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "so if you go to the gallery and you import that as your blueprint as your devops task set you'll get two new tasks that you can incorporate into your pipelines as i said one for creating the blueprint the other for assigning it the limitation there if you consider it a limitation is that there's not the gui form that's in the classic pipeline you have to use the the raw yaml to fill in the properties but it's pretty nicely documented i found if you as you can see here it walks through each of the configuration parameters what you have to plug in here it's pretty straightforward to create the blueprint you need your azure service connection name of the blueprint the path in azure repos presumably where you've got the the folder your project folder include subfolders yeah because that's going to be where your artifacts are are you going to publish etc so they're pretty pretty straightforward i found in my humble opinion so that is about that let me see if there's anything missing here that i wanted to cover um i don't think so let me cue this slide and let me go back to vs code one more time and do one more pass over here him yeah you know uh there are a couple of questions good let's do it okay the first question is uh can we this is from uh uh uh i think nigeria can we provision aks cluster via azure blueprint so kubernetes aks cluster yes what's beautiful about the blueprint metaphor is that if if it's uh deployable in an azure resource manager deployment template then you can use it with blueprints yeah i mean the arm template is one of the four or so artifacts that are available to you in blueprints yeah yeah literally any azure infrastructure that you can do in a json deployment template you can include in your blueprint definition okay um if that didn't answer the question please uh please let us know and that was actually from uh uh maryland not um sorry my name is rocco maryland yeah thanks okay thanks thank you sure and then um is there any part of the infrastructure that needs to stay live in the environment that you will deploy to with blueprints and then it goes on uh azure ad tenant or active or azure or uh active directory directory services or active directory vm any of that stuff uh use case came up with a customer they were looking to turn down uh wvd due to costs but i started wondering about a d and user accounts it's kind of a long um involved question maybe you want to glance at it if you have the um that the team's chat available to you tim rather than my to read it yeah well some things that came to my mind i hope i'm striking on at least a couple of the right notes here i heard dependencies perhaps and i heard the question of deployment modes as i mentioned earlier the default deployment mode is going to be incremental which says that you know azure says so to speak that i'm going to put these resources in this resource group and if they're already there i'm just going to leave them alone and if they're not there i'm going to add them and if the value is changed from what's in the template i'm going to put what's in the template you can alternatively do your deployment in complete mode which says that anything that's in the template is going to go in that resource group and if there's anything else in there it's gone you know so it's kind of wielding a pretty heavy hammer as far as other dependencies yeah the deployment is going to fail if azure resource manager needs to reach out and touch a particular service like you mentioned azure ad domain services and if it's not there if it's not present then it's to me if i'm understanding your question correctly it's just going to come down to looking at the details of the deployment and seeing what failed and trying to fare it out what it is you know that kind of thing and just to review all of our deployments are going to take place in the context of a resource group and i don't care whether it was you who did the deployment or blueprints it doesn't matter we can go under deployments in the resource group and we can see and track specifically every single deployment and we can did this change in the last couple of days or maybe it's my my screen resolution yeah you normally can look at every single operation and ultimately view the json of the json and see exactly what happened and grab the template i don't know if something changed or if it's just my resolution but this is kind of bugging out on me here i hope that response made some"
    },
    {
        "speaker": "",
        "title": "Tim Warner: Everyone's an Architect Manage Your Deployments with Azure Blueprints",
        "videoId": "dTDyCXy15lI",
        "description": "This is a recording of the September 1, 2020 virtual meeting.Everyone's an Architect: Manage Your Deployments with Azure BlueprintsGovernance has historically been a tricky business in Azure. How do you ensure consistency in your environment? You don't want to over privilege users, deploy oversized resources, or create Azure assets manually.In this demo-heavy one-hour session Microsoft MVP Tim Warner walks you through Azure Blueprints, a new-ish Azure governance platform that simplifies the entire deployment life cycle, from ARM templates to Azure Policy to RBAC permissions. Join us, and don't forget to bring your questions and curiosity!Session material: https://github.com/timothywarner/azblueprints## SPEAKER BIOTim Warner is a Microsoft Most Valuable Professional (MVP) in Cloud and Datacenter Management based in Nashville, TN. His professional specialties include Microsoft Azure, cross-platform PowerShell, and all things Windows Server-related. Contact Tim via Twitter (@TechTrainerTim) or his website, TechTrainerTim.com.",
        "start": "00:55:40",
        "seconds": 3340,
        "text": "and ultimately view the json of the json and see exactly what happened and grab the template i don't know if something changed or if it's just my resolution but this is kind of bugging out on me here i hope that response made some semblance of sense so thanks that tim and uh christopher if you'd like to elaborate or or unmute and ask further feel free can you guys hear me okay yes excellent thanks uh thanks for taking the time tim yeah so i was speaking to a a partner the other day and they had a customer and the customer was concerned about the price of wvd and they wanted to be able to turn down wvd and then turn it up whenever they needed it and my concern i was thinking blueprints and i was thinking like infrastructure as a code but i was wondering about the users and kind of can blueprints build out active directory and would you then import users and things like that that's kind of where my question was headed or is that need to be there kind of like asr right when they do asr you should have a virtual machine that's a domain controller in the failover site always there for testing purposes and things like that um so that's kind of what i was thinking about and you did kind of touch on it with the different implementation strategies but kind of getting into do you need to have a tenant or could you build a tenant out with blueprints and stuff like that okay yeah let me answer what i think i heard two things there first you mentioned about a windows virtual desktop being too expensive so is it possible to scale it down and scale it up and i've done i haven't done that with wvd but i've done that with several other azure services and what i would recommend you consider is maybe using either azure functions or azure automation run books to where you can programmatically and on a schedule or on some other event some other trigger you can do that of course there's going to be limitations if you're using a particular service level and then you wanna during off hours or whatever scale down if you're using features that can't be scaled down that could be a blocker but as long as you have some wiggle room i found that's a nice solution for for cost savings now the the directory thing's a bit trickier because i mean that's really the top of your hierarchy you've got your azure ad tenant and then your subscriptions that trust the tenant it seems you could deploy a tenant with a blueprint it seems to me but shifting that context because you know that this the blueprint has to live somewhere and you've got the management group the management group and the subscription is your only scope so so i don't i i don't think you know i wasn't i wasn't expecting a full answer because this is kind of uh you know an out there use case but i just felt that there was a lot of value if you could do something like this because i felt like it was something along the lines of devops right where you're spinning out a whole development environment uh only when developers need it um you know my thing was just about what are the dependencies are there any that need to be there like virtual machines active directory stuff like that or users um to be able to grant them the access right but uh i i your advice i think was good though i mean scaling in and out and uh doing that i think is a good idea and given that the blueprint definitions are in json and i showed you all some powershell you can always port blueprints to another tenant it's just with a couple line of code re-authenticate to the new tenant import the blueprint into into that tenant and away you go they're not trapped the blueprint definitions aren't trapped in in your current tenant by any means yeah i think that's good for for partners that are going to market with some of these things uh leveraging blueprints right could kind of uh shave off a lot of time with going to market there's a lot of power there yeah yep great thank you thank you again tim i didn't realize it was you until i heard your voice and then i got the pluralsight and i was like oh my god look who it is legislation with you likewise that's such a humbling thing thank you and it's kind of shocking like at a conference or something i remember when's the last time we've been at a conference in person you know but i i've introduced myself to somebody and he's like oh i knew who you were by your voice it's like whoa it's humbling it's gratifying thank you that's great yeah cheers cheers any other questions comments concerns let me bring up my contact deets and again the link to the resources are on this slide there there we go and my twitter's open my dms are open you don't have to follow my account if you want to get in touch that way or through my website it's all good as they say whoever they are but i think that's all i have jason thank you awesome thank you yeah me too good good jason no i was just going to say yeah thanks it was it was it was really good so one of the one of the drawbacks well it's kind of off topic but some of the one of the drawbacks to the virtual thing the events are that we're like doing things behind the scenes trying to you know keep things going and social media and all this stuff and it's like well at least it's been recorded so now i can go back and watch it because i did catch most of it but i definitely have to watch it again yeah that's how i am too once i i might have to watch initially but once whatever it is that's being presented i know what it looks like i can normally just listen to the audio stream and fill in the blanks in my mind it's convenient way to learn definitely were you going to say something in there bill no uh i was gonna also uh wrap up and uh thank tim in the audience uh see if there's any more questions so i'll just go to that so folks in the audience uh uh if there are any more questions feel free to unmute and ask them right now or uh mention something in uh in text and uh in the chat channel uh while we we'll give that a minute to see if anything pops up but uh in case it doesn't either way tim uh thank you for uh enlightening talk and helping us figure out another important area of azure and how we might put it to work for us and folks you see from tim's last slide how you can find him and rumor has he has quite a quite a lot of useful material on the plural sites so you can check them out further there uh thanks everybody for joining us from uh as far away as uh nigeria and uh uh nashville and um uh and uh around the united states and uh well i i don't know if we have another meeting booked but you can look follow us uh you know on boston azure on twitter or the on the boston azure.org we'll lead you to the meetup sites where we'll post the next events but we've been on a roughly two month cadence for uh uh and that's what we've for some months now since coven and that's what we plan to do into the future so so there's uh you can expect you know check back frequently we always we're adding new uh new events uh uh as soon as we book them so thanks everybody i guess that's uh we call it a night thank you again tim excellent talk appreciate it thanks tim all right i think that's uh probably "
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:00:01",
        "seconds": 1,
        "text": "A Fireside Chat about Build 2020 Announcements and Q&A Session. This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.. and if that's a problem would be curious clear tell us go scrub and see we can figure out where we're new at this but you know if it's recorded for the previous ones we've posted them to YouTube there's a YouTube channel if I add that to the slide deck so people can find it more easily and so if you speak and we're recording you'll be recorded of course so caveat and again if you're if you if that scares anybody and it prevents you from participating I'll be very appreciative if you could let us know that that's the case and because I'm recording it for YouTube maybe having the opposite effect that we had hoped for also as I mentioned we're trying a different format this is a fireside chat so we're all sitting around the virtual fire you know having a chat and since there are double digits people on the call we can't obviously talk at once so we're going to try and do is use the hand raised feature that teams offers and say for me I on the main floating bar on top of the team's you know at the bottom on my Mac at least there's a raise your hand hand and I'm just gonna click it now and my hand is raised I can click it again and raise my hand so we'll try to make sure that we we call we we will process people in some sort of order we'll try and keep it to the order that they raise their hands where that makes sense and I think teams will keep track of who who raised their hand first and we'd like everybody to be able to participate so that's just a mechanism for that but we're trying new things as I mentioned so we'll see how that goes other than that Jason a lot Veronica probably a lot bill very little have prepared some some notes that you know just to leave the conversation and share the learning's that we have but the hope is that you all jump in and get involved and participate in the conversation it's a fireside chat not a fireside lecture so with that let me ask Veronica and Jason if I left anything out though I bet you I think you I think you got everything okay uh excellent thanks I'm going to turn it over them to you Jason to kick off the fireside chat welcome everybody yeah welcome everybody so we wanted to kind of get together and talk about the build conference this year in previous years or kind of compare it to previous years and and kind of our thoughts what some of our strange screen freeze we we just wanted to go over some of the announcements that we thought were interesting and then also some of the related topics that may or may not had to do with an announcement per se but some of the sessions that we attended and you know pick other people's brains as I'm sure some of you guys have been to previous build conferences or attended some sessions at the conference this year so just gonna kick it off a little bit with talking about high level what the build conference is and sort of my experience with it in the past and then kind of get into the Veronica's and try to get a conversation going here so bill I see your handout yeah so I went to build a couple years ago and it was of course it was downtown Seattle it's the conference is really geared towards developers because I last year I went to ignite and it wasn't so developer oriented which which was fine I just wanted to experience it see how it was different than the build conference and between the build conference and ignite conference I definitely as a developer prefer the the content that's at at the build conference and when I went to in Seattle of course is like any other conference it's multiple days you're downtown the city you have to deal with you know you only have so much time during each of those days to get into the sessions that you want to get into sometimes there are opposite ends of the Convention Center which for building that also a big Pro is because the Convention Center is so much smaller than the the Convention Center in Florida worked night was because that building was a mile long if your sessions weren't close together there's kind of a problem at that point but the build conference it was pretty convenient being downtown Seattle so it was it was definitely nice to I like to go downtown Seattle but this year you know we didn't have that so and also when I went to build one of the cool things was it was"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "was it was definitely nice to I like to go downtown Seattle but this year you know we didn't have that so and also when I went to build one of the cool things was it was my first year as a MVC they had a fast lane for my first year as an MVP so they had a fast lane for MVPs and our DS so and they had reserved seating down front and that was kind of cool so um that was kind of my first tech big big tech conference and so for Bill you know I got I kind of I kind of appreciate build thinking about that first experience that I had a couple years ago and I know Veronica went last year and I saw her tweet so much and little jealous because she interacted with so much so many more people than I did okay she really had a good time you want to share your experience at Build last year Veronica sure it was super excited it was my first field that was awesome and actually it was my first field it was my first time in Seattle it was my first time being a VP I got my MEP just a couple of days before appeal so I I was excited but I didn't have any you know fancy things they didn't have any special line there cuz no one knew me I didn't even get my you know stickers that I was an MVP so I was hunting for program managers to give me the stickers so you can see that I'm gonna be peon um so that was fun lots of sessions I I know that they changes a little bit I have nothing to compare with since it was my first one but they changed the layout so some of them bigger sessions they had in rooms but lots of sessions they were just on the floor basically they had like a stand and then a presenter was next to the stand and then there were like a bunch of chairs around so it was more informal and even the keynote they had just lots of chairs in the middle of that huge room and people were coming in and taking the chairs so just standing around I wasn't too late for the keynote but I so then get I see it so that was a little a little upsetting but altogether it was a great experience I met so many people talk to all those amazing people that I'm talking to online door I'm following on Twitter ask questions they were all super nice so that was the best part during sessions you can learn some things but I think it's better to learn when you're actually talking to people who are building all that stuff and then Seattle was amazing I will like it there the food wasn't good and I'm not the one who is complaining about that these years the food was definitely better but their conversations were not there so it was really hard to communicate with people are ask questions though they implement is really good that you know the forum's last charts option so you could still ask questions but it was really hard to follow on the questions and you know it just is just hard when you are not in the same room with people and yeah I really nice people so that's the downside of this year is build you have to tow anything like that one good thing to this the the build this years you could do it you you could watch it in your pajamas you know you didn't have to worry about cuz usually when I travel you know everything's wrinkled so I have to like iron it in the hotel room and you know I didn't have to do any of that stuff and like you said the food was the food was much better this year than a bill you had been to build before PDC which was what it was before bill I have been to build as build and before that there was a conference called the professional Developers Conference which maybe morphed into build not sure did you get it is that back in the years the years when you got some really really good swag at the events like these give like what hops and phone yeah I think I got a phone a Windows Windows Phone I know who's jealous and I think I got an Xbox 360 I'm trying to member that was a PVC or build they gave us some heavy-duty swag yeah so this"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:10:12",
        "seconds": 612,
        "text": "phone a Windows Windows Phone I know who's jealous and I think I got an Xbox 360 I'm trying to member that was a PVC or build they gave us some heavy-duty swag yeah so this year the swag wasn't quite as good right there is there is some links online where you can get images for wallpapers and things like that yeah so can I pose a question here like Jason for yourself what are some of the topics that were at build this year that you're most excited about so my what I wanted to get out of build was as much container kubernetes the stuff that I use for work more or less what what could I learn that would help me in my everyday work so I was really looking at sessions I had to do with kubernetes and that sort of thing containers kubernetes and I found a few but not as many as I was hoping how about you - I worry about all the cool stuff like AI and bots and the virtual reality on hololens I know they were pushing a lot towards them power apps so I don't know much about it and it was kind of cool to see what you can do and you don't have to be a developer to create cool things is there is there a particular one that you you you either have you drilled into a little bit that you like - I can lighten us on what's so cool about it yeah definitely I have some stuff should we should we ask the the crowd any questions before we get into like announcements and the sort of stuff that we really got out of it what do you think what do you guys think sure yeah anyone has a question please and you want to raise there anyone want to raise their hand and give us any their build experience this year or previous years just like that we have a very interactive crowd tonight so that's cool folks this is gonna be the brave first one oh we got why thank you Gary hey guys first of all this is the first time I've been invited to build and I think it's because of my MSDN subscription but that's beyond the point one of the things I did notice was that as you guys are talking this 15 minute break or so or a 30 minute break between sessions and so since we were doing this remotely we really didn't have to wait that one for each talk no it's one thing the other thing I was looking for was laser they announced that blossom is now [Applause] you can code it wasin which is the the the UI portion of it without how to use JavaScript the client-side web assembly stuff yeah and then they also talked about Maui which was a new product that xamarin is moving toward I guess but now he's not going to be around til next year so I'm not sure exactly how I'm gonna be able to use Maui since I don't have access to that and then the other thing is if we do have another one of these which is remote it whose people to sign up for the for the events that you want because I waited till last minute said well it's virtual you know I can just kind of walk in into it but there's a certain limit to each of the sessions so you need to pick the sessions that you want to go into those were my observations yeah that's a really good point Carrie cuz I I had that frustration too there were several sessions that sounded really good but there were already fool and that that really kind of surprised me like well it's virtual why can't I get in it the rooms not full I mean but there I guess they either artificially put limitations or it was the framework that they were using I'm not sure because some of so some of the sessions I went to were team sessions like I went to a focus group and that was a team session and it was it was pretty much just like we set tonight up you went to link and then you join the teams like this and that was actually when I was first exposed to the the ability to raise your hand and and teams never saw it before but that that was a team's session but some of the others that I went to weren't someone were actually"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:15:16",
        "seconds": 916,
        "text": "actually when I was first exposed to the the ability to raise your hand and and teams never saw it before but that that was a team's session but some of the others that I went to weren't someone were actually pre-recorded ahead of time but yeah that was it was frustrating that some of them are actually full I think they were limiting the attendance if you don't mind my pipe enough they were limiting attendance on sessions where they really wanted audience feedback just because they didn't want it to get to like really chaotic scan and stuff like that teams itself does have a limitation at two hundred and fifty people in a in a standard teams channel so you know the the teams live capability that they have they didn't always use that and and those you know can get I guess I don't know how many people they can put in a in a team's live meeting but which I think most of the the sessions that build were if I recall correctly but so it really depended on on what the type of session was and whether they were looking for feedback or not you know or targeting it for feedback so did you attend very many sessions Jim did you have any favorites um yeah I tried to attend a good number of them I I was also trying to balance the fact that you know that was that was my biggest problem with with build this year was when you're when you're there and attending in person you you can pretty easily you know get work to kind of you know lay off a little bit and let you attend the conference especially some investment that they they've contributed to and and all that stuff but when you're doing it remotely like this they they don't really see you know the investment and it is easily and so they they're like well you know hey you're not going anywhere why don't you get some yeah get some billable work in and you know that's that's all well and good but they didn't actually clear off the table for us to attend really so we kind of had to still get some you know get our get our regular workday in and attend sessions but yeah I definitely had a few few favorites very interested in the the Maui and and the project reunion stuff actually but I dig in on that and until we're to a point where that's fun to talk about I guess I that's cool yeah I kind of had the similar experience it's so much easier to make sure that you feel your day up when you're you know you don't want to sit in hotel room you traveled for the event you want to go to the conference and experience it whether you're on the floor of the expo talking to people or you know maybe side meetings with people that you met up with there or you know going to sessions but when you're home and your pajamas and you still have that day at work that you need to get stuff done it is kind of hard to get the most out of the day special and you know you can always go back to and watch it anytime you want so it was it was definitely difficult for me to watch a lot of sessions I think I during the two days I think I watched six sessions that that was pretty much it I've watched a few since then but yeah I definitely had the same same same problem yeah that's that's actually one of my biggest concerns with recording sessions and stuff like that it's like kind of reminds me of the you know the VHS and DVD collection that you know you you spend all the resources buying those movies and videos and then they sit on the shelf and you never actually pull them down and watch them and and that's something that I kind of worry with like you know build sections and stuff like that it's like all right there they're online they're available by the time I get around to watch them they're gonna be a little dated already so being there for it lives makes a lot more sense it's worth the investment but you know kind of going back it's like you know I already know you know a few things that are a little a little dated already and that it won't be long before they're very dated that's true a lot of this stuff you know bill is asking what was some of the stuff I was interested in video so one of the things that goes along with the content just stuff that you can consume is the whole the announcement Microsoft learned TV it's basically if you let me share my screen real quick I can show you what it is real quick you know the sky is red Jason I do I was going to click"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:20:22",
        "seconds": 1222,
        "text": "learned TV it's basically if you let me share my screen real quick I can show you what it is real quick you know the sky is red Jason I do I was going to click on these I'd like to show you the web page let me go back to teens here sure jump into this give you the context so this is um can you see my screen yep yeah all right cool so this is uh one of the announcements it's in preview of Microsoft's learned TV you know they came out with the Microsoft learn last year the year before but this is this is kind of like you could go to this link and any time throughout the day they're playing new content and it's kind of a 24/7 location to get content as it's kind of going out you were down time to playing with it sounds kind of interesting i-i've I kind of collected new content to to consume but I haven't I haven't gone hearsay and started watching stuff yet because I'm still going back to the build site itself I'm speaking of let me go back to this slide so we put together some slides to kind of drive the conversation if we needed to so here this is this slide has the resources that we thought were kind of cool so the the digital swag Jason I don't see you don't see the slide okay cool I am sharing my half instead of my desktop then yeah you can see it now you can see this you can see this slide now github yeah okay okay yeah see I actually wanted to share the desktop on me stop sharing sure desktop okay all right that way you can get all the apps okay Kim can you see the power PowerPoint presentation now yeah okay so there is this there's this github that has some swag in it but something that was kind of cool was the wallpapers a day they put together I thought about trying to use one of them for my background tonight like the background for Mattie Ledger's kitchen [Laughter] [Music] yes so they get there's some different wallpapers and this is on the location we can actually download it for your your computer that was Bill branded stuff the important thing for everyone if they haven't dug into what is what was announced it build is this group of content that they put together they call book of news the interactive ones pretty good there is a PDF version floating around somewhere but then are the the one mount on the web is much better because you can get the videos and then of course there's a lot of hyperlinks to jump off the blog post with the information of course you've got the table of contents and then you can of course search it cuz it's a web page but this is definitely a really good a link to get is the the book of news here that's got all the announcements are the pre announcements that they I'm the planned ahead of time if you haven't dug into trying to find any of the content if you can always go to channel 9 they still do have channel 9 around even though they're starting to put content in other locations there were some interesting insights directly in the the book of News's index yeah yeah just just the way they organized some of the topics so it's like if you if you look at it a lot of the the dotnet and stuff like that is now under Asher which I mean it kind of makes sense classically that all would have been on you know probably connected the windows because you know dotnet was so deeply connected to the Windows platform but but it's not that anymore so you know the the only real news under Windows as a separate category and it was interesting that it got its own separate category it it almost felt like it should have been a subcategory you know Windows should have been a subcategory of Azure just just adds a sure as your client I guess you could think of it but I did get its own major heading and and the only real thing under it was project reunion you know I I looked through the table of contents bid but then I started searching through it and I tried to kind of gauge where what I wanted to watch from that and there wasn't a"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:25:30",
        "seconds": 1530,
        "text": "thing under it was project reunion you know I I looked through the table of contents bid but then I started searching through it and I tried to kind of gauge where what I wanted to watch from that and there wasn't a lot of kubernetes stuff so I was kind of disappointed on that one via so the Channel Nine's got the videos but the build the event build sites a lot more useful so you can go here and do a nice searching it shows you the three days that they were run but like this isn't as your user group so if you type in Azure it'll give you all of the sessions that have to do with Asher Asher and there's like two hundred and successions you know I found I found Jason that I was trying to search for a specific content through here and it was fairly useless like I was looking for stuff on app services I think and I had would only be like ten hits maybe and I was getting like multiple pages yeah okay so I have the the same issue it's kind of like using Google sometimes you just have to find the right phrase to the query but see oh and this actually highlights another thing with this year's build as you see duplicates in here so since it was a forty-eight hours straight content being played you actually had more than one chance to catch a lot of the sessions so and the sessions that were live because some were pre-recorded and just you had a link to it but the live ones oftentimes the Q&A session was different between one versus the other but the content was pretty much the same but the Q&A sessions would differ and they tried to play them at different times so that it would catch one side of the world versus the other side of the world so it'd be different ends of the business day or different ends of the day or sometimes would be one and running one day and then one at a completely different time the next day so you do get a lot of duplicates in here when you're searching or it appears to be duplicates but yeah so the search isn't the best it's not Google but it does it does provide some sort of filtering for you versus like channel 9 it's it's not quite as good either maybe they use the same search engine so they don't have um then I have a search they don't have a sub search for this they have a filter sort by level but yeah one thing that is kind of cool about this site so this is the the msbuild site if you go into one of these like for instance I said I was looking for a lot of kubernetes stuff soku Burnett to see what comes back with this one there weren't too many sessions and you can see there's several duplicates but let's go into this one so as your arc you know oftentimes the the big thing that I go to these especially if I don't make it to like build or ignite is I'll go this and now watch the session which is it's nice because you can speed it up and not be just one time's play but the related links are almost all hyperlinks here they don't really give you the download of the presentation these days or on on this site but you can and they do link the relevant sites which is kind of cool for some of them it's a little more useful than others some of them really have context friendly related links others are real general like let's see if this is azure arc and kubernetes let's see if it even takes it okay so at least it takes us a document for the session that we were at not just generally the docs so it is nice that they did connect some of the dots to add more value to the content it would be a really nice touch to give you a download for the presentations too though is kind of questionable as to how valuable having a PowerPoint really is it is nice to kind of give you one of the things I do like to download content ahead of time is to see whether or not it's something I want to watch because it's kind of hard to preview a session I would say that the I get that point Jason that downloading a presentation in advance would be pretty useful to gauge your interest level or whether it's too superficial you know maybe you're trying to dig in and learn a lot more whether it's high level or you know really advanced but if they do point to the the official Doc's that that content is going to age much better than a presentation one and and they've really done a fantastic job of last few years of building out their Doc's at Microsoft account site it's really first-class it was not nearly as well structured and rich as it is these days you know just a few years ago totally true so this slides the important one that has all the high-level stuff some of the announcements that I thought was interesting beside the"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:30:36",
        "seconds": 1836,
        "text": "rich as it is these days you know just a few years ago totally true so this slides the important one that has all the high-level stuff some of the announcements that I thought was interesting beside the TV was Windows Terminal I've been watching it for a while but it hadn't been announced and like my laptop has the the slow ring insiders build on it for Windows so I get some of the new stuff but my desktops not even on windows insiders build so it's a lot slower than the one on my laptop so my laptop I've had wsl to and terminal for a while but I haven't been using them day-to-day because they're not on my desktop but Windows Terminal one is now available for recent builds of Windows which is kind of cool and I definitely want to show that in a few minutes we have a chance here's some of the stuff I thought was interesting interesting around aks for any of you who are interested in the kubernetes side of things is they G so they g8 a few things that were already in preview but Windows Server support I mean that's that's kind of important to have pools of Windows Server containers running and have it G aid for production purposes and along following the trend of putting everything on a private link and Azure they've now got it so that you can put the azure kubernetes api which is a public endpoint compared to like and as your websites application you know it's on the internet but it is protected by a authorization but now with private link you can create your custom your private cluster because your cluster work compute was always able to be on a virtual NIC network and not in the public IP space but the API always was you could do a white listing so you could whitelist api's but you couldn't put it in your virtual network now now you can so that's also that was also announced and a couple things that were announced just slightly before build but there were some build sessions related to it was the azure spot for IKS you can actually if you have like a dev cluster or QA cluster test cluster if you've got something that's really built like Netflix that you can put a chaos monkey in this would also apply to you and production but it's in preview of course but as your spot is the quick what are the cheaper way to get VM resources so you could put in a KS cluster up on these resources and save they were saying you savings between 45 and almost 90 percent sometimes on the resources that you want now I don't know if you know since the whole everyone is working from home and you know we've learned that compute is not infinite in a cloud anymore I'm not sure if the savings are quite as steep as they once were but that's definitely one way to save because and the other way coming down the line to save that they still haven't been able to light up in too many locations is the AMD chips those are those VMs are a lot cheaper than the Intel chips so I've been I've been kind of watching what's the cheaper ways to get the cheapest ways to get kubernetes and the spot ones the one that they previewed and there's also this new optional uptime SLA because the the thing is with aks is you have the underlying VMs but the whole management plane is not you don't pay for it so it since you don't pay for it then Microsoft really can't put an SLA on it so they now will take your money and give you an SLA for it so there's this there's this whole optional SLA you can get and that also found kind of interesting because it it's really geared towards okay so how can we service the customers didn't have these requirements of SLA so those were some of the announcements that I was definitely interested in she's chasing that I'm fascinated by this optional SLA I honestly hadn't realized that the controller was not under SLA so how much are they charging for for the yes all right so here's the pricing so you've got to choose I think it's an East US ten cents per cluster per hour so that's a 9.95 okay that's not in that's per cluster that's not too bad okay yeah oh yeah well with that 72 monkeys of today 72 bucks sounds about like a VM Tamiya so they must need they need to must need to make"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:35:44",
        "seconds": 2144,
        "text": "cluster that's not too bad okay yeah oh yeah well with that 72 monkeys of today 72 bucks sounds about like a VM Tamiya so they must need they need to must need to make it highly available more or less but that's actually reasonable not that it's I'd hope it's highly available in with but we're just not paying for it right yes hey Jason you mentioned something a minute ago about private link that that's a good launch point for a quick comment one of the things that I've noticed over the years with Azure like anybody has been watching Asher for a while you've seen it kind of grow up right and fill out all the functionality kubernetes for example now you can have private link which is the security feature but the some other examples of security features that are kind of filling out the platform are that here's a couple more examples that along that theme the azure Security Center which is a if you're not familiar it's a place to examine the health of your resources and this is thing anything from maybe I have a database that doesn't have proper firewall rules maybe it's wide open or I have some storage that isn't encrypted or I have a virtual machine that isn't patched stuff like that that it can statically scan it also has some dynamic scans dynamic responsiveness like it's advanced threat protection calls it things like if your sequel database is seems to be undergoing a like a sequel injection attack if it notices that or its actual training an unusually large amount of data it can give you some real-time Alerts of those things so some of them are configurated some of them are might be you know your apps been cracked kind of thing but they have this secure score that is kind of they've gamified the the idea of how secure you are and just as an example of maturing that they finally you can interact with the search your score buyer an API and also they have so that's one one example you know they're filling in the details they are checking the you know more and more of the boxes as your Sentinel which is their send their incident and event management security tool where all of your logs security related logs can be aggregated in one place and analyzed holistically that now has multi-tenant capabilities where if you want to look across multiple systems but not all in the same workspace you can now look at that under one pane of glass you know that's example that's getting more sophisticated and even private link like Jason mentioned is making its rounds and becoming available with more and more services as a community service for one another one I know that lit up recently was with Azure key ball and that should just be there in game like everything ultimately is going to have for example private thing and one more small example is in the beginning if you wanted to encrypt something like a sequel database or a storage account the keys were all managed by Microsoft's you could check a box in the portal and have your data encrypted at rest and Microsoft managed the keys just as another example of them filling out their security you know feature set is more bring your own key features have have lit up I know recently it wasn't it build was a little while ago maybe six months ago address equal database lit up with that I believe and then now as your key vault this is another feature that's available there so you can bring your own key to a sure key balls encrypt - so just thematically the security platform is continues to mature and continues to fill in small gaps so it's good good time of help that's really interesting stuff bill thanks welcome Jason um a quick interrupt can you or somebody who was Roenick I'm sorry the link or the something flew by about zero downtime deployments I'd love to see that link I can't find it yeah that was for pass yeah okay that was on the that was on the learn TV see if it still up it was this session coming up zero downtime deployments with Azure passes 645 you mention it by three minutes on that and I learned TV right"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:40:52",
        "seconds": 2452,
        "text": "if it still up it was this session coming up zero downtime deployments with Azure passes 645 you mention it by three minutes on that and I learned TV right now so yeah that's all live stuff so they're not recording that you think it's got to be available somewhere I mean they wouldn't they wouldn't produce the content and I just let it disappear yes it's being done by a MVP and RD but yeah here I can I can make sure oh I got it it splits on channel 9 evidently is it on Channel 9 - well there's something from March 31st with that title it might be the same thing ok great yeah cool it's so well I had a couple of things here from Veronica - so you want to talk about these Veronica sure I just have a couple of slides there so I was really impressed by them announcements related to machine learning and BA framework I think last year they were really pushing towards everyone was pushed towards Asia and everyone every every every other announcement was related to a sure these time the the announced lots of things and they were trying to connect them to Azure but not all of them were on Azure like responsible ml that is really cool and we actually if you attended our meetup last year we when we celebrated our anniversary a basket of Boston measure we actually learned about responsible and well before it was officially announced we had team from Microsoft and they were talking about it and they show some examples so it was amazing and now even built they had several sessions related to responsible amount and that is really important because you know you need to make sure that your model it doesn't have any bias that the data is correct that you are you as a human you have lots of power to actually train your model and create AI model that is no it is fair it is including different you know aspects that are important for your application for that specific model and then you you can change it and then Microsoft is helping you to achieve on that that is actually mostly for researchers for people who are doing machinery and full time but it just interesting to see how what they do there how they are helping everyone how you can use jupiter notebooks with responsible machine learning you know we I hope some of you had a chance to attend a session for our Nita if not then I check the blog post check the video recordings from build there were several sessions around that and then boss very work did I inject the comments on the phone oh yeah thanks so I remember one of the points they made about responsible machine learning and AI was that they wanted to have transparency into how it works so you can't tell if it's biased unless you understand it and in another principle that they talked about was like using it responsibly I believe that they have it's not telling you how an algorithm works but it's their responsibilities of AI and they just announced I think it was today that they are not going to sell base recognition technology to police departments anymore so I think that's them trying to live by their you know with everything that's going on today and responsible ml is you're part of a solution here where I also I think it might have been from the lecture we had at Boston Azure where we learned that different races might come up with more false positives than others right so proudly responsible ml is you know having your technology work for everybody not just for the"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:45:57",
        "seconds": 2757,
        "text": "that different races might come up with more false positives than others right so proudly responsible ml is you know having your technology work for everybody not just for the the people who are building it out and Redmon's say put to the whole country the whole well I thought that was a kind of topic all yeah there are lots of options how you can change the parameters to make sure that you include everything that is important and not make sure that it the model is not biased I didn't use it myself I just read about it attempted possession that was really good with a couple of sessions during build I am NOT on that level of understanding how much it really works but I'm trying to learn more about it and it's really cool they're definitely moving forward okay can we move back to the slides okay so the broad framework that is actually closed to what I am doing I had a couple of projects with the pave work so I am really following their announcements I'm really following their news and they released a framework is DK 4.9 with lots of cool things so there's like the whole least integration with Microsoft teams and another cool thing is that actually you if you have several BOTS they can be combined together as skills so each bot is a skill can be used as a skill for another body and then you can create the whole bought tree with different pots combined together and they fastened you know information back and forth also adaptive dialogues I know they were talking about it a lot before and they did lots of work around it because that is really important because you know sometimes you can enforce a user to ask specific questions and I remember I had lots of issues when I was building BOTS and virtual assistant skills you kind of forcing your users to ask the questions or choose an answer between two or three options but you know sometimes most of the time you you shouldn't do it and that logs can help developers to without you know extra effort to integrate adaptive dialogue so even if your user is not following your scenario that you created that's fine your body is not going to be confused the body is gonna sell returned correct information or you know another cool thing it can actually now pass pass the conversation to real person so they have the handoff and I think I have it and in my slides yeah so the the human hand off here is the YouTube video so you can either watch this video or watch videos that they have on the channel 9 or any build sessions related to that that is really cool so they integrated they can be integrated I think with two services that can actually connect BOTS with humans so if your body is confused or your customer actually insisting to talk to a real person and there are lots of cases that when they actually need to do is a real human that is really now it's an option you can integrate it with those services using still buffering work and if we go back to the slides yeah okay so I wanted okay I mentioned the skills and oh yeah I missed the composer so boy framework composer that is basically a UI and UI tool where you can drag and drop some boxes and arrows and then create your dialogues create parts of your dialogues but the cool thing is that you're still getting your your solution and with project with real files so you can either use the UI or you can use Visual Studio or whatever ID you're using there and continue maybe"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:51:05",
        "seconds": 3065,
        "text": "your solution and with project with real files so you can either use the UI or you can use Visual Studio or whatever ID you're using there and continue maybe maybe you start in the composer and then you moved you move to your no Visual Studio and then continue doing it there so that is really cool I know the kind of a week challenge about exporting from power virtual agent to bought composers so they are working towards it I know they showed the demo where they did it but I think it was like really raw demo they basically can I combined it just for build it is not actually working so you can connect both framework composer with power virtual agent and power virtual agent kinda I think I have it in my slides maybe not so power virtual agent that is also yeah maybe next like doctor I have yeah I didn't put a link but if you if you google it they I think they released it last year and this year they actually with all with everything that is happening in power platform now they own they have so many cool things like one of them is partial ocean so you will have to be developer you don't have to write any code to create your bot it is the drag-and-drop experience you can upload some probably PDF or FAQ page if you have and it's kind of parse it is pretty intuitive it is II I think it's easier to understand how it works without going back to documentation but for the bathroom or composer you probably need to read a little more about it there are so many things going on at the same time and you you actually have code and you actually need to understand what's going on in composer but for power virtual agents you can be just a business user you don't have to code anything and so yeah initially they're gonna connect the composer and the virtual agent so you'll be able to know extract your files from one thing to another and then connect them together and you know they can be skills for each other so if you create a POJO virtual agent but then you can use it as a skill for your part as you create it in the composer and then okay call your services they didn't talk about them a lot so they so those two links they are showing basic updates they moved some things to GA they still have a bunch of things in preview not nothing some nothing revolutionary happening there but in are small things like they eaten more URL voices for speech that is great because before they had I think three or four now they have eleven and different languages and no oh yeah you've seen new voices yeah that's that's awesome and you know small things here and there and then Q&A maker you can actually so in Q&A maker you can have that chit chat so some some things they are really pre-built for you so you are not starting completely from scratch language understanding and text analytics know they're there enhancing down slowly and you know adding new small features there maybe not as huge is like the bot framework but still know if using those things everyday then that will definitely so some of your problems okay let's move back and I wanted yeah I put them on expand time here just to mention so you know about it they added some key optimization techniques that were built for training the touring model for them onyx run time so they will be available I think now it's June and radius so probably now I haven't checked it so onyx that's their open source she's living in tool it is kind of"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "00:56:12",
        "seconds": 3372,
        "text": "so they will be available I think now it's June and radius so probably now I haven't checked it so onyx that's their open source she's living in tool it is kind of like tensorflow but yeah I shouldn't compare those things because they are completely different but you know there are lots of different tools and onyx is among them and and Mel dot not I actually I don't remember if they had a session about it and if they specifically mentioned all those improvements maybe they did maybe I just missed the session but I later on I attended that I'm a lot not conference I think it was just a couple of weeks ago he did maybe a week ago yeah I don't remember and there the worm specifically talking about and all dotnet and you features there so now model builder is part of Visual Studio you don't have to install it separately and model builder is basically also a UI tool that allows you to to have all the benefits of them other ml so you don't have to you know start from you start building your models from scratch you just basically using that UI tool called model builder uploading your data or connection to your database and choose the scenario here and based on auto ml capabilities it will choose the best model type for your data and then you get a model you're basically getting two projects connected their two projects in your solution one is your model you'll remember that model and then the second is a console project that you can use for testing your model and then you know once you get your model then you can use it in your applications like any kinds of applications and also they have a new feature in the model builder you can connect it to our machine learning so it wasn't available before and you know in general they updated the UI is look it is looking way better than it was before they added new scenarios Oh doesn't work okay that happens but yeah in general you don't need to install model builder if you want to try them out not and you don't have to be a scientist to use amoled nuts that is for C sharp and F sharp developers it is really easy to start I I tried it I had a couple sessions were explaining how I used it and you know there was the whole amount on that conference recently so they also had lots of videos posted on YouTube if you want to learn more about it and I think that's it for me Jason I I had a few others like I mentioned the majority of stuff I was looking at was geared towards kubernetes or stuff that I use in day-to-day and there was this this was a pre-recorded session by Sean McKenna that you can watch having to do with kubernetes best practices it was a it was a good session really brought up a lot of stuff and highlighted some of the new features that they've turned on in natural portal it's becoming more and more integrated with like the advisor and they've actually started adding more useful stuff so I can show you the two things that I found most valuable out of that talk was this new item under diagnosed and solve problems you click on that you'll be taken to this and you get two choices cluster insights or networking cluster insights it scans your cluster for certain things gives you a green checkmark or some information and I don't have any red heirs which is cool but they do give you some warnings you can find out more information about them and it's actually been pretty useful like for instance one of the things this view has been nice for is I have some jobs that run cron jobs so they run as a container and then they go away so if you're looking at it if you're looking at your history or logs in kubernetes by itself you don't see a lot but this view would"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "01:01:18",
        "seconds": 3678,
        "text": "jobs so they run as a container and then they go away so if you're looking at it if you're looking at your history or logs in kubernetes by itself you don't see a lot but this view would surface jobs that were being killed because they ran out of memory and tried to restart so this would highlight the the oom kills which was very useful for me to track down that one of the jobs actually need more memory than what we were giving it and then the azured record advisor recommendations they've tied those into the AKS cluster as well and this is just a sample cluster there's not going to be any recommendations here but they do scanning if you if you click on this link it'll show you all the recommendations that they will look for so that's actually that that link was actually pretty interesting wait sorry or I should say this this it's it was about an hour long and it's but it was pretty good I had quite a bit of good content and especially if you do use nae KS and then it highlighted these new blades this link is actually pretty useful and it was just kind of mentioned in one of the sessions this is it's a blog on medium and it I don't know if any of you guys out there use aks and you turn on the insights for containers and before you know it you were paying as much for ingesting yes metrics yeah so you know long if you've run into that this is the article that you want to read this was written by one of the guys on the edge of monitor team how to fine-tune your capturing of metrics so that you're not paying as much for ingestion as you do compute so that was that was definitely a really good find yet Jason assist you think just aks or you think it's more general to up insights that's a good question I believe it looks general from it is kind of general but it's geared towards the container pieces which is going to be your aks yeah so we we have some app services it is obviously it's different than I guess but we also finding said our as your app insights bill is getting increasingly bigger bigger piece of the pie yeah and when it's your ingestion feed it's not like you can get that any smaller I mean even if you're not keeping it I mean we all know that you for keeping storage around it's going to take it's going to cost some money but if you're not keeping very much data but there you get that cost it just ingesting the data so that you get to charge for the few days or 30 days that you're actually keeping that it just you're just frightening when you see that that cost as much as your compute does but this is this is an article that they recommended you look at if that is your feedback as to at using Azure monitor because it was it was a session having to do let me show you I've got the notes here so it was it was as your monitor for containers this was the session that I was on actually was a focus group so you may or may not be able to find this recording but the the gym in that focus group was that link that medium just medium link right here but yeah that was that was one of the key takeaways that I had was that that article because it's been a real pain point and last but not least was the Windows terminal so I do use I often use the WSL for Ubuntu to interact with kubernetes but with and you can see I have all these icons across the bottom but now with terminal one being out I can I can get rid of some of my icons on the bottom because I can use the the Linux here at the command prompt PowerShell and you can even do a cloud shell here so I can get rid of like 4 or I can get rid of 3 of these icons that I have my my bar so if you guys aren't familiar with terminal it's basically for those of you who present or have vision issues like the older I get the more I get is you can actually easily scale this by the mouse like anything else what you could do to control and then roll it on your mouse that's super nice I mean it's strange it that's such a nice feature but you can also get all of your other terminals all in this one location so I can go to command line I can go from PowerShell to command line I can go - boo - and then they're they're really they're really starting to add a"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "01:06:22",
        "seconds": 3982,
        "text": "also get all of your other terminals all in this one location so I can go to command line I can go from PowerShell to command line I can go - boo - and then they're they're really they're really starting to add a lot of features to this until you get used to it so one of the cool features because there are other terminals that friends of mine used to have multiple screens but so this has multiple screens if you do shift alt D it'll split the screen so now I get two of them next to each other because one of the things that I'll often do is I'll tail or watch a log on kubernetes and it just needs to run but right before I started using this I had to have one window open and do the actual work in another window and see events happen so it's kind of nice that you know Microsoft is actually created a terminal does this because there there are many other terminals that do it and you you can keep splitting them I just did something I didn't mean to do but it's it's highly customizable if you go to the drop down here and you go settings this is where you can it will open a JSON file this is where the settings are for your profile and you can customize a little bit but until you get used to what it's doing you might wonder what the shortcut keys are this is kind of hidden if you go to the drop down you hold down on believes the Alt key and click settings that opens up the default this is not an editable file this is generated but this is a JSON file that will show you the defaults that are set up for the system so these are some of the this is like some of the settings that you can change in your settings file but this these are the default well what it currently is so if you want to change something you can look and see what it is currently because this is the fine-grained like colors but all the way at the bottom are the shortcut keys so here the shortcut keys that that are default out of the box so duplicate keys next tab previous tab so if you want to learn how to use it a little bit better it's probably documented somewhere but this is this is just as fast as trying to google it but that's it's kind of a hidden thing to have to hold down the Alt key whenever you go to the settings but that was that was an interesting talk to to finally you know like I said I'd I've been paying attention this for a while but I haven't been using it because I just haven't been able to install on my desktop but now I can actually install my desktop pretty slick and the interaction with docker is so much nicer than it was before ok so close oh and I believe that that was all the items that I had I have one more I can add which is another piggy back up here some of the community stuff you're talking about is the so in the old days of azure as you used to have something they only talked about I think I'm visual there's no garmin-sharp video um the bass have something called the azure appliance and I don't know if they ever really shipped it but it was talked about a lot so you get of your own Azure in your own data center and I don't think the appliance went anywhere then it resurfaced some years later as azure stack and azure stack was actually a more I think that got more traction I don't know how much traction I don't really have any insight I use the public cloud so I don't really have a lot of I don't pay a lot of attention to how's your stack which is a similar API experience as the public cloud except it has fewer services and you can run them on Prem again I don't really know much about it but I did notice that it build many of the announcements were centered around Azure stack HOD and I guess it's a rebranding about your stack if I'm understanding it correctly somebody can correct me if I don't have this quite right because I want to read the description Azure stack hub is an extension of Azure just like Azure stack was and as your appliance before that that provides a way to run apps on Prem and deliver services within your data center but the thing about this is that I found most interesting was that there are aligning it with edge computer IOT and other things that really have a there are much bigger drivers now than they were back in the early days of azure when they were trying to figure out he has your appliance and how to get delivering this and their data center maybe the killer app is that Asscher for sure not running in Azure cloud but running outside of it is you know machine learning running on an IOT device that doesn't have a network connection all the time for example and so forth and there are a bunch of announcements around Azure stack up some of it would release their partner ecosystem some of it as new capabilities that light"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "01:11:25",
        "seconds": 4285,
        "text": "connection all the time for example and so forth and there are a bunch of announcements around Azure stack up some of it would release their partner ecosystem some of it as new capabilities that light up like some aspects of Azure container networking interfaces fleet management as your container registry and a couple other ones but just de matically it seemed kind of interesting that that was the focus anybody know they have any better insight than I do on what Azure stack hub is intended for did I get it roughly right I personally up now either but I did see that they were like I've got it on a screen there I did do quite a few announcements around Azure stack and they do they do seem to be adding more and more to it the - your stack up I'm not sure Veronica did you have any final observations you wanted to share no I think I covered everything maybe we can move to questions and you know maybe someone can share their insides and what they like mm-hmm what what was excited yeah so just to piggyback off Veronica's comment um we'd love to hear your feedback of course and your questions and comments but also before you vanish we'd also like to hear your feedback on this session is this a good format for you any any ideas for us would be appreciated with we're still trying to figure this whole virtual thing out and so we were experimenting some but it's hard to get feedback unless we get it from people like you who actually attended so - Veronica's first point I'd love to hear your your your comments on build and what excited you and and if you're especially excited about something that you'd be interested in requesting a talk on it like a you know a 60-minute version of you know al-jabat framework or something any thoughts from anybody just unmute yourself and if you kappa looks like the the hand waving thing didn't turn out to be that important after all i think you guys a good job oh sorry your hand up there i just wanted to give all the presenters uh bill and jason and veronica kudos thank you for giving us the guided tour i think it's it's very easy to kind of lurk and absorb information and I think it makes the presentational format very organic for remote things with groups that don't necessarily know each other and can get in I think it being physically co-located makes it much easier just kind of have those hallway conversations and not feel like you're interrupting someone it's easy to have someone go on a roll and I've just learned a lot absorbing things through Mohsen here people doc is always nice so thank you for driving that even if engagement can be difficult we have been using bot framework recently to kind of augment all of our call center staff that we've had to spin up who have been very like overwhelmed and so we've built everything into their knowledge base and so a lot of Veronica's updates hit close to home I was like man I gotta go look at skills and I gotta go look at escalate to person because now we've forked off some of the work that we've done and we spun up like four BOTS in the last a couple months here and so and there was some unification work but everyone has their own content authorship and guarded about who can actually login so that's kind of fizzled out even though it's all kind of part of the bigger organizational thing that would make sense for all of them to be able to leverage information other knowledge bases so I definitely have to look into that after tonight another big piece of Q&A maker that got a refresh during build was they used to have everything editable in markdown in terms of the answers in terms of links in bolding and for probably people on this chat for developers that's not super scary but for people in the communications department that's not their linguistic franca it's not something that they like doing and and I'll also boot I write down and mark down every single day their variant was really bad it like it killed whitespace and so any weight any liner turns got automatically created converted to like slash n slash n"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "01:16:29",
        "seconds": 4589,
        "text": "down every single day their variant was really bad it like it killed whitespace and so any weight any liner turns got automatically created converted to like slash n slash n so if you wanted to do list in markdown it was slash n /n immediate asterisk space and there were no carriage returns anywhere that were allowed so it made it really hard to actually read what was going on and see paragraphs and stuff and now they have a nice WYSIWYG editor and it's exactly it makes it way easier to actually manage that content which really democratizes the people putting in the content which is the whole point of Q&A maker existing in the first place is that anybody can go put stuff in there so that's been something interesting to learn about certainly if there's we've spent a good chunk of time doing it so if to the immediate point before this if folks want a 60 minute overview of bot framework I feel equipped to do it at this point because I've done it organizationally for setting up other departments for times now so it's somewhat rehearsed in terms of getting people on board to that that's a most of my thoughts and takes on this thing so that's great thank you for sharing that Kyle in case we want to take you up on the offer to share more about bot framework later because you would you mind reaching out to one of us so we have a contact yeah I think I'm friends with Veronica on Twitter I don't think I don't know I guess friend we follow each other yeah I can put it into the chat we can certainly reach out and talk about what would be a good vehicle for doing that others think someone else had a question questions comments concerns Gary follow up on what you said bill was I remember going to measure that worldwide event I forget what it's called but the mill 5 organization I think they actually purchased an azure appliance and I think they said it wasn't wasn't cheap as they kind of said and then they said that they powered up it was really noisy but they probably would be so I'm on that team over there probably could help you if you had more questions about the you know the follow-on product you were referring to so no thanks Gary sure that that's one thing the other thing for Kyle if you're still are they just was thinking that you know yeah for someone who's even cut considering a bot is like how could you what's the the costs were a proof-of-concept you know and you know creating a bot you know you talk about an organization that you're not sure that you're going to have the throughput that your call center at the Vermont institution that you work for a Kyle as opposed to a small company where you're not sure that you're going to get that much calls that come in that would actually hit the bot and things like that so that's wondering about you know in terms of cost of starting out things like that so those is just some of my thoughts right now and that's about it great question I have costs uh can I share my screen I don't have to I can just I can send you some links we did I did a cost analysis of putting together a bot for when we were doing this I just made you a presenter we're just gonna go through my work emails come come back to me so we're not waiting poking it while I search this but then I'll share some of our onboarding observations no other questions comments I know I still have a list of sessions from build that I want to watch it's just now that it's furthering for the way like someone mentioned maybe"
    },
    {
        "speaker": "",
        "title": "A Fireside Chat about Build 2020 Announcements and Q&A Session",
        "videoId": "FMIUo3sPOQQ",
        "description": "This is a recording of the June 11. 2020 virtual meeting.A Fireside Chat about Build 2020 Announcements and Q&A SessionBill, Jason and Veronika will manage the meeting, but all attendees are welcome to ask questions, provide their feedback and share information.If you have any questions or feedback you can reach out to @bostonazure on twitter - or to any of us directly via twitter (handles below) and via Meetup messaging.",
        "start": "01:21:35",
        "seconds": 4895,
        "text": "no other questions comments I know I still have a list of sessions from build that I want to watch it's just now that it's furthering for the way like someone mentioned maybe after you mention it but it's like the further further away you get the less relevant or the more outdated it's gonna be so it's not hot to watch anymore you know Oh real-world cost here whoops muted so people should be able to see this uh yeah so they have a very generous test tear when you stand up a bot there lots of services that come alongside that visor see what it's been billing us but cognitive search is one of them you need to get an app serves this plan those have a lot of different like tearing and scales you need cognitive services emboss services there a couple other there's AI or the the application insights and stuff there are a couple other services but these were the ones that materially affected the cost for your test system there are just some real low level two years worth of stuff that you can do it might run you nine bucks a month for production which is all we have we don't really have a dev environment other than our local machines on here and the way that they provision some in Azure some test tier services our / subscribe to our only allowed one of them so I think like the as a cognitive search is one of the expensive ones the f-test tier you can only have one person so if you wanted to stand up a dev test environment that we're both cheap you'd probably one of those would have to get a lower tier but productions like 164 bucks month is compared to the cost of a call center it's nothing so 174 bucks of bucks months all-in is probably not bad we don't actually get a huge volume of stuff on this right now I mean I think we get 500 messages a day which is not trivial but we're going in production we're going nowhere near any kind of limits that we would possibly have on it so it's like it's like all things in the cloud and you can kind of scale out as needed and reprovision stuff we've ran into some weird stuff where cognitive Services is one of the very few things measure has where the scale out skews the scale out ability to go change between services has a lifetime skew it doesn't allow you to manage it during a instance you have to stand up a brand new one and then move a whole bunch of indexes they have like a dotnet package solution that kind of helps with that a little to migrate stuff over and then delete the old one and kind of repoint some things so there is a way to do it long term and I think they're working on in their feature backlog for that team is seeing that they can transfer across SKUs yeah feel free to if we have time for though feel free to ask any other questions that if people if folks are interested in it or if there's tons of interest we can certainly find a time to go over more stuff in that space thanks Kyle cool always nice to hear real-world stuff definitely yeah I started researching the virtual assistant template I think I forgot to put it in the slides and then forgot to mention that is something really interesting it's like the whole new template for if you create a new virtual assistant skill and it provides you out-of-the-box lots of cool stuff like connections you can a maker Louis and option to deploy it and it's pretty much like it me working a virtual assistant skill out of the box and you can just build on top of it so it's really cool I'm I'm actually writing a blog post about it so probably I'll publish it sometime so yeah I'm just slow a slow writer but it's cool I was impressed by that template well are there any final comments from anybody on the call oh I kind of say a lot of things I'm I'll just add my two cents here is that just virtual thing is kind of exciting because I've actually logged into the zurich user group and so you know you don't have to limit yourself in this area anymore and so um there you know it's noon time for me over here but for them it's after hours and they all have a toast where they all carry their own beers and you know I have after the event and things like that so that's pretty cool the other thing I did at the build event was that I logged in really East Coast time which obviously building in the West Coast hasn't started yet they're three house behind us and so I was able to actually see build from the UK because it's there their time at work and things like that so the machine learning I think I'm not sure which one it was was there talking about one product which is still in preview where it's used by lawyers actually to go through a bunch of documents PDFs and things like that and condenses or something like that if you're looking for something specific and so I think it was actually a project that Microsoft has which is out of the box that you can actually use but I I just remember going around that's a really cool product you know and so that's something else go look into but those are some observations I've had well I've been staying at home here on that note on Gary's note who's dialing in from the farthest away who's furthest from Boston the Kyle are you from Vermont yeah I guess Burlington Vermont is the the price to be keep track and see how how much reach we get people to give any calls in from Zurich where the West Coast the rat was on a few of them earlier not today thank you everybody for joining thanks it was at least week is there a place we you guys post the slides we can would be the best place to put them probably this slack group or what I what I'll do is I'll stick them in blob storage let me put them in a slack group I can also put it in a comment on the meetup so you can get them from either location oh that would be great thanks Jason cool okay thanks Nate buddy thank you thanks Aaron "
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Azure Landing Zone by Abdul Kazi. This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog). um and let me know when you guys can see my screen i can see it perfect so um hi everybody uh so my name is abdul qazi um and i'll be presenting on uh microsoft azure lan uh landing zone so it's gonna be an overview before i get started quickly you know i want to keep this very interactive uh so feel free to come off mute i won't be looking at the chat but if you have any questions just come up off mute or you know um bail uh veronica these guys are going to be uh monitoring the chat anyways is there somebody speaking in the background okay thank you so before we jump start uh get started so here's a quick introduction uh about myself you know um i've been in the iit industry for almost 20 years now and one thing i want to bring your attention is about my blog so i have actually written a couple of blog series on azure landing zone and caf cloud adoption framework so do check them out uh they're pretty detailed today it's gonna be really an overview so i'm not gonna go into much detail but uh hopefully you'll find uh those articles uh helpful uh what i'll do is also at the end of the presentation i'll put the links in there that is you have them there and then feel free to connect with me on twitter i'm very active on there also on linkedin uh always nice to have people and learn from others as well so quick agenda uh for today so we'll talk about uh cloud adoption motivations why people are moving to the cloud the value that the cloud ready environment brings i'll do a quick overview about uh the cloud adoption framework uh cloud adoption framework is a huge uh piece and it can take you know days to cover so i'll just give an overview of what that entails then i'll talk about the azure landing zone uh how it relates to the cloud adoption framework and then we'll talk about the azure landing zone design areas and then uh go through azure footprint uh blueprints blueprints is still in preview but i'll uh go through it anyways and then lastly talk about the azure policy and how it relates to the azure uh landing zone so let's talk about uh cloud adoption motivations right why people are moving to the cloud so as you might know cloud has really become a buzzword a couple of years ago you know a lot of people were saying okay everybody's moving to the cloud i should move to the cloud where you know so really a buzzword but i think as cloud has mature people have understood okay why do you really want to move to the cloud um because any company regardless if it's enterprise smb mid market what have you you know you have to provide a justification to move to the cloud why do you want to move to the cloud is there a cost savings is there a reason that you want to exit out of your own data center you know or are you looking to move to the cloud because you want to build a dr disaster recovery or you want to build a second data center in the cloud rather than building a another location or an extension to your on-prem environment so it really depends on what the motivation is going to be but there are multiple motivations there a lot of people are moving to the cloud what i've noticed with our um enterprise customers um at least they have one workload in the cloud now so um i work for a microsoft partner who is a azure expert msp so we usually work with the enterprise space and those customers you know are already in the cloud now but the challenge i'm seeing with them is they have no idea um how to get there or um when i start doing their landings on reviews things were not properly set up or it was not properly accounted for meaning they said okay let's go to the cloud and then there was not a lot of planning done why they want to go to the cloud the other biggest thing about the cloud and it's a challenge i'm seeing is around um you know it's a different model so cloud is really a opex model"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:05:04",
        "seconds": 304,
        "text": "done why they want to go to the cloud the other biggest thing about the cloud and it's a challenge i'm seeing is around um you know it's a different model so cloud is really a opex model versus a capital expenditure so if you think about a traditional on-prem environment you're buying hardware you know software hardware what have you you're buying servers networking equipment firewall switches you're usually buying them on a capital expenditure generally speaking uh you would do a depreciation of three five seven years and after that you know you'll go back and do the same thing cloud has changed that paradigm what we're doing now is um think of a netflix right we're renting the equipment uh from the public cloud company in this case azure and as long as you're paying rent uh you have the services available um i try not to use the netflix example because the challenge with netflix is it's a flat fee so the much more uh better example that is the line is a utility bill you know the more consumption you're using the more cost it's going to be so the biggest challenge i'm seeing with the cloud is people um do not understand how they are being charged or or what the cost is going to look like so i think uh that's the biggest challenge right now um cost optimization so uh when people generally speaking move to the cloud uh what they're doing is they're taking their on-prem environment from the architecture uh and design aspect and moving is as is which sometimes does not match um i'm not talking about lift and shift so lift and shift is you know something different but what people are doing they're saying okay what do we have on prem just move it to the cloud and we'll uh go with it uh it doesn't work that way the other thing is operational uh compatibility you have a cloud operates on a different operational compatibility versus on-prem environment right so those things um have to be accounted for the other piece uh important one is um lack of cloud skill set and we've seen this in the industry um working with one of my enterprise customers they're moving from on-prem environment to the cloud and they're bringing their on-prem skill set into the cloud uh and they're struggling you know uh for example is automation so devops a lot of people there's still a lot of need for automation for example terraform or jetkins or you know the other uh languages that might be out there so that's still innate so what you need to do you know you don't not only have to plan for if your cloud is ready but uh you also have to plan if your workforce is ready if you still have the skill set and how that's going to play when you move to the cloud otherwise uh it's not going to be a smooth transition the other thing is compliancy your compliance is going to be very different um in the cloud versus on-prem because on-prem it's your location you are basically you know you are going to be hosting in that location if you're multi cl like if you're doing a private cloud then that's a different story but majority of the things we've seen is people when they have their own data center they're abiding by you know the compliancy but when you move to the cloud uh you can host your data anywhere any country then that becomes much more complicated um and we'll talk about that so that's uh other another thing and then the other thing was lack of trust and desire for control that was the biggest um i would say drawback why people were not moving to the cloud or they were not ready because they wanted to hold on to that you know data they're like oh this data belongs to me i need to hold it i need to you know see it um but i think with with time they're seeing that cloud is much more secure uh microsoft spends around a billion dollars a year on security alone uh so they're seeing uh cloud is becoming much more secure than their environment and it has become much more relevant than to host um workloads in their own data centers so before i jump into the landing zone i want to talk briefly talk about um what the microsoft cloud adoption framework looks like so for any of you who are not familiar with the caf it's known as caf cloud adoption framework um it's basically a collection of documentation technical guidance best practices and tools uh for companies to move to the cloud and adopt cl or make a easy"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:10:06",
        "seconds": 606,
        "text": "caf it's known as caf cloud adoption framework um it's basically a collection of documentation technical guidance best practices and tools uh for companies to move to the cloud and adopt cl or make a easy transition for cloud adoption uh cap actually started with microsoft own consulting services this is what they used to use internally and then they made it public now so anybody can look at cap and then follow uh the framework and then the adoption the clouded option framework basically brings so it's three faceted it's people process and technology one thing to note here is uh cloud is always going to be a iterative process so regardless if you uh have done a project or uh build a service or an application what have you you you know it's gonna come back again because things keep changing so it's really iterative process um and then as you can see the circle is going around because it's really a iterative process around people process and technology uh technology might change people might change and then you might have to change up change your processes um to make sure that it's aligning with the technology and the people so it really becomes um a strategy and then for calf i would uh say you know the first thing is governance and we'll talk more about i'll touch on governance but governance really becomes a important piece of for anybody moving to the cloud i cannot stress that enough so let's take a look at what the cloud adoption framework uh phases look like so there are uh six different phases so the first phase is strategy so in the strategy phase you define your business justification and expected outcome so basically you say okay why do i want to really move to the cloud you know what is the business justification the second one is plan so you uh create a plan and basically an actionable plan for the adoption how you are going to be adopting cloud to meet your strategy or to meet your desired business outcome uh the third one is going to be ready and the ready is really you know preparing the cloud environment for the plant changes and that's really where the landing zone comes into play so landing zone comes um is part of the ready phase of the cloud adoption framework now moving along once you've uh planned or prepared are you ready then you start doing the migration so you can you can start migrating uh your workload so the different ways of migrating uh mainly two you can do a lift and shift so you can migrate as is or you can do modernization of your application so you can refactor re-host you know those kind of things um so it really depends on what are you trying to migrate where are you going to migrate and what the use case is uh the other one is govern and govern actually comes again from a governance standpoint uh before you even go to the cloud you have to start thinking okay how is the cloud um going to look like from a governance standpoint there should be a government board uh who should be making the decisions for example saying okay uh how are we going to limit people from provisioning everything because once uh it's think of cloud as the pandora box if people open it you know it it can go haywire very quickly so you really need governance from that aspect and lastly manage uh you have to have um some kind of uh plan how are you going to basically conducting your operation for the cloud so from patch management to you know compliancy security those kind of things and then management can also include your uh hybrid environment as well if you are going to be going that route uh so that is very important as well but today we are only going to be focusing on the ready state for the landing zone pins so now let's talk about uh what exactly is a landing zone and why use a landing zone so first off you know um you'll be surprised i guess you won't be surprised but a landings a lot of things within a landing zone you probably would already have used it or would be familiar but i'll use an example of a house or a building or even a bridge right when you're building a house you lay the"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:15:10",
        "seconds": 910,
        "text": "landing zone you probably would already have used it or would be familiar but i'll use an example of a house or a building or even a bridge right when you're building a house you lay the foundation so you have to start from the foundation you just don't go in and start building the rooms or you know start putting um construction the foundation there has to be very strong foundation same concept with azure is an azure landing zone helps the customer set up the environment you know not only for scalability but security governance networking and identity because these things have to be planned uh beforehand before you even get there so i'll give you an example uh from a identity standpoint right uh people might um already have an on-prem environment they want to move to azure now if you did not plan your identity properly then when you move to the cloud there are going to be hiccups there another example is networking and we'll you'll see that in the networking slide is if you do not properly manage your ip space there could be a potential conflict between your on-prem uh environment ip versus in the cloud ip scheme uh so that has to be planned so that's why what happens is azure landing zone is crucial for any new environment when i'm doing a lot of reviews for my enterprise customers the challenge i see is that you know they um lag planning on all the services and they were quick to move into uh testing they're like okay we want to start looking at this workload and just start testing and start moving the challenge is you have to have a better a very strong framework and very strong base if you will um to make sure that your azure environment is smooth and up to par now with landings on uh you know you can uh so so for example i'll back up actually so basically what happens is let's say you're setting up a brand new azure environment so you'll set up a new tenant then you'll have the azure active directory and then on that you'll set up subscriptions now you can have multiple subscriptions or different kind of subscription azure offers so for example you can have a enterprise agreement ea you can have a microsoft customer agreement mca or you can even have csp cloud service provider agreement which is fairly common among the smb market uh based on those subscriptions you can have landing zones within it so landing zone is not limited just to enterprise agreements or mca and actually it also includes other offers so if you want to test out landing zone you can even do it under your msg and account or other accounts there there's no limit that i know of where you can not install or you can configure landing zone so hopefully hopefully this is making uh sense so far if you have any questions just feel free to ask any questions so how do you get started with landing zone so with landing zone you know as i mentioned it's really a iterative process uh there are tools out there so microsoft actually provides terraform modules for the people who um want to automate the entire process this can be automated i mean amazingly from setting up management groups to win v-nets to you know um ip addresses what have you everything can be done so it's really a iterative process and depending where uh you are in the life cycle and how big is the environment sometimes what i've seen is customers really want to start small so smb customers they want to start small maybe with one vm uh you know a couple of virtual machines so that can be they prefer to do it manually because also learning process but and then if you're rolling it out for an enterprise customer you definitely want to go with the enterprise scale landing zone um which really um is a much bigger piece of the pie so it involves much more um things if you are going to be doing a landing zone for a smb because estima uh enterprise customers in this example is enterprise customer requirement would be having an express route versus a side-to-side vpn so those are the minor differences but that actually makes a huge difference in the environment and those things have to be planned out up front because if you don't plan that out accordingly then that can cause a lot of issues from a latency from performance from"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "makes a huge difference in the environment and those things have to be planned out up front because if you don't plan that out accordingly then that can cause a lot of issues from a latency from performance from you know downtime um so those things really need to be planned accordingly can i ask a question the um so i get the importance of uh planning your landing zone right uh you know so it's right sized for your enterprise if you're so so some companies start small like you pointed out and they they might want to grow is the landing zone something that can also grow with you is you know can it be very lightly uh you know a very light uh landing zone at first then a year from now you've uh built it out so that it matches your you know maybe you go from one workload to 10 workloads can it grow with your workloads i guess is a good way to put it yeah exactly and i'll actually answer your question in the next slide because that is going to be the perfect slide for you to see how that's going to work for a small and large environment so i'll come back to your question okay thank you sure no problem uh so moving along let's talk about the design areas and so these are all the design areas i'm not going to go into all of these because i can literally do a session on each of them and actually it does require a vast amount of time um to go through it because there's so much information that is required but the first one is the enterprise enrollment and generally speaking uh you know what you've seen is majority of the companies are doing a enterprise agreement that's why it's an enterprise enrollment but it's not limited just to uh ea it can be c uh csp mca right so the first thing is you're setting up your tenant so azure 80 tenant that's the first thing the second thing is going to be identity so are you using your existing azure 80 tenant from your office 365 um or is this going to be a green field environment and just cloud identity so there are a lot of things that needs to be discussed because if you are you bringing um if you already have a let's say on-prem environment you'll have your active directory you'll have to do a azure ad sync those identities have to be synced properly you know permissioning would probably be there uh as far as our back or that should be there with uh our back so those things have to be uh figured out upfront because uh you don't wanna assign too much permissioning and then i'll talk about our back in a second and then resource organization uh organization so what that means is um how are you basically going to be organizing your resources so from a management standpoint you know management growth subscriptions um your risk your resources how are they going to be assigned so those are the things you have to start thinking and then network topology and connectivity so you know that is something that is important as i mentioned before so what you need to start thinking is okay how's that going to look like um do can we get away with a side to side vpn do we really need a express route uh you know do we need multiple express routes and then from a networking uh aspect are we only gonna be doing a single cloud are we do we have to connect to other uh public clouds like gcp or aws so that has to be a factor in there as well and then obviously business continuity disaster recovery right because anything you do you do you have to account for and as you might know azure by default does not come with any backup uh so and i use the term backup but it only the backup only is one facet of uh vcdr but you know you have to think about other aspects okay like you know there's there shouldn't be any single point of failure so are you gonna be uh using um availability zone does your region even has availability zones so for example um in canada in the um we have two regions so the central uh canada region toronto we have availability zones but the east region which is quebec city does not offer availability zones so uh how are you going to plan for that if a disaster happens you know are you looking at that region or do you have to go to a another region outside of your country and is that going to be an issue from a"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "disaster happens you know are you looking at that region or do you have to go to a another region outside of your country and is that going to be an issue from a compliancy aspect so those are things that have to be accounted for as well governance this uh discipline so from a governance aspect you know like how is that gonna um what is the baseline gonna look like because moving to the cloud you have to have a baseline you have to have some policies uh security policies compliancy policies uh so that there has to be a baseline before you even start rolling out the services and then deployment options deployment options could be you know automated you can uh do it manually so those are the things that you'll have to talk about and then from a operational uh baseline so the operation baseline you can um talk about you know how the process gonna it is gonna work uh is your team ready from an operational standpoint can they even take care of this um so so these are all the design areas that um need attention today i'll be only talking briefly about uh resource organization networking and sum of governance um because we don't have enough time to cover everything so coming to the question now so if you look at this slide um you know you start small so you start from the three things what you really need uh you really need our back it's a role based access control because regardless of the moment you spin up a new tenant you know um and you're adding users you would be assigning them um permissioning so uh start with our back start with networking naming and tagging is uh absolutely paramount very important and i would actually add policies to that list and i'll explain that in the last slides why policies are important but um if you have a really small environment start with that you know uh governance would still uh play a key role but security operations and you know of shared foundation utilities might not come into play but those are the main things you really want to start looking at and saying okay um from a rvac standpoint how does it look like and hopefully that answers the question i'm good thank you perfect so let's talk about our back so um azure rollback base access control you know so it's you're providing access to the azure environment uh and i would say anybody moving to azure should um have the rule where you basically limit the uh access you know provide least amount of access for all the resources or all the services uh you just don't want to start you know giving out a lot of permissioning like owner access and what have you because that's going to cause a lot of issues so with our back basically there are three uh scope uh that are in here right the first one is a security principle so a security principle could be really a user uh group service principle and a managed identity a security identity is really used for applications and services to access specific azure resources and then the managed identities are identities in azure active directory that is automatically managed by azure um so that's really the scope that's where you would say okay so i'm going to be using a user group service principle or manage identity um as a service principle and that's where the permissioning is gonna be assigned the second thing is gonna be role definition and the role definition is really a collection of permissioning right uh and then so the definitions are and the built-in definitions are you could be a owner contributor reader um so those are really you know uh the high level ones i do not recommend any you assign any of those readers yes uh when i'm reviewing my enterprise customers account they provide me with reader access because you know um but i don't recommend owner or contributor assignments right off the bat you should uh find out okay why um they should be assigned those roles and honestly there should be a"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:30:22",
        "seconds": 1822,
        "text": "you know um but i don't recommend owner or contributor assignments right off the bat you should uh find out okay why um they should be assigned those roles and honestly there should be a racy um define for our back because who's responsible you know who's going to be taking care of this who's accounted for those kind of things if you have a racy that really helps put accountability and then that's that's how you can define the roles better as well uh the other thing that also is under the role definition is um there are built-in accounts and they're custom accounts so for example the virtual machine operator is a custom account um for custom account or for you to create a custom account you need a azure ad premium p1 or p2 license unfortunately those are not free so the built-in ones are there but if you want to create custom accounts you have to buy the azure 80 premium licenses um and that and then you can add a lot of custom accounts so uh if you have a special need say for example if you uh have a person who's doing patch management or doing backup you know you can really create custom accounts for that and define the scope based on that and that lastly you know the scope piece you can uh define the scope on the management group subscription resources or resource groups and resources as well and keep in mind our back is um inherited down like a to the resource hierarchy so it really depends how you want to assign the roles and how the management groups are going to be defined we'll talk about management groups uh in the next couple of slides but generally speaking what i've seen is usually people assign our back on the management group or on the subscription groups depending on the use cases and that works fairly well for them so resource groups tax and are back right so as i mentioned uh you need to basically let's say so this is actually a good use case uh for the finance department so they need to basically break down cost by various dimensions such as customer cost center environment right and then you create a role based on the appropriate permissioning based on our back and then you would assign tags um to the resources so depending on what the resources are and then based on that you can do our back you can do actually do tagging as well um and then resources and then uh resource resources and and resource group should always be tagged as a best practice um and actually i'll talk about the policies as well what i recommend is anytime a new resource is going to be spin up uh it should have a tag otherwise it should be denied or if it says okay a tag is not there then the policy should deny uh creating a new resource because in the beginning it's not gonna be a problem but once you have a bigger azure environment and it's going to get big as time goes on it's going to be hard to manage so if you if you don't have tags right away it's going to be hard to manage not only from a cost aspect but from an operational standpoint as well so uh tagging is absolutely critical for all the resources that you will be managing as well so now let's talk about uh tagging decision guide how do you do tagging so let me take a step back and say okay what exactly is tagging so azure tagging is leveraged to logically grow and track azure resources you know uh it can also help you to automate the deployment and provide visibility on reoccurring cost so the perfect example is if you uh are going to be doing a chargeback to an inter department then azure tagging is going to help you because what you can do is tag those resources with the name tag for those departments so let's say accounting is running uh some accounting software in azure you would tag all those resources there and then based on the tagging you can do a charge back to the accounting department and um go from there now larger companies uh they're starting"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:35:27",
        "seconds": 2127,
        "text": "you would tag all those resources there and then based on the tagging you can do a charge back to the accounting department and um go from there now larger companies uh they're starting to use third-party tools um you know there are many tools out there that you can use such as cloud checker and there are many others so it really depends on are you going to be using all the native ad azure features or um are you going to be bringing other third-party applications the other thing about cost management is um is there's a finops practice going on right now because a lot of enterprise customers are doing now is they're starting to build their uh finance practice and based on that they're bringing third-party software or applications to manage their azure and cloud environment and then cost management is only is one piece of that but tagging really helps with that as well so and then tagging the way you do tagging is you tag the names um which tags are uh name value pairs right and they're organized in resources uh in the azure portal and then tags can be applied to individual resources or resource group that are part of you cannot assign tax to any uh to management groups not that i know of um so generally speaking you assign tax to resource groups and resources and that that way you can definitely manage all the tags and do a chargeback and then they're all obviously the other thing is you have to understand the limitations so each resource can have a maximum of 15 tags associated with it so that's going to be a limitation there the other limitation i want to point out is um there is a limit on storage accounts of 128 characters so if you're doing storage account that's going to be your limit there the maximum number of characters for tag names is 512 characters so those are the things you have to also consider because a lot of companies i've seen that do is um they use preferences and preferences can get really longer with their name um naming convention so because if you have multiple regions you'll have that in the naming convention or tagging then resource groups then resources then the application uh then the project or depend so uh you have to figure out naming convention right off the bat because it's gonna help you with tagging and how you're gonna do tagging as well um the other thing is there are some tags that you cannot use so for example um azure windows microsoft are reserved and cannot be used uh the other thing is there is no inheritance hierarchy for tags so unfortunately you won't be able to use inheritance when it comes to tagging before i jump into the next section any questions so far hopefully this is making sense okay i'll take that as a yes so now let's talk about networking and i think networking is the most crucial piece uh when we talk about landing zone or if you're moving to azure regardless if you're talking about landing zone or not uh um networking is to me is the most crucial piece and here's a reason why especially if you have a on-prem environment you know um i've seen time and time again people did not plan their networking properly uh so they ran into issues where um the ip addressing planning was not done in the design phase and then they had a conflict uh or they had an overlapping ip space uh with their on payment environment and azure environment and that's a big issue um so that actually has to be figured out first of all and then this actually if you look at the diagram this does a great job of looking at how things are going to work out meaning let's say if you are looking at a virtual network you do not require a virtual network then you are going to be doing a pass model platform as a service you know so if you let's say you're running a web app um on azure or you're running functions or what have you then you will probably would need a virtual network depending on depending on the use"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "you know so if you let's say you're running a web app um on azure or you're running functions or what have you then you will probably would need a virtual network depending on depending on the use case and the requirement but in case you need a virtual network um you'll go down and then look at the decision tree so for on-premise connectivity as i mentioned before let's say if you uh are an enterprise customer yes you would probably need a express route if you do not need express route then you would need probably need a vpn gateway so you have to go and start thinking okay how are things going to look like what are the requirements how are things going to look like um and what do we need uh the one thing i also want to mention out is azure firewall uh in the enterprise customer space i see a lot of companies bringing their own firewall uh because they already have the licenses um they just bring it as appliance nva and then um just attach it to their on-frame environment uh and that they don't really use the azure firewall so and that also becomes challenging depending on how you want to set that up because bringing your own firewall you know it can get complicated um enabling if you want to do bgp um and all those things you also really require that um networking background as well um and how the network is going to look like so these are all decisions that you have to make um the other considerations you have to do is a vaf web application firewall if you have a front-facing application are you going to go through your vav through azure bath or are you going to be using uh your nvf firewall for that so those are the things that you have to start thinking and saying okay how is this going to look like uh and then if you have let's say um multiple regions how is that going to look like from a um redundancy standpoint if you have to do uh you know failover um is is the third-party firewall capable of doing that can you even do that so those are the things that you have to start thinking in in the design phase right um the other thing to mention is um and and i see this quite a bit is that azure reserves five ip addresses which each subnet so when you're defining your subnet uh factor those ip addresses in there because a lot of people don't think from that aspect right i'm not saying just go and do all your sliders with slash 16 to me that's sometimes too much as well but look at the use case depending on how much growth is going to be there um so look at that the other thing when you're designing the networking is some services um you know some azure services such as the application gateway your vav web application firewall azure firewall azure bastion and vpn gateway require uh dedicated subnets so you have to account for those subnets and how that's going to play into uh your virtual network and is that going to be an issue so those things have to be planned properly um and then you can you can delegate subnets to some azure services that can be injected into the virtual network so that actually might help you uh and as i mentioned plan for future growth because if you do not what i've seen with customers that they did not plan properly and then um it caused a lot of headache and then it can even cause outages as well so that's um that can be challenging from that aspect um and then the other best practice from a networking standpoint is uh public ip addresses should not be used for virtual networks uh i've seen people do that and that's not a recommendation so avoid doing that the other thing is dns so azure dns is a critical part of networking because some you know companies may use their existing dns solution and some others may adopt native azure capabilities um we already saw case with another pro public cloud provider in december uh they went down because of their dns um so dns is absolutely critical so it really depends on how you want to do it again i'll come back and look at seeing here requiring custom dns settings if you say no then use azure dns and if you want to bring your own dns then deploy your own dns you might already have your own dns running um in your own data"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:45:37",
        "seconds": 2737,
        "text": "requiring custom dns settings if you say no then use azure dns and if you want to bring your own dns then deploy your own dns you might already have your own dns running um in your own data center so these you know really this is really a great decision guide because it gives you an idea of um what you need to do um and then majority of time i've seen is oh connectivity you will be doing a vlan so hub and spoke is pretty much a standard uh given and then if you do not need uh v-net peering um or if you don't need uh centrally managed share then do v-net otherwise you know i've seen majority of the time hub and spoke with v-net work perfectly fine um so it really depends on the use case on the on the customer environment how big is it how much they want to grow and then what the long-term solution is the other thing is um uh express route i'll say this and i've seen this is if you're doing express route and this is um saying without giving that you know don't have just one express round because that's going to be a single point of failure um at least have two express route the other thing actually you can do is if that's not going to be cost prohibit then what you can do is go with one express route and then use a vpn gateway like a side to side vpn as a backup so in case your express rod goes down you have a second option the other thing is use private link uh for all azure platform as services over express route you know so that's very important um i see a lot of people not using that that's actually a very secure way of doing it so private links should absolutely be used for any all the past services regardless of what you're doing and then um express route should be the primary connection if you're doing it and then the backup should the vpn gateway um and then the other thing is all both on express route and vpn gateway there are so many skills so for example on the vpn gateway i don't personally like to use the basic skill because it's very basic it has quite a bit of limitations uh so i'd usually go with udw1 or you know the higher ones the cost honestly is not that much it's not that um it's not as higher from the basic one but the features are much uh higher and i believe if i'm not wrong don't quote me on this but if you go with the basic one you won't be able to change that uh last time when i deployed i had i ran into that issue that when i deployed the basic uh sku i wasn't able to change it but with the vp with the other skills you are able to do it so that's another uh drawback of the basic ski for the vpn gateway same thing with with express route there's so many different skills choose the proper skill express route obviously is very costly uh you know and depending on what the bandwidth is needed start small and just start small and then you can always go up so that's going to be my recommendation the other um thing that we've seen especially on the networking side and this is really a gotcha for a lot of people who are moving to the cloud is um people don't realize that you know data going out of azure data centers between two virtual network has a cost uh obviously data transfer going um in between the virtual network is free right so data going into um azure data centers between the two virtual machines is going to be free so that's not a problem but data going out of azure data centers between two virtual network is going to be costly so um the challenge is you cannot predict the bandwidth cost because you don't know um unless currently you're doing a lot of testing and you are testing it out for multiple uh months and whatnot even when you go live the bandwidth is always going to be uh go up and down and it's going to vary be uh depending on the usage um so that's one of the things you have to be very careful about is the bandwidth cost um and actually um i don't know if you guys know uh troy hunt he's a aussie um who who runs the site known as i've been pawned uh he got hit actually with 11 000 dollars because of the bandwidth charts and whatnot so i'll actually put the link in there after uh"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:50:40",
        "seconds": 3040,
        "text": "who who runs the site known as i've been pawned uh he got hit actually with 11 000 dollars because of the bandwidth charts and whatnot so i'll actually put the link in there after uh the session but yeah that's a that was actually a really a ah moment for for him saying okay i didn't realize that the cost can be higher too so those are things that uh you have to be careful when you're designing and um figuring out how these things should be set up time for a quick question sure go ahead so on the uh on the would you mind go back to the price slide for a moment sure on the um uh the need to connect virtual networks subscriptions row i'm curious just in your experience how often you see v-net peering across essentially across spokes i guess as you know something that happens in practice or is that super rare and usually pure pure spoke model prevails um actually uh with my customers enterprise customers it's very common it's actually a need so i've seen vina appearing done with spock all the time so again you know those are enterprise customers they have the need but it might differ from use case to use case of course yeah it makes sense yeah i'm curious about your experience thanks for sharing that yeah so i've uh worked with a enterprise customer in the financial industry and they have they're in both the regions and they are doing a v-net pairing yes got it uh and then um jeff is curious um will there be a demo deploying the landing zones or is the focus on covering the um cloud adoption framework decisions uh honestly we don't have enough time to do a demo at this point maybe in the future i might come back and do a demo um but yeah unfortunately no demo today i'll take it take that as the action item for next time okay yeah uh and and that's um there's some comments here so people might want to check them out their references to external stuff but that's it for the questions right now thanks abdul okay thanks so much so moving along you know uh factors that influence the right setup so you might be asking okay why um or what is the or what is influencing us moving to the cloud so i'll give you a quick example you know um and i'll start with governance so as you might know azure has 300 services right um and then if users don't or if there's no governance anybody can go and start spinning up um those 300 services so that's going to be a huge challenge right off the bat so what should happen is a customer uh should create um you know guidelines of what needs to be done so i had a customer who was creating a new recovery services world every time they were provisioning a new virtual machine uh because things were not defined there was no responsibility there was no governance you know so those things um have to be put in place uh so those are things very important so as i mentioned you know like tagging and ownership this comes into play and depending on the organization some organizations are centralized so tagging and ownership is going to be dependent on them if the organized uh station is decentralized meaning each line of business is going to be managing their own azure environment then they would be responsible uh of managing their own uh subscription or management growth or depending on what the level of accountability is right uh and that should be defined really in the roles and responsibilities that who has a access to what what owners and delegations um should be assigned and who is given what and the minimum access to carry a task right so as i previously allowed it in the example if somebody uh is doing patch management or somebody is doing backup you know they should not be assigned a owner role they should not be assigned even a contributor role because that's way too much access for them so they should be assigned whatever the appropriate role is maybe have a custom role uh and provide them with a minimum access there and then from a compliancy aspect you know um so for example me i'm in canada and then a lot of our financial customers or the customers who are regulated they"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "00:55:44",
        "seconds": 3344,
        "text": "access there and then from a compliancy aspect you know um so for example me i'm in canada and then a lot of our financial customers or the customers who are regulated they can cannot leave their data or they cannot their data cannot be outside of canada um neither in u.s or you know south america or what have you so those are things that have to be a factor when you are doing the right setup so those are the things that have to be figured out before you even get into the cloud so now let's talk about uh how do you organize your azure resources uh says you're aware when you whenever you set up a a new tenant you have the rule tenant on the top then you have the management groups subscriptions then you have the resource groups and then you have the resources um so you have to basically um make sure that this is thought out depending on the organization and how this is gonna look like we'll talk about how this should be done but these are the main four layers of how things are going to look like from a organizational or structure standpoint um and then as i said before having a effective naming convention strategy is very important because um not having a um great naming convention or not even having a naming convention uh the challenge is going to be that you know everything is going to be hotspot um i was working with the customer they did not have a naming convention now they want to move to a naming convention the challenge is you cannot change uh the names on resource level uh and resource groups sure you can rename your subscriptions if you want to but resources absolutely not so the challenge becomes is now what happens are you going to move them over to a new resource group new naming convention uh that's going to be timely and costly too so that's why having a naming convention is very critical because from the get get go you know okay how we are going to be doing and i get it it might be difficult because sometimes you don't know if you are going to be in multiple regions or or if you're just going to start small but microsoft actually does a great job of providing um the best practices for naming convention um so yeah start with that that would be actually uh really good so now talk about uh resource consistency right so why should you have a consistent um management such or management groups so the management so the first the one is the management drop right so management group really depending on your organization it really reflects the hierarchy so this could be a line of business this could be a department uh and depending on how you want to basically break this out and then you have subscriptions you can have multiple subscriptions so let's say if you have a line of business um and then you can do subscriptions so even subscriptions could be production subscription non-production you know those kind of things and then resource groups where you have the actual resources there and it really depends how the organization is going to look like so let's take a look at the example so these are two different examples the first one is done by the service process so they're doing development subscription uh so these are subscriptions then the lab subscription keyword subscription and then production subscription right and then these are all the resources under here so this these could be resource groups and resources up there whereas from an organizational unit design what they're doing it they're splitting the subscription under hr accounting and marketing so it really depends on what the business requirement looks like and how that's going to be and then who is going to be managing the subscription you know because let's say hr you might only want hr department to have or user to have access to the subscription then yes then the rbac would come here you can apply policies because the hr policies might be different from accounting policies so"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:00:49",
        "seconds": 3649,
        "text": "want hr department to have or user to have access to the subscription then yes then the rbac would come here you can apply policies because the hr policies might be different from accounting policies so it really depends on how you want to do it but this is mainly the subscription level um and subscription you know management groups and subscriptions can get uh complicated very quickly my what what i tell people and the best example i can use is going back to my uh active directory days is whenever you're setting up a new active directory uh you figured out okay what kind of uh org is it gonna be and how many organizational units would you need and you would based your oil use based on that right is it going to be on a department level uh is it going to be on the product level right so same concept for subscriptions and management drops are you going to be splitting the now uh based on the department hierarchy or is it going to be based on line of uh business application and then from a subscription aspect you know uh obviously there are going to be multiple subscriptions i cannot uh foresee having a single subscription uh obviously there are limitations on subscriptions so know the limits on what kind of subscriptions or what this limits are for subscriptions right um and then based on that you can define okay how many subscriptions you want um how the subscriptions are gonna look like and so forth and then from an organizational structure subscription as i said you know do you want to uh separate from a separation of duties is it going to be test versus uh dev environment different end customers uh what i've seen also is a lot of uh if you are a isv i've seen some isvs put their customer uh by subscriptions separate them out by subscription so it's easier for them from building aspects i've seen even some of some uh put their customers on a group resource group level so you know it really depends on how you want to do it some do it on a project basis as well some say okay this pro we're doing this special project so we just um make this a new subscription and then once the project is done now um this is going to be done so it really depends on the organization what the use case is what the needs are but uh this can get complicated fairly quickly so i will say just keep it as simple as possible because you're gonna grow right uh you might start with two three subscriptions and then you might end up having at least five ten i've even seen some customers um having 12 15 subscriptions so now let's talk about uh the management group you know before we're talking about subscriptions which are under the management drop so now let's talk about management row so what you can do is you have the tenant then you have the root management group under the root management group i would say create a i corporate it and then you can do production development or qa right or the other one i've usually seen is uh is you can do core services so all your core services can be under that so under core services you can have a another management group for networking and then uh under that you can have a subscription for your hub and spoke um so under network and then you can have another subscription for security so all your security subscriptions can be there that's going to be the main core services then you can have production management group and then you can have non-production right um and then under production you can have all the production subscriptions there and then resource groups and all that so it really depends on how the organization is going to look like but yeah it's really an exercise you have to go through the process and finding out okay how do you want to structure uh who's going to have access where the policies are going to be implemented are we going to implement policies on a subscription level management group level right uh or their resource group level um where are we going to be uh doing tagging tagging is obviously going to be done on the resource group level and the resources level"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:05:53",
        "seconds": 3953,
        "text": "management group level right uh or their resource group level um where are we going to be uh doing tagging tagging is obviously going to be done on the resource group level and the resources level so those are the things that are going to be defining how you do your management group uh there's another this is also a great example of how you can do um management group based on geography right so you have the business unit you can do the uh geography um and then you can do the environment so production non-progress production um all that and then you can split them up so mission critical productive data you know other production um and then these are resource group based on the applications you have and again depending on how the environment is going to look like as they say there's there are multiple ways of skinning the cat so depending depending on how you want to start your hierarchy and i think hierarchy is going to be you need to define the hierarchy first and then the subscription because once you have the hierarchy then it's easier to define the subscription groups or subscriptions rather than defining the subscription first and then the management groups a lot of companies do line of businesses so they might even what they do is they might even uh create a management group for future line of businesses and say yeah you know we have this project coming we'll create this line of uh line of business management group now and then one once that project comes in we'll have the subscription under that line of business management group um so it really depends on how you want to do it and azure actually does a good job of showing so when you go into the management group in the portal it's going to show you okay how how does the hierarchy look and it's easier to navigate from there and from a management group aspect you can go in up to five or six layers i don't recommend going that deep because it can get complicated fairly quickly maybe just keep it two or three layers if that to the most because the more management groups you have um the more complicated it's going to be to manage you want to keep this as simple as possible to manage your environment because once it grows you'll have more management groups you'll have more subscriptions you'll have more resource groups that's going to be a challenge to manage the question that's coming in abdul yeah sure uh montu asks uh how does this play with companies which are rapidly growing and evolving you know that's a good question if you're evolving and rapidly growing you need to define okay how are you going to do things uh and depending on the company as well right so what kind what kind of company are you um are you a isv you know are you a uh service provider are you a managed service company you know are you a stand-alone so are you a startup i i think that's those are the things those are the questions you really need to ask and depending on that you need to start positioning the management groups and the subscriptions so for example let's say a company is growing rapidly uh if they're growing rapidly it might not even affect the management growth it might not even affect their subscriptions because if they're rapidly growing they might even bring uh those new services that they might uh spin up in the same region in the same subscription and even in the same resource group right so it really depends on on the need and what the use case is and what they're trying to achieve so yeah hopefully that answers the question any other questions yeah there's another question um before asking that um your answer to that makes a lot of sense um to the question monty's question is just answered i think you're saying uh think about this stuff in advance keep it as simple as possible and that's your best chance of growth right if you've got your tagging and your uh our back models in the right places growth is a snap you just add more uh branches down below i think it's a good story exactly exactly because you don't know and i said you know if you know you're growing and if your company let's say um is project based for example you know you can always add management groups so you can"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:10:55",
        "seconds": 4255,
        "text": "exactly exactly because you don't know and i said you know if you know you're growing and if your company let's say um is project based for example you know you can always add management groups so you can say okay yeah we have this new project coming up we'll add a new management group so for example you might just say okay maybe uh add another management group here bring that service or product or what have you there so adding under the management group and then doing it that way or if that service or product or offering that you're building or that's coming up now doesn't even affect any of the environment just bring it inside uh because the more management groups you have the harder it's going to be managing the environment uh and then depending on your i.t um landscape as well right i think that that's going to be the biggest question uh how does your it landscape look like because as i mentioned if you if your i.t is decentralized then definitely you'll have to uh you know scale out your management drops because let's say if your i.t let's take example here let's say uh this management group is the u.s and this is canada for example right now you want to keep uh this management group permissioning separate from this management group right so so that's gonna uh make a difference now if your i.t department um is not decentralized it's all centralized then they probably come at this level and then manage these two environment as well right so one of the reasons you want to also split up your management groups is from a our back standpoint from a policy standpoint tagging honestly won't make a much difference uh naming convention is going to be pretty much the same because you want to follow the same naming convention regardless of uh if you are even in a different tenant because you know that should be your standard um i have customers who actually have separate tenants complete separate tenants for testing purposes so it's a live environment they have two environment one is full production one is full uh testing they don't want to do any testing in the production environment so they have a like a replica of testing and they're following the same guideline same naming convention uh same policy structure um you know for testing purposes so it also depends from that um i think our back and policies play a key role in defining how you are going to be defining your management groups and subscriptions and how that's going to lay out so i think i uh abdul you almost uh anticipated this and and might have just you know answered it uh uh before you heard it but uh uh matu had a follow-up asking can the hierarchies in terms of lines of business be changed at a later point of time so changing the hierarchy that you show here that's really the question can you change that as your i guess as your lines of business evolve oh absolutely yes you can so you can change hierarchies what you can also do is um you can even change um yeah so you can absolutely change hierarchy so i'm working with one enterprise customer we're changing the entire hierarchy it's a lot of work because some of the things are limited some things you cannot move some things you can move um so yeah depending on how much work you want to go through and what it's going to look like it is doable but um there are going to be some challenges and some pain points that uh that brings us up to date on questions back to you abdul thank you so much so now moving on to uh the next topic which is going to be the azure uh blueprints and this can be fairly quick because i i honestly wanted to add this because it is part of azure net zone the biggest challenge right now is azure blueprint uh has been in preview for more than two years now i don't know when microsoft is going to make this ga but it's an amazing tool and the challenges this cannot be used in production environment because since this is a preview you know there's no support for it uh but the amazing thing about azure blueprint is it's really a package for creating specific sets of standard and requirements right that governs the implementation of azure services security and design so in in uh clear terms what that means is azure blueprints makes uh azure landing zone repeatable very easily you know you can uh repeat the process of landing zone with azure blueprint so you can define and then you can start repeating the process again and again and again and"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:15:59",
        "seconds": 4559,
        "text": "very easily you know you can uh repeat the process of landing zone with azure blueprint so you can define and then you can start repeating the process again and again and again and again rather than uh you know doing it manually and and it's best for scaling so if you have a larger environment for uh enterprise customers or big customers uh you know it's amazing and then the good thing is it works with arm azure resource management manager so you know they go up hand in hand now you might say okay you know i'm not using arm i'm using third party uh software like terraform or other you know devops which is fine um but this is a good product and hopefully microsoft brings this tool light ga soon and would be nice to have this useful because this is definitely going to be a very useful for the purposes because it gives you a artifacts and then you can go and start deploying it at scale so now let's talk about the first landing zone so you know you've spin up the azure canon environment you have the azure ad there you've done some you have those cloud identity users now you're basically uh synced up your uh users from your on-prem id using azure id so now you're thinking okay what is the next step so if you look up here you know from an architectural complexity um compute is simple you know identity is fairly simple um networking and data it tends to be more and more complex as i as we talked about in the networking section right depending on the networking if you're going to be doing um express route then yeah you would need uh bgp and other things if you're just doing side to side then yeah it's going to be less of a complicated architecture so it really depends on what the architecture is going to look like but this actually paints a good picture of how the architecture is going to be looking like for the azure landing zone and then for the azure landing zone once you start expanding there are three main categories so the first one is hosting so you know decision to um the student has to be made what services are you going to be using and majority of the time i've seen compute storage networking and databases right that's pretty much um given you would be using those services now other than if you're moving to [Music] a pass model then yeah some services might not be there but majority of the time those hosting services would be required then the other thing is azure fundamentals those are the building blocks and i'll we'll see them in the next slide what the fundamentals look like and then as i've mentioned again and again applying governance principles for each landing zone i cannot stress governance is uh key to success for azure environment not only for landing zone but azure in general because um for example let's say you know if you don't have any governance in place uh people can go start spinning up and series uh virtual machines which are the high compute gpus which are be expensive and then once you get the build finance people are not going to be happy right so you have to have governance uh what i've seen with a lot of customers is they say okay these are the services that we have authorized or we have quote encode blessed that you can only provision because out of you know you don't want to start saying okay yeah go ahead and start spinning up all those 300 services because the thing is you have to do start testing because you have to maintain those applications or services as well do you have the skill set is there going to be an issue have you done any testing so a lot of companies what i've noticed is they're starting to um approve a set of azure services and you can start with compute storage networking databases um and say yep you know these are the services you can do um also they say okay these are the virtual machines so could be you know like a d series just like"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:21:02",
        "seconds": 4862,
        "text": "um and say yep you know these are the services you can do um also they say okay these are the virtual machines so could be you know like a d series just like yeah you know for our regular workload um we're just using um d series now there are exceptions so let's say if you're using a high compute power let's say you want to use cad applications sure um d series might not be the ideal one you might have to use n series or the f series or depending on the requirement so that has to be also called out in your governance policy um and the governance board has to say yes there are exceptions but in general you have to do that um i've seen companies where there were no governance and people were just starting to spin up different level of series and that became an issue because they could not uh automate a lot of things um they didn't have the proper structure so from a governance aspect and from an operational standpoint that's going to help you a lot and hopefully that makes sense so recommendation practices uh abdul uh if i can inject um a question from sandro uh since blueprints are not ga yet they're not um they're still in you know preview or beta or something uh how do you typically deploy the uh uh the caf basic landing zone for your customers so how do you deploy it if you don't have blueprints yeah good great question so generally speaking uh we use terraform for automation uh because we don't want to do it manually um so yeah that's what we're using and we have pretty much scripted out from creating management groups to creating subscriptions to you know resource groups even to the nsg levels so it's all automated you and i think that's the direction you want to go in um depending on the company you are so my company is a azure expert msp and then we are amanda services as well so um automation is really key for us we're trying uh to make sure you know more and more automation in that sense uh and even if you're not even you know like a microsoft partner or msp or um or whatnot um you should look at automation that's going to actually save you a ton of time because when you are doing changes that's going to make your life easier as well yeah sure you can go into the portal and do a lot of things but um our automation is the way to go and a lot of things actually sometimes um you can only do things through the you know cli or automated so for example when um windows virtual desktop came out now it's azure virtual desktop uh you could not do a lot of things within the portal the azure portal right you have to go and use the powershell command list so yeah automation is going to be the key and i think that's going to be your best bet thank you i think we're caught up with questions perfect okay so um and then from recommended practices right so these are the fundamentals that you should be looking out for so the azure fundamentals networking uh identity access storage databases and cost management cost management obviously as i mentioned you know there are multiple ways of of doing it if you are a enterprise customer and you have multiple cloud and and this is becoming a very common occurrence now and i think that's one of the trends uh i've already saw in 2021 and i'm gonna see this a lot in 2022 uh companies are going to be in multiple public clouds and then from a cost management they'd probably be buying a third-party software to manage that but if you guys get an opportunity to look at finops so finops is a like a non-profit org um which basically does guidelines for cost management for the cloud uh and i think that's gonna gain a lot of traction now as well uh but for this session you know i'm not going to go into detail uh because honestly each of these subjects are taught require a session by itself but these are the main pillars um which"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:26:07",
        "seconds": 5167,
        "text": "uh but for this session you know i'm not going to go into detail uh because honestly each of these subjects are taught require a session by itself but these are the main pillars um which are pretty standard and then the other thing is if you want to look uh at cost management i look at my blog i've done multiple cost management uh sessions so you can look at the recordings on that as well and lastly uh we're looking at azure policy so you know uh azure policy before i start talking about the importance of azure policy let's let's take a look and see what azure policy is so azure policy is you is used to create assign and make uh you know policies which can help you enforce compliance and enforce uh auditing for azure environment um and then one of the things about azure policy is you know uh you can implement azure policy at various uh scope levels so you can do it from a management groups subscription resource group and individual resources as well so that's the best thing about azure policy and then um the reason you want to use azure policy is you know there's a couple of reasons is you can apply compliancy security policies to existing resources uh you can automate compliancy um and then for security purposes as well uh the one big thing about azure policy and if you have logged into the um azure policy section is it gives you a word iv of all the compliancy posture across the resources so it's going to say okay you are complying you're not in compliance uh you know and you can go and take a look and see why this is happening now we could take a look at the use cases for azure policies as well uh the multiple use cases so i'll talk about that as well in the next slide but from a uh azure policy building block uh there are three building blocks right so the first one is going to be the policy definition you are going to define um a policy from for a compliance aspect like taken into evaluation what exactly is the policy going to do then you would initiate that definition the policy definition that you defined um so basically then you can manage that policy and lastly you would initiate that policy okay um and then the scope of that policy the policy could be on the management group or the individual level so it really depends on where you want to apply and then coming back to the point of the management groups and subscription groups if you want to keep it simple because if you have many management groups you'll have to go and apply those policies into each managed brain groups as well so um the less management groups you have the better it is because then it's easier to manage from that aspect um here are some use cases for uh the policies so you know one of the uh uses i've actually talked about is limiting the ski types for virtual machines to help control cost so when people go into provisioning a um resource if you have a azure policy that you know uh that is going to limit the skew so you say okay only d level skus can be provisioned and you have a policy uh and depending on if you are enforcing that policy um then none of the uh vms are even going to be visible in the list so or if you're doing through automation then you know you have to keep that policy in mind because otherwise you'll get errors thrown back at you um the other one is um you know allowing resources to be provisioned in the approved region so as i mentioned you know if you have compliance reasons you want to only provision uh resources in specific regions you can enforce that policy um so that's always a good way so these are the minimum use cases but my microsoft actually has a lot of um built-in policies that you can use you can also customize policies but these are built-in policies that you can start with i would say start with a handful policies roll them out and then see what happens my recommendation is to start with audit policies do policies in auditing mode do not start with enforcing right away uh and do not uh have policies in denying mode because the challenges the deny especially"
    },
    {
        "speaker": "",
        "title": "Azure Landing Zone by Abdul Kazi",
        "videoId": "H1Dwny9XqSY",
        "description": "This is a recording of the January 25, 2022 virtual meeting.Azure Landing ZoneDo you want to know what is Azure Landing Zone and why it should be used? Join us as Azure Architect Abdul Kazi shows us all tips and tricks about Azure Landing Zone.0:00 Introduction1:17 Abdul Kazi2:15 Agenda3:10 Cloud Adoption Motivations6:37 The value of creating cloud-ready environments9:52 Microsoft Cloud Adoption Framework for Azure14:54 What are Azure landing zones18.43 How do you get started?20:38 Azure Landing Zones Design areas26:54 Do you need more?28:15 Azure Role-Based Access Control (RBAC)32:38 Resource Groups, Tags and RBAC34:31 Tagging Decision Guide39:14 Network decision guide53:07 Factors that influence the right setup56:31 How to organize your Azure Resources58:51 What is Resource Consistency?59:50 Subscription | Design considerations1:02:01 Single subscriptions vs. multiple | Consideraions1:02:38 Organize subscriptions1:04:11 Management Group best practices1:06:13 Governance MVP Considerations1:15:04 Azure Blueprints1:17:10 Ready | First Landing Zone1:18:37 Ready | Expand the landing zone1:24:48 Ready | Recommended Practices1:26:34 Azure Policy | Key Info1:29:29 Azure Policy | Scenarios1:31:06 Azure Policy | Best practices1:32:56 Thank you!## SPEAKER BIOAbdul KaziAbdul is an Azure Architect at FX Innovation focused on Infrastructure as a service (IaaS). He has 18 years of IT experience and has worked at various levels of IT.He is very active in the Azure community and speaks at various conferences.@abdulkazi (Twitter)https://www.linkedin.com/in/abdulwkazi/ (LinkedIn)https://abdulwkazi.com/ (blog)",
        "start": "01:31:12",
        "seconds": 5472,
        "text": "is to start with audit policies do policies in auditing mode do not start with enforcing right away uh and do not uh have policies in denying mode because the challenges the deny especially if you're automate automating you'll get a lot of errors [Music] and then if you start denying denying policies um you will know where the issue is right so start in stages start everything with audit mode audit everything uh understand what that's going to entail and then start denying where you know that it's not going to make a difference so for example the skew i mentioned right only allowing the uh approved skew and then everything should be as should be denied that that will work fine or only provisioning uh resources in allowed region so for me like canada central and canada east uh any other region you know east u.s west u.s uh even brazil would be denied by policy so those are things you can really do um to make it easier um so yeah and then lastly you know and policies um they're always remediation you can always go back and see what is working for you what is not working for you um but yeah policies are intriguing part of landing zone uh it's not talked much about but it's going to help you manage your environment and keep that operationally and compliantly healthy so with that you know um that's the end of my session fantastic abdul uh thank you uh very much does anybody from the audience have any final questions for up to them and before uh we get to the questions i want to point out um this github repo uh this came out like four days ago um go check it out it has the checklist so it actually i think has 160 ish um values where when you're doing the landing zone review it's going to basically go check you can check those and say okay yep we've done this done this done this and especially for us um when we go through the microsoft msp audit this checklist is absolutely helpful for us so that's going to be very helpful what i'll do is i'll put the link in the chat there the other thing i also want to quickly mention is um i don't know if you guys saw this but this um i have a blog on the azure landing zone overview so you can take a look at that and then the networking piece because i get a lot of questions on networking so i also have a um blog on networking so that's um there as well so i'll i'll put the links up there okay um they uh there don't seem to be more questions pouring in just uh gratitude and uh positive vibes about a good talk so uh i'll echo that it was uh illuminating and uh very well delivered so thank you for that abdul but jason do you have any announcements no not that i know do you want to say anything about the youtube video um yeah so the youtube video be out i'll post it out tonight but then i want to index it so i'll go through i'll watch the video through and index it with um time stamp so that you can skip to the relevant sections easier later on cool thank you and that'll be available at youtube.com boston azure starting uh tomorrow awesome yeah i'll tweet the link and and send it to all those presenters when i get it but um the indexing won't happen probably till this weekend fantastic okay and uh veronica anything to uh add before we roll i just want to thank abdul and everyone for joining us and yeah keep keep your eyes open for future events we'll post them and meet up and share on twitter and social media okay abdul uh thank you very much it's uh it was uh it was great i appreciate your uh you're sharing your expertise with us all oh thank you so much i really appreciate it stay warm you too thanks so much okay thanks everybody good night everybody "
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:00:01",
        "seconds": 1,
        "text": "Azure SQL Security Concepts. This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/. it it's all yours awesome thank you so much Jason yeah uh thank you um everyone for attending this session this evening and thank you Jason for giving me this opportunity uh this is the first time I'm presenting here I hope you like this session um today I would like to speak about Azure SQL security Concepts so basically um this is like an overview of what all layers we have in Security in in Azure uh space um this is not like a 400 500 level session but I would like to touch base with all of the all of the concepts that we have and bought each of each of the means so um hopefully you'll like it uh so let's get started as Jason mentioned everything so I would like to skip this slide but if you would like to uh contact me later with your questions if you couldn't ask here you can contact me on Twitter or or you can also contact me on LinkedIn uh it would be an honor to get in touch with you search by my name you'll find me um so um before beginning the session I would like to start with an analogy very simple analogy let's say a thief wanted to rob a bank um and he would like to go ahead and break the key break the money world in in the bank but if before even touching the money money ball right he need to cross several several layers of security that are in place within the bank let's say he crossed the cameras which are in which are in place in the parking lot let's say and then he break the main door of the bank somehow um the bank was closed on the day so he broke the bank and he broke the main lock let's say he entered into the little lockers that are in place in the first room that he entered but each and every each and every Locker have that little key where he had to break so he tried he got frustrated so he directly wanted to enter into the main money world but before entering into the main money board door that lock he had to break the digital lock that is in place so he tried couple of the couple of times we have multi-factor authentication set in place so he tried couple of times and I it caused an alert which the alert is like call 911 automatically to let them know somebody is trying to um you know trying to enter into the main money world and they couldn't enter Because the lock the digital lock is wrong the key that he entered is wrong so right now at this point of time security guy know about it he received a call alert um through the automated system and 911 uh the call went to 911 police are arriving and he couldn't even linked her into the he couldn't even break the digital lock to go to the main money world and there you are he police arrived and they caught him so this is like a physical bank right it is not even like it is not a computer it's like a physical bank so to enter into the main Money Vault he have to cross like though he broke the though he tried to escape the cameras he like he he checked the blind spots and somehow he he did not uh get captured in the cameras but he mean he entered into the main door he broke the main door but then as as you see like though he broke one of the layers there is a different set of like complexity into the next layer and he couldn't actually get into the he couldn't actually get into the main money wall to get the money in the same way there are like several security layers in Azure as well like the like the cameras the security cameras which are in the parking lot for the bank in the similar way we have the outer layer of security which we can say the network security and as you go as as you go deep down you have other layers of security access management um threat protection information production and any any person who want to who want to enter and see the data you want to check the data who is an unauthorized person he have to break all of these layers which is which is tough so we are going to talk about each of these what each of these layer means and how it will actually protect your data in azure so let's talk about the outer layer of security which is the network security so here we have four different options so let's say while you are building a Azure SQL database you have this um network security in like four layers of network security that you can choose left side from left we'll talk about from left side to right side left side is the least secure"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:05:06",
        "seconds": 306,
        "text": "Azure SQL database you have this um network security in like four layers of network security that you can choose left side from left we'll talk about from left side to right side left side is the least secure as you go move to the right side it's the most secure so let's talk about each of these options let's talk about yellow access to Azure Services which is the least secure options once you it's like an on and off button so once you turn it on anything in Azure can connect to your database anything in Azure but outside of azure your on-prem servers cannot connect to your database there is not there is not that option you know you only only azure any of the Azure services within Azure can connect to your database so it will have it have the public ID address and when you do the NS lookup you can see all of the like hierarchy information where is your database hosted like we what region and control ring information and IP address all of that information is shown but you might be thinking like why do we even have this option right so it's like if you turn it on like to do to do your testing or to do your development uh testing if you if you build a new database and you wanted to quickly test something then you can just turn it on and then do your job and then and then like delete your database or turn this option off that's why it's there it's the least secure one but when you see the next layer firewall rules these are the firewall rules that you create generally on your on-prem servers to connect to your to connect to the different service it's a similar way you create the firewall rules like any any service that wanted to connect to the Azure SQL database you will create a firewall rule so here you can have the on-prem connections it still have the public IP address and when you do the NS lookup the ring control ring information where your database is hosted is public it's still not secure but better than the low access to Azure Services because you are creating firewall role on each of the service connecting to the database the next layer is virtual Network rules so here um let's say like your database is connected to different like many virtual Networks all of the virtual networks will be connected together will be connected using like the latest Technologies like we need to v-net express route kind of Technologies to connect to all of those virtual networks together but one virtual network will have a rule on the top of that virtual Network and that like our database will be connected to that virtual Network so there is only one role that we will be creating and it will have the private IP address but still some of the information is still shown when you do the NS lookup like controlling information and the region where the database is hosted is still visible so it's not it's not purely secure you know but if you use a private link by creating the private endpoint to your database anything like on-prem or in Azure any service should pass through that private endpoint to connect your database it's a most secure ones because it will block all of the public access like internet will be disconnected completely and any um anything in Asia or on-prem they have to pass through this private endpoint and if you do the Indian like NS lookup none of the information like we talked about will be shown there so it it is like really secure so when I say like hello at hello Azure services and resources to access the server the first option right from the left side which is not secure so where do we see that option if you have the Azure portal go to portal.hr.com login to the login log into the portal and then go to the SQL Server that you have built Here in My Demo I'm using security demo so once you clicked on that underneath the security we are talking about the security Concepts right so underneath the security go to the first option which is networking we are we are talking about the network security layers so um go to the networking and there the first option if you see the number one it says like hello Azure services and resources to access this server it is just like turning it on or off and then save say so by clicking it on anything in nature can connect so going to the second option the firewall rule I would like to disconnect like I would like to uncheck the first one which I did um and then the second one you need to"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:10:08",
        "seconds": 608,
        "text": "nature can connect so going to the second option the firewall rule I would like to disconnect like I would like to uncheck the first one which I did um and then the second one you need to literally add the IP address here so that it will create a firewall Rule and that service can actually connect to your um Azure SQL database so my local server like my local machine I wanted it to connect to the Azure SQL database so I created a firewall rule by adding the IP address so that it can connect so I connected I added my Firefall rule right so I went to the my local ssms SQL Server management studio and I um I I connected through the logical server name and then I could connect because my firewall rule I have added a fireball rule with the IP address of my server so I could connect and by going into the last option the so the last option is like the the private endpoint so where do we create the private endpoint again go to the resource like SQL Server security demo is my SQL Server that I created underneath the security um blade left side go to the networking and there underneath the networking blade right go to the private access where you can go ahead and create the private endpoint for your database so it is very simple to create a couple of the things that you need so once I clicked on that I have created it here but you all you need was like any um any resource that you create like no matter if it is a private endpoint or anything you need to provide like the subscription details and then like on which on which virtual Network you wanted to create which region all of the information right so after you create the private endpoint now I created a private endpoint on a virtual Network where I have the virtual machine created so right now at this point I went to that virtual machine I connected to that virtual machine which is hosted on that virtual Network and I connected to my Azure SQL database from there and I executed this query like like where my connection is coming from the client net address and it have given me the IP address which is 10.0.0.7 so I would like to see like where this is coming from and I went ahead to my virtual machine that I created through the portal if you see here security VM is a virtual machine that I created on that particular virtual Network and if you see the private IP address that is your IP address that is shown when I connected through then I connected to the Azure SQL database it's a private IP address let's talk a little bit about the identity and access management so we have like authentication and authorization these are the two different things authentication is like you are a user and you have to prove that you are the authorized user to enter into the system enter into the Azure portal so we have that multi-factor Authentication um available it's a way of authentication thing right like when you try to log in you get that um you have that multi-factor authentication the code sent to your phone you need to type that two digit number like you get it two digit number into the portal that's when you will be able to get into the system that's a type of multi-factor Authentication and then you can also you you can use like azure um for the for both of these Azure SQL database and managed instances user you can use like SQL authentication as well as Azure active directory authentication or you can just use the Azure active directory authentication only but when you build like for example let's say you are building an Azure SQL database while you are building in Azure SQL database you need to also create a logical server while building your database because like a logical server is not the server itself it is the way you connect to your database through your management Studio that's how you will be connecting and seeing your Azure SQL database so as you build your logical server you will be giving a authentication like SQL authentication ID and password and that that ID and password will automatically become the server level principle and if you are building the managed instance then that that account that ID and password will automatically becomes the sysadmin it will become a part of this admin server role an authorization is all about like permissions to your resource of itself to your tables database objects so"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:15:13",
        "seconds": 913,
        "text": "and password will automatically becomes the sysadmin it will become a part of this admin server role an authorization is all about like permissions to your resource of itself to your tables database objects so for both the Azure SQL and managed instances it will support like the additional like database roles and custom designed roles and we can also have like low row level security which is known as principle of least privilege so as I mentioned like when you build the logical server right the ID and password that you provide while building it it will automatically becomes a server admin so here are my logical server name is DG test server and if you see the server admin is deeply so I have given that deepti as an ID while while building this logical server so there are also some specific role-based access control like at least three of them um which are owner contributor and reader so if you give the role of an owner they can actually read modify and assign the resources to other people as well they can read modify and assign the contributor they can read and modify but they cannot assign other people to the resources a reader as a name itself says they can just read and these permissions can be in the hierarchy level they can they can they can start all the way from the subscriptions Resource Group as well as the resources underneath those Resource Group they can be inherited as well so where do we see those uh basic three role-based Access Control so here I have my logical server digital server once you open up open that app left side your screen you see the access control which is iam click on that and try to add a role assignment to to just see those roles so I try to add add role assignment and that's where you can go ahead and add add specific roles to the members so the next tab says let member so once you click on this and go to next it will ask you like what to whom you want to assign these roles so these are the basic role base access um that are available in Asia like owner there are several others but these are the three main built-in roles that are available owner contributor and reader and there are like um logins users and differences so what are the differences between like managed instance and Azure SQL database as per the logins and users like we discussed in the previous slides we can create the SQL logins as SQL logins as well as Azure active directory logins the while building the managed instance that ID and password will automatically becomes the server admin so you can you can create the database users as well as contained users within the managed instance contained users are the users you do not have to have a login but directly you have the ID and password where you can directly connect to the resource itself like the database and you can directly give the access to that user that contains user and when compared that with the Azure SQL database we have um we have like Azure active directory server it means we can create the SQL logins Azure active directory logins but here we have additional roles just to limit people from giving the server admin access we have like login manager DB manager additional roles and we can also create the database users contained users but any any user if you want to create any user on Azure SQL database you have to login as an Azure active directory server admin only you can't log in as a SQL login and you can you can create the other logins you have to be the Azure active directory server admin so let's talk about the data encryption we have multiple options here so there are mainly three data encryption like options here encryption in transit encryption at rest and encryption in use encryption in transit is all about like encrypting your data while it is being moved from the database to the application and from the application to the database while it is being moved it needs to be protected and uh this encryption in transit happens through the transparent layer security which we are going to talk about in the coming slide and we have the encryption interest it's all"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "needs to be protected and uh this encryption in transit happens through the transparent layer security which we are going to talk about in the coming slide and we have the encryption interest it's all about the files like the database files backup files are they being encrypted because these are on the drives we need to make sure these are encrypted and they are encrypted uh by default and these are always encrypted by the transparent data encryption and the third option is encryption in use so while your data while your data is being processed while your queries are running whether the whether the query like while the query is running whether your data is being protected while while the queries are running um during the query processing right so there is something known as data enclaves and encryption in use uses that data enclaves so um let's talk about the encryption in transit like I said like it is an industry standard protocol um transparent layer security you are enforced to use this option by default and it will enforce all it is enforced all the time for all the connections but from your site what you have to make sure is your application um from your application site make sure like encrypted connection from implications there is this option make sure it is always turned on and the other thing that you need to um focus on is like whether the TLs version that you are choosing in your Azure SQL database is it applicable and is it valid with the with the application sometimes the TLs version though if you are using the old DLS version it can it cannot be supported by your application and you will have you'll be having the connectivity issues connecting to your database so you need to make sure like they both are align aligning properly it is always recommended to use the latest TLS version so where do you see this transparent layer security and how do you choose right DG test server is my um logical server so I connected to the logical server here again networking go to the security blade select the networking um we have seen the other two options on the top but this time go to connectivity underneath the connectivity you have like encryption in transit that's where you can choose the minimum minimum TLS version um you can choose the version you want but always make sure like the recommended version is the latest version sometimes sometimes you would not identify that you might be using the outdated one so always make sure you use the right version and also that version should be applicable and supported by your application encryption is addressed it is all about the all about the data which is inactive on the drives it can be the data files it can be the log files backup files right so while the data is being pulled and pushed to the drives make sure like it again this encryption at rest is automatically enabled and it is enabled by default and you have two options right um Microsoft managed keys so encryption address is supported by Microsoft if you choose like default option meaning like it is Microsoft managed key they will be rotating the keys and everything you do not have to worry about that but you can bring your own Keys as well and you can place those uh the keys that you have created you can place them in the key vault uh key vault is an application available in azure it is like you need to pay for that service but it is like you can create as many keywords as possible um you can save your keys after you create you can save your keys within those keywords so key generation rotation giving access um it's up to you if you are using bring your own key option instead of like my Microsoft managed key so um where do we see this option date like transparent data encryption encryption at rest so how do we do that so again security demo is one of my SQL Server go to the security plate select the transparent data encryption and then here we have like remember that we are doing the encryption address this is this comes under the encryption address we have two options here you can either choose the service managed key um or the customer managed"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "and then here we have like remember that we are doing the encryption address this is this comes under the encryption address we have two options here you can either choose the service managed key um or the customer managed key service manage key is nothing but it's by default you need to change that option and Microsoft is going to take care of that first option service managed key so here I would like to show customer managed key if we choose customer managed keyboard are the things that we have to perform so I will be choosing customer managed key under the key selection method so select a key so if you do not have a key currently I do not have a key I need to build the key vault to place the key that I create so I would like to go ahead and select on change key but then I will go ahead and once you have the key right once you have once you have the keep set in place in the keyword you can go ahead and change the key if you want but we do not have a key so in order to create a key you need to have a keyword so by going you can go ahead and search for the key Vault on the top very simple you need to like again you need to provide the subscription ID and location and name of the keyboard you can create the keyword within with few clicks but then here once you build the keyword I would like to go ahead and um go to the objects and underneath the objects there are Keys click on this keys and to create the key um remember you can on the top you can generate or import the keys if you have it outside you can import them but you can also generate Here in My Demo I have created two keys security demo one and security demo 2. I would like to click on one of them security demo one to show like how it looks like um so while you are building right you have to give the activation date and the expiration date the current version that you are seeing like the digit that is automatically popped up so once I click on that current version I can see the details like what I have provided while creating that key so the key type um RSA key size all of the those things are populated automatically but I have to be more focused on like what is a creation date and expiration date right expiration date and if you wanted to give any permissions to this key to someone else you can give right at the time like creating the key you can give that underneath the parameter operations like what kind of permissions are accepted on this key you can choose that encrypted Crypt options and then um you have to give the permissions right so underneath the access policies again this is under the keyword we have saved that key so go to the access policy and that's where you can give the permissions to those keys so I have given my account to wrap and wrap the key and into that particular key so I have given me the permissions no I have created the keyword created the key gave the permissions onto that key now I'll go back to the transparent data encryption which is underneath the security demo SQL Server go to the security Blade transfer transparent data encryption now we have choose the customer managed key right now just go ahead and select the key and underneath the keys click on change key where you will get the option like which key you want to update for that option right so you have given the subscription details and then this is what key Vault are you using you can have multiple keyboards so what is the name of the keyboard give the name of the keyboard what key you wanted to use and what version remember like if you are managing bringing your own key this this version will be outdated once it hits the expired date so you need to come manually and then you need to um create a new version to update that key and then go ahead and select and then click on save so that you have used the bring your own key in this option now let's talk about the third option encryption in use where this is the like a client side encryption technology um data needs to be encrypted and decrypted from the client side so while the while the queries are getting processed right so uh there is this something known as client driver while using the data Enclave um will will actually this drive will make sure like while the data is being processed from the client side as well as from the database side database engine perspective it will make sure like your queries are being"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "will will actually this drive will make sure like while the data is being processed from the client side as well as from the database side database engine perspective it will make sure like your queries are being processed and encrypted while they are in processed so um the SQL client driver is a driver which the secure enclaves uses and the data while it is being processed right and while it is being moved to the database client this SQL client driver will make sure it is encrypted so the database engine will delegate the operations on this encrypted data to The Enclave where the data can be securely decrypted as well as processed so most of the operations right the there are certain operations that this secure Enclave will use um like the queries which have the range queries right greater than less than and if you have any sorting and if you have any indexing those sort of queries will use the secure enclaves and let's talk a little bit of dynamic about like Dynamic data masking option we have and uh it comes under the security option again Dynamic data masking is not the encryption at rest these are two different things like if you have like Dynamic data masking enabled that doesn't mean like your data is encrypted on the drives right are encryption address is automatically enabled but these are two different things Dynamic data masking is all about like encrypting your data inside your objects like you will permit people who can see your data it's like Dynamic data masking that we have on-prem so how do we add um data masking option in azure here I'm using adventureworks database and uh go to the adventure Works database like any database that you have built it's a SQL Azure SQL database and you have the Security Options even underneath the database as as well until now we have seen The Logical server at the server level we have the security laid and all the options we can also see that under the database so the options that you see under the database is little bit different if you see you have Dynamic data masking here click on Dynamic data masking and if you want to add a mask click on add a mask and there are only couple of details that you need like the schema you need to select the schema table and the column you'll get that in the drop down menu and as you select the column table and the schema it will automatically give you the function The Mask function once you do the then once you create these masks you can go ahead and just like the way you give the permissions to other people to access um you will give in the similar way you can give the access to other people to like unmask and mask permissions in the similar way you can give on this database as well and we have a threat protection and detection so underneath the threat protection we have um Azure Defender so underneath the Azure Defender we have SQL vulnerability assessment so it's all about like are we following the Azure standards Microsoft Azure standards there are certain standards that we need to follow so it if you enable the Azure Defender it will continuously go ahead and check for these um vulnerability issues like whether you are the database that you designed whether it is aligning with those um with those standards if not it will give you the list of assessment details where you can go ahead and implement or you can just ignore them as per your needs and there is also SQL thread detection underneath the Azure Defender um if if a bad actor trying to access your database from different locations suddenly you'll get an alert you can set up the alerts in such a way that you'll receive the email um immediately once the alerted once somebody tries to login you you'll get that triggered and then you'll get the notification and you can also see that underneath the Azure security Center so Azure security Center is like a One-Stop shop where you can see all of this information together like the vulnerability assessment threat detection details all of that and we also have the SQL auditing um just like the way we audit the SQL on-prem we can also audit your data in azure now let's see like Azure Defender so you can um like a to access the to use the Azure Defender you need to pay for that service like it is clearly mentioned there it costs 15 USD dollar per month per server um so while you turn it on you"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "like a to access the to use the Azure Defender you need to pay for that service like it is clearly mentioned there it costs 15 USD dollar per month per server um so while you turn it on you can go ahead and um you have to provide certain details like I said like any any service that you wanted to create right you need to provide the subscription details and um a resource Group and all of that but this is like a a tool that we are using so we will just create the subscription and then where do you want to store the results of this um Defender like once you do the assessments you can choose like the storage account if you do not have one you can create it here and you can also send the scan reports to the email address you can provide the email address here and then you can go ahead and enable it enabling it is um simple so you once you enable it you can't see the details immediately you need to give certain amount of time for it to go ahead and do the assessment and scan your resources so uh one like I have given certain amount of time and I have went to the DG test server which is my logical server and underneath the security I went to Microsoft Defender for cloud I have seen like couple of recommendations and findings here so if you see the bottom of the page you have like you can either click on the top like recommendations or you can also see the additional recommendation in Defender for cloud so I have clicked on that to see more of these details in the recommendations so it have given me like a couple of like listed listed couple of things here and it have seen like security score 81 percent and the red active items which shows like mostly recommended one and uh you if you see the insights like the bottom screen like right side of your screen it says like red color the color insights as well you can see like what are these and like um how many resources are being affected and unhealthy and click on them to see more of the details so I have clicks like you can see that underneath the server level right these details but you can also see the same details at the database level on the database like what are the recommendation at the database level so go to the database Adventure works here underneath the security blade Microsoft Defender for cloud we have it here as well so it shows like three findings I would like to go ahead and click on that to see more details so it have given me like a vulnerability assessment findings you see each of those findings have an ID um that is from the standards right from the Azure standards so it says like database owners as as expected and couple of other things and the severity level is looking like high so I would like to click on one of them to see more details so I have clicked on the database owners are as expected but then here it is saying severity level high it has provided me the description and it clearly says like remove unnecessary database owners there are many of them and here is a script that you can implement this you can just run this script or you can directly like you can also ignore this Baseline you have that option you can choose that option you can add this certain thing to the Baseline like um or you can remove it from the Baseline but you have the query in place to remove right and then it shows like what are uh who like list of the owners that are um that have this database owner role and everything but it is it is up to you to just um take action or just ignore and then the similar way we have the auditing as well here again I'm I'm clicking on the digi test server which is a logical server and underneath the security blade we are going to the auditing and here the auditing is turned on but we know you need to make sure like how you want to select like wait you want to place the results auditing results um and you have to also make sure like if you are um auditing at the server level as well as auditing at the database level there might be like uh double amount of data that can be created so if you are turning it on the database like server level all the database that and that comes underneath the logical server will be automatically um audited you can go ahead and um just to do the auditing at the database level independently as well um you need to provide the subscription and where you want to store this data details you can save"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:40:31",
        "seconds": 2431,
        "text": "you can go ahead and um just to do the auditing at the database level independently as well um you need to provide the subscription and where you want to store this data details you can save it in the storage account or you can create the log analytics workspace separate workspace for this if you do not have you can create a workspace here um if you can see the underneath the log analytics I have clicked on the workspace I have created it here and the last option that you have here if you see the bottom of the screen it says like enable auditing of Microsoft support operations so basically you can turn this off but the only reason why you have to turn this on is like if you are if you are opening an etiquette with Microsoft if you are having an issue with them they need to if they have to have the access to your auditing details then thanks so um Once you turn that auditing on underneath the database you can go to the security auditing and you can click on view audit logs that is a place where you can see the all the logs centralized and I have clicked on that underneath the database right and it shows me like view dashboard once I click on that it will provide me like something like that so um Azure SQL like if you see the circle over here chart that is related to the data governance I am going to talk about that in the coming slide but here let's click on the security insights Azure SQL and once I click on that it will give me the more details security insights where it will be giving me like what all auditing details it collected so I'll be clicking on that audit distribution to see all the details um so here you can you can see the you can you can actually execute the query here itself to grab the details filtered out like if you wanted to get the details of any specific timings you can you can use the query to run and grab the details but it is similar way that we have the auditing details we have the query who executed it on which instance and database principle and what are all the details will be visible here underneath the logs and this here we I have created the default workspace so that that's how it is showing me here and the data governance um is nothing but like if you are having any um if you are having any sensitive data like for example date of birth SSN details credit card details and if you want to know who is accessing those sort of details like if if somebody tries to do any selects on that particular columns you can actually tag those columns as sensitive um very simple to create those tags and if some once you create those tags you are classifying your data and if anybody try to access those columns you will get an alert mentioning like what uh who did that like through logs again we are auditing right through logs it will go ahead and capture the data so how do we do that like underneath the database adventureworks database go to the odd like security blade underneath the security blade go to the data Discovery and classification and once you select that um you have the drop down where you will select the schema table column and how do you want to label the call column right highly confidential and confidential and you can also give the information type whether it is a financial you have like a lot of uh like different types of data so you can choose from it and then you can enable it and once you enable that option again it will be collected underneath the auditing details and I have chosen the default workspace so I have clicked on that and I would like to see like who accessed these columns right so I have clicked on that chart over there which will again give me the amount of details like you can clearly see like who access the data um and what query has actually executed so here in my case I have uh chosen like product ID sales order ID as sensitive just for my demo purposes and I have you know out outside like using management Studio I have executed couple of queries so that it will get captured and it is automatically get captured in the logs through"
    },
    {
        "speaker": "",
        "title": "Azure SQL Security Concepts",
        "videoId": "HgmpvP6Z68E",
        "description": "This is a recording of the August 31, 2023 meeting.Planning to move your databases to the cloud but seriously doubt if your data is 100% secure? No matter if you are on-prem or in the cloud, making sure your data is protected in every angle possible is the most crucial and important step in building a secure data tier of an application. Let's dedicate this session to knowing the different multi-layer defense-in-depth security techniques and strategies available to armor your Azure SQL database. let's dive deep into each of these layers starting with the network security, Azure role-based access control (RBAC), data security at the row level, auditing, advanced threat protection, different layers of encryption, monitoring, and more. By the end of this session, you will have the knowledge to make the right security decisions for your environments and implement these techniques in securing your data.Additional resources can be found at: https://dbanuggets.com/category/azure/About the speakerDeepthi GoguriDeepthi is a SQL Server Database Administrator with several years of experience in Administering SQL Servers. She is a Microsoft Data Platform MVP, Microsoft certified trainer and Microsoft certified professional with an Associate and Expert level Certification on Data Management and Analytics. Deepthi blogs for DBANuggets.com.Deepthi is an Co-Organizer for Microsoft Data and AI South Florida user group and Data Platform Diversity, Equity, and Inclusion Virtual Group. She is a Volunteer for Data platform Women in Technology user group. She is a Friend of Redgate. Along with this, Deepthi loves arts and crafts. You can contact her on Twitter @dbanuggets.After Show Podcast with Deepthi Goguri: https://sites.libsyn.com/464280/after-show-with-deepthi-goguriBlog: https://dbanuggets.com/Twitter: @dbanuggets (https://twitter.com/dbanuggets)LinkedIn: https://www.linkedin.com/in/deepthigoguri/",
        "start": "00:45:36",
        "seconds": 2736,
        "text": "demo purposes and I have you know out outside like using management Studio I have executed couple of queries so that it will get captured and it is automatically get captured in the logs through auditing so I I believe like I covered all of the layers like like as an overview but if you would like to go to detail in detail of this like an extension of this session you can go ahead and choose the Azure category under under my blog where you have like I have talked about more of this topic in my blogs and also like there is an entirely different uh series of um series of videos from Microsoft um Anna Hoffman has hosted many of them so each to each layer that I have talked about have a entire different session like one one hour to one end of hour of session like I have I have I have watched all of them and I have I tried Max to make a single presentation out of all of them and have learned a lot but if you'd like to go more detail into each of those security layers please go ahead and watch these resources it's very valuable and I would like to thank Jason one more time for giving me this opportunity to speak at your user group and here are my contact details again and I would like to thank everyone for attending this session today thank you awesome thank you very much are there any questions out there we put a bow on this uh one um one one question uh first of all thank you uh very nice coverage of like very many topics you really tied them all together and made a package out of it um my question is for a do you have any advice for a development database versus a development database that has no uh no real data in it only synthetic data as opposed to a production database that has you know real real meaningful data in it in a in a developer database which of the security layers do you typically put in place that's a nice question um so which layer are you talking about like if you talk about like network network security layer at the top layer right um I would always encourage for the production like private endpoint but um in my like for my development purposes if I'm building something if if you were me like I I would like to use like firewall rules if I am only connecting to um couple of resources like if some of the resources are connecting to my development database then I would go ahead and use the firewall rules but if many people have to like many people and many services have to access your database then you need to go ahead and look into that last two options which is like private endpoint or the um what is the other one the all right and the virtual Network rule I would not suggest the least option the the first option hello access to Azure Services I will not choose that option and this is not even in a Dev database got it um database now because anything anything I don't want that thank you again uh deeply thank you so much anything else for me today I I would like to share like I will be sharing these slides with you Jason later I will be sending you the link awesome all right yeah it'll be elevation selling or I can I can share you the GitHub repo of mine yeah whatever works for you yeah sure sure I'll do that so Andrew's got a quick question so would secure not Andrew sorry Russell that's a question so would secure enclaves protect against a user doing select start from employee order by name it have order by in it right so certain operations are um securely uses certain operations I mean like if you go down deep into the um query level like like order by they clearly mentioned like order by greater than less than it uses the secure Enclave but if there is an entirely differentiation on like security Enclave if you would like to go more into it but um but as an as an outline yes it should um I mean if they order by salary so if someone selects everything from a list of employees trying to find the person with the most pay secure enclaves are a way to protect them against doing that protect the system from people seeing that kind of information I think while it is being processed right because um that option like Security in enclaves like that option is just while the data is being processed while the SQL engine is is doing the operations behind the scenes but the to encrypt itself like people not seeing the data itself that's when the um data and asking comes in place and like if it is in the Drive location then we need to protect that that's automatically done through encryption at rest okay thank you looks like that's all the questions going once going twice well very good uh great presentation lots of good information there I'm going to be looking back through this uh at least a time or two because um a lot of good stuff in there so thank you again and everyone have a good evening thank you Jason so how many attendees do we have today I just wanted to know the next uh 15. awesome thank you so much and thank you everyone for attending yeah thanks everybody thanks everybody thank you bye thank you "
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:00:02",
        "seconds": 2,
        "text": "How vulnerable is your Azure environment by David Okeyode. This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog). officer for azure cloud so so just some just some changes there so but yeah it's been a pleasure thanks very much for the for the lovely introduction and just looking forward to really meeting with the group and just answering questions and just having interesting conversations about azure and azure security so um i will go ahead and i won't reintroduce myself you know so um it's exactly what what's chase what bill said about me so um no i'm i'm very passionate about azure i do azure every single day my wife has to seize my phone on weekends to prevent me from doing pleasure on weekends also so um yeah so i just i sorry suggestions of apologies as bill mentioned also so i have um two books that we just released on azure so penetration testing azure poetic lockers i was actually i'm looking at this about two days ago when i realized that it was number one in the uh computer hacking category above the ethical like uh uh the popularity called like a book right upper place called like a book so it was actually number one for like about 15 hours before it went back to number two so but that was exciting to see so i've also written another book on microsoft azure security technologies which just focuses on um the isr 500 certification but as what um bill mentioned my approach to technology is to try to make things as simple as possible so that's the sort of approach that i bring to any any material that i put out today so enough about that we're going to be looking at vulnerabilities relating to azure um today and one of the things i like to mention is why i like taking this different approach whenever i talk about um just security in general so i like talking about the offensive side when i talk about azure security and there's a good reason for that so there's a lot of content already out there on best practices um it's not as if we've had all the information that we need but i think that there's a lot of information out there you can go on microsoft documentation site you can go on on um and go on youtube and type as your security best practices and you'll find tons of videos by microsoft by people in different communities talking about best practices and and that sort of conversation however you're going to find very little information about the offensive side of azure security right so that's one of the reasons why i like focusing on that because at the moment there's less information around that there's more when we talk about aws but less on azure so um the other reason is um understanding attacker behavior is definitely an important part of cyber security education so it's important for us to understand best practices and how to configure things correctly um how to implement services in the right way from a security perspective but also important for us to understand the mindset of the attackers what tools are they using what what techniques are they using what approaches are they using how are they evolving that right um i like the way someone sort of put it uh like he said um if the threats that you're facing that is evolving right and you're still using um the type of security that people were using 10 years ago however the threats that you're facing have evolved right no matter how great your techniques are it's not going to be a match for the kind of threats that you're facing so it's very important for us to understand what's out there what techniques are going on out there so we can sort of evolve um our approaches to that so and it's also important for us to learn from the failure of others right so whenever we um just recently there's been lots of major breaches on the azure cloud um some of the things that i'm going to talk about are some of the lessons that we can learn from some of those breaches right so we've had chaos tv we've had azure escape we've had oh my god um vulnerability um detect about discovered by different um security researchers we've even had others before that from checkpoint and other security researchers so what can we learn from those right um in terms of how much trust you will really be putting um when it comes to the shared responsibility model you know there's all this whole thing about shared responsibility shared responsibility model should we really be trusting um in full what a cloud service provider um are doing in this case so some questions around that so um when we talk about just talking about vulnerability in general we're talking about something that's a weakness in a system something that can be exploited by an attacker to deliver a successful attack an attacker doesn't necessarily have to be a bad actor it could be an ethical like i could be a pen tester it could be someone that works in the registry or property of an organization it's really um what weaknesses can we look to exploit and in what ways um can we look to exploit that to deliver a successful attack right um it's what we're really talking about here and that can be down to software flaws uh maybe that software flaws on the side of the cloud provider maybe that software flaws on the side of the development team that are"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:05:04",
        "seconds": 304,
        "text": "successful attack right um it's what we're really talking about here and that can be down to software flaws uh maybe that software flaws on the side of the cloud provider maybe that software flaws on the side of the development team that are putting an austin application on azure right so it could be down to unintended functionality so it's something that is actually working the way it should be working however um there's been um a discovery on how to use that functionality in a way that i was not intended to be used so and there are different sources for this so we some of them are zero days um they're publicly um reported also um by researchers that discover them so in many cases especially when it comes to things like the public cloud platform it's down to a feature misuse right away functionality machine so something that's intended functionality but then it's been misused um to do something um bad right so um a good example of that was i was looking at um it documents the other time of um you know when people um have like just ip um allow list and or maybe hyphy block list and one of the ways that people try to block um different types of attack and then using the clouds to bypass those type of systems so using the clouds to sort of generate um attacks from different ip addresses because it's the cloud so i can generate an attack from each u.s region west years region and just as springtv as you're just um just a varied regions where the attack is generated from to bypass different systems so that's definitely um an on an intended functionality of the cloud to be able to deploy into different regions but then using that in an unintended fashion so it could be down to just user error or missed configuration also so whenever i talk about azure in general i just like to quickly do a review of what the organization structure looks like because that helps us to understand why security in azure is complex security in azure is complex so it is not simple and there is a reason for that at the top of the azure ir key we have the azure ad tenants where we have our identities we have our users we have our groups we have our service principles we have a managed identities like service principles which are application identities managed identities which are resource identities in azure which can be either system system assigned or user assigned identities but when we talk about users there's a whole lot of complexity when we talk about users in in azure or users in azure ad right so this could be just native users this could be synchronized users from on-prem ad this could be guest users that are invited from another partner's azure ad this could be external identities using their gmail credentials to sign in and this could be just a federated identity uh maybe coming from octa or any other federated service so many people don't really look into that in terms of um federation that may be set up i've seen scenarios where organizations set up con conditional access to be able to um allow um um as a set of conditional access to be able to define um the conditions by which they allow access to certain application and to bypass that condition is as easy as switching to it into it infiltrated identity and bypasses the whole security that they've configured right so sometimes you know we focus on you know native users of azure id or synchronized users from one play media but sometimes we ignore things like the federated user so external identities that we're bringing into our environment so then we have um within the azure resources section we have something called the root management group so the road management group is sort of the top of the azure resource hierarchy that's where organizations can apply policies and that they want to apply across the entire organization so you have the root management group you have the child management group and you can go up to six levels deep in terms of the child management group you can have your subscriptions groups together on the child management groups and then you have your resource groups and within your research groups you have your resources uh one of the things that you see is that azure ad as a separate um outback structure to azure resources and that's where you begin to see where some of this complexity begins to come in right so azure ad has different roles and different hardback structure roles like global administrator user administrator application administrator azure outback has different um a different outback structure where you uh that used to grant access to resources so you have some built-in rules like owner contributor and reader um on on that level now as a good practice you want to ensure that you are separating these rows from each other in other words if i have a user here called um joe i do not want joe joe's account to have access um to azure ad to have administrative access to azure ad and at the same time that account has administrative access to manage azure resources so that's a basic um good practice because that allows for lateral movement because that's why if j's account is"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:10:10",
        "seconds": 610,
        "text": "ad to have administrative access to azure ad and at the same time that account has administrative access to manage azure resources so that's a basic um good practice because that allows for lateral movement because that's why if j's account is ever compromised in what way maybe a token an access token is stolen from just pc and then used to access the environment if joe's um credential has access on these two levels then it's easy for an attacker to move laterally across from azure ad and then begin to access azure resources or maybe even more from accessing azure resources to being able to open back doors in azure ad so we want to be really careful in terms of how we structure our role assignments between these two um outbox services or these two our back systems so when we're talking about our back in terms of azure resources we have um that's defined in json and you find um that in four sections you have actions where you can define management permissions that you want to allow you have data actions where you can define um data plane actions that you want to allow and then you have not actions where you can exclude management plan permissions and you have not data actions where you can exclude data plane permissions so there is no um not deny framework except you're using something called blueprint um however um you can you can exclude permissions from what you've already added so one of the places where you begin to see that complexity is in that permission structure there so for example um here is a latest um the latest snapshot that i took from this website um azure.permissions.cloud so it's a nice website that was built by ian mckay so here does amazing things in the um security community so him puts together this website where he's bringing in information from um iam on aws and azure and google cloud and bringing them into this website which is just permissions.cloud is the main website um but you can um prefix that with whatever cloud that you're going to so in that particular case i'm talking about like the azure cloud right and if you have a look at that i mean have a look at that this is about currently about 1340 actions that we can define when defining permissions in azure hardback now you can begin to see where some of that complexity is coming from but 1340 actions and now um multiply that by the number of users that you have to manage in a typical organization right multiply that by services changing all the time and new capabilities and new actions being added all the time right and then have a look at all the different ways that some of these permissions can be misused and then you can see why this is really really complex for many people to handle the other issue that you're going to find there is that they're about 317 built-in rules and many cases when people see those built-in roles many people build their id and their iam structure they build them using the built-in rules but one of the things that that um cover like um like in um when we talk about like pentax in azure one of the things to know is that for many of the built involves it's very easy to exploit um some of the permissions that they have as part as part of the built-in permissions so for example one of the things that um i'm not sure um bill has seen that in in the book uh one of the things that we covered there is you have like a reader credential what are the some of the different options or different methods that an attacker could use to um escalate privileges from reader to a contributor and then escalate privileges from a contributor um to owner of the entire subscription right so there are lots of permissions that can be easily exploited and they can be really really um just taking advantage of to move laterally within the environment or to be able to escalate privileges within the environment and the other thing that also makes it very complex in terms of azure security are the massive amount of services that we have in azure i think the last time i counted i think there were probably about let's go here let's clear the screen i think last time i counted i think we have about 179 something like that let me go ahead and just let me go ahead and just do a quick count of current azure services right there's a lot of them um sorry there's this um we used to count that let's go to azure powershell and let's bring up some information here and let's go to that okay so typically just go to like the directory of azure cloud services and i just count the services there counts the unique counts the unique number of the services that i existed so what i'm going to do is i'm going to count all the services in the directory of hydrocloud services and i'm going to remove any duplicate count so i'm going"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:15:14",
        "seconds": 914,
        "text": "counts the unique counts the unique number of the services that i existed so what i'm going to do is i'm going to count all the services in the directory of hydrocloud services and i'm going to remove any duplicate count so i'm going to use the i do that using the unique parameter and that's going to give me a list of all the services that are currently listed on this page and if i do a count on that that's about 177 services right that's a lot of services in terms of understanding how the services could be misconfigured understanding how these services could be exploited understanding um what's what sort of ways that it could be misused right so so that's one of the reasons why things are so complex in terms of managing that another thing that also adds to that is the let me go ahead and bring up the slides that i'm looking for another thing that also adds to that is um the cloud native approach which is how many organizations deploy things to azure distance let me go ahead and bring up these light for this so if you have a look at the cloud seek on the cloud native security model for example which is how many organizations adopt the cloud and the way that they're deploying things you have organizations having their code and they have their code and their code as um runs typically in a container or if it's not running in a container it's running directly on an online host and the container or the code is running directly on a node which has an operating system installed so that could be linux windows that could be where that car os if you're using something like openshift on azure and that node is managed by an orchestrator or managed by an azure service like maybe azure functions or azure batch um or azure have services managing the nodes and then you have that um that service about castrator running on the azure cloud and this is one of the other reasons why security is very complex in an environment like azure because um vulnerabilities can be introduced at any of these layers into the environment and can be used to exploit the environment it could be vulnerabilities introduced on the cloud layer or the cloud level that's exploited to be able to gain access to a service and then being able to compromise the rest of of the stack or it could be vulnerability that's due to chords that's been deployed into the environment that exploited to break out of the container into the node and now still credentials for the cloud and then use that to move laterally into the cloud so now you're not just talking about one security model that we have to understand you're talking about having to understand about four or five different security models you have to understand the security model in terms of application code and understand security model in terms of containers and in terms of operating systems and in terms of orchestrators which is a completely be a complete beast on its own and at the same time understanding security model for the cloud so hopefully that just gives you like some quick information on how complex that is so one of the things that you mentioned that i put together um is around something called the azure um the azure attack matrix so one of the reasons why i put that together was because i didn't see anything that was really satisfactory so um what mata has out there it's not bad it's good but um looking at what i've seen in terms of my own experience i don't think it's like as comprehensive as it could be i have recommended some some of the stuff for them also mita used to have something dedicated for azure but then they removed it in favor of just going um miter matrix for ias so what i started putting together a while ago was i started putting together things that i've seen um in my own research and other people's research and i started putting that together in something called the azure attack matrix which changes all the time which goes all the time and just putting together different tactics and techniques that i've seen used in terms of discovery techniques and where an attacker is aiming to learn about a victim's environment trying to identify the attack surface trying to gather as much information as possible about a victim's environment and some of the techniques that um you see used um in in that sense and then talking about credential access and some of the different approaches that i used to get access to credentials um in an environment like azure right and there are different methods that could be um because guessing credentials in azure 80 that could be compromising the node in the cloud that has an identity associated with it that could be application credentials that stored in configuration files or in the configuration sections of services like azure hub service or azure functions that could be that could be down to just cloud um service credential access um in terms of what's been what's been exposed maybe in things like storage account or just data stores and then methods that attack actually use in terms of initial access so this one is a new one that i added due to recent vulnerabilities"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "um in terms of what's been what's been exposed maybe in things like storage account or just data stores and then methods that attack actually use in terms of initial access so this one is a new one that i added due to recent vulnerabilities in azure so cloud provider service vulnerability because if you look at all the recent all those vulnerabilities in terms of chaos db and in terms of um um as your skip and in terms of um oh oh my god all of these are down to cloud provider service vulnerability where there was a vulnerability in the way that a feature was implemented in azure that attack has exploited and then been able to use that to move laterally into another customers um into another customer's environment right so that could be exploiting anonymous access so one of the things that i'll show you later in terms of the lessons learned they're just about um tourist services at least that i've seen exploited that support anonymous access in azure so and um in terms of how people exploit that that could be a trusted relationship maybe you have like a private link built to another customer's environment that could be through v-net pairing that could be on multiple layers right not not just like the network layer that could be on the access layer in terms of trusted relationship in terms of identity so there's multiple um level of levels of depth into that that could be due to application vulnerability is still popular from in terms of in getting initial access into the environment that could be weak all defaults and service credentials typically with services like virtual machines that could be cloud credential compromise and this can take a lot of funds that would be stealing cloud credential from a developer system i could be stealing cloud credentials from developer toolings like devops so then like maybe from azure devops or from github actions or from other developers like that okay so let me just move on very quickly in the interest of time okay so um and you know different approaches to to run exactly and perform execution um to do privilege escalation and um to evade the defenses right the very defenses could be just modifying the uh ip allow this one that i saw recently in terms of um um well no not defensive vision so the one um that's coming to my mind is in terms of persistence so i saw one recently in terms of persistence where um someone um added an ftp credential to an azure app service right as backed up so i probably need to add that to that list so somebody added like um so you have a job service in the environment because azure app service allows you to be able to it has a default um app level ftp credential but then you can have additional ftp credentials but there's no way for you to have visibility of those credentials in the portal and looking at the back end they were seeing a sort of credentials that's been added which means somebody could ftp into the app environment and get access to source code right so you have all these different approaches that can be misused and leveraged you know you have modifying and now list another one is using our job policy as backdoor so we're um using exploiting things like guest extension for kubernetes to um first install a back door in kubernetes that gives an attacker persistence into the environment even if you go ahead and remove something um as your policy will ensure that it's put back there right and just leveraging that for better so there are multiple approaches that we're not going to be able to cover and some of them today but i'll just go ahead and just talk about a few of them and then i'll talk about recent bridges and some lessons that we can learn from that so in terms of discovery that's um you know um can be from two approaches that can be on authenticated discovery where an attacker has no credentialing to the environment they don't have any credential they're coming as it is from the perspective of a complete outsider um or that could be authenticated discovery maybe you're doing something like um a zoom bridge and pen test scenario where an attacker is giving a video credential to see what they can find in the environment and that so when it comes to things like um on authenticated discovery so typically you know the normal type of you know scan the ip address range look for vulnerabilities that you can exploit to get into the environment or in this particular case of using dns and innovation and using dns innovation to try to um look for um services in azure that supports anonymous access as i mentioned a few services in azure that support anonymous access and then if you find any service that supports anonymous access using that so exfiltrate any data that you find in that service hoping that you find some form of credential or some form of information that would be useful further in the attack chain um later um in that particular case one of the tools that's really popular for doing um both authenticated on or on authenticated discovery is a tool called microburst so microburst um was actually written by the person that we co-wrote the book together so his name is calfossine so kyle leads um"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:25:19",
        "seconds": 1519,
        "text": "authenticated on or on authenticated discovery is a tool called microburst so microburst um was actually written by the person that we co-wrote the book together so his name is calfossine so kyle leads um a group of securities a group of pen testers and out of oregon so car was these two which is a set of partial scripts that you can use to perform different attacks on azure so it also includes a script that you can use to do dns elevation of services in azure and then look for those top type of anonymous access so his name is carl fossum so that's his twitter handle github repository for microbus it's an open source project so anyone can really contribute to it it's written in um powershell so i will show you a little bit of some demo of microbus but before i do that let me just point out in terms of um the azure dns um suffixes that exist that was like micro box can scan so um if i go to no not this one so not this one let's go to this one um yeah so in this particular case so for many services in azure um many platform services you have the resource instance name dot the dns suffix name and then so for example if you have an azure storage account um called azure offensive it's gonna be azureoffensive.blob.com.windows.net but you have multiple other services in azure like um you know azure website and stuff you can find those um it's not a comprehensive list i've not really seen where microsoft has like a full comprehensive list anyway but if i do is that cloud show um and i'll put a stable and if i do is it cloud um okay now that is that cloud show yeah is that cloud show and let's say the name of the cloud platform to show is azure cloud so let's do that and that's going to give like a list but it doesn't give like a full list of the dns suffixes of the services and you can see this across all the different um cloud that azure has so that's for the azure public cloud you can view the same thing for the azure um let's say azure us government for example but again it's not comprehensive so i've not seen why microsoft actually has like a full comprehensive list um anyway so in case anyone knows of where you can find some but you can go ahead and you can see some of those dns suffixes listed there um and again tools like microbus can scan those so what i have is i have an environment where i have some um services and if i go over to my virtual machine and i'm going to download micropost and let's see that in action so let's discard that let's bring up my virtual machine oh no do i not have oh no oh no um okay i let me see if i have this on my normal machine if i have this on my normal machine i'll just use that let me go ahead and bring up powershell on my system let me check that i have let's do let me make sure that i have um make sure that i have azure powershell installed so okay it's command view lists available if i have a job portion installed then i can go ahead and just get micropost from github and then i can use that let's minimize this come on okay yeah good i think i've got i've got that installed so we're good to go so what i'm going to do is i'm going to first of all um just go get go clone i think i've got git installed good so let's go to get microbus downloaded and installed and i'm going to import the micro bust modules and once that's imported to the modules come on come on come on you can catch the modules oh shouldn't take that long um it's doing something if that does not respond quickly you can move on and i can come back to this later yeah okay it's not uh responding i can say that it's doing something i can say that it's trying to download because i'm looking at the network monitor here i can say it's trying to download some things uh but normally shouldn't"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "this later yeah okay it's not uh responding i can say that it's doing something i can say that it's trying to download because i'm looking at the network monitor here i can say it's trying to download some things uh but normally shouldn't take that long to download okay while that is downloading let me just take you to the microcost url and just show you um some of the i'll just show you some of the modules that microbus comes with so typically if you go into the az folder you're going to see some of the modules there you see some of the modules under the miscellaneous folder also if i go to the az folder you can see some of the modules here and a lot of these modules are what you use for authenticated and discovery so you have some credential into azure so typically you have a reader credential you want to do authenticated discovery you can use those but then you also have if i go under miscellaneous so this is where you're going to find some of the modules for doing on authenticated discovery so for example you have a module here for invoke animate azure blob so that's going to look for anonymous azure blob you're going to give it a base name and the best number you provide is going to scan that base name and check and check if it's going to find any anonymous blob using that base name so that's something that you can also modify the permutation so the permutation that is going to use by default is listed in this document right here let me expand that and let's go to that so it's going to use the permutations listed here so for example if you want it to when it's searching you want it to look for maybe a container name called um you know something else right so you can go ahead and just put that container name there and then microbus will include that as part of the path that is going to search when it's trying to do anonymous listing so unfortunately still doing some type of download and once it's finished i can come back to show that to you so um so that's one approach in terms of doing just um the discovery when it comes to things like initial access there are multiple ways that that happens right so i'll just point out one of that so it mentioned cloud credential compromise but that could happen in multiple ways so typically it could be um it's an attacker having the aim of the attacker to try to get a credential that they can use to um access the ammon point of azure and um that could be um also maybe just to access like the data plane in terms of the services and there are multiple approaches that could be taken so targets that usually be just doing phishing for user accounts in azure ad um just looking for service principles on typically on different developer systems or devops services and in many cases just looking for access token that's been issued and and cached locally on different services and some of the methods uh targeting user admins in terms of phishing targeting devops systems and scanning devops system which with our credentials looking for variables that contains cloud credentials that has been exposed so um azure devops um you know as a command line to that if you have um with the right level of permissions you can go ahead and you can um extra trade and and export a lot of the credentials that people have um in variables on the india pipelines right so that could be targeting admin workstations in this particular case it's mainly looking to steal cached access tokens microsoft made an improvement to that recently um in moving fully to m cell instead of edau which means that some of those tokens are no longer cached locally so that's there's some some improvements there so there's less um options for an attacker to steal those tokens right um that could be just targeting just azure hosted applications and maybe through application vulnerability because this resources can also be assigned an identity and that way token can also be um stolen or exfiltrated and then used to um access azure ham endpoints to do um further recon to do for the animation of the environment using the credential now so i'm looking at the time here and i'll need to pause there in terms of some of this so let me quickly go talk about um some of the recent breaches or some of the recent vulnerabilities on azure and some of the lessons and that we can take from them so let's look at um so a lot of all the ones that i'm going to be talking about here they fall on that the category of um cloud service provider vulnerability and my whole reason for doing this is to help us to understand how can we um protect ourselves even if there is a vulnerability on the side of the cloud provider like the theory um that happened and how could we protect ourselves that that even if that were to happen um there is uh there is less possibility that our environment will be compromised so let's first of all go look at um the first one which is chaos db so chaos db is the one that was discovered by some which such as from whis so"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "there is less possibility that our environment will be compromised so let's first of all go look at um the first one which is chaos db so chaos db is the one that was discovered by some which such as from whis so the way that the vulnerability worked was there's a feature of cosmos db which then if you create cosmos db it comes with jupiter notebook and you know you can query data using code and you can you know run python and then query code and just do some fancy things with with data just using code so what the researchers did was they they didn't just use python they were trying different languages and they ran some c sharp code and then they realized that c sharp code was running as words if they run the code using python it was running with a non-sudo user which was cosmos user was just switching to um just switching to c-sharp it's notice i was running as roots and then they use that word account to create another account that they can then use to look at the environment so they use that to escape out of the container of the jupiter notebook and then they started doing some recon on the environment and they noticed that there were some explicit block rules in ip tables and they noticed some explicit block rules that was that was blocking some ip address ranges and typically you know you work in security if this is something that's explicitly blocked you want to know why they're blocking that so what they did was they used the roots permissions to remove those blockers in ip tables and then check the environment to see what they found and eventually what they found was they found certificates that were exposed so they began to query the internet metadata service and they found some certificates that were exposed and then they use that those certificates later when they gain access to some internal systems to authenticate those internal systems and the end result of that was they were able to get access to multiple database access key for thousands of users so this was something not on the side of the user in terms of some of the other options this was something on the side of the cloud provider that caused that right another one that happened just a few weeks after that that was disclosed was azure scape so this was discovered by researchers at palo alto network so it's the guy's name is uval so um this is from an azure service which is azure container instance and what the researcher did was the researcher as a tool called uc so it's a tool that i've blogged about um in the past in one of my blogs so if anybody's interested in testing out that tool and seeing what that's all is uh if you go to davidakiadel.medium.com blogged about that too called uc so it's a tool that you can use to enumerate any um container runtime environment so very very useful too so um uvo um was the one that created that tool but then he used that too to essentially enumerate the runtime environment of azure container instance and what they found was that the environment was running an outdated version of one c and there were no exploits for that version of vance that it was running so he used the exploit of that cve and he he used that exploits to escape the container and now is on the node that he should not have access to and then he began to do some enumeration of the environment i and found that um it's running kubernetes and it's running an outdated version of kubernetes so what he also did was he used another exploit excuse me to tweak a bridge pod on the node and it essentially sends an exec to that bridge pod and that which would send an xx to the api server and in return what he got was it got an exposed privileged service token and then without privilege service talking it can begin to move across to other nodes in the cluster and other nodes in the cluster runs other customers container workloads so it was able to compromise other nodes in the cluster and began to run another cluster because other customers and began to access other customers um workloads and even begin to run code on their container environment so um both of these has been fixed and patched by microsoft but i just thought there are some very interesting lessons to learn from them in terms of how if this were to happen again how we make sure that we are protected against something like this so and one aspect of it i think is very important i've seen this in my own experience also is that we need to start normalizing private network access for platform services right so for some reasons many organizations still have um platform services that they're not using private access for and i understand some of the reasons for that right from a usability perspective so for example i was looking at if you're using azure container instance in a private network i was looking at the limitations that includes you cannot use managed identities you cannot use it with v-net pairing so just with those limitations alone i can see why the development may"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "at if you're using azure container instance in a private network i was looking at the limitations that includes you cannot use managed identities you cannot use it with v-net pairing so just with those limitations alone i can see why the development may make the decision to say we're going to use this with public access instead with private access because we need all this other functionality but wherever possible we should have mitigations um even if we have to use something in a public way but we need to start normalizing private network access there are multiple ways to have platform services with private network access in azure so one of the common ways is to do something called v-net integration and so v-net integration is not supported by every platform service in azure and this is where you have a platform service you deploy it into a private network and then um you can have increase and egress traffic control of the virtual network applied to that platform service so at the moment this is supported by only about 23 platform managed services so it's not supported by too many and platform managed services um many of those services are going to require dedicated subnets which means that when you're doing your architecture um they cannot run alongside other services in the same subnet so you have to have a subnets that's dedicated to that service so it's service like azure cache provided sql managed instance so these services are going to require a dedicated subnet if you're going to integrate them in a virtual network and some services also require delegated access so delegated access means the service is going to require permissions to be able to create resources um in your network so some organizations can be a bit careful of that especially if your network is also connecting to maybe your on-premises environment and some organization may not like that um someone that's not my team or something that's not my team can be creating resources in my environment so for example if you go use adjustable manage instance adjustable manage manage instance is going to require permissions to be able to create network security group um in your network it's going to require permissions to be able to modify the root table in your network so um you know for for in many cases microsoft has done a great job that they do not take more than the permission that they've listed in their documentation but just be aware that some of them are going to require delegated access to your environment so vignette integration is one of the ways that you can use to do that um if chaos db happened which is cosmos db where credentials were stolen and v-net integration was implemented well linux integration doesn't work for cosmos db the other one works for converts cosmos db but if private network access was implemented an attacker would not be able to gain access to the data so they will still need to go to another level of the layer of defense before they can get to the data of the customer so another option to implement um private um network access for platform services is used by the endpoint which just means you link that platform service to um a private network and the downsides to this compared to venus integration is that this only affects ingress requests so requests that's going from your services or from your workloads into those services not um traffic that's coming out of those services so this is only this is for ingress only and but again in the case of cosmos db if this was implemented and public access was blocked even though the researchers had the access keys they would not be able to access the data or x not except they can compromise the network also and gain access into that network right so another option uh which is at the minimum if you want to make sure that you at least restrict the ip addresses that your platform services can be accessed from so at the minimum you want to restrict that to trusted ip addresses so that even if the credentials were stolen it's something that you still need to compromise um you know the trusted network to be able to use so you can use this in combination with private endpoint and and then you can have it that way another important lesson is to disable key based and local authentication where possible azure services supports a range of authentication and authorization options we have some services that support anonymous access some services support key based authentication so typically that could be long-lived access tokens or temporary access tokens like in the case of azure storage it supports long live access token it's a 512 byte um access token in terms of the access key but you can also generate temporary shared access signature tokens that you can use some services support identity-based authentication so that could be local authentication in the case of a service like azure container registry or that could be something like azure ad in the case of azure file and azure blobs what support azure id and even keyword support um azure ad so you have to understand the services that you're adopting and understanding the type of authentication and authorization that they support um in terms of anonymous access um services the main ones that i've seen exploited are services like azure blob"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:45:33",
        "seconds": 2733,
        "text": "support um azure ad so you have to understand the services that you're adopting and understanding the type of authentication and authorization that they support um in terms of anonymous access um services the main ones that i've seen exploited are services like azure blob storage azure container registry so um azure blob storage container can be set to have anonymous access and again tools like microbus can be used to scan and discover those in an automated way and even or exfiltrate data from them in an automated way so um services like a service like azure container registry can also be set for anonymous pool so typically organizations that do these um i've seen where people set that to be able to do some tests and then forgot to remove that so and the only information that an attacker needs to be able to exploit that would be to be able to guess the name of the registry and guess the name of the container if both of those unknowns can be guessed then essentially they can pull down the container image and it's not unusual you know i see that on a regular basis it's not unusual to find a credential eating in a container image even though it's not good practice it's still something that we still commonly see right so again information that's needed for external attack in this case if you need information about the resource name information about the container or in some cases you need the object name if it's for the container you need information about the repository and the image name and again both of those information you can use at least or or get or guessing um it just puts like a permutation listing tools again like microburst or lava and then you can use them to to be able to get those when it comes to anonymous access for those two services you can disable anonymous access on a per resource basis so you can disable that for azure blob you can disable that for container registry but you can also disable it centrally using azure policy so microsoft has some policies in preview that you can use to check um um if um what's it called if um public well this is not public access actually so the one that we're looking for is key based um oh sorry this anonymous access yeah if public access is allowed so they have like a um they have a a policy in preview that you can use to check that um on a central basis across your entire environment so you can leverage that so the other authentication option which is long-lived access keys so this is supported by about 28 services so in terms of the count i think i'm going to come out with a blog in terms of because i did a detailed account and looked at the different services and looked at what can be done so there are 28 services in azure today that supports long-lived access keys which are access keys authentication and authorization so services like storage account of course it has two access keys services like cosmos db also has to access keys um you know compute services like batch accounts service fabric cluster signal how ai services like cognitive service and board service and data services like data factory developers services like app config all of the services and others support long live access keys which means you have access keys that can be used to authenticate outside of the central identity control plane so um and the access level that the access case grants it ranges from unrestricted management or data plane access in the case of cosmos db um with the ksdb issue read and write keys will give unrestricted bot management and data plane access to that so um and it's the same for azure storage access keys so unrestricted management um and data plane access in some cases some of the keys are just data plane permissions um only and in some cases they're just read on the data plane permission for example in cosmos db you have read on the keys that you can use um just for for read only access in that particular case i'm not going to go into the other one in details because i'm looking at the time so there's a lot of information that we could cover on some of the behaviors of some of these long-lived access keys and some of the differences um between them but i'm looking at the time and i'll just keep some of them so when it comes to local authentication there are some services that supports logical authentication of course virtual machines support local authentication but they also platform services like azure sql database azure sql managed instance container registry the support um the support stats so the good thing is that you can disable local authentication for both azure sql and azure container registry so azure sql when you first of all create a database it has something called an admin user the admin user has access to all the database within the service including the master database right so that is a user account that if not disabled then someone with the right level of permission can reset the password of that admin user and use that to access all the databases in that service so there is a way to disable that so you can disable admin users so that you only use azure um azure ad authentication for azure sql same thing for azure container registry there's an admin user that you can enable it's disabled by default but"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "there is a way to disable that so you can disable admin users so that you only use azure um azure ad authentication for azure sql same thing for azure container registry there's an admin user that you can enable it's disabled by default but um it can be enabled maybe maliciously as a back door into the environment um or maybe somebody enabled it and forgot to disable this you can disable it individually or you can disable enforce it and disable using azure policy so there are policies that you can use for container registry to disable local authentication for azure ad and sorry for azure sql to ensure that only azure ad authentication is enabled right so good practices when it comes to this is you want to disable long-lived access local authentication long-lived access key or shared signature generation where possible where possible stick using identity based authentication especially just going through azure id because of the powerful identity security capabilities of azure ad you also want to monitor for configuration status changes so if somebody maybe compromises a credential and they enable an ad the admin user for your support database or they modify the configuration to enable admin user for your container registry you want to monitor for that so that it flux and a lot so that you can see that that's been changed you also want to monitor um events um for usage of um local authentication long-lived access key search generation or anonymous access so you want to monitor your resource logs for that i was going to show you some of that but i'm looking at the time now and it's a bit late so i believe that i i wrote a blog um i wrote a blog about anonymous access and one of the things that i highlighted in the blog is how you can sort of enable [Music] the resource logs to be able to check that and what logs looks like and what you can see in the log so and the same thing i'm going to put the same thing out for local authentication so you can know what to look for in the logs so if you're doing uh if you're looking at the resource locks for anonymous access for storage account you'll be able to find that once you enable resource logs you'll be able to find under the identity section you see that the type of access is anonymous and then you can flag that if that's happening in your environment so um we are not possible to disable do the following so in some cases it's not possible to disable that so for example if you're using cosmos db and you're using the sql api of cosmos db the sql api of cosmos db supports identity based authentication with azure ad however except something changed recently the other apis of course must be the api the cassandra api the table api and the graph api they do not currently support azure ad authentication which means you still have to rely on key based authentication in those particular cases you want to make sure that the keys are stored in key vaults you want to make sure that you regularly rotate them unfortunately um microsoft systems doesn't have consistency in terms of a lot on rotation if you're using azure storage you can say to add your storage and say allow me um if my key is older than this edge but you it's only address storage that has that capability um in it so i would love to see microsoft introduce that across any service in azure that supports uh long linked access keys so enable private link and then it's integration on the second line of defense so that those were to be compromised um you'll still be protected so i'm looking at the time now and there's something else that i want to talk to you and i have a nice demo that i wanted to show you on this one so just give me five more minutes and i'll do this i'll show you the demo and i'll stop so the other thing that i learned from the vulnerabilities is that runtime protection is still important because what has happened is that um as we begin to transition to the cloud in order for us to achieve um ease of use in order for us to be able to achieve speed in order for us to be able to achieve reduced management cost the price that we've paid is less visibility like in the case of azure escape where uh you know the team were running an outdated version of run c and we had no visibility until the security researcher became decided to use a tool to enumerate the runtime environment and so that it was running and running an outdated version of 1c so we have less visibility as part of that but because of that what i'm saying here is less trust it's not no trust but maybe the way to put it is say trust bar still protect yourself so when you're using services like managed runtime environments like functions and app service wherever possible where you can have that extra level of runtime protection and better than your application it's still good to do that so that in case those kind of vulnerabilities are upon the game if somebody were to try to run some code in your environment because they were able to exploit this the service providers um miss implementation or misconfiguration they're"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "00:55:41",
        "seconds": 3341,
        "text": "do that so that in case those kind of vulnerabilities are upon the game if somebody were to try to run some code in your environment because they were able to exploit this the service providers um miss implementation or misconfiguration they're able to exploit that you will still have some level of protection that will allow you to say somebody's trying to run some code in your environment that they should not be able to run so it's still important so even though it's a managed environment and you don't have visibility still look for ways to protect yourself another way to implement runtime protection that could be using you know technologies like rasp and embedding runtime security into your code itself so that's still important the example i was going to show you was on azure container instance so right now if i go over to this environment so apologies i wasn't able to show this to you but hopefully i'll be able to show this next one to you so i have an azure container instance that's running um an application that's compromised sorry that's vulnerable so if i go to my azure container environment let me quickly authenticate to that and so what i have here is i have two container instances running on azure one of them without one time protection and one of them with one time protection so if i go to container instances there i have this one without runtime protection embedded this one just one time protection embedded so even though they had you know i don't have underlying control of that i still have one time protection embedded into that so now i want to show you what that looks like so if i go back to this environment here and i connect to the one that does not have one time protection embedded into that and i'll quickly connect to it i'll put in the credentials so i'll do that off screen so it's in the credential for that and i just put in the credential for that so let me go ahead and clear the screen okay so let's do that over here so now i'm connected to that let me go ahead and just to remote code execution and run that on that container instance and i'm able to get to that i'm able to see like the files that it's included in that environment i can begin to um even you know gets environment variables so by looking at the environment variables on this environment so if an attacker is able to exploit like a service provider it's configuration they're in the environment and they're able to run code in your environment and they can see just by looking at this environment variable that this um instance has a managed identity associated with it so you can see identity here there you can see identity api version so that means it doesn't manage the identity that means there's um potential to be able to steal a token um from from this um from this service and that's running this application and then another can just proceed and um get some tools installed maybe even just get a remote shell so let me see if i can get a remote shell to this environment so what i'm going to do here is i'm going to [Music] do this let me go to open it listener so let's go to opening listener on this environment so no doubts let's do that again so open the listener on this environment and i'm gonna open the listener for part 444. so that's listening to any um request so i'm going to go to the con i'm going to go call out the container instance and i'm going to get it to um to open a reverse shell for me so i'm going to do that by using this piece of code right here and i say run that i mean i've noticed but what he did was he opened a remote shell so now i'm on that container environment i can begin to poke around look for the managed identity type as look for who am i look for the credential that i have and see what type of access that i have and this is on an azure container instance by the way so and i can begin to look at that so but this is an instance that i don't have underlying control of the environment but i have another environment here so let me go ahead and exit out of this i have another environment we have runtime protection embedded even in um an azure container instance environment so let me go ahead and connects to that so i'll connect that instead so that's called um our call that you have protected and i'll go ahead and connect to that with my credential and i'll go ahead and connect yeah so that's connected so let me bring that back onto the screen and what i can do is if i go to run that so you can see that the attack is still successful and stopped that's because i've not implemented runtime protection even though i have the protection embedded so what i'm going to"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "01:00:47",
        "seconds": 3647,
        "text": "and what i can do is if i go to run that so you can see that the attack is still successful and stopped that's because i've not implemented runtime protection even though i have the protection embedded so what i'm going to do is i'm quickly going to go to the environment where i have um my um where i can configure my policies so i'm going to go do that right now so it's taking a short while it's just authenticating me sorry so i'll go to the environment now come on come on come on okay so it's authenticating me now so what i'm going to do is i'm going to go to implement my runtime protection and if i go to on the defend and if i go to under runtime so i've embedded that into the application itself so i can go ahead evo and i can call this azure container instance protection row i can scope it um based on any scope that i want but in this case i can really in an aci environment i can define the processes that i want to allow are the processes that i do not want to allow even in an ac um in an aci environment that i don't manage i can do this for azure functions i can do this for azure app service so if i put in that process there because that's the process where my application exists and i can say that's the only thing i want to allow and i can say anything else i want to prevent anything that's not part of the allowed process so even if an attacker was able to compromise some other way and get to the environment and they begin to try to run some code to enrich the environment that's not going to work even in a managed service so i can do that for also like the networking process but i'm going to leave that for now i'm just going to do that for the processes and i'm going to save that so now that that's saved um if i want to monitor what's going on if i go to under monitor and event i can go monitor what's going on on the app embedded so what i'm going to do is i'm going to run the same um commands that i run just now that was successful if i go ahead and run that again so i was able to list the environment variable just this minute ago if i go ahead and i run that again and let's see oh am i in the right environment maybe not maybe i'm in the right environment oh okay i can see what i'm doing so sorry i'm in the wrong environment let me go ahead and do that in the right environment let's go ahead and do that in the right environment so i'm going to do that so that's loading protected this environment i want to be on and if i go ahead and i run that [Music] okay let me go ahead and log back into that environment sorry now actually i can see that something happened just now so let's run that again yeah there we go so something happened so i can see that i run that and if i run this and you can see that i get no reply back and instantly if like that's to me to say in your container environment someone was trying to run um that to list the environment variable someone was trying to run this in your environment and i prevented that from running in that environment and it's going to flag that to me and i can go check the forensic and it's going to collect the forensic of exactly what happened um even in an azure container runtime environment so that's something that's still important um especially as more attackers begin to focus on cloud providers to look for vulnerabilities in that sense so in conclusion follow those three lessons right so make sure that you go check your environment make sure that you normalize private network access for platform services make sure that you make sure that you disable key based authentication local authentication where possible and do not use them and centralize that and monitor for usage across your environments and number three wherever possible even if it's a managed service make sure that you have that last layer of protection in terms of a one-time defense so i'm going to stop there so hopefully you got one or two things so apologies i had to rush some of that but hopefully you've got a few things so i'll take any questions if anybody has any questions well thank you david this has been really excellent so we do have some questions here and um mike p do you um was it mike p do you want to come off and ask your question um live here yeah thanks for that i wanted to ask if um you had any go-to tools for miss configurations in azure uh anything that's comprehensive that will enumerate all the different uh misconfigurations or common misconfigurations yeah your policy is awesome for that azure policies awesome and it's free um however it's it involves a lot of work that you have to do right so because your policy is embedded into the control plane"
    },
    {
        "speaker": "",
        "title": "How vulnerable is your Azure environment by David Okeyode",
        "videoId": "Hj7U3E26uWQ",
        "description": "This is a recording of the December 1, 2021 virtual meeting.How vulnerable is your Azure environment?Abstract: Ever wonder if you did everything securely in your Azure deployment? Join us as Azure expert David Okeyode drills into an interactive session on: How vulnerable is your Azure environment?Through discussion and demonstration you’ll gain insight into the following topics:Azure Attack Chain - Methods that hackers use to exploit Azure environments; Identifying critical flaws in your attack surface; Lessons to learn from recent cloud breaches; Top 5 steps to prevent attacks to your Azure environments.## SPEAKER BIODavid OkeyodeAzure MVP - Cloud Security ConsultantDavid is a cloud security architect at the prisma cloud speedboat at Palo Alto Networks. Before that, he was an independent consultant helping companies secure their Azure environments through private expert level trainings and assessments. He holds 13 professional certifications across Azure and AWS platforms, including the Azure Security Engineer, Azure DevOps and AWS Security Specialist certifications. He has also authored two cloud computing courses for the popular cybersecurity training platform - Cybrary.David has over a decade of experience in Cybersecurity (consultancy, design, implementation) and over 6 years of experience as a trainer. He has worked with organizations of different sizes from startups to major enterprises to government organizations.David has developed multiple vulnerable by design automation templates that can be used to practice cloud penetration testing techniques. He regularly speaks on cloud security at major industry events like Microsoft Future Decoded and the European Information Security Summit.David is married to a lovely girl who makes the best banana cake in the world. They love travelling the world together!@asegunlolu (Twitter)linkedin.com/in/david-okeyode-b3376033/ (LinkedIn)azurehangout.com/about-us/ (blog)",
        "start": "01:05:50",
        "seconds": 3950,
        "text": "or common misconfigurations yeah your policy is awesome for that azure policies awesome and it's free um however it's it involves a lot of work that you have to do right so because your policy is embedded into the control plane of azure it's embedded into ham so there's really nothing that you cannot access you can access any configuration and you can do that zero day like if microsoft released a new feature you can begin to access it using azure policy so job policy is awesome for that there is a two that was written by ian mckay and let me see if i can find the link to that too that you can sort of leverage in terms of azure policy um so em okay i shall policy oh maybe no sorry i think it's bran kilmate is what i'm thinking about not here in my case sorry it's brian and killman um uh yeah you know what um why don't we do this is it possible can you connect with me on like let's say on linkedin or on twitter and i'll get the link that i'm thinking about and send that to you thanks so much yeah yeah no problems and and then so the other thing would be so either you go down the road of azure policy which is free you have to put in some work to begin with but you know it's it has its own advantages or you can go down the route of looking at uh maybe a csp m2 and that you purchase so this launch cloud security posture management tools that does the same thing so like the tool that i was just using right now is a tool created by palo alto it's called prismacloud so it has cspm capabilities um so some of them goes beyond just looking at the resources and looking at some of those use cases some of them goes beyond that to look at how your identity is structured so for example um you know we didn't even really touch on like even azure ad because there's a lot of misconfiguration in that outbound process that people can do um you know there's a one that came to my mind is you know you give somebody permissions to be able to list keys right they can escalate privilege easily um with that permission so um yeah so some of them goes beyond like um just the native resource miss configuration to looking at identity misconfiguration so but those are paid for so it depends on if an organization has budget for those so things like again tools like chris mccloud would be good but as it starts azure policy is awesome thank you for that uh david if you share that info with me as well if you come up with the link for um for mike um yeah i'll i can share it with the uh community generally uh lucas do you want to come often uh ask your question uh sure just wondering if we could get a copy of the slide deck so much good info in there uh just to review my own azure environment would be great yeah i'll do that so i'll convert that to pdf and i'll send that over to um bill um so bill i'll put it on github and i'll send you the link perfect thank you so much so i'm just making a note of the action that i need to take so uh do we have any final questions for david before we do the uh raffle okay veronica do you have a scheme for the raffle i don't but i'll come up with something okay um so my idea i was thinking about it a lot um so we i actually have a list of all them attendees um they are in alphabetical order um in teams unfortunately there is no way to remove from at least bill jason myself and david but if for some reason um [Music] you went from that shorter list of organizer um gets selected and um i'll regenerate and random number um so i am gonna share my screen so you know that i'm not just making up numbers here oh and then yeah well veronica's doing that david i know it's um it's past midnight for you i'd like to well you should feel free to go to bed uh and we'll thank you so much this is a really engaging talk i've been working in azure for 11 years or so and um i learned a bunch of stuff so really really uh well put together very thoughtful so appreciate you sharing the knowledge and um uh maybe we can have you back in uh 2022. yeah but i really appreciate that thank you very much for for the invite also and i'll get to the information i i promise i'll get those over to you so yeah thanks very much everyone i'll see you later thanks bye for now thank you david thank you bye yes thanks deal um so yeah i didn't mention what the prize is the the most important part um so the price is actually um a 50 gift card um for an online swag store um it is um for um it is actually from our new hampshire friends uh new hampshire code camp provided the gift card um some things to them um it was a great event i was really happy to participate and see bill there in person okay so let's go back to the main part um currently we have uh 24 people um in um they're participants list so i'm gonna generate a number it is 23. let me see so [Music] it should be a tony tony uh guest i don't know what the last name is um tony can you please um unmute yourself or somehow let me know who you are okay tony okay great so tony is here tony please reach out to me offline um i mean not offline but offline of this meetup um through twitter um through slack if um you are in our slack but if not um our uh my email you can use that too i'm gonna post it in the chat so just i email me your information and i'll forward you the code and thanks everyone for joining us that's um the last event of um 2021 and we are really excited to see you next year i guess be all back to you thank you yeah everybody have a great hol a great holiday uh be safe and like veronica said we'll see you on the other side of new year good night everybody and this uh youtube recording will be up usually tomorrow usually the next day on the on youtube.com boston azure over and out i'm signing off for the night thank you "
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:00:00",
        "seconds": 0,
        "text": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions. This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.. hi everybody out there it doesn't look like we have a real-time chat or anything for this just QA so I'm gonna talk to the camera and assuming you can see me all right well we'll have a little conversation and I'll show you some cool stuff ask your questions along the way I'll switch over to the the Q&A every now and then to answer your questions when when I can actually let me do that yes yeah this bill again I just hid a suggestion if you'd like to take it but we can make other arrangements certainly this is work well on Prime meetings where Jason Veronica and I will monitor both slack and the Q&A in teams and we can you know if you have natural pauses you can pause and say hey are there any questions and we can have them queued up okay that sounds great to me yeah just interrupt me whenever whenever I stop or switch between slides okay fantastic so folks you've heard that so use use slack di te ly you know bitly link /ba slack Boston Azure slack and go there to bitly slash be a slack join us on slack there's a meeting there's a channel with specifically for this meeting or that's the best way or you can put them right into teams and Veronica Jason and I will monitor them and we'll make sure that we bring them to Kevin's attention that appropriate intervals so with that let me just pause for a second and thank you for joining us Kevin it one of the great features of this virtual format as we are lucky enough to be able to invite speakers from a wider geography I know you don't have to come to Cambridge Massachusetts or Burlington Massachusetts to to share your wisdom with us so thank you you're you're you hail from was it Virginia that's right I'm down in the Norfolk Virginia area so only like an 8 hour train ride away from Boston not not that far okay well if you want to make an 8 hour train ride to talk to Boston our next time we would be happy to to host you again hey that sounds great well when we're allowed to go places again well we'll chat fantastic so in further ado III will oh I'll just super briefly introduce you and let you have the stage they're here to listen to you not to me so Kevin Griffin he's author teacher mentor consultant he focuses on software development been in a Microsoft MVP for 10 years he specializes in asp.net web development as a training and services company called swift kick so you know he has a sense of humor and if you see avatar you'll EE no yes humor he's a big smile and on next slide next slide there we go boom oh yeah there we go you sound like a good-natured you look in sound like a good-natured guy so he's uh you know I'll leave it at that other than that they very enticing I have to check this out he co-hosts a popular too frugal dudes podcast I have no idea I'm not gonna ask any questions but without further ado let me turn it over to Kevin Griffin to enlighten us for the next hour and change so over to you Kevin thank you awesome thank you sir I greatly appreciate it and I everyone out there on the Internet's I'm so glad you're here with me today and as always if you have questions drop them in the chat and there's so those are done a good job introducing me but if you want more information always hit me up on Twitter that's the best place to get in contact with me on the fly and I also do a daily twitch stream so twitch comms are actually it's twitch TV and you fix the slide oops but Twitter is the best place to go for all your information and during these times of quarantine I always like to show off my home office and I I have shed quarters this is a picture of my shed quarters I'm inside right now behind that's a window from the left and I love it to death and I do all my work out here and the kids don't bother me my wife doesn't bother me I can get all my work done and if you look closely I have a little sign in the the open window that says no that's how I tell my kids whether or not they can come to sturb me at any point in time so right now it's it's set the nose they know not to come and knock on the door because they will so this is my first time doing this particular talk I'm really excited about it and I'm hoping I can give you some good resources or at least spur your imagination a little bit but afterwards if you want all the resources for everything that we talked about I created a special site just for Boston Asher so if you go to consult with Griff"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:05:03",
        "seconds": 303,
        "text": "good resources or at least spur your imagination a little bit but afterwards if you want all the resources for everything that we talked about I created a special site just for Boston Asher so if you go to consult with Griff slash Boston Azure you'll have all the details there yeah once we have access to a replay I'll post that there as well and any resources that I come up with along the way you can get it all there right now it's pretty empty but we'll fill it up I got the inspiration for this talk a couple months ago I was having a conversation with a friend of mine and he said you want to see something cool I said sure and he gave me a demo of Asher logic apps and my assumption is a lot of you out there might not have tried logic apps or if you've seen a working demo of it you have a general idea but whatever your level of experience with logic apps is I'm hoping I can build on top of that well my friend Joel he did this demo and I have at least 50 uses for that right now and I started diving in specifically into background services or these background tasks that's I believe is the thing that as urologic apps is really good for and over the past two months it's radically changed how some of my applications perform and that's why I want to talk to you about today at least giving you working examples of what I use logic apps for and I'm hoping by giving those real examples to you that you can then go and build your own or at least you have some momentum so let's talk about background services for just a second I'm coming to you as a consultant of web developer app developer and most of my applications kind of work like this at least 95% of them there's some internet basing application and the requests come into it the responses go back but then there are some things that need to happen in the background but we have a whole nother process that is simply for doing background tasks or performing background services and both the web app and these background services talk to the same databases and in Dana stores this is a really simple diagram and it's meant to be like that but what do our background services do and this is kind of the thing that you learn as you mature as a software developer in my opinion you learn that not everything should be done in the web web application because there's no there's a variety of reasons but let's talk about what's type of background services we should have I have background services for sending email any time you want to send an email never send it from your main web application because you're not guaranteed that that email is actually going to get sent there might be failures with SMTP our services might be down your application might go down in between so you need make sure that somebody else is processing those tasks we deal with credit cards so on a regular basis we might need to go charge some of our customers so we're processing payments we don't want that to happen in the web application because well the web occasion might go down and might get a DDoS attack there's a variety of things that can go wrong we have regular clean-up that we need to do so things in the database that don't need to be there anymore I have files on my file systems or up in blob storage that don't need to be there and we want to clean that stuff up and just in general any reoccurring tasks you might have there's not something that you want your main web application to have control over you you want to do this in the background you want something else to take care of that and I'm just scratching the surface but you probably have a variety of background tasks that you can think of your application performing well how do you perform these now well there's probably a couple different ways you might have some sort of cron job or you have a Windows service if you're billing simply Web Apps I have one I love called hang fire and hang fire just drops into any dotnet or Dante core application and can give you background processes and more importantly background process management so something fails it can retry it it can show you what errors occurred and it's amazing it's free open source and it's good there's also background workers built into asp.net core if you've never worked with that before I've actually started moving most of my hangfire tasks to background tasks background workers in asp.net core cuz it's just a little bit closer to the metal a little less than maintaining a little less overhead and it just works but I have a fundamental issue with how some of these are implemented and this is what it looks like these are the graphs I get from Azure specifically for the background services processes that I have running you see I'm running 100% CPU all the time"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:10:09",
        "seconds": 609,
        "text": "some of these are implemented and this is what it looks like these are the graphs I get from Azure specifically for the background services processes that I have running you see I'm running 100% CPU all the time and I actually dealt with this today with hang fire we have hang fire and a small quote I'm using air quotes a small web application we just use the default configuration and deployment well hang fire hang fire it likes his resources and it will dominate your process if you let it and you don't reel it back and you run into this issue at least I've run into this issue two or three times where a hang fire will actually handicap the actual web application and that's a problem and what we did today was we set some tighter restrictions on what it can do how often it can pull for new tasks and we took our 90% CPU utilization down to a reasonable like 10% and our response time for all of our requests went from 900 milliseconds down to 100 milliseconds because they should return quickly and they weren't so yeah the other thing that could have gone wrong is I just write bad code and that's that's really most likely what the issue was I wrote a horrible code and I had to optimize it but more cases than not this is what I run into so my buddy Joel showed me logic apps for the first time and I took the approach of rewriting a bunch of things that I had in hangfire to actually run on top of logic apps and all right well let's just start with a discussion of what our logic apps and last week I was on the dev talk show a couple good guys out of the Philadelphia area do this talk show on YouTube and twitch a mixer and we talked about logic apps at a more conversational point of view and I had to really boil down what logic apps means to someone who's never looked at it before and I said it's like zapier or if this than that for developers and businesspeople and the idea is the more I have written code I have deployed systems I have become more senior more mature in my career I've learned that the less code I write usually the safer the system is the more stable the system is so I really grasped on the logic apps because it's a low no code approach you're basically building workflows for a task and it just works in the same way that zapier or if this then that helps you if you're not familiar with out of this tool you're probably staring at the screen right now saying Kevin I'm I still don't know what's going on though it really boils down to this logic apps I'll start with a trigger and I'm going to show you a logic a but it's just not ugly slides the trigger is you know something that happens it could be a recurrence meaning every day every hour every three seconds whenever this reoccurrence happens well we're gonna kick off our logic app and then after the trigger we have a series of actions so do this and then do that and then do this other thing well if this condition is true do XY and Z if the conditions false do a B and C and each of these actions can go to different will calm connectors for now and you'll see why different connectors and they perform tasks or perform functions and these I'm just scratching the surface as your functions I can make my own HTTP requests I can talk to sequel server I can talk to Azure storage I could talk to Google Drive I can talk to Twitter I can talk to a lot of different things but it's all based off this original trigger and then what it is I'm trying to accomplish the thing I like most about logic apps is that they are consumption based in the same way as your functions or consumption based you only pay for what you use and here's here's an example of a logic app I have on production that runs once a day you can look at the start times they at 3 a.m. then that's 3:00 a.m. Eastern Time so a 3:00 a.m. is will execute and it runs for a 100 or so milliseconds less than a second typically every time except this one time in the 8th it took 4 seconds I'm not sure why well this app that just run to exist cost me a cent you know if we sat down did the consumption map I'm paying a couple cents just for this they exist and do the one thing that I needed to do if we were comparing this"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:15:12",
        "seconds": 912,
        "text": "cost me a cent you know if we sat down did the consumption map I'm paying a couple cents just for this they exist and do the one thing that I needed to do if we were comparing this to the background task that I was originally deploying and it was running on hangfire or in asp.net Corps background workers well I would have to have that task running all the time because I'm not just shutting it down it's part of the web app or sometimes we put our background workers in separate processes well those always have to be running because they're polling and they're looking to see when should I run this task well the test is only running once every 24 hours it's sitting there the other 23 hours and 59 minutes not doing lick has just seen when it's supposed to work again and I'm paying for that because you're paying for the consumption of that app service or that virtual machine or whatnot and I'm like I don't want to spend that money I'd rather spend a cent or two versus the ninety some dollars it cost to have a basic app service up in Microsoft Azure I'm gonna go really deep into logic apps but first I want to show you a very basic demo and get you comfortable with the UI then I want to show you some aspects of the UI that I think are really cool now I want to walk through a couple scenarios and any time along the way if you have questions just toss them at me but let's just turn off slides oh I was going through all the the logon into Azure and the team stuff I logged out of the portal so let me log back into the portal and I created a resource group specifically for you all I'm showing you there's nothing underneath my he said thought I did or I was in the process of it all right I didn't all right well let's go create a resource groups Austin and Azure all right and I have zoom it turned on so we can do some zooming in from a resource group in Astra you just click add any type in logic apps a logic app because you can type in launching apps it doesn't show you the right thing so logic app and from our logic app we just need to give it a name so we'll say I'm gonna call this Twitter two sheets you'll see why in a moment create alright and this only takes a moment unless I just killed as you're trying to get logged into teams alright it works when you create your first logic app it's gonna drop you into the logic apps designer and I love this tool because there's a little YouTube video that tells you more about logic apps but then it starts you off with a couple templates if you've used if this and that or zapier you've you've seen their recipes it's like oh do you want to correlate in order delivery by service bus sessions I don't but you might then you have other multi-step receiving as2 payload and reply with the asynchronous or synchronous mdn to sender all right I don't want to do that but you might want to do that let's scroll down there's a lot of them in here and I really don't pay any attention to those let's start up at the top with common triggers these aren't all the triggers these are just a couple that are mostly used or at least the ones that Microsoft wants to promote because these work the best out of all the logic apps I'm going to start with Twitter when a new tweet is posted all right there our logic app the this is creating what's called a connector and we'll talk more about connectors here in a moment but a connector is like API credentials and those are stored away and they're sharable across multiple logic apps so I've authorized my Twitter account for this resource group once and any logic app I create that I want to use Twitter with will work just fine so I've created my connector and I've established my first trigger so this trigger is when a tweet is posted and you can't really get very specifically with some of your triggers this is just doing search text against the Twitter API and we're going to tell it well let's do a search for my twitter ID when kev Griff will check it every we'll say ten seconds and don't tweet me yet I can set some additional parameters and every connector every action every trigger is a little bit different so you can customize this even more maybe I want this"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "and don't tweet me yet I can set some additional parameters and every connector every action every trigger is a little bit different so you can customize this even more maybe I want this to start on a certain time in a certain time zone I could do that I'm not going to I'm just gonna say 10 seconds so when this trigger occurs I need to do something with it so we'll say next step the next step brings me to a D action selector and I love this dialog you get a couple recommendations and this is just based off my prior usage of as your logic apps you'll see there's some built-in ones I control controls by a simple if-then statement so if this if this is true do something if it's false to something else there's for each box which will come back to actually the one I want to use is here so text analytics which i think is so awesome well come in and say all right well let's let's look at text analytics what actions does text analytics give to us and text analytics is another Azure feature of you never used it before well look at the text sentiment and I don't have a cognitive services account yet but we could do that in easily like two seconds open another tab real fast this only takes moment and I did have another count but it was in another resource group and I deleted every source group earlier where is my Boston Azure there it is so we'll add cognitive services test Austin Azure tests Griffin said our pricing tier this is not going to cost me anything so we'll just create it real quickly family wait wait wait I love his dialogue cuz you just sit here in your way it doesn't even tell you how long it might take might take two seconds might take 10 hours I'll grab the key I don't care if you copy my keys because I'm deleting it afterwards so we'll call this cause Boston as your text and we need to cite URL which is that guy create so that takes my credentials and it stores it away as it what's again what we call a connector so that connector will sit there I can reuse it as much as I want to and now I have reaction I have to fill in some blanks with the action well for the text sentiment there's one called documents and for documents I need to give it a unique ID which let's see-oh logic apps is jumped in and said Kevin here are some parameters some variables that you might want to use and in particular is looking at the trigger and saying here's what we're getting back from the trigger this might be useful to you so these are the properties that when a new tweet is posted we'll return the time it's created the description who's in replied to location that go through the list supports retweets it supports reply tweets you name it down here at the bottom I have the tweet the tweet ID so every unique tweet gets its own ID we'll use that as our document ID because I want to identify this tweet specifically though this is really cool I click on that it adds a little marker in document ID that says well you're pointing to the tweet ID all right well now I need to send some text to analyze well we have original text down here at the bottom I'll select that as well and then language will say English okay so this is creating a list of documents is sent to cognitive services I'll press next what do we want to do when that returns well I want to put it into Google sheets I know weird but we'll insert a row into an existing spreadsheet I already have and notice I have to sign in or create a connection to Google sheets I'll do that very quickly again this is creating another connector given logic apps access to it or specifically I'm giving this connector access to to my application or to my Google Drive that's taken much longer than it supposed to don't scare me Google I"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:25:24",
        "seconds": 1524,
        "text": "given logic apps access to it or specifically I'm giving this connector access to to my application or to my Google Drive that's taken much longer than it supposed to don't scare me Google I was working with the YouTube API earlier today on my twitch stream I might have set some flags and system oops alright come on there you go all right so Google Sheetz is up here he's asking me which file I want to append a row to or insert a road to well remember in a moment ago I had this cool little selector that was showing me things that I got from the when a tweet is posted well depending on the connector that you're using in the action you can get other cool little dialog so here's a picker it shows me my Google Drive I don't care about anything here but I won I have a document in there called tweet checker and I could just type it in it would work but then it's asked me okay what worksheet do I want to add the tweet to well it went pulled that file into memory looked at the columns in that particular document and said I'm sorry it looked at the the worksheet said here's the worksheets are available all if I select a worksheet give it a moment it's going to show me here are the columns available in that worksheet and now I can fill in the blanks so tweet text well the tweet text is simply going to be the tweet text that I have passed into cognitive services tweeted by oh this is going to be a little bit different let's scroll down and there's tweeted by and then score so score is just a column that I created in this Google sheet well here I have detect sentiment but there's no there's no score there's just an ID sometimes you're not going to get the information that you're expecting but there's always a seam or that tells you the other properties that logic gaps is hiding from you so you see here I have a score which is a number between one zero and one will select score and something interesting just happened yep I got it because I access the property from the text sentiment logic apps kicked in and went well the data you're getting back from detects sentiment is technically an array it's a list it's a collection because look here aa-actually so add new item I can send multiple documents to text for text analysts and because I'm sending a collection I'm going to get a collection back I'm going to leave that one because I don't need it so that collection is coming back and I asked it for the score but I'm not telling it which one so logic apps is kicking in and it's created a for each loop for me automatically over the documents collection that it got from cognitive services so when I say score it's you see a little tooltip it's getting the items from the for each it's pulling the score property off of it and that's what's gonna go into the database and you know with that this we actually have enough to to do a basic logic admin do a run so how about this let's save now if you're out there on the internet I know you are send me a tweet say something nice about me on Twitter and while you do that I'm going to head over to Google Drive and open up that particular file there it is oh it's already kicked off it's already kicked off oh these are from earlier and they're mine so it's being a little bit aggressive so I was looking at previous tweets so it's running every 10 seconds and you see I have some room earlier so these are not new tweets they don't count I see do I have any runs anyone seen anything nice about me on Twitter I mean you can no no one's tweeting anything nice about me on Twitter I have to tweet something nice about myself all right here here we go all right I see something from Jason I'm just gonna we have to wait ten seconds I should have and you know just run trigger I can kick it off me and if I don't like oh I got three runs at the same"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:30:29",
        "seconds": 1829,
        "text": "I'm just gonna we have to wait ten seconds I should have and you know just run trigger I can kick it off me and if I don't like oh I got three runs at the same time okay so I have three successes we go over to the tweet up alright Jason I don't see yours yet so maybe hasn't come through all right Andy I see you out there all right close that I don't need any more well you see it's populating new tweets in is getting the sentiment so virtual Boston Azure is live that was a point five out of ten so got up your game or add a 100 point eight eight for that was good though the retweet was better than the original tweet I'm not sure how that works but I can come in here I can refresh again see whoa this works so much better when I did last week all right so we have more triggers that kicked off which means I should have some more tweets all right let's see Andy that was yours uh well it's funny I don't see Jason's in there maybe it's blocking Jason oh well you can see it working so the task is occurring and what's really cool is about all these different runs we can jump into the run details and see exactly what happens and this is one of my favorite parts of logic apps you can walk back through the process will zoom into when a tweet is posted what was the search text we were looking for there's one keV Grif I will see what's the output so the output was tweet text from well Jason all right so one calf Grif is doing a Twitter demo let's send seven tweets and here's all the metadata about that tweet so that data was passed into the text sentiment you see the document that we sent that was the tweet ID we want English analysis and then the text cognitive services reported back a score of 9 point Z or 9 0 or 91 percent basically so good score we took that we iterated over it but it was really just the first element in the list because there was only one element we added that to our Google sheet and here's the information for that but so cool that was an end-to-end demo and everything magically worked so cool I'm just gonna leave that up and let that run so if you want to say more nice things about me on Twitter please do that but let's jump back in the slides for a moment because I want to go a little bit deeper into some of the features that's that I couldn't really talk to you too much about but before I do that are there any questions I don't think we have any questions right now okay no problem well keep going on okay all right very powerpoint always puts the presenter mode on the wrong monitor and i always have to move it there we go okay so the the the big thing that I think is really cool is the expression editor I don't even know if that's the official name for it but that's what I'm going with well you saw me use the demo of I can look at dynamic content in my logic app so any actions that I have or any triggers that I have all that data passes down so I can use data from an action that was three actions ago in an action down at the bottom and I can format this data in any way that I want to of the big thing I really didn't show you let me you know I'll just shoot back over here let's go back into our editor is I can alter these requests any way that I want to instead of just saying tweet text I can append something I could say tweeted and that becomes the new text this is now inserted into that new string the same thing for the score so you notice the score comes in as just a number between zero and one well I can change that with the expression there so if I know it's between zero and one what if I say alright let me do some math so I could do multiplied the score so it's a hat I'm trying to do this off top my head I go away go away this is the easiest way to do it cancel that go back into score scroll"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:35:34",
        "seconds": 2134,
        "text": "do multiplied the score so it's a hat I'm trying to do this off top my head I go away go away this is the easiest way to do it cancel that go back into score scroll down get the score now so you see how this says for each items for each question marks score well if I haven't shown you this this is a custom expression editor there's a built in programming language into logic apps I could tell let's multiply the four so items alexsei for each and kasing doesn't really matter but the name does so it's for each and sorry I'm doing this part on the fly didn't mean to we'll get the score there's the easier way for me to get this name but I'm not showing that to you yeah yeah so items I'll call the for each I'll get the score off of it all right so get that number and then we'll multiply it by 100 and if I did that part correctly I did that part correctly I would lock up the browser the expression is invalid okay I did something wrong oh I forgot a bracket there there we go so now notice how I have a pink fill in the blank here so it's multiplying the score times a hundred so now it should be 100% if I did that correctly I'm assuming I did that correctly I haven't actually tested this but maybe it works say Knight more nice things about me on Twitter and we'll see we'll come back in a couple of minutes I'll check the results nothing yeah nothing so far so we'll give that okay a little bit of time alright so again is going to run every 10 seconds let's jump back in the slides so that's the thing I didn't show you was the expression editor there's a lot of methods pre-built into logic apps that you can use for four different things maybe you need get the current time maybe you need to figure out what the the date is in two weeks well you can do that day time math you can do basic multiplication division addition subtraction you can update strings you can create lists you can convert things to JSON or parse it from JSON into objects there's a lot of power in the expression editor and I really wish I had more time to go through everything but there's a lot in there and I think the real power is that you can combine this expression engine with the dynamic content of the actions and the triggers that you're using and it all just flows together the picture on the left side of the screen is from another project I'm doing on my twitch stream where we're taking RSS feeds from from my podcast and we're running it through a logic app to do some some work on it well I and this is one of the big reasons why I really left onto logic apps in the first place anyone out there who writes code think about the code required to parse parser manipulate and RSS feed I'm not talking just XML an RSS feed that it has a very specific schema to it and it can be a little bit different depending on the the type of RSS that you're reading think about writing that code and now how many attempts would it take you to write that code correctly the first time and for me that's probably a four digit number and I would mess it up over and over and over and over again with logic apps is just can I built-in there's already a pre-built connector I pulling the RSS feed and I can start doing work with that data and to me that is so much more beneficial than trying to get that code written right the hundred and twentieth time it's probably not going to work at that time either I have to keep iterating or I'm forgetting gonna forget something or I'm gonna get to work and then something later I'm going to mess and no one unit tests anything anyway so it's always gonna break but logic apps I don't have to worry about that I just say all right well let's take the data in let's do something with it and I love that the other nice thing about logic apps is we can manage our dependency errors a little bit better I haven't gotten this deep in the demo but if I was talking to external dependencies like sequel server as your functions other HTTP services well those fail in my code they just fail they throw an"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:40:37",
        "seconds": 2437,
        "text": "errors a little bit better I haven't gotten this deep in the demo but if I was talking to external dependencies like sequel server as your functions other HTTP services well those fail in my code they just fail they throw an exception everything breaks if I want any sort of retry logic which is useful to have because if it's an HTTP error it might just be a fluke if you retry again two or three seconds later it could work well you have to build in that retry logic use something like poly and it's you get a little bit of an assistant but you're still responsible for it in logic apps if something fails I can set a retry policy and there's there's one pre built into it it'll try retry up to four times before it just fails altogether and when it fails you see I get the little exclamation mark up in the corner that tells me this step failed and I get the report up on the main screen that says alright this the entire run failed I can dive in and figure out why if I don't like the retry policy that is built into the default I can always change it I can tell it well just retry every 10 seconds or retry exponentially once so that's the the Gmail approach all right you got disconnected from Gmail I'll try again in one second all right however you try again in two seconds I'll retry again in four seconds so on and so on you can just build that into logic apps so I love this approach because when dependencies have errors and dependencies will always have errors that's just a given you can figure out where the error is fix it or have some sort of retry in case let me walk through a couple scenarios and these were actual logic apps I've built for clients I blurred out the information that I have to blur out but let's just talk through the process so this is scenario 1 processing incoming email the first logic app it's not the first ology app I built it's probably the second or third where my clients came to me and said Kevin we have a person that is sending us in an email every day and that email is going to have an Excel spreadsheet attached to it we need you to take the Excel spreadsheet and put that data into our sequel database so we can show it on our site to our customers I'm like cool all right I had just learned this about this thing called logic apps and let's imagine I didn't have logic apps now I have to write a whole bunch of code and worry about a whole bunch of dependencies and odds are that is just not gonna work right the first time we've already covered that I'm a horrible decoder so none of this stuff is gonna work how do we attach detect that all right first I have to write an smtp connector that will access us in this email box every couple hours so it sent every day but not always at the same time every day so let's check every hour this mail box let's pull the email down let's pull out the attachments on that email which there are help our libraries built to do so much of this stuff so it's not like I'm writing all the code but I'm pulling in all the dependencies that we'll go do all these things so let's get that attachment pulled down probably into a memory stream or something and all right let's do OpenOffice on on that excel file if you ever worked with Open Office Excel files it's not for the faint of heart it's and this is a basic spreadsheet so it wouldn't be that bad we have to pull out that data and then we have to go talk to our database which is probably the easiest part of the entire scenario is talking to the database so I I thought about that my alright this will take it'll take a day or two or a good amount of hours and then some testing and then put in a production make sure it doesn't break em but instead of doing that I decided let me try writing this as a logic app and I went into logic apps and I said well is there a connector for Gmail and so I typed in Gmail and a connector came up and said oh here are the triggers available for Gmail and the top one was when a new email arrives yeah well dang that just saved me hours of coding so I filled in the blanks set up the connector to the email address and they're using Google suite so it's not going to at gmail.com it's going to their domain alright let's connect to the email box it's gonna come into inbox the subject is going to say yesterday's top 25 and the important start I don't care about all that but I also care about attachment so if there's an attachment let's pull that in let's just check every 50 minutes because why not sound like it's my"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:45:42",
        "seconds": 2742,
        "text": "top 25 and the important start I don't care about all that but I also care about attachment so if there's an attachment let's pull that in let's just check every 50 minutes because why not sound like it's my code when that email comes in it starts the process so the next thing we need to do is I need to get the email details well when the trigger comes in all it's telling me is that a new email arrived it's not telling me very much about the email so I have to take that emails ID go get the email with its attachments and then that goes to the next step well there's a bunch of values that I use in other aspects of the logic app that I need to account for and these are all basically magic strings so things like the name of the worksheet in in the Excel document what else do I have I have a I think actually thinks the only one I worry about at the moment so instead of me hard coding that where I'm using it I create a variable and just call a table name and this is really useful in K as many variables as you want to you can change variables you can in any way shape or form this is really useful because then you can bind to them like you would any anything else than any other step so I create this variable we move on to is huge for each loop because the attachments is a collection of attachments even though it's only ever going to have one attachment in it at least it should only have one attachment in it I have to iterate through it as a for each and actually it's probably safer for me to do it this way anyway because what if someone accidentally attaches something else maybe an image or whatnot so we go through all these attachments and we check for a condition so you see I have a condition this is if if it conditions true do something if it's false do nothing at all and what we're checking is to see if the attachments file name contains XL s X so isn't an excel file if it is we're going to go through the process of processing it like an Excel spreadsheet this is where I started to get scared because I went into true and say alright well I need to open an Excel spreadsheet and there are office 365 connectors that will talk to Excel online they kinda suck so I found the next best thing there's a series of tools from third-party providers that will basically convert files from one format to another format for you so I took the Excel content that I got told it which table I needed to get data from see I'm using the variable name table name and it's takes the excel file for me pulls out all the content and actually passes it in as JSON so the next step is all is all JSON content underneath the scenes which leads me into another for each loop well this time I'm for eaching over all the rows in that excel file and there's another condition that condition is simply is the is the cell name equal to a one and there's a reason why I'm doing this a 1 in our document is the header row and I don't want to process the header row as though it's real content so if it's a 1 I need to just toss that out go to the next row if it's not I want to start processing it like it's real data in that is actually our false condition and our false condition has two actions inside of it the first one is an azure function I learned this the hard way when we get our excel data back from the convertor they don't convert daytime sin to actual daytime objects even though it's marked as daytime in the excel documents instead of returns it as the base format which is the number of it's like the number of seconds or something from from 19 January 1st 1990 I forgot the technical term for that is which is really weird because very few daytime libraries pull parts from that date it just happens to be an Excel thing well there's nothing in logic app so we'll do that conversion for me at least not easily so I said well what if I could just write some code and I could fix that problem with no issues so I did I used the nazzer logic app this is where the rest of the talk name comes into play I used the logic app to take that day time number this conversion on it and sends it back to me in a actual parsable day time format which I then passed into a sequel server connection where I just want to insert a row into the database and this is"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:50:47",
        "seconds": 3047,
        "text": "day time number this conversion on it and sends it back to me in a actual parsable day time format which I then passed into a sequel server connection where I just want to insert a row into the database and this is where logic apps really starts to shine because I use the connector to connect to our sequel server database totally which database name with the table name and then after I selected the table name it looked at the table and said here are all the columns in that table and they put asterisks neck so all the ones that are not knowable because they're required and I just went through and I filled in blanks all right email subject line is this the email date is that file name is this sales rank event date venue name this is all data I'm pulling out of the excel file and the event date well the event dates not coming out of the excel file it's coming from the Azra function so that this this made my job so easy I knocked out this entire logic app in about 30 minutes give or take it was easily less than an hour and it was he was just fully working even writing the code for the logic the Azure function didn't take that much time and so what would have taken me hours if not days I knocked down about a half an hour and gotten production and just and it works flawlessly I checked on it yesterday and I'd only spent about 30 cents in the month on it because it's not doing very much work and I loved it to death but the real hero here are the connectors I didn't show you the full list but there's hundreds of these things for every service you could probably imagine and once you create a connector or create an authorization to a connector you reuse it for multiple logic apps and that's why I love again is if I'm building another logic app that needs to talk to sequel server I don't have to re-establish my connection the sequel server I just reused the existing connector and if you run into a case where you need to write your own connectors maybe you have internal services that you control you can write those and the website I put up earlier I have a link to the custom connectors documents if you want to look that up but every connector has its own list of triggers and actions and depending on what you're trying to do there's probably an action there for you and they're all tied specifically to your use case so you just film the blinks it goes off and try to do the work and I love having Azure functions as a fallback and I'm not taking credit for the quote there's actually my friend Josh Carlile he did a talk yesterday on Azure functions and he said Azure functions in terms of logic apps is when you sit there and say to yourself this tool is great but if I can only write a line of code it'd be much better and that's what as your functions is is you write very small very concise functions that do one thing but they solve the problem without you trying to hack around the system to make something work and I use Azure functions quite a bit to insert functionality in certain places in my logic apps where stuff just I just can't either figure out how to do it with logic apps or it's just easier to write a line of code so here's the example of the logic app I built for the Azure function I built for converting date time to date you see all I'm doing is taking 1900 and adding days because that's what the date value coming out of the excel file is and that works and I returned that object and everything's good actually I have the one line of code is doing the actual work everything else is just protective code making sure that I'm passing in something legitimate before doing any of the work but worst case scenario I throw an error and if I throw a bad request error that shows up in my logic app as a bad request and it tells me why so if I have an error in the future I can just go see what the error is and then fix it but passing in the data you can pass it in as body data like you would an HTTP request or I just send mine is like a query string so the query string for date value goes into the request and there's a date value key in there I pull the value out do the work right shouldn't pop up during that I think we'll have a couple of questions no questions okay no but you have a question okay oh yeah we have so many options to ask questions so a question from slack okay is there a way to test or simulate a logic app without the need for live data so limits thoughts no not not as I've seen I spent some time with that not too long ago trying to figure out the"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "00:55:55",
        "seconds": 3355,
        "text": "or simulate a logic app without the need for live data so limits thoughts no not not as I've seen I spent some time with that not too long ago trying to figure out the best singer for testing the the way I'm showing it that's not there's no what your testing environment is that you're using connectors that talk to test environments so you're not talking to your production sequel server you're talking to a dev sequel server something like that it's a little bit harder to set up actually through this process I really believe so much of this is geared more towards business users not necessarily developers because developers were saying they're thinking like testability and they are I have to run through this entire test script before pushing this production business users are like well all I have access to is the production database I need to build a simple app that does this this this and that's what they go off and do we do have a little event coming up next week called build where I think there's gonna be some announcements around logic apps I honestly don't know because they don't tell me anything about hazard tools but usually when they announce something big it's that build and I heard on the grapevine that logic apps is gonna get some love I just don't know what that love looks like this is really the this is like the second iteration of logic apps so I think as people use it and they ask questions like that and that is a perfectly reasonable question to ask but the answer is not perfectly reasonable and I think they're working towards fixing that awesome thank you and not a question about other functions yes so what are the triggers they're the triggers for as your functions so when you know I'll just show you an example I'll show you a real example too so this is a app I'm writing on my stream so I'm connecting to some Azure functions but let me let me just pretend I'm going to add a natural function in here Shh as your functions so so I have an as your function as your function app service called podcast YouTube and when I load that the nice thing it does that it will go talk to my as your function app and it will return here in a moment but it should list all the functions I have available in that app if I have things like swagger or open API set up on my extra functions it should pull in all that functionality as well which is super useful so these are the extra actual Azure functions I've created I don't know if they're actually I haven't looked see if there's triggers based off as for functions but it's easy enough where we could just go look real fast tens we're creating a new logic app you validate actually this might not be the best place to it because I let me do it in my other let me do it my other resource group because I actually have a serf unction Zin there I'm just not sure I'm not sure what triggers there are so we'll create it we'll call this test wait for it to validate and create go to resource alright so one of the things I'm going to do is I'm going to ignore the common triggers and just start with a blink app because when you do a blink app it just gives you the connector list in the trigger list so we'll see as you're functions and there are no triggers there just yeah there's just actions so in this case what you might want to do so I guess the use case would be how do you get a as your function to talk to your logic app that's a perfectly reasonable thing to do you can do an HTTP request so you can say when HTTP request is received and I'm actually going to talk about this in a moment in much more detail but this comes in as a web hook so you see HTTP post URL generated when we save you can pass that into your functions and tell your functions execute this this web hook if you need a logic out to kick off this is really useful so if there are any other questions I can just start talking about that scenario"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "01:00:59",
        "seconds": 3659,
        "text": "pass that into your functions and tell your functions execute this this web hook if you need a logic out to kick off this is really useful so if there are any other questions I can just start talking about that scenario right now because I use that in several cases and have have that laid out I don't know how we have I don't think we're have any more questions ok all right well let's jump into the web hooks then and hopefully answer that person's question a little bit deeper all right so scenario two was web hooks which I found extremely useful in our web app we used this course as our forum software so we have a community of people that interact and they post messages into the forums and my clients have particularly use cases around discourse where they want to know when certain certain posts get updated they want to know when certain people post messages and they want to build all this interaction into the forms but if you've never used this course before and that's fine in order to write plug-ins for it or add-ons you're writing Ruby and Ruby is not my first programming language it's not even like five programming languages I can read it if you show it to me but I'm not going to write it very well so I sat down and try to figure out well is there a scenario where I can use their API to do all the work that I wanted to do and turns out I could do most of that work through web hooks that discourse issues whenever someone posts a new message well instead of well actually before I knew about logic apps I wrote all that web hook code and the web hook code is just simple asp.net core I would have a controller it would receive the request and do something with it that's pretty straightforward once I got lots of gaps under my tool belt I decided let me try doing this with logic apps and it actually ended up moving all of our web hooks to logic apps because it just works so much better the first step was creating the HTTP request trigger and gives me this very long post URL that's I can go into discourse and say well whenever a new message is created post to this URL and when I go back into logic apps logic apps is going to ask me for the JSON schema of the requests body which is easy for me to do because this course gives you all the information so there's a low-low button down here at the bottom or a little link that says use sample payload to generate a schema very useful feature because I took an actual request from this course copied it pasted it into this tool it generated my schema for me and I can actually go through and delete parts of the schema I don't use but now everything that comes after this schema is gonna be hard basically hard typed to that json schema so i can use proper names and variable names the way that I would expect to so I'm telling it on a post and I can set some other parameters like headers and whatnot on this but I'm not doing any of that work after the trigger comes in I said a whole bunch of variables because I have a couple things that are going to change and be different depending on what webhook is being called the the biggest reason I use variables is that I copied and pasted this particular logic app and used it in four or five different scenarios that all work identically except for these key variables so I made a variable so I could change them later turns out there's actually a feature built in the logic apps called parameters that would do all this work for me I just didn't know about it or more importantly I was ignorant of the feature and what do we do when we're ignorant of a feature we don't use it so we we find another way this was my other way so we create a bunch of variables we move on have a condition so the webhook comes in I want to check to see if the webhook if the body of the web book matches the type of message I'm looking for and in my case I'm looking for a very specific message because we want to know if people are replying to it so I check to see is it a public message does the slug and the topic ID all match what I'm looking for now if it does I'm gonna go update a database if it doesn't I'm gonna do nothing though it still succeeds it just doesn't do any work so update Row is again talking to a sequel server database telling the table ends the row ID that I'm talking to because row ID because I'm updating a database this is one of the shoes I had was I had to already know the row ID for this particular connector to work which was fine in my case because I"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "01:06:02",
        "seconds": 3962,
        "text": "because row ID because I'm updating a database this is one of the shoes I had was I had to already know the row ID for this particular connector to work which was fine in my case because I knew the road that I was updating and it was never going to change at least there's no reason for it to ever change but I'm updating a value a couple values in that particular table the the way I'd rather do it is I'd rather updated based off of the preference key which I I have magic strings right here this should probably also be a variable as well that's why I'd rather do it I won't want to do it by row ID but in order to do that with logic ops right now I'd have to write as a custom sequel expression which would work but it's a little bit more flaky because I have to write more code and like most things in my career when I have to write code things go wrong so I just followed the rules and everything worked the way that I expected to and then the last part here is another HTTP request where I assure a web hook back to our web service telling our web service that we just updated this information instead of us doing all this web incoming web hook work updating the database all our what all our application is doing now is is making the signal our request to everyone that needs to know that this value is updated so there's still very little effort on our application it's all mostly done in logic apps so I mentioned before I had copied and pasted this between multiple logic apps and the reason I was able to do that is because for you don't have just the signer mode you also have this code view and if I go into an actual logic app Boston Azure let's go into the one we built before Twitter two sheets anyone say anything nice about me no come on folks I love you but you don't love me that's right it's going to edit and you see we have our earth reactions if I go into code view this is the code view for the entire application and this is really nice if I want to change things like names so this is called the text sentiment v2 well I can change that name here if I wanted to but if I do it there I have to also do it everywhere else it's referenced in the me and something this is one of the reasons I don't change the names too often is because this is where stuff can break if you're not careful all right so get sent to me to get sentimental you see if there's a v2 in here there's not so let's save go back to the designer right see I changed the name on it that's the biggest reason I would go into the logic app code view is to change names now the second is you see like right here the text tweet is really let's trigger the body of the let's get the trigger body and pull off the tweet text well if I wanted to make changes to that quickly or if I wanted to copy that value remember earlier I was trying to insert the row with a percentage how much time it took me to try to figure out what exactly I needed the tight because then give me intellisense that I desperately needed I could just go to code view I could scroll down to where's the percentage so it's in here somewhere yeah so right here's score well I could come in here and I could I could type it out faster here then I would in the expression editor another reason why you would want to go into the code view every time you update a logic app it makes basically keeps a version so it has some built in version control can you see every version I've created I could go back to a couple older versions and let's say this version was the good version and I want to go back to it well I can promote that up to what's currently working or I can go vacuum and further and and there's nothing there so we don't want to promote that we want to keep what we have I know some folks are currently working on open source tools to help you actually pull this into DevOps so if you want to have source control on your logic apps and you make changes DevOps can help you push those into production that might actually help answer the previous person's question about testing I don't know anyway the testes locally I just know how to"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "01:11:08",
        "seconds": 4268,
        "text": "control on your logic apps and you make changes DevOps can help you push those into production that might actually help answer the previous person's question about testing I don't know anyway the testes locally I just know how to build them in the portal but I try to keep them as small as possible so they're doing one very concise thing and the smaller the more concise it is the less likely you need comprehensive testing on it at least in my opinion but that is so that's the second big scenario I'll show you the last third scenario that I have then we'll wrap it up with any other questions because I don't think I yeah it's just blob cleanup this was the first logic app I ever built because I have this client they've been running on Azure for years and when we deployed their application it was a fresh fresh rewrite we we take files and we put them in the blob storage and they're fairly small they're somewhere between 30 kilobytes to like a Meg and when I wrote the feature I went you know it's not a big deal blob storage is pretty cheap I don't need to worry about this and at least I won't have to worry about this for a while because it's not going to explode that much well three years later I remembered I set that and I looked at the blob and the blob was approaching three terabytes yeah yeah a lot of data I needed to clean up because I'm storing this much data and my clients paying for it and none of it's necessary really it's it's only there for in case something happens I can go look at the data it got uploaded because we uploaded the blob storage reprocess it and then we should throw the file away but I was just too lazy if there the file away oh okay I need a new procedure for cleaning up blob storage if you've ever used the storage a SDKs for dotnet me they've gone better they're still not as good as I think they could be for a lot of scenarios so I'm like well can I do this in logic apps because I just learned about logic apps and let's build a scenario this literally took me 10 minutes first started with the trigger and trigger I used was a recurrence where every week specifically on Sundays I would run this logic app and you could get very precise you could say Sundays at 3:00 a.m. in the morning whatever you want I tell logic apps to go go to blob storage go into a folder and pull all the blobs from that blob or from that container and we're going to iterate through them and what I want to do is I want to check the last modified date and so it's all getting hidden in in the details but last modified date when that is less than the I do add days and I think that's thirty days ago so I do negative thirty or gonna do negative ninety it really doesn't matter what I look for dates in the past so if it matches my criteria I'm going to delete the blob and everything's great we move on if it's false we don't delete blob so the first time I ran this it took a couple minutes because if there are all these blobs it deleted them but it cleaned up a whole bunch of data and now it's on in iteration so every occurrence every week it goes through and cleans up old blob data and I ended up doing this for a couple other cleanup tasks as well you follow us a similar process but it keeps our blob storage nice and tidy and again this is stuff that I would have written code for but I would also have to maintain the infrastructure to run them because you have to have a place to run your background services and logic apps has just made my life so much easier and that's why I wanted to do this talk for you all exploring logic apps a little bit deeper hopefully I gave you some some good suggestions that you're gonna take back and try to implement if you have any questions at all please feel free to reach out to me on Twitter or go to my website consult with grip calm and talk to me if you need help setting up logic apps you definitely reach out to me I would love to help you with that and you know with that any final questions that we might have out there I don't see the questions bill do you see the questions you I think bill is muted okay yeah I don't see a question so if anyone has a question please post it here I think oh yeah lots of thinking notes for"
    },
    {
        "speaker": "",
        "title": "Kevin Griffin - 21st Century Background Services with Azure Logic Apps and Azure Functions",
        "videoId": "iibGXI2YHRw",
        "description": "This is a recording of the May 13, 2020 virtual meeting21st Century Background Services with Azure Logic Apps and Azure FunctionsHow do you handle \"background tasks\" in your applications? Maybe you build a cronjob or a Windows service to execute some code on a schedule? Maybe you have a background task in your web application?No matter what you're doing, you are probably building infrastructure to support these background tasks. That can be costly, unreliable, and difficult to debug.In this presentation, you will be offered an alternative approach to building background services by taking advantage of Azure Logic Apps and Azure Functions. You see real-world scenarios that were implemented and that are running right now!SPEAKER BIOKevin Griffin is an author, teacher, mentor, and consultant focusing in software development. He is also a 10-time Microsoft MVP, specializing in ASP.NET and web development. As the owner of Swift Kick, a software training and services company, Kevin specializes in helping businesses push their technology stacks into the 21st century. You can often find Kevin speaking at conferences and user groups across the country or blogging at http://kevgriffin.com. In his spare time, Kevin is the co-host of the popular 2 Frugal Dudes podcast.",
        "start": "01:16:12",
        "seconds": 4572,
        "text": "you I think bill is muted okay yeah I don't see a question so if anyone has a question please post it here I think oh yeah lots of thinking notes for you Kevin people are super happy and excited that was a great presentation so yeah if anyone has questions we still have a couple of minutes and we are monitoring that's like and also we're monitoring questions here but I don't see any more questions bill I think bill is back bill any questions for Kevin am i audible yes okay good I have a close the meeting and rejoin it too I get off of mute so Veronica I missed what you're saying you were gathering final questions yeah so I don't see any questions here did you see any questions on slack so let's uh let's say this folks if you have any final questions please toss them into slack in Veronica we'll keep an eye on it and we'll pose them in a minute if there are any while that's happening let me I think we do have a yes you can you can hear me yeah oh it can't Harry I I just noticed a question here so what's the difference between flow and logic apps the GUI looks very similar but flows John's show up in the logic app that's right so my understanding is flow and logic apps are basically siblings of each other I so flow is out of power apps if I recall correctly and I am that is just my understanding I have not personally used flow or power apps so I'm not not the best person to answer that question but what I've read is that they're basically siblings of each other so they're similar workflow engines if you're running custom connectors so if you're writing your own custom connector the connectors actually can be shared between the logic apps or flow and power apps so I think the short answer is they're probably exactly the same thing at least the engines underneath that just depends on yeah what you're trying to use them for [Music] and am I still not able yes okay good so thank you very much Kevin this was great and thank you for joining us virtually all the way from your headquarters in Virginia I'll give folks another minute to post questions and Veronica can pass along if they come through in the meantime I'm gonna very briefly make a couple of quick announcements sure this tonight has been our third virtual Boston Escher event and we have a fourth scheduled for two weeks from tomorrow night we'll be back on our Thursday night cadence that's also at 6 p.m. Thursday May 28th and it features Tim Warner from Tennessee Nashville and he'll be talking about badger blue prints the title the type title of the talk is everyone's in Azure everyone's an azure architect manager of deployments with larger blueprints and two weeks in and by the way in the slack channel it would be great to hear any feedback folks have on the start time of these events we're doing it at 6 o'clock p.m. local time which it was the traditional start of the in-person meetings but we have more flexibility these days we don't know if people are eating dinner at 6 o'clock you know in the coronavirus reality or you know is this a perfectly convenient time or or C or D you know let's share your feedback we love to hear feedback so two weeks from tonight two weeks in tomorrow night rather everyone's an architect managing your deployments without your blueprints and then two weeks after that we have a kind of experimental idea we're going to try out and thinking about it as a code along where the idea is that you show up with your laptop because we all were already all logging with our laptops typically anyway our phone at least that could be a laptop and we have a shared coding experience we'll pick a scenario to lean into and we'll learn some new content well we'll learn some depending on who you are you may learn some new concepts and or maybe learn some concepts you already know in a different way or a little more depth and I've posted into slack a link to another slack channel but in this meeting flashing light posted a link to hashtag code along that's a separate slack channel that describes the idea and a lot more detail and love to get folks to give some feedback on that the draft you know still in the early stages but the draft scenario is around building a using a static website generator to deploy a website on Azure blob storage they have a bility to host a website on that and there are all kinds of ways that we can use the azure tooling to surround that experience from arm templates to the CLI or PowerShell to in all kinds of ways we can enhance it with a portal with dashboards with monitoring with the azure DNS service with Traffic Manager the CDN there's so many so many directions that could be taken in and of course we can't do as your DevOps to regenerate and deploy the site for example all kinds of stuff so we can obviously do it all in one you know small block of time so be great to have a conversation to try to sort that out and see if people are interested in that and if you'd participate so with that I'll go back to you Veronica and see if there are any final questions I don't see any more questions but if anyone has any questions later feel free to reach given on Twitter or post on slack and we'll pass them to him excellent great idea Veronica and one final thank you so this to our speaker visit us uh and thank you to behind the scenes for Veronica and Jason and the three of us I'm bill wilder three of us primarily run the the set of Boston as your user groups and again thank you to our great speaker Kevin Griffin very nice job I look forward to having you back in the future and maybe after an eight hour train ride yeah definitely I'm looking forward to it thank you everyone so much for coming down tonight thanks everybody have a good evening you "
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Udai Ramachandran: Infrastructure as Code using ARM Template. This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.. here in tennessee oh okay i'm sure we see it in boston too um i'm edible okay sometimes the teams have problems so i want to make sure all right good thanks thanks bill thanks for having me uh thanks for the people who coming tonight to listen to this topic i will make sure your time's worth spent and thanks andrew for joining from uk um i'll make sure that you have valuable information a to z of um on template zero to hunter i gone through it i worked a lot um you know a month ago for some projects then i thought that through so uh speak is a great idea all right uh about me a little bit i think bill already said you know enough about me um i work for a company called uh accumina as a cto i've been in this field the cloud expert area in the azure aws and google for a long time i also run the user group new hampshire cloud and here is my personal website um so i have an extra topic linked here as a front door service and it's also a great topic you know second a practical experience we've gone through a large scale software as a service implementation across multiple regions you know we have some lots of practical hands-on experience i put through a talk which is coming on next week visit and you know i would like to have you all here too sometime next week um i the talk that today i'm talking is already in my own user group i'm going to chat this url all the presentation samples tech you can find it from there is the chat window from here and we'll also have another details to bill and jason all right with that let me begin the topic so today we're going to talk about the arm template as i said it's a to zero to hunter any any technique they they applied the technology solutions they provide to the market we're going to discover from 0 to 100 um you know so we're going to dive into what is infrastructure as a code and sometimes it's also called the platform as a code if you don't use infrastructure because we have a confused definition iis and armed template structures and how to create a basic linked nested templates how we can execute from the power cell rna cli um you know some people love to execute from the ca cd by using the service principle because you know a lot of big enterprise big companies they don't allow developers to easily access into their azure cloud so they delegate the service principles to execute those people's they prefer to go through a ca cds um ca cd also can apply to gitax and how we can execute those templates using the gita actions um then we will talk you know how we can build a ui around it you know why do we need a ui how we can use a service catalog this kind of marketplace for the corporate service catalog is nothing but a private marketplace for a corporate and how you can take that same exact thing then you build for the corporate put them in the public marketplace where you can marketize it and you can incentivize to get more money you know how you can do all those stuff so bring all those things just take one template in many variable form of using it and marketing it microsoft also has a concept called template spec as blueprints they both are slightly different um but they complement each other we will dive into it what is the template spec what is the blue springs and they have they have a way to execute the script some enterprise you will have to execute a lot of power cell or cli script so you can do 0 to 100 in your applications without manually manipulating any steps so these are the entire areas in my opinion that i am on dust right so we'll dive into it everything i was simple demo and i have some materials that you can deep dive into um we'll see as we progress so infrastructure is a code it's a very simple form you should be able to repeat that if you take any enterprise smart companies they're not worrying about it they go create it but if you take enterprise they want they need everything to be repeatable manner if you do more than once i worked with a lot of enterprises but if they do more than once they definitely need a repeatable way to do that um so that's why the infrastructure is a code in the form of json you take a json template either use a power cell or cli tools or rest api or use any programming language that's going to call again arrested api they all need the pal payload in the in the form of json so it's nothing but that's why we call arm template is your infrastructure as a code so it's composed with the three units one is the code other one is the template and configuration what do you want to do and then the policies so what type of policy it can be a compliance security or symbol naming conventions that you want to apply it and you put them on a source control in a typical way you want to repeat"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "want to do and then the policies so what type of policy it can be a compliance security or symbol naming conventions that you want to apply it and you put them on a source control in a typical way you want to repeat in your day-to-day life and then use the markers trader this orchestrator can be a simple power cell or the ci cd or whatever you call it as or a template spec or the blueprint on the service you you make that a mass orchestrator and then you deploy the infrastructure for your required application this can be a simple web app just a web app and storage to enterprise multi-node scaled across the world can be anything but those can be composed a simple form of arm template that's all we're going to talk today so here are some tools um as a resource manager is what we're going to talk today and there are additional tools terraform aws cloud formation um um you know ansible talker tucker might not be the iac but you know if you look at it take the concept what runs on my mission i won't run it on the other machines the talker is the best example but i'm not sure that giving us an example i'm not sure how it's infrastructure as a service um google cloud deployment manager for the google cloud jeff and puppet if you want to run it some um you know change state configurations you can use those tools so to begin the arm template here is the basic structures you need a schema valid schema so once you create a new arm template that's the schemas when we come in and you need a version that's never changed for a long time one zero zero zero and then it has the another five types parameters um functions variables resources and outputs the parameter you you in just like how you write any programming language functions or routines you know you just take a parameter same excite format it comes to the default parameter or you pass in the parameters um functions it you know when you say functions it's not like how we write a compile the routines like functions you do you know thousand things uh but here the functions are simple manipulation purpose you can't even query certain things or what i will give you things where the functions won't work correctly but if you if you use some string functions you can use that the parameter can be any primitive type like a string integer time or a composite type like array an object you can define a variables if newer in your arm template you're repeatedly using certain things you can define a variables and then have them stored in the variable refer them um resources where you're going to define what resource you're going to provision part of your templates it can be anywhere from a simple resource storage account to anything that as it provides that hundreds of resources you can go through it you define all the resources some resources can have insider resources for example keyword is a resource as a main resource but creating the secret creating the key creating the certificates they are sub resource so a resource can be a resource but once they have the proper tool you know you will never miss a syntax you know they give a lot of shortcuts as you type in it it emits all the syntax and required parameters easy to complete and then the outputs if you you know for example you create a storage account you want to get the output string so you don't have to log into the portal right for example in enterprise they don't allow developers to get directly into the azure portal but they can create their own account but they want to see the storage connection string so that they can connect to it provided they are not putting them in the keywords some reasons or in this case if they put them in a keyword they want to displace the keyword to uri so they can use it in their application so that's output those kind of things that you can output but anything you can output but mainly it makes sense to output those kind of parameters um here is a little difference how the basic linked and nested template works uh before i get into let me open a simple demo i'm going to go back as i said i have all the the demo that i'm going to use all the code is over here i'm going to use all the files from here i already downloaded it let me open it so very good okay so let's open uh this one over here here's the template so if you have the tool i'm using the vs code it's a pretty sleek tool um if you look at the add-ins as a resource manager right so microsoft so once you install this store it gives you all the syntax that you want you don't need to remember any of those index so once you are in the in the thing you know you just keep typing for example you want to type a resource just type arm and bring it in for that close that one so you select you know for example i want to app instead of type then it leaves all the syntax that you want and"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:10:05",
        "seconds": 605,
        "text": "you want to type a resource just type arm and bring it in for that close that one so you select you know for example i want to app instead of type then it leaves all the syntax that you want and then you go ahead and then modify the values that you want to modify it okay i'm going to do that and similarly um you know for parameters you know everything they have the shortcut defined so you say like a parameter name it gives you that all the syntax so you don't need to remember anything just have that add an install good to go and similarly that gives for variables functions and all those things so here is the simple arm template all i'm doing here is the i'm creating um creating a simple storage account right so it has the parameters parameter needed locations the best practice for locations if you don't pass it in the default value must be this i'm saying must because you know as we go through we're going to show some demo how you can um submit for marketplace and all those things those validations need these to be a default value so they have some inputs to best practices so that's why i'm saying that default value should be location if you want to keep a default value empty then don't use this default value this will fail so to summarize the syntax the case of parameters you can add as many parameters you want you know it supports any primitive types um array or object a primitive type includes the string integer you know date time and so on the resources and then now you define the resources the resources come as a type you need to know the type and then you need to know the api versions right so how do you know that what type you have to see what api version so one way you know you can google around the other way if you go back to um resource explorer and then you go to the providers i'll call everybody no storage account i'm sure everybody knows storage accounts it's okay storage accounts see so this is the type like delete account so in this case in our samples we have the storage account so if we go back and look at it so it says the supporter location so these are the locations supported api versions what's the default version they're setting it so you can look at it so before you compose a resource you can come back and refer it over here so you can use any resource that defined over here as part of the provider can be used within the armed templates rights and so on you define um you know whatever the encryption mode if you don't know the syntax just type the amp storage it's going to emit that and then you provide the values and then the output um i you know once this is created it's going to execute the output syntax and then you know there is some way to read it list keys api and for the resource id um and then get this and these things you can pretty easily google around and if you don't find in the microsoft site you can find out all those things how to get this output output of any connection string of readings or storage and also a lot of services creating together but any service you create you need a certain things to be output or you can pretty much read anything but some single single line read like this some are multi-line rates you have to make multiple cards right so let's get back to the slide that's a simple syntax um this is i call it as a simple form like a basic form no nested nothing so let's go back to look at the other types so if you look at that's a basic type right so you have a simple file arm template no parameter file nothing so in the same file you had a parameter you had a variable if you have a function you can define it and then the resources and then the output but now how it works with the linkedin uh linked sorry linked under nested templates so here is the basic templates it has everything inside but if you look at on the right hand side which is the linked template right so what i'm doing is i'm copying this content of the resource and movement a new file called storage.json and then i'm referring it so my uri so in the template link i'm providing the uri this url is going to be wherever the template is running as a root path plus artifacts storage.json because when i store it i create a folder called artifacts and then underneath i create a file called storage.css so that's how i'm structured my file so i'm i'm giving it that way it is the main template url it's going to return the main template url minus the file name and then add these paths and it's going to get that one and now you need to pass in the parameters so if you have a simple requirement basic template is the way to go right so you have one"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:15:07",
        "seconds": 907,
        "text": "the main template url minus the file name and then add these paths and it's going to get that one and now you need to pass in the parameters so if you have a simple requirement basic template is the way to go right so you have one or two resources okay that makes sense but if you have more than one resource um the basic templates will be pretty confusing you know i know you have the editors it can help you to format and read and traverse pretty efficiently but still it will be confusing to maintain it it makes sense to create a multiple templates right so you create a storage for example you create an acid search then you can search.json already cache or cosmos db whatever you call it as and you have it separate templates and from the main template which is the orchestrator of the template and you pass in the parameters you collect all the parameters from the main template and you pass in those parameters to the reference to templates they're called linked templates the nested templates again your nested template the temp linked templates can link to another template for example you have you know provisioned the websites right the websites might include you know separate several components like a website storage um app insight and then you may have another nested template you know to do a diagnostic settings or um log analytics or whatever you want to configure it but you can refer them so again the nested template refers to another template and that the linked template refers to another template that will become a nested template so so these two levels is more than enough so it's a basic template it's a high level or a high level template and if you need more and then you can put them in a separate file and refer them as the linked templates and then you pass in the parameters and then you can read the outputs by using the template name so in this case the name is equal to storage so instead of reading the variable of x you will be seeing the storage of explicit in the demo right so here is this syntax how you can execute using the power cell similar syntax applied to um cli if you use it for this talk i'm going to use a person um you know you connect it and then you if you have a multiple of subscription you have to set the context um you know in my case i have like a hundred sub subscription it will randomly switch to one of the subscriptions so i have to be very careful and select one for the demo purpose um the here is the you know command that you're going to use new age resource group deployment and then you provide the name and deployment name resource group name and then the template file right and then the parameters so if you have a template uses a three parameter you can say parameter name whatever the name in this case storage account are the location are the x or y whatever the parameter and then the value right so and so on that's one way of executing it the other way of executing the template is to define the template file and then define the parameter file as a separate parameter file so somebody dynamically manipulate the parameters are then they can feed in that as a parameter file so they will never change the template file but they will change the parameter file for example um your dev infrastructure residency stage versus the production so they're going to change the parameter file for the dell for the pro stage and then the prod but the template itself is not changed in that case you can use the parameter file but again they can we can override those parameters by using the parameter name if you want to um the you know this is the file this helps you if you run it in the local and you have the you know c drive reference kind of things and this is the url if you run it from the cloud it's always a relative path so you have the nested file structure then you store them into plop storage or the git or wherever your your destination is where you can reach to a publicly um if you put them in a private url you will have to give them a sas token shared access signature token url then they can download and do it but the path has to be related to your main template then only it can traverse properly right and then the template parameter ui wherever the parameter ui so one thing to identify or note if you put them in a git make sure your template is following a utf-8 format by default the githi uses the utf-16 format i was waiting couple of hours to identify a problem um if you put on anywhere else utf-16 format is okay but the git sorry utf-8 is is everywhere supported but by default git assumes a utf-16 so you make sure you save your template as a utf-8 if you store utf-16 as a git when you read it it will not read correctly you will get a error just things to note that i gone through i wasted a few hours all right let's see some demo here um so i have some power again the same location you can see it you know i'm going to run i already logged in i guess so i'm going to run these two commands to make sure i'm in the right context here right um i don't need to create any resource group i already created one empty resource refresh so i have it um i'm going to run this one so i take this file path i'm going to give that as a"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:20:10",
        "seconds": 1210,
        "text": "here right um i don't need to create any resource group i already created one empty resource refresh so i have it um i'm going to run this one so i take this file path i'm going to give that as a deploy all in one right so that takes a parameter storage account right and then i'm going to say i keep it unique so we don't need to face this problem fixing it all day fast and zero one then i don't have a second parameter and all the other parameters are i defaulted so if i look at the template over here i'm looking for three parameters resource group i set user is is the resource location storage account you know this is the wrong practice you shouldn't you should not add if it's empty value you should not leave that that's a wrong practice this should look like this here it's the right practice because you providing the default value okay i don't need to worry about it because i'm it's a very simple demo so i don't need to worry a lot of things so i'm putting hardcoding the default value and here i don't have any default value i need to pass it in but here i have a default value so i'm going to save this one i'm running from the local um i copy this syntax you know from i'm running from the same path so i don't need to worry about it i just that it knows the path reference if i am in a subfolder then i need to provide the proper pathing reference okay it shouldn't take a long time um let me see what i have in the next all right so what should be done by now we can look at it over here so one is deploying no idea where storage are going to takes this long ed succeeder so you can look at it so if you look at the so anytime you deploy it it will tell you what is going on over here you click on it and you will have that deployment name that you chose and you can look at the input parameters what you passed in and then the output parameters what is coming in the best practice not to emit like this as output parameter in your script and if you some reason you want to package that as a marketplace they will not approve it you will never be able to emit the sensitivity information like this the closest you can name it is a keyword url some sort of um like client seek ids or secrets that's the closest they will let you do it um you can emit a reduced connection string you can't emit a cosmos tv connection string you can emit a sequel connections any connection setting is not allowed to emit an s output parameter that's a security violation even though you're going to run within your your account and whoever has to access the other one going to see it even though you can reset that connection string but still they don't um approve that action so they will reject it until you remove the type of um output variables things to note here all right so we got it we executed simple templates let's move through it and then i'll come out to come back to more topics over here okay that's a one way you know you have a power cell cli you can run it and then the other way that you can run is the uh ci cd pipelines right so if you want to use the ci cd pipelines i'm going to go back to my other machine bring some url any questions so far okay everybody's there yes okay i just want one more point in the powershell script we have one important feature called depends on it's then one of the property in that template yeah it is the ice i stacked on the other demos i'll come back to it yeah um so i'm not ex i didn't dive into all the concept i say progress i will come into that thank you for that and now let's go and how we can use the same thing on the dev apps right so i go back and then bring this window all right so how to execute that in the in the ci cd pipelines there are multiple ways some custom some enterprise might prefer to certify that cicd pipeline meaning that instead of running you know giving you as a simple file reference and you calling it passing in as a parameter um some enterprise will certify that as a add-in and then they can go drag and drop you know so if you uh i mean let me tell you what i mean so if you go back you click click releases right and then you create a new release uh new pipe release pipeline right so and then the uh i'm just going to empty job i have nothing else to add so i click some job over here and you home template add so you see that"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:25:16",
        "seconds": 1516,
        "text": "and then the uh i'm just going to empty job i have nothing else to add so i click some job over here and you home template add so you see that right so when you click add it see that you can certify your template as add-ins then it will appear over here for example um user group storage creation user group web app user group reduce cache so you cannot you know once you certify that it will appear over here some customers prefer that with some enterprises large enterprises they want to well control it who using that then you need to certify those those you know json templates uh once you certified they can drag and drop just like how we did for azure templates over here okay so now i i have it resource group you know you need to have a managed connections in this case i have some pre-populated connections um if you want to create a new connection you click on the manage you know to let you log in and then choose complete that login process all it does is it creates the service principle so you can securely communicate within your credentials and then subscriptions um it's again it's attached to whatever the name you give it um create or update resource group you can do that if not it will create otherwise solids that update on the action um whatever the name you want to choose in this case you're going to use the one that we chose rg would have person and then the location it brings the drop down by default again if you have a certified product you can bring anything so you can compose all these unit as a certified unit um you can call it as a name you want it appears in this portal all right favorite of you yours used to do in this case linked artifact are the url of the file linked artifact is the one you do it part of your devops process you do a build process it drops the builder you take that file location and you have the template part of the file locations structure and then you reference them then you use a link to artifact i don't have the builder set up so i'm going to use the url of the file so before i do url up the file i'm going to upload few things here um so let me go back to this one here is a storage that we created demo i'm going to upload few files here see demo so i'm gonna upload um right now these three i'll tell you what i'm going to do with that um let me upload yeah let's upload those three now upload right so he also upload i would have done that before so artifacts and go to a folder called artifact all right great so now i'm for now i'm going to choose these as a deploy.json for example over here um let me go back to my pipeline um just take the link close copy link create copied put over here and then go back to the same portal parameters file um url close click share access signature create copy put it over here right so what i have here is the two files as you deploy and as you deploy parameters.json so if i look at my those two files so this is all in one right i had everything and now i am going to split it slightly different so i have as it applied.json which has some parameter i defined over here and then uh i have the storage account in a storage second skew but i have more parameters over here but i split it i split it as a as it deploy and as it apply parameter.jsons but if i look at the resources here um i have a multiple resources i have a type i have apa version and then i use the link to template and that link to template ic artifact"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "split it as a as it deploy and as it apply parameter.jsons but if i look at the resources here um i have a multiple resources i have a type i have apa version and then i use the link to template and that link to template ic artifact is going to be storage.json so when you run that you use that one and i'm passing in the parameters that's required for it and then the uh you know i have another um resource which is app insight right and then i have um another resource called the deployments which is using the web app.json so i'm now creating the web apps but in that i have something called depends on i don't want to create a web app until my storage and app insight is created the reason may be and i may be adding some some you know enabling the app inside so i want to enable the app inside part of the web app but perhaps it needs to be created before that that's why i use the depends on syntax so if you have multiple templates in this case if you look at it artifact so we have the artifact of app insight keyword storage and web apps in this demo so we create the storage we create the app inside and then um storage and app insight now we create the web app by calling the web app.json but we say that you know wait until these two templates are created that's a different sound right once it's depends on once those created then it's going to execute this template and then you pass in the parameters in this parameter if you look at it we use the reference variable so reference of app inside app inside is this template which is the reference name coming from here whatever the name your reference to over here so use that name reference app insight and then tell me the output of webapp instrumentation key dot value so if you go back to appian say dot json um i have the output variable called web app you know instrumentation key web app inside connection string but that connection string again formatted the value like this right so you go through a component called uh inside slash components and then apply the name that's a service and then look for the variable of api version then read the instrumentation key so that's how you read the instrumentation key and this is how you read the connection string right so that is referenced over here so if you look back this template so we say that okay reference app inside wherever that reference is it's going to go back to here okay here is my app inside so that executed that's ready because it marked us deep and run that's ready go back there and then read those outputs and then output of that key and then the corresponding value that json json properties right so if you look back the app inside.json that's all it did so it come back it passed in those parameters it's created it okay it outputted that value um you know and then it's going to read it and if you continue now we create the key vault as a last one now you can't figure the app storage app inside the web app um you know because web app needs a app insight in order to enable that um you know application in setting inside nature um now we're creating the keyword when you clear a keyword you wait for all those three components to be created so it's going to execute it as a last then it's going to take some object id now the reason that this demo what it's doing is we are enabling the identity of the web app and then we are adding that identity into a keyword access so that you can set this keyword to uh web apps when you know they are working it so you hide your connection string into a keyword but now you need to give a web app access to a keyword so that's the line it does right so it goes and takes that keyword object id and then you know it sets the connection string um and then you know sets the value value of the web app object id into objectivity granted permissions and it takes the uh whatever the uh whatever the permissions that need it you will look at in the keyword so before i get into keyword let's go to the web app so in the web app we have some parameters location web name web skew but here i'm not saying anything because this is not the master template my master template is as it deployed.json from there these are called as linked templates right so i'm also talking about the package uri i want to give the you know i want to deploy my web app packages over there part of this deployment and then i have the resources i got i go through it i create the web server forms i you know i said all these things application inside that's why we want to create the insight first before we create the web app and then here i want to create you know if if the package url is created so you can also execute that resource as part of the conditions right if this condition met then you create this resource whatever the action is given perform it otherwise just skip it in this case if the package uri is a valid uri then you go ahead and deploy it this is called the ms deploy as a extension model then it applies it's a it's equal to a ziptiply that we do in the azerbait um right and then it takes the package url and it downloads the package and then complete the zip deploy at the end you got everything that you need okay uh then we are outputting a variable called output in that output we enable the identity dot"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:35:23",
        "seconds": 2123,
        "text": "um right and then it takes the package url and it downloads the package and then complete the zip deploy at the end you got everything that you need okay uh then we are outputting a variable called output in that output we enable the identity dot principle id so we enable the identity and i don't have to tip into how to create a web app this is the arm template session but you got the concept we enable the system identity because of that it will enable identity and then we'll have all these values set okay principal id so that it returns the two names website host name just like how you get it from the azure web portal um and then the object id which is identity of the id now when we get back to the key vault right uh you know we have the variables we do that you know we go through it we define the permissions here so we want to set a key permission to be getting list secret permission to be cut and list nothing more than that so once the web app is created identity turned on for that identity enable access of key permissions in the secret permissions for getting this that's all we're trying to trying to do over here i would go through it and then it emits that you killed url this is o this is okay to display the portal because you know somebody knows this url they're really not going to get it until somebody grants them the access of their identity which nobody does that anyway but in this case web app web app only knows they uses the service principle local host mechanism to connect to a keyword and runtime start event and then they take the value put them in the environment variable but that's okay it's safe to share this value you can't do anything we can talk about it you got the value but nothing you can do with it and somebody go ahead and create a new version of it anyway so that's how it works so you know um from the main template we called everything it created and then it outputs that value okay uh let me go back to my template secret value it refers to templates and complete set and finally it outputs this value um i'm going to hold this demo for later but let me run a simple term of rci cd so i'm going to go back to my storage account let me pull this value alone um let's start access signature create copy all right so i'm going to empty this value i'm going to put it over here um you can run the same way but i'm holding that purposefully for another demo uh so i can save some time i see it's already seven o'clock um now over it parameters value so if you look at the command line now how we pass the parameter we override the parameter by two more right one you can pass in the template file or you can override by the name so in this case we we set this right so you can do the same exact things over here so i'm going to copy that value i go back to my cacd right and then i can put it over here so that's how you override the value either you can do it that way or you can use a little little overhead parameter builder so it loads this window as soon as it loads what is going on okay it's sometimes crazy um click on it it says storage accounts you know you know whatever the value so i'm going to change to 2 for now and then if you want to add a more parameter keep adding it okay cut it i'll change the order too now deployment mode is going to be incremental or complete or validation only validation that validates and gives whatever outcome for example the service name available or not and so on and complete it's going to try to start over if there is a service they exist it may throw the error incremental if the service already deployed part of the previous deployment is going to skip it and move on to the next next step in the deployments you know the com conflict happen on the name existing we created by this particular deployment is going to skip it and move on um you you do have to give us some deployment names so i'm going to say chcd type one uh deployment outputs you can read those variables i said you know from the powershell and if you want to output anything and then control parameters condition control options output variables and then click save i'm going to delete it so it doesn't matter where i'm putting it in so i saved it now i'm going to say create release you know it's a simple demo so i don't need to worry about it i say at least one it's running it's cute you look at the logs it should be done fast enough but you get the concept so that's how we run from the ci cd yeah we will come back we don't need to wait here to be allowed to see this in this document um right so what we discussed so far uh we talked about the basic template we talked about the nested template you know we've gone through how you can nest and depends on how you can read the outputs uh how you can pass the parameter from one template to other template uh how we can call from the local file how we can call from the cacd and so on right now let's"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:40:26",
        "seconds": 2426,
        "text": "how you can read the outputs uh how you can pass the parameter from one template to other template uh how we can call from the local file how we can call from the cacd and so on right now let's move on to the next one git action okay so now we exceed the ca cd on the dev apps you know you can perform the same exact things on the gita accents again and every tick i gone through i provide you a link where you can get exact details of what i'm talking about over here okay so in this case you go here you find all the commands you go here you find all the commands in this case git action so you go here um you look at it this has all the details that you want to um the git action there is that you know you will have to create a service principle again um um it has some you know not a simple c client id and client secret also needs the 100 id subscription id because it is running outside of your your login infrastructure so you are it's not using your login account so you need to plan for the service account you know there's a command you can run the service account it's going to emit the output like this once the output is created then you create a name i mean they're predefined as you credentials as resource group as subscriptions but you can pretty much use any name you want to and you need to store them into a the portal and then use it let me quickly walk you through okay so once you're logged in you need to log in for this one and then go to settings store the sensity informations you go back to the secrets um right i already created something so i mean if you click on if you want to update it's not going to display the stored currencies will never display now in the git portal which is a good thing you know um if you have a new one you can update it but you will never be able to see what is stored um a resource group and then the azure subscriptions right um you can create a new one but let's not create a new one let's go ahead and use that one directly here so you i stored these three values already and then the all you have to do go to actions and then you create a new workflow and then you know when the new workflow comes in so all the steps are explained over here how you can do this in again in a devops aml file right um you use the same exact ml file over here i create a new one so i click on over here and then you know and then run it so go back to my uh go back to my uh file skill once again here tick tock and workflow so i go back over here here's my ammo file you know but if i go and then edit it it gives you this option to commit as a commit it's going to launch this command and run it so i'm going to say something like the scroll bar scroll bar i'm going to call this as a demo05 it's going to get in a different resource group because the credentials are created against a different resource group so it's going to create a different resource group and then all i'm asking is create a store account called um um sdudai demo05 and then use it all all in one json template created right and i click on the commit i don't need to put anything it's just a demo um i committed it uh don't worry about that walking through now if i go back to my actions it's working on it so you know it's cute once it's done it's going to create a new story okay so let's go back to the portal where we were right oh scroll so this one this again the second one we create a part of the ci cd and then this one it will create uh when it comes back i believe demo zero four or zero five we call it as it will come back and once it's done it will create whatever the value product means again again i am a file you just are triggering it on change so the pipeline triggers thing executes that command so that's a gift actions all right let's get back um so now we know how to execute csd devops easily get the accents now let's get a little bit more details into how you can um you know for this demo i'm going to use those nested templates so how you can create a uis to collect a set of parameters right and then and then you know how you can host it as an internal marketplace so in order to do that we have to have some ui definition markup standard followed so if you go back to over here we"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:45:30",
        "seconds": 2730,
        "text": "collect a set of parameters right and then and then you know how you can host it as an internal marketplace so in order to do that we have to have some ui definition markup standard followed so if you go back to over here we had a you know all in one template then we had a tip light apply as the parameters you know you don't need to have another parameter file but it's a nice that's the recommended way parameter files now the new thing now we talking is the create ui definitions you only need to create a ui definitions if you are going to have an internal marketplace or you are going to have a public marketplace in both cases you need to have the create ui definitions um if you have no intention to use the internal marketplace or a public marketplace you don't need to create this file at all okay and once you have a create ui definition that also follows the different syntax instead of as you deploy the name must be main template.json i mean this is nothing but a copy of the azure deploy there's nothing newer than um you know copy of the ac deploy but the name has to be a main template and that's the naming they're looking for when you when you when you when you apply for a certification they look for to you the file called main template yes do you have a file called create ui definition yes then they will go for another validations um so before we dive into all those things let's see how we can create a ui definitions uh let's go back to the slide and then the ui definition you can always go here and look at it how the ui definition works so i'm going to open a new tab and then click on the create ui definitions it gives me a markup right so here is the inbuilt controls that you can look at it for example you want to build a storage account selector you just have to track this one over there then then and as you walk through the ui it will draw the storage account selector um you know so if if you need to know what's what uh con json format it look like just to open it up you know it tells you you just drop these snippets on your on your um ui wizard or ui json file and it's going to drop this ui for you to select it right so that's how it works so in our demo here i have a very simple case um ctrl a i select it i go back to my ui designer you know i say control you delete everything and then paste it and then i can preview the cool things about it you can preview how it's going to look on the web portal um either in a private or public marketplace right okay so i have the resource group i have the region i have the web app name i have the web app sku i have the package url and all these parameters are defined okay i call create next okay i got my validation failed and then i look excuse me i look for view payload outputs i'm not going to get it because it's a validation failed right so i have to go back and then fix this value in this case i'm not going to give anything so a demo reason so um that there is no validation over there but in the real package we need a validation so i will keep it empty um just put some random values okay now i review it okay the validation pass now you want to know how these values are collected and passed back to the main template right um that's the view payload now it will tell you okay so these are all the parameter i'm going to pass into your main template so now with that let's go and look at it so create ui definitions the default one is the basics so if you go to a marketplace here um portal.nc.com how you create a resource you can create anything you want you know say for example um windows 2016 server right um so this has the basics that's exactly the basics this okay you can compose anything that want to be in the basic blade and then if you look at it it has the disk this is you know another tab networking is another tab management is another tab right that's you compose it over here um you know it's a basic blade i have the web name that's queue um so here is some allowed values right so i have i predefined some a load values uh microsoft has a two statements one you cannot predefine this kind of um this kind of things on the computers for example virtual machines they won't let you pre-define it because they have they have a control um to to call in a virtual template so if you go back to my videos previous previous okay let's go back to this one so you got it i'm going to cancel it now you can you cannot deploy it from this visa it just your validates your markup it's a valid how it's going to look up you have a crazy regular expression so i may be having not to regular expression here see i i mean some regular expression over here um i have the storage account and then the storage account now i call it as a text box here i will show you another place where i call the control text box here so it's not going to draw their"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:50:33",
        "seconds": 3033,
        "text": "see i i mean some regular expression over here um i have the storage account and then the storage account now i call it as a text box here i will show you another place where i call the control text box here so it's not going to draw their control it's going to give me a simple text box and then i say the validation it should be a lowercase um 60 characters right and so on um in in here they have the vm compute uh if you look at it uh uh credenza compo um virtual network compost so they have the vm size selector that's a vm site selector if you try to hardcore i want to support you know for example f1 f2 s3 you know t1 t2 t3 they will never approve you they will reject you um you know whenever these components are available you are forced to use those comp com components um mainly on the uh on the size size part of it some skew any anywhere that you see the skew you will have to use the predefined components if they don't have a skew defined components then you are okay to write either drop down or text box text box based okay so again you know you can only validate the template over here you will never able to run this you never able to run this you just validate your validation is correct say for example storage account we have the uh um you know something like that right so if you go back it's going to tell you it's been three to sixty layers so you provide the uh regular expression you provide what the error message that serum is going to tell you it enables and tells you over there okay um that's okay now i have the ui definition what i mean what i can do with that so this is called internal marketplace um service catalog managed applications um i mean when i say external uh it's internal like in your corporations um create a ui definition and then the main template dot json create a zip file with the ui definition and the main template and any nested template so these are the two files mainly required um you can put all the resource inside the main template or from the main template you can call the artifacts if you want to slice it down for the easy maintenance create a zip file and put them over there and then create a service catalog you know you go to the portal look for the service catalog create a new catalog and then apply your your zip file into the service catalog and boom it's going to look it's going to appear in your catalog and then you deploy from the catalog okay so the way that it works publisher creates it's again like you know you know one or more json files publisher creates it um he deploys the service catalog right and the internal user comes in he deploys it and he uses that study schedule like it applies it so these are the four parts that cover part of the service catalog now you want to take these as you know everything works nice or you feel like some point you want to go to a public marketplace you know there is a there is a thousands of offer available in the marketplace you want to be one of them it's not going to cost you anything you just need to set up the account right um you you put them over there you just take the same exact zip file that you put it over here and now put them in offer my public marketplace offer and they will go through the process and approve it once it approve user can use it external users can use it oh okay here i defined internal service catalog external marketplace so that's why i confused service catalog for internal it's corporate only um our enterprise or the company who wants a subscription external marketplace once you put them in a marketplace there is no way you can hide it however you can create a multiple offers those offers can be uh hidden and then you can create a public offer that can leverage the hidden offers uh i'll walk you through some demos down the road um so that that's the service catalog so it's got like nothing but internal of marketplace and publisher creates a json template population to the service catalog the user comes in it applies it and later stage you decide that you want to go public then you can put them in a marketplace as offer and it publish it anybody can see it here is a sweet link that you can go through now let's run this demo i can reuse the same demo for the other steps so to do that we defined it clearly over here we're going to create a create ui definition and main template and then the artifacts that we want to use within that main template so i go back to my folder here um i bring it back this folder um so i enable it to uh think over here i have made template i have the create ui definition i'm going to include the artifacts that's all i'm going to do i want to make sure i didn't edit anything over here and it will break up late and edit it what does i want my editor reply is fine you don't care about it okay all right so that's why i did not run that part of the cacd pipeline so as the definition we need to create a ui definition we need a main template we need artifacts right so i'm going to create a zip file right um you know audio fight. you can name it whatever you want i'm going to go back to my storage that i created part of this very first demo i go back toward boston um i'm going to i'm going to go back to one of this account storage explorer and then demo"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:55:36",
        "seconds": 3336,
        "text": "whatever you want i'm going to go back to my storage that i created part of this very first demo i go back toward boston um i'm going to i'm going to go back to one of this account storage explorer and then demo i'm going to upload this file um on template name doesn't matter but in real world you will name it whatever your product you call it as so i'm going to upload it okay i got the artifact. so what is it contains here this is a clear ui main template and then the artifact the artifact is we're going to create app instead keyword store is in the web.json right all right now let's go back and then create the sas url for this one i create because it's a private container so you know if you want to put in a public you do it but most people who hand use this stuff they most likely put them in a private wall because they want to protect the intellectual property so you know what they do is you know as they when it goes public marketplace they prompt okay under the enter some site some you know package you are right then they have to talk to you so that's how you hide your intellectual property and somebody paying for it before they're buying it um but you can give the enter json template but this is we're assuming that um um the the component that you used inside is your intellectual property you can hide it by by forcing them to input these parameters but in this case you're just giving the package url so i'm going to copy that one i go back to the acid portal i'm looking for service catalog any question i know i'm maybe going too fast uh i you know it's i think i want to make sure we cover a lot of stuff so far so good so then please continue okay great all right so i'm going to add a boston demo one it doesn't matter name but you would be giving a proper name in your stuff um i pick a subscription okay i pick a resource group in this case i'm going to use the one that i already use so i can delete it up this demo um the package ui so here is the package uri which is the package of the marketplace that we composed those those those arm template okay so in this case we're going to we're going to create the infrastructure which composed of um appian said keyword storage web app created all the time so every time you reply it does the same exact thing it's a dell or prod or stage it's going to create the same exact thing um come back to here and then here there is a lock level you can say read only or none i would say none for now but if you if you sell read only you know you can only read nobody got deleted okay so anybody can read it um so lock level none is somebody can go and delete it because that's what i want to do you can also add authorization who can see this catalog you don't want everybody to see it you want you know certain people to see it for the dow only certain people you want to see for the prod only certain people you want to see it so you can control that okay um so i had authorization if you want to but i'm going to skip all those things they're pretty pretty simple you just go ahead select select a user and go back like just choose this one location for the package you are on this i can say that deployment more complete or incremental i always keep incremental uh i'm going to say none and then i create it uh in few seconds this will create that template okay wait created it either i can refresh it here i know and then sometimes there is this difference won't work you do a hard trip rest but going from here works 99 percent of the time a hundred percent of the time okay um so i have to think um i can look at it you know i can set some access control if i want to i can do all those things right but now i'm going to apply it over here so it's deployed from the definition right so i deployed over here now that's the ui that you are just validating right so that that coming from that create definition markup point so whatever you see here um now we put a i don't think i tip dive into this one so we put a basic that's the basic over here like a basic we don't have a side step next step but i will give also some other demo later um you know the basically are the web names queue and all those things right and then we have the output so these are the outputs location web name websq package url storage account is passed back to main template what does that mean you must define all the outputs that are referenced in the main template if you are not defining it's going to throw error so you will not be defining if you have the default value say for example i have the storage account"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:00:39",
        "seconds": 3639,
        "text": "does that mean you must define all the outputs that are referenced in the main template if you are not defining it's going to throw error so you will not be defining if you have the default value say for example i have the storage account defaulted value then i i don't need to define these output values otherwise you must provide this output value and then it validates that okay now the main template i i know it's going to read all the value from this ui and then pass on to the main template and main template takes that as a parameter and then it goes through it you know i you know for the demo purpose i create the app web app insert name i just prefix the app inside that's a app i dash whatever the web name that i provide right and then i run through it so here is the one thing that i want to highlight this does nothing but i have it here why for internal marketplace it's not going to make any sense once you go public which is a external marketplace you if you you need to keep this value in this format any good then microsoft will track and pay your money okay so it'll pay your money meaning that your template has been consumed we are happy we generated the revenue and then and hence you know you you get you get some incentives um if you make a hundred thousand dollar per year through your templates then then you get a lot more benefits on that you can call sell with them okay your template is awesome you made a hundred thousand dollar a year now let's do a course you submit all the all the marketing material uh you know they will work with you any deals come you know they'll understand your business and they know where you where you fulfill their demand and they will route all the um all the leads to you in that area okay that's the reason you have to keep this if you don't have that requirement you don't need to keep this at all again it's nothing but empty resource and this is the one way that microsoft tracks this is coming from the public marketplace they validate the name names equal to be detached as soon as it comes in they will track it on their system okay this is coming from the this is eligible for english incentives and so on right um for our demo i put a dummy name but in a real world demo you will be putting a pid dash from unique id and if you go through there's a lot more process i will walk through in a few minutes uh let's go ahead and complete this one here so i'm going to pick a yeast to use too that's my favorite region uh i don't know why i'm doing that but that's how i do no day boston lost and one i'm going to copy these values okay i'll keep it a little simple here p1 s1 i'll come back to the package url storage account um you know if you go again it will be a validation issue i'm going to say yes t and i follow some convention like this kv if you create a name we just add a kvst and so on standard this is nothing but i just can put anything you want now i said if i have the package url i say it's going to deploy it you can you know in real-world scenario you will have the web package but this is just a demo so i'm going to use this this url over here it's also it's a file right so it's going to extract and put some information all right so now i review all right no validation and i'm going to create it um it's submitting it's creating um you know if you don't want to wait and you can go back to the resource group open a new tab then you can keep watching how it's deploying so it's deploying it over here okay so it's going to take a couple of minutes let's not waste our time move on and we'll come back to it so now you learn how the internal marketplace works uh right you did it now let's talk about the marketplace itself and same exact concept you know you organize the stuff create your definition main template and then the artifacts um you know you clear on template you test that ui you happy with it you create a zip and you do it um the same you already done all the steps but now it's not easy to test by everybody the corporate needs to have account with the microsoft it's called a partner account you need to create a partner account once you have the partner account then you will go to the portal unfortunately i can show those ui but in other words i will share it um you go to the partner account uh you might have some screen save to save okay so here is a partner account you can look at it uh and then you select offer it can be a software service it can be azure application which is nothing but solution template as virtual machines as a container or consulting services if you are a great in consulting you know you can submit you know what kind of specialized your area or the dynamics or iot and so on um software as a service you just leave an end point you connecting back to"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:05:42",
        "seconds": 3942,
        "text": "great in consulting you know you can submit you know what kind of specialized your area or the dynamics or iot and so on um software as a service you just leave an end point you connecting back to your your system um you know as the user clicks it collects the user's details and then submitting to you as your application is nothing but a solution template it's on template nothing but optimal player as a virtual machine is a vht you directly submit a vht but i would recommend if you have to submit as a virtual machine don't ever do that you submit to ask your virtual mission as a vht as a hidden offer and then you create a azure application that leverages the hidden offer okay so that way you can see how microsoft tracking your usage is you know some reason you you you have a lot of consumption on your vm um you also get paid for it and then container and so on i never used all those but i used the top three right um once you have it now how you submit it you create a new offer or not this offer as you create the next step will walk you through offer setup properties offer listing preview audience technical configuration that's where you're going to upload the zip file you just created in other words that you uploaded over here okay oh it's failed you will look at it creator created the file over there there is that one okay um core sell with the microsoft you know it's not eligible until you meet a hundred thousand dollar per year revenue generator um by resell through csps cloud solution providers and you submit these ads go through it okay so you finish it it takes a certain amount of time from three ticks property should sign off it may go two days and then it will take like um seven to ten days if there is a failure then you will have to start over and work with those team to understand what its right there isn't your link to their github you go through it fix it fix it deploy it fix it apply it under you you and microsoft and agree together sometimes you think the best practice is not defined by microsoft team i've seen it several times um for example you know i i define my variable a version as a variable because every every resource has a different different versions so i don't want i want to replace it in one place but microsoft says that's not a best practice but they're looking for a constant over there similarly if you look at this template over here and template over here in the in the output main template [Music] let's go back to artifacts over here i see that this output is okay uh let me look at the storage uh storage yeah this output is not okay this will not pass i'll show you the passing template this will not pass because you can do a concat over here but that's concat should be done on the variable and then you can recall something like apa versions of zero now you're going through collections they don't allow you so you need to hard code the version number so some something to know but when once you are in that mode you will get it you know then you work with them now sometimes it's a too much of problem from their side they will ask you to do some json comment here to override um you know that may get you past the validation but you know two months now you change it that go through a different person they might not pass the validation so i would recommend you record it all those conversations so they listen to you very well anyway let's fix this one what is the problem over here so that's how the marketplace works let me see what is the next topic uh new offer we looked at it okay next one is template strike we'll come back to it um so you can look at it what is the problem click on it okay so it says uh foreign okay okay so i look like there is some uh some at recession is used i understand fully over here dude that's not our authorization to perform the action components start right over the scope uh boston template inside some reference template is let me choose a different one here so it's catalog yeah the same thing deployed last night deploy do you want me to apply it we will come back i'll show you how to deploy this one but trust me it'll work but i have no idea why that's not working"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:10:46",
        "seconds": 4246,
        "text": "deployed last night deploy do you want me to apply it we will come back i'll show you how to deploy this one but trust me it'll work but i have no idea why that's not working but i can go back and look at it um we'll run if we have time towards the end all right let's get back to the template spec template spec is again you know you you create a resources same exact way but minus the create ui definition create a ui definition and the main template you don't need it all you need is as it apply again as i said as it apply is nothing but a main template okay it's copy of the file but they needed the particular naming conventions um so you have that you know the only key difference between that and then the template spec is templates that you use the related path okay um you don't need to create a zip file or something as soon as you you specify the lengthy path it will take it so again now template structure um it supports the the same exact syntax that we've gone through but it is on something called a relative path support the template spec as a link to template uh create you know you can create templates by using the power cell and you can also have a template specular for another template spec so just like how i set a certified cacd controls um you can have a template spec for app one template stick for app to template stick for app three and you can refer those them into app four and so on okay so here's some some syntax how you run the template spec and then the uh and then the you know if you want to refer it as id you read the template spec by name and then pass in the template spec id that's all you have for it again if you visit this link it gives you all the details let's run the quick demo um so to run that template spec i go back to apply.json um i call this one i'm going to put a template spec again i created the copy of the file i call it as the template selector json template spec.json i copy that one name that name can be anything okay so template spec it's it's in the rg right template go back over here um it's going to come back to that one why go back to that's failed group like boston uh you have the first few times to appear the templates background so here is the template spec so here is the uh the service catalog that we deployed okay so we deployed to the service catalog and then that comes over here and then once you click on it open a new tab um it you know that's a this creates another is uh okay so you didn't go through it but if you click on the resource screw so that's the hidden resource group and then we'll create all the resources but if you look at the log it failed on the app inside and hence it's failed everything so you first create the storage and then create a app and say there was somewhere in the app inside that failed um and then you know then everything else so you have two options um you can resubmit this offer right now not not not this offer the redeployment so you can go back to service catalog uh open a new tab open a new tab click on the boston demo one and then deploy it okay so you can redeploy it by using that one and this time this may work but i i think that we're like giving a wrong name i guess so before it continues to one more time highly make it possible like you're wrong sd av dash just until this puts the result manage resource group name but this url i'm going to go back copy this one let's do a new resource group over here rg would i austin two just in case okay maybe the name is pretty big i don't check what is the size i gave it but i will i would assume that may be highly possible all right let's do this here sometimes we restrict the name size okay so that should be good let's review and create all right create let it go so let's go back and look at the template stack so here is the templates but when i click on the template spec it includes artifacts so i go"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:15:49",
        "seconds": 4549,
        "text": "okay so that should be good let's review and create all right create let it go so let's go back and look at the template stack so here is the templates but when i click on the template spec it includes artifacts so i go back and look at my template spec definitions uh template spec definition so i have the parameters nothing different than what you did on the deploy.json as i said it's a copy of that file i have the parameters you know i have the variable i have the resource then again you don't need this resource if you don't use the marketplace okay uh and then storage and app insight and so on i created it and then higher output parameters but in this in this um the you know when i refer this i have depend on storage app and i've been set but if you look at it i say relative path i only run this file right in the syntax i only run that particular file template spec but how it knows to bring all the other files under the artifact because we are saying that relative path is equal to artifacts keyword related path is equal to artifact slash web app you know and so on artifact slash related path artifact slash um app insight and relative path artifacts less storage so it it passes the file and crea you know collect all the files referenced files and then put them in over here okay and then you know it calls nice version one that's what we gave it but now if we're going to run this one i can call it as replace it if i do as it is or i can say version number two okay so now i modify a little bit over there so if i save i can run that person number two okay so no problem so if you if you re refresh these few few seconds later we will have a version number two as a latest okay so two is the latest now how do i deploy what version i want either you go back to the versions and then you pick the version that you want to deploy one point zero or 2.0 it doesn't matter so in this case i'm going to dip by 2.0 um you know it says main template and then click on the deploy options again not different than what we what we deployed before you complete the parameters um you know i would leave it location let's create a new new rg dash dash austin let's go back apathy dash faster oh that's me so badly excuse me drop on so we're going to say p1v1 hardcoded this is why you have to imply the dropdown dropdown place when you data internal marketplace you got a dropdown so you select it but here you put a text box they are not going to worry about it they only worry about if they are out of the box control then they won't let you do it misty kv standard and then here you don't see all those things again this ui is not something you create the ui this ui parses the json file right the form and the parameters that you defined over here based on that parameters this ui is created okay so that's the cool thing about template spec um if you only want to use it within the subscription this is the right way to do it you know you know just go ahead and create your template spec uh one or more templates back you nest them as a template or a template spec and then you use it review and create now create um you know you got it so that's going to go that's why it is you can deploy multiple versions if you deploy multiple versions select the version and deploy it now the next answer any questions so far okay the next question that we're going to have is the blueprints there's not a lot of difference between blueprints and template spec they both are complement each other um and in my definition they both looks a little bit of duplicate but the one that you define under the management groups so if you have like hundreds of subscriptions and you know you can define a management group to categorize them um and then you can apply which management group can see it out and then the corresponding subscription can apply to it right that's a only a huge difference that i see in it it also let you define the policies and then the r back um i think you can do it in a template spec i never tried it but now that's how the difference that you can you can think of it i would let you sequencing um by using the different sound that depends on you know dynamic and static parameter publishing support and everything but again blueprint is only runs within the subscription it has nothing to do with the marketplace but again if you look at all these demo you had a one basic thing called as it deploy right uh and i call it as rn1 because parameter file that's the one thing now we're using a multiple variations of how you can leverage that asset apply we leverage the ca cd we leveraged internal marketplace we leveraged external marketplace we leveraged templates back now we're going to leverage it in the in the market in the blueprints this is slightly different when you compare the template"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:20:51",
        "seconds": 4851,
        "text": "the ca cd we leveraged internal marketplace we leveraged external marketplace we leveraged templates back now we're going to leverage it in the in the market in the blueprints this is slightly different when you compare the template spec and blue springs that's the reason you know um i i like the blueprints but now i need to localize like this um you know you can write little little programming to dynamically do that so watch this here is this default format structure so you have to have blueprint.json and then you you put your um put your artifacts okay um in their artifacts um you define the parameters blueprint.json has the predefined structure you know it's not a lot different than what you've seen so far parameters yeah i understand and then you define that variable called um you know anything it can be anything you you name it you know i call it as my boston that's okay but that's the same exact value should be used over here okay so if you put a my boss in here it should be my boss in here you know keep it on my user group it should be my user group that should be named and matched okay and then you set the darkest scope so here you have the target scope functionality it can be a subscription level or it can be a management group level no you know if you're not if you're new to management group management group that you sleekly organize your one or more subscription in you know categorize one or more subscripts in a multiple hierarchical way that's a different term um and then it uses a type called blueprint slash blueprints type okay so that's the blueprint.json the parameter file nothing different than what we see in the parameters but in the artifact this is the only reason i don't like the blueprint because i can use the template i defined for the template stack i can use the template i defined it for the marketplace now i have to localize slightly different so the difference is you see that section called template that's nothing but this template okay you copy content of these and put it put them over there uh sorry put some over there my i know minus the parameters the parameters you can define it after that minus the parameters you put the content up to you your your artifact gets in over there kind of template all your artifacts gets in over there and so on so you can create artifact called storage.json and you know if you have a typical arm template copy the content of it put it over here it will become a blueprint template blueprint artifact if you have web.json copy the web.js and put it replace the template section that will become a blueprint web.json and so on right that's the only difference um over here no that's my note on whatever uh there's some syntax how we can execute it um i don't want to waste the time uh jason bill how are you looking at the time okay i'm fine for next 10 minutes uh yeah okay they're not gonna kick us out of the room so we're good okay um okay all right so and you go back over here now i'm going back to the uh deploy.json is some index no okay i'll copy from here right um you will have to import this module csg blueprint um if you don't have it i i'm running this for months so i think i should be having something um i'm just going to copy this syntax directly you know yeah all right uh my blueprints say boston tool template management group id your subscription id or management group but it doesn't matter so this is how i create it so first thing i need to go back to the folder where my oh hold on i didn't explain how that works uh so let me go back to the portal here it's also failed at that we'll come back and look at it uh um so if you look at it as your governance right so i have the blueprints over here okay i have the artifact or the file so that i just open it from here okay blueprints so that's the syntax i collect all the parameters that i wanted okay then i call it the demo and you go back to and then you can have some r back you can put them in the hardback rules and ascend.json it would take it and then here is artifact so i go back to you know how it's linked artifact um it's a convention based again you don't need to worry about it any"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:25:53",
        "seconds": 5153,
        "text": "put them in the hardback rules and ascend.json it would take it and then here is artifact so i go back to you know how it's linked artifact um it's a convention based again you don't need to worry about it any folder under the artifact is automatically executed you don't need to refer them anywhere okay so in this case you execute the blueprint.json it opens artifact it's going to execute it but what order it needs to execute that's what you're going to control it by using that depends on okay so it has the parameter passed in you know whatever the parameter collected there it automatically passed in but if you need to map it on the bottom okay so this is how you map and then you say depend on storage so if you want to depend on multiple and you just uh keyword depend on storage um webmap depends on something else storage and search okay so you define that and then if you want output you can output it um you can read the output uh from the other template by just saying that uh how do you read it um given an example over here okay artifact of stories and then whatever the output variables and then the name of the variable that they slightly make a difference syntax here it's not going to follow the other default arm template syntax um that's the only thing i feel annoying otherwise it looks nice it's well organized you know naming convention based it's all works great and you control how to execute an artifact by adding that depends on how you read it you go to the artifact name outputs and then whatever the name you put over here here if you look at the storage artifact and storage artifact is all i know the outputs the name called storage connection string so you go back to the web app and that's how it reads uh that i was reading and i was reading maybe yeah output storage connection that's how it reads okay um to run this template uh you know so here it is some syntax you run it input path and then you need to specify the subscription or the management group id and then you read the blueprint and then you publish again just like a template spec you have to specify the version number um you can you know if you put a same version number to apply again it will replace it or you can keep doing the worst running they provide your worsening um you don't need to maintain your in your devops that's how the blueprint works okay let's go back to the template script uh yeah some time shortage but um um i have some other demo i i can record it record a demo microsoft template script um now you have all the arm template it does everything which is nice and great but what if you want to create some sort of ad application to enable authentication ah there is no template does that template today can do that there's no way it can do that so you need to use these some sort of power cell script and load the 8080 commands and then provide all those options right so that's why the script comes into they allow you to script a powershell or cli for one or other but not both at the same time okay so you can create but the way that you run those things by by you creating the user assigned the managed identity you go back you create a user center manager identity and give them the access control in most cases then you know if you create the create any any services then you need a contributor rights and you want to read write a data then you need a data contributor you only want to allow read it you need a reader so you make sure you have enough access provided to the service identity and then you use them as a script um let's go back and look at it how that looks so i have the last one called template script so create a user identity so you go back to the research group uh let's go back so scroll boston add you know user what is the name user assigned managed id forget that yes oh god i don't like this player um so and then you create it you name it um is to use to you can call it as the you know um user assigned manage identity too okay and then review and create and then you need to grab the max create it it quickly creates because it's just a name like a logical variable just like any other variables um you go back to a resource group it is there but you can you know if you want to you can give any access control you want say for example i want to give a access control after i am and look for the name which add role assignment um i provide this name it's gonna find that name and then i give a contributor"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:30:56",
        "seconds": 5456,
        "text": "example i want to give a access control after i am and look for the name which add role assignment um i provide this name it's gonna find that name and then i give a contributor okay good good to go and i done that now i should be able to my power script inside my arm template my my arm templates right so to do that let's run this one as a template spec okay uh we don't have any relative path here right and again this is for demo only um you know i need to copy your subscription i think just copy um you know you in real world studio you will be parameterizing that but for demo it's okay uh user user access managed identity deleted tool i think so so let's go uh yeah uea mi2 so uea mi2 and then there is a you know container setting storage accord so in a when you run that you probably know when you run a cli power server you will have to create a storage account you know september space it uses it if you don't provide it's going to create it if you do provide then it uses that account if you do provide you should make sure the keys and everything is working otherwise throw the error right so we did that we put a subscription manage the entity umi two we study that um you run the power cell again we are not doing rocket science over here we're just passing the parameter called v1 we're looking for that output there and then there is some parameter when do time or 30 minutes uh one day retention interval um that succeeded events and then here we say deployment script output okay empty object in that empty object we set the property called text and then whatever the value that output which is the v1 over here i'm going to run this as a template spec so it's easy to verify it um so might deploy two call it as one but it doesn't matter you can you name the word it doesn't matter what person it is location and then template script which is on template and blade script.json yeah i think this could be another thing i might have broken i edit and that's not saving it okay let's do a quick scan seems to be fine i don't see anything okay it is one problem uh what is the name i used template script i save our okay template script let it create go back and review this one finally best practices ensure that your json is properly formatted and the utf-8 the git stores this gtf-16 if you if you don't pay attention utf-16 stored in anywhere is fine eggs have been git use variable values that are multiple times throughout the template are complex expressions if you have a concat don't do it on part of the parameters to eat part of the variable use the latest api version the microsoft recommendation not older than two years would even go one year but if you look at that they have a lot of resources it's hard to stick to two years some may go back to five years older too um i mean by documentation says they say that in practicality it's not possible to live with two years but they don't even consider but they will say that anyway assuming that someday they will replace are they thinking that they're replacing remove news to variables and parameters so you know if you have variable never used in the template i remove it keep it clean minimized we use a default value but not set the empty string that was one example we saw the default value is good to have it but don't set as a empty it doesn't make sense always the default value for the location to this that was a recommendation coming from microsoft and i kind of like that recommendation uh all empty i mean you don't need to sit on the sub template but you do have to set that on the main template all empty or null properties that are not required must be excluded so we if you look at the template we set a lot of places null um rra right empty arrays right um so you want to say allowed ip you will put an empty array by default you don't need to just remove that if there is an empty array empty"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:35:59",
        "seconds": 5759,
        "text": "a lot of places null um rra right empty arrays right um so you want to say allowed ip you will put an empty array by default you don't need to just remove that if there is an empty array empty default value now remove all those lines and some reason you want to go marketplace they're going to reject it it's that's one of the validation um you know the problem is you are not interactively working with them it takes like seven to ten days to get back to the result you waste technically seven to ten days until unless you are a billion dollar company or you can get dedicated people directly work for you in my case i have to wait seven days do not use allowed values for listings like meant to be increased you for example vm sizes wherever they have the control defined uh you use that otherwise it's okay to bring down your allowed values all parameters should have a descriptions i like that you know that helps other developers to look at it what the previous developer did or what's the intention of the parameter uh do not output keys when used to the marketplace um sensitive information is kept to be secret don't display it um if at all you have to do it use the keyword uh keyword keys secret certificate whatever way you want to use it that's the best thing that you can you should follow it uh let's go back and then see what it does might apply to we call it as right so here somewhere mighty by two um yeah i got a version one i create a deploy but no it should be doing that okay let's let's go back it didn't have any artifacts because we didn't relate any templates right so deploy it and you don't have any input either there is no parameter defined it's just just trying to do some something some some demo thing so just create it it's going to create that work may take some time but when it ready we can look at it so let's go back and look at how many things failed why it's failed yeah so that's over here position two that's a one type of boston i did not deploy it up here refresh all right any question i think that's uh that's the last part of the talk but i covered everything and some demo failed that maybe i would have typed some keys um if you really want to do what uh one of the enterprise that we have here for online iosu.com i'll quickly walk you through that move that's the final topic go to our criminal view a lot of offerings so this is the biggest offer than the other offers um now see look at it i have the cognitive search cache studies type cosmos tv logon redux workspace name and then i asked the deployment package so where is the package this is where i i control the intellectual property you can go and buy it but without you giving me you are talking to me you know it's not going to you are not taking my intellectual property so i control it it will complete the creation but you're now paying money to microsoft microsoft knows because of the tag i i added over there right like empty empty empty resources the pid microsoft knows they're using my offers and they will start sending me the statistics how is using who is using all those things and then i can follow it they also give a free market marketplace urls if you go to a marketplace i'm just going to bring this page over here fire up the question if you have anything please while you're waiting for me so uday uh so thank you uday and thank you everybody who uh uh who joined us uh as veronica mentioned in the slack in the um in the team's chat it's okay to unmute yourself and you can ask a question of uday uh directly or you can type it in and one of us will uh read it or uday can just read it himself i guess at this point this is not presenting uh uday i had a quick question that um maybe you could speak to is um there's if you're if you're familiar with it there's this other critter coming out of microsoft that is a little higher level abstraction above arm called i called it bison earlier but uh uh bicep um and i'm wondering if uh if uh can you spell it for me can you spend it oh uh okay so b-i-c-e-p it's a pun on arm is uh like a human arm and the bicep is the muscle uh one of the muscles in the arm yeah okay so if you're asking that you probably aren't actively using it it's a i think it's a project out on github and it's not really part of the platform as i understand it it's more a um uh you know it's a it's a kind of like the entity um uh entity"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Infrastructure as Code using ARM Template",
        "videoId": "imsyK69IgB4",
        "description": "This is a recording of the March 9, 2021 virtual meeting.Infrastructure as Code using ARM TemplateThis is an online-only meeting. This session will deep dive Azure Resource Manager (ARM ) templates usage in the following:1. ARM template structures2. Creating UI definitions and validations3. Creating Basic, Linked, and Nested templates4. Building Templates for Marketplace5. Building Templates for Blueprints6. Executing Templates using Azure DevOps7. Executing Templates using PowerShell/CLI8. Executing Templates using Git Action9. Service catalog managed application definitions10. Executing Scripts and MSBuild part of templatesUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:41:02",
        "seconds": 6062,
        "text": "it's a i think it's a project out on github and it's not really part of the platform as i understand it it's more a um uh you know it's a it's a kind of like the entity um uh entity library whether that was intlib enterprise library um you know one of those um uh you know slightly differently delivered uh solutions so that's cool so maybe we'll get a talk on that in the future but that this is an active project if you're not familiar with it today you may want to check it out and clearly you see yeah uh plugged in almost everything else so yeah except with these so now i need to change my statement not here to z to y not 0 to 100 that's right that's right okay so yeah i was going to ask you any comments on that but it sounds like um that would be a future discussion with you so um if you can if you want to look at the comments in the in uh teams uday you can read them directly or or i can uh read you out uh read any of that come in here looks like andrew uh yeah yeah you can do that yes okay thank you for the credit srikanth uh that's not a question that was a credit to me you can do the caf yes very well you can do it um what's other question okay who would definitely do that any other question guys i don't see questions okay so right uh mark and the oxygen it's on template the hood but provide a higher levels in this yeah i'm new to biceps so i think bill is my master right now oh a poor one there another question that maybe you could weigh in on uday is um back in the beginning of at the beginning of time when arm first became a thing it was i think i don't remember the timing with great precision but um i would bet a little money that uh arm came out before the cli or before the cli was mature and arm was the only way to do like item potent and goal state kinds of deployments right you could say what you wanted in the platform would figure it out um so it was more obviously the the tool if that was your goal it was before there was mature ci cicd and so forth as well so going way back um but um since then uh cli my understanding of cli is that it's also a pretty good tool for accomplishing the goal that you you stated up front is you you want a predictable you're an enterprise and you you're not going to do it just once you want to you want to be able to repeatedly do it and you know one way of accomplishing that is with arm i'm curious if you have any comments about arm using arm for that obviously you you like arm i'm wondering if you have any uh comments on that about using um something like cli for the same end goal of having a predictable deployment experience i would define everything as an arm and then i use cli to execute it based on where i am um you you you know you you are there is always room to ucla power source but um is the one controls everything i will not use for example create a storage as a cli i will define a create storage is arm and then call execute the resource template from the cli you know you want to use that directly from the cli create a storage account internally it's going to translate that into arg template and then transfer that payload into a resting point um you know now over the time the class gets changed but on template follows a very simple syntax human readable anybody can change it you know it's easy to maintain say i you know my what always goes to warm template you maintain everything on template and then you use the cli as your orchestrator put it that way um or you know as a service catalog as your orchestrator or marketplace as your orchestrator or ca cd as your orchestrator um or gita accent necessary orchestrator or template spec as your orchestrator you define it or maybe the bicep which i didn't go through it yet but yeah it could be your another orchestrator i would define everything sound template good answer if you want to play with the orchestrators you need something that's uh orchestratable uh thanks for that uday yeah uh oh and back to the audience are there any um lots of uh kudos uh it looks like there aren't any further questions if anybody has any final questions please unmute and ask it now otherwise we'll uh go into um do we have any announcements veronica or jason or anybody from the audience now i have this meeting if anybody wanted to join uh it's again my practical experience how i build a cloud across the regions if you want to join but i may be repeating in boston if plus and jason plus me someday i don't know very cool very cool all right thank you for staying late that's that's you know i i know i took um 20 minutes over or 10 minutes or at least thank you for staying late and thank you bill veronica jason for the opportunity thanks everybody stay safe out there um we'll uh keep an eye on boston azure uh our virtual boston azure announcements um we our next scheduled meeting is uh the 14th uh daniel colon on ark as mentioned and um but keep an eye on things in case we announce a talk uh before then until then uh thanks everybody thank you thanks again uday uh excellent talking about this i've always learned something "
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure. This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.. yeah yeah go for it perfect i'm just feels better already so uh hello everyone uh yeah i'm michael crump um you haven't been doing that azure tips and tricks thing just for a little while um actually i started it in 2017. i put it on my own kind of like personal blog and as i was getting like more and more more traffic i got to thinking okay well how can i kind of scale this this out a little bit uh so like we were missing videos uh at that time uh we were also um uh this the site that i was using and i'm still using it like today i think it was like a jekyll based site um i wanted to move to like view press for some additional speed uh and also like search uh functionalities uh so uh anyway that's just a brief kind of like history with like tips and tricks um i work on azure as uh in the application development uh area so uh think of end-to-end application development so um what that means is is that any time that we're at a meeting right now but oh i'm so sorry just as soon as you know what time of day uh and so uh one of the things is that uh being in azure application development um we get to look you know left or right throughout all of the services which is an extremely fun job at least for me because i have that ability that um uh i get bored really easy i like to like move on to like other like different uh you know different things over time and so uh yeah and so um definitely definitely uh kind of some of my kind of sweet spots here i'm just going to go ahead and share my screen here let's go this one share content and let's see if i pick the right screen this time okay i think this is working you should see it now um so hopefully everybody kind of sees it this is a just kind of the little uh you know kind of our intro kind of our our dashboard here uh where most folks can typically find me at is a twitch and twitter uh mbcrump i do live streaming i do actually a live version of tips and tricks on wednesdays with one of my good friends cecil uh cecile pillbox uh so kind of coming into this one uh today i thought of a couple of different things um some people may or may not be like familiar with some of the existing tips that's out there and i think as you can kind of see uh from right here let's go here let's go after dev dot tips today we hit 274 um so there we go 274 as of today uh so anyway it's been we've been adding this out uh kind of as we go so what i thought about doing is i thought about adding uh some kind of the new stuff and then maybe a little bit of a mixture of the old stuff and then also i was thinking what may be kind of cool is that i've been given some access to some fun little stuff in github that uh i have like the ability to show you some of the stuff that you may have seen and some of like the keynotes and stuff so a little bit of like everything maybe we'll do a little softball and by the way i love for this to be interactive um ask me questions away if i don't know it i'll gladly tell you that i don't uh and we'll we can like figure a lot of those out together but what i hope would i aim out of this is that at least you're able to get uh you know a couple of different things that may help you be be a bit more productive as you're using um azure okay so let's see what we have here today so uh before we go into it i'm just gonna pause this um if you're wondering a little bit more if you are brand new to the series uh you could totally just get to the site just as your dev dot tips um this is a very much open source project it's been open source since may of last year every every bit of it has been and so um if you go over here and you take a look at the repo this is the repo that we currently uh that we currently are maintaining we've got a bunch of contributors um and today i did a bunch of kind of clearing out of some of the like the latest pull request yeah and so um uh yeah the weekly emails 273. know what's so awesome is is that uh sometimes we'll see we got it over here yeah 272 673. this isn't the first time we missed one uh so uh yeah we've missed we've missed a few of them before and i could tell you what happened here i had to i actually have a guest that created this one completely from"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:05:06",
        "seconds": 306,
        "text": "this isn't the first time we missed one uh so uh yeah we've missed we've missed a few of them before and i could tell you what happened here i had to i actually have a guest that created this one completely from scratch and he picked 274 and i merged the pr that's how good i am as a maintainer uh okay so uh i just wanted to give you a little bit of history there and uh but yeah anybody can update this anybody can um submit articles to it i tell folks you know like in that latest one uh today you know put your social or any of the places that you think you know folks could potentially uh reach out to you and um you know they could chat you know maybe chad and kind of keep the conversation going yeah i usually put that in most of my my pull request month again um so uh yes so andrew i think you may be talking about the weekly emails that may come from like my blog site is that the ones you're talking about because i send out um i do send out a weekly kind of like update free tips and tricks up from there from uh my blog uh yeah all right cool yes i think they come through on a sunday yes they do and i actually believe it or not uh there is a plenty of uh there's plenty of tips and tricks that i got out of that uh out of that okay so i put together and by the way i love the interaction and the talking i put together just a little mixture of a couple of different things that i had here and yeah just drop questions in kind of like as we go here um in the early days and you'll notice that to this day i'm sad to say it but the azure dev dot videos actually there's this other way around the most popular tip and trick out of the entire series years worth i'm going to scroll down and i'm going to show you i promise i'll get us somewhat back on on the schedule here uh the most popular tip we've ever created was actually this one with 63 000 views for keyboard shortcuts and so well i won't go through like all the keyboard i won't go through all the keyboard shortcuts just if you wanted to like know where to like find uh those that i think it's over here and yeah there's keyboard shortcuts instead of kind of going through that same sort of thing i thought about okay here are my top three so maybe a top list inside of a top tips and tricks post uh so gna is the one that i use uh quite a bit let me see if i can get it to work there we go g and a because i'm always going to resources so uh the keyboard shortcut there is a g n a and you can come into this uh you can come into this little uh thing i always click on that one you can click you can you can always see kind of like the full list that's in there but i only use three that i'd kind of say every day so um if you just press on your keyboard uh g and then you hit a uh it will take you over to all resources so that's that's one instead of you know coming over here navigating to it the second one that i use pretty much every day is uh in regards to search so uh this one you do a g and a slash here let me just do this let me come over here this one is a g and then a plus a slash here so that gets you to the that will get you the uh the search bar a lot of the times when i do need to search um i need to get over to it quickly and so this usually will take care of me of what i'm what i'm trying to do next uh let's see what else we've got we also have uh the favorites so if you notice there's favorites that's in here um you can customize this list which i'm sure most of you already know about but sometimes you want to jump to one of these one of these lists and so i work a lot still with sql databases and so one of the things that i thought that was kind of fun there is is that if you count the number and you'll just remember these after time like this is one this is two and this is three that same g a command so i could do um g3 and it will take me over to this one so um those are little keyboard shortcuts that i think is pretty interesting so like if i wanted to go to i think it would be five uh g5 let's see here there we go g5 takes you over to the function apps so just something kind of interesting there that you can do uh let's see what else we got so a couple of things that i think is what could be interesting here is is that um most folks they don't really know"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "so just something kind of interesting there that you can do uh let's see what else we got so a couple of things that i think is what could be interesting here is is that um most folks they don't really know where to go when they might need a little bit of help and i'm not talking about like technical support help maybe you need an azure expert maybe you know you need something like freelancers uh and things of that nature uh i've been working with one consulting company and over and over and over i'm like we've got partners so just simply on the help here down in here there's this find an expert where you can find somebody that does just about anything uh and that you can use them now the reason i'm talking about uh also get freelancers is that some people are like okay well some of these you know if you need to bring in maybe get some additional help they could be expensive and yes i understand that uh you can also come over here and looking at this there's also this uh azure freelancer uh this is completely on another separate site you know versus ours this one is going to upwork so upwork.com hopefully those internet problems don't last there but um uh this is where if you're wanting somebody to build like a smaller type of application or maybe you need you got some smaller tasks i totally even use uh one of these type of people they're all certified and uh yeah i think there's there's a lot of kind of cool stuff you can do in here uh okay so um the other thing well i guess i'm already in here is is that nobody clicks on this when we look at the data for some of these buttons nobody clicks on it so now we're like okay maybe you actually like find a better way to like surface these but if i ever want to know what what is the latest and greatest in azure this is usually one of the spots that i go to so like uh what is the 11th uh iot core services are generally available um this is oh this is windows iot core in a container uh and you can also see right here like this one this is probably a pretty good announcement uh for powershell 7 support uh and azure functions i actually had no clue that that was g8 until right this second so this is we're learning together as we go here uh i was just i don't know who started my internet i'm hardwired into the internet so it's a little weird but maybe it'll get there um a few other things that i thought that was uh useful in that last dialogue that we were just in then we'll maybe go play with some other things uh was uh the road map so where are we headed next what's kind of upcoming where should you kind of go to if you want to see some of the the stuff coming up uh so this uh road map right here uh this one this has got the 10th uh uh yeah so actually i was looking i was hoping that they had more more of the road map in here but maybe i'm not in the right place um but there is another spot that we can kind of that you can kind of like think of in here and uh whenever we do like um build uh whenever we put together uh you know what did we do for build there's this thing and it's it's in here it's uh basically it's like it's called the book of news so you can think of it as uh if you do search for something like a book of news uh build 2020. we'll do a quick search right over here on this it'll give us take us a second or so um this one will come back with a full list of everything that we announced um at that prior event so uh this is something again hardly nobody kind of takes care of nobody's like really wanting to say hey yeah this is a this is a great resource i never hear anybody say anything actually in all of the the folks that talk about it the only one build five nines website uh you may be familiar with his stuff this is a very good solid uh resource um also to kind of learn and kind of keep up with things let me drop that one in here let's see did that paste right there we go well i double pasted it uh i'll send that through maybe that worked no uh okay there we go okay uh that one landed there just wanted to make sure i paste some of these kind of then as it would go and uh i'll probably be able to uh maybe uh give a little bit more of a wrap up so in case you you didn't get all this we we have to have it somewhere um the other thing was definitely over here in"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:15:12",
        "seconds": 912,
        "text": "i'll probably be able to uh maybe uh give a little bit more of a wrap up so in case you you didn't get all this we we have to have it somewhere um the other thing was definitely over here in the going back over to the dashboard here uh was the ability to sign out uh when inactive this is something that um you know you got your own pc maybe you know we're all living in a world of like coven you know maybe you don't need it to sign out but um internally you know with our or most of our accounts we all have sign outs on these things and i would say in general it's probably a good idea to uh to have a sign out uh kind of upset there um and then one other feature and we'll leave out of this kind of section is is that the double clicks that you could use to do to to to change the themes does anybody remember that where you would like double click and you would change themes here we got rid of it gone [Laughter] you can still change them uh you can come back up here you know and you can change them in here we used to even have an additional option that was like enable that back again but um uh yeah if you've been around in azure world for a little while you probably remember you could double click and you could rotate through all of the themes uh it was definitely a hated feature that we eventually had to get rid of uh yeah and i think the other thing at least that i wanted to show was was that um i used to work on a project a windows template studio does anybody remember windows template studio maybe like raise your hand or something it'd be interesting if anybody knows what windows template city was um the short version of it was that it was a template generator uh for uwp apps now it's morphed into a couple of things there's a brand new team that's kind of like taking out there we go michael uh a couple of teams that's kind of like moved on and i'm not on this project anymore but we created uh a bunch of dashboards um now these were these were completed by people like way smarter than i am uh that put all these dashboards uh together uh but one of the things that we were using with this uh it's absolutely you know the way that we wanted to kind of monitor this outside of like alerts and rules and things like that was really uh we sometimes have a bunch of additional monitors or additional screens that we can use and so what we did was we basically took uh a high def uh screen we posted it where we were walking through and it was more of a you just walk by you glance but we were just using an azure portal running in full screen and you know you can do things like up here at the top like you can do things like you know setting like the auto refresh uh you want to only span for like that 24 hours what i find is that you can be pretty darn creative uh with your dashboards so um you know you know markdown uh images uh there's a vast variety of things that you can kind of put like on a template this one's about as good as we were able to kind of make it um but i will say that uh i will say that there's a there's a couple of nice uses for that you know and also you can come in here and you can do things like share dashboards this one is already shared like i said it was created by somebody uh like you know smarter uh than me uh and so forth uh okay let's see what else we have here today um so i've gotta go yeah i'm gonna have to go you know i kind of got a little rough list of some of the things i think we should uh talk about let me just do this really quick um cloud shell since you're the azure group you've probably used cloud shell in some sort of fashion over the last little bit let me take this one i'm going to move this up and we're going to try to connect to the terminal um if you noticed in the past this power shell was like a preview obviously that's gone now uh it's there um i customized uh this prompt so um you know a lot of people they have like really fancy like prompts like if they were inside of uh let me see if i've got a directory uh test one let's see yeah so like in this example um uh i have a folder called test one and this is all of the current like statuses uh by default they won't ship the cloud shell with this on there uh but if you want to kind of learn how to do this or how that i did this um"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:20:14",
        "seconds": 1214,
        "text": "and this is all of the current like statuses uh by default they won't ship the cloud shell with this on there uh but if you want to kind of learn how to do this or how that i did this um i've got a couple of dev.2 articles uh that you could you could check out um so like you know you run like a get status here uh you could see you know we've got a new file here uh readme and then you've got uh drr uh color so yeah it's waiting you know for this to be like committed into that uh let me do this i'm going to uh yeah let's just clear back out of that so up here at the top here um this was just the documentation they had to add in one eventually for like copying and pasting uh because folks were having some issues with that text font size uh was obviously still in here as well and this one was actually a better way to upload and download files i don't know if you know but it's pretty easy to get files inside of it's pretty easy to get files inside of this uh and then over here this one right here is openings in a new session so uh what's kind of interesting is is that we'll see here um oopsie that's gonna switch over to this other chat there we go uh let's see yeah it's just uh another version of that it's just azure dot tips and you can kind of get more of them from there um yeah and then i mentioned dev.2 if you want to get your cloud shell kind of environment you know kind of up like this right here uh where this takes you to is a shell.azure.com uh when you click on this button here and actually we'll just go ahead and click on it uh and we'll open this up because we'll probably switch over and look at this one since it's a bigger screen and by the way uh sorry for using matt today i've had to go back and forth with a couple of uh different things uh at work and but i keep my my good windows down here at the bottom too uh okay so yeah so this is the shell.azure.com basically it's a full screen version of this uh one other thing that is interesting is is that uh over here uh in windows it the in the microsoft um store you can download the windows terminal uh from there uh windows terminal 1.0 came out at build and the only reason that i'm bringing this up right here is is that you can download the terminal and by default now the windows terminal has azure cloud shell like baked into it so if you don't want to go to a web browser you can totally you know jump into it you know straight from here you obviously can do it through visual studio code there's a mobile application and even documentation uh we have live docs which uh you can do even more kind of cool and fun stuff there uh let's see uh okay and so uh one of the other things i was just gonna mention this one let me go back into that test was it test one see test autocomplete for the win uh let's go uh ls and then let's just do this code readme dot md i don't have anything in it uh hello world uh it's here uh so this is the uh this is you you're probably familiar with like visual studio uh code so what this is is that inside of cloud shell uh they went ahead and put a code into this uh yeah so they went ahead and they put a code into this and or visual studio code think of it as the lighter obviously the lighter version of this you can come in here you can go to the command palette a lot of the things that you probably already like know and love like copy which is the one that i use the most uh probably like copy line down or one of these other ones that's in here so you get some of this already by default but i guess what i'm wanting to say is is that let's see let's close this one uh if i do this right here um i'm never going to get out of it and honestly i mean you know i know that's like been like a running joke for a while but um i don't know for me there's just a lot better you know editors and things of that nature that we could use and so i you know normally i default to nano but uh if i have access to code then i'm always going to use a code and you don't even have to use it right here um there is which is this button yeah it's this button right here so if you want to navigate through your cloud shell environment pretty darn fast uh you can come into uh you can just click on this button right here you can see"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "which is this button yeah it's this button right here so if you want to navigate through your cloud shell environment pretty darn fast uh you can come into uh you can just click on this button right here you can see here is some of the the terminal configuration stuff that i had in here and tips and tricks there's this little empty tips and tricks file down here at the very uh at the very very very bottom that uh i'm not doing anything with uh but yeah this is kind of how i've got mine set up where i think it really makes the most is is that when you want to actually be able to top easily and also use some of the you know features and functionality like finding text in them i don't know it's hard and i would even say that um yeah you can totally do it and it works and everything but uh some of the rich uh the richness i guess the visual studio code uh you know just kind of comes out here uh awesome how we doing everybody's doing good even documentation wow yeah the thing there uh let's see doc azure vms i'm just picking one that i have used in the past oh and you know there's another one let's do this one let's do uh this one's more cooler uh yeah i'm gonna do azure billing docs and let's see in here uh azure billing basically we want the api that takes us into this maybe one of these will get us there uh what i was looking for was um actually we'll just go back we'll use the vms just because i want to be able to find it kind of quickly uh vm azure docs what's kind of interesting is is that once this finishes up a bit um you can connect from docs into your local like environment and you can run and try out some of the stuff kind of live so like here's an example of creating a resource group and there is one for billing i probably just in search right uh where you can copy this and put this in your own editor or over here which is what i i kind of like it's like try it uh this just opens up cloud shell in the browser uh and uh from here you can actually run through each one of these steps um and kind of like experiment with it you know kind of as you go which i think is is interesting because um it's it's definitely the the mode of how i learn i'm always doing something like i'll take a window like this one uh i'll try to get it to dock oh yeah i'm in mac so mac doesn't work really great with docking even though i do have a docking app that should be working uh but yeah anyway there we go this well it's trying a little bit to work there uh i think that's just one of the new kind of like ways i think people are especially like learning and you know trying to do a few more uh trying to do a few more things um another thing that i think is kind of cool was that uh when we were uh let's go back to our shell let's go to our shell dot azure let's see maybe i got rid of it let's go to shell.azure.com i'm just going to go to the web browser um a few of the things that i think's in here that's a bit interesting is is that the first thing is is that um underneath you know kind of the hood here this is just a container that's running um i did a couple of posts in the past about like you know getting into the container running some like lsb uh information to understand what's really behind the hood uh learning that you've got access to things like python which could be pretty cool and let's see if this is going to get me there let's say reload site let's see what that does for us if not i may go back over and oh there we go maybe it's thinking maybe i'm just i'm just pushing it just too hard today all right we selected a repository i mean we selected a group here um uh yeah so once you get in here you know you're familiar with like a z so like az over here uh this is just the azure cli and i was talking a little bit about you know putting that this is running you know underneath you'll see it's just a container uh you can do things like you know run python uh the lsb releases lsb underscore release dash a for architecture i believe is that it lsb lowercase a yeah so you can uh you can do this now um one of the things that i'm going to tell you about this is is that this one right here is 16.04 one of the things i've been meaning to do i've had this cloud shell instance for a long time but creating another cloud shell"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:30:21",
        "seconds": 1821,
        "text": "to tell you about this is is that this one right here is 16.04 one of the things i've been meaning to do i've had this cloud shell instance for a long time but creating another cloud shell instance and seeing if it picks up a newer vm image of this uh especially when i start to think a little bit more about like security and and some of those other uh sorts of things uh could be interesting but so this uh this a z scrolling up here this uh uh azure cli here it's the same exact you know azure cli that you have pretty much like everywhere so if i type in a z here give this just a second uh you'll see it's the same same sort of thing come on my computer maybe i've got too much stuff open today uh but yeah this this will return at some point uh while that's thinking there uh what i'm going to do is i'm going to scroll down a bit because um everybody's probably dealt with this sort of thing um you do a z uh you may type in like web out and so like right here you're seeing oh okay so we've got a z web out okay here's the next kind of like list of things uh create uh and more there was a preview extension that uh came out uh a long time ago actually and they decided to keep it in preview yeah my font still at large i wish i could make this spawn a bit larger than this um but uh a couple of the things that they did there and yeah i'm still waiting this totally has not finished returning to that's the longest a-z ever so there may be something going on weird behind the scenes here uh but one of the things is there's like the there's the interactive mode so you can do something like a z interactive uh if you do this for the very first time um so it's having a bit of an issue and we'll go check and see why it's doing that but um if you run this for the first time you do have to install it um i've done a bunch of kind of playing around in my azure cloud shield and i guess somehow i have broken it so let's see if we can resort back to there we go let's see if we're going to resort back to this instance of it so you don't have to watch me try to troubleshoot it uh okay so i'm doing a z and then just interactive and if this one's too slow we can always keep moving on to the next ones uh but yeah this should get us there i need to like the spongebob thing of like three hours later or one hour later um let me do this too while that one is thinking for a second uh i was going to just try to maybe like sign in uh over here that way i can get back to an instance of this let me go over here and let's look at this uh let me paste this one in i think my i think my login may have signed out that's okay we're going to try let's take this one at this point all of you could have signed in as me all right let's see here yeah i have no clue what is taking that top of the processing units down maybe i need to shut down a few things let's go all in with like shutting down uh let's close this type of stuff uh normally it doesn't have that big of an issue i want uh let me see if i can fix this real quick force quit oh it said application not responding get rid of a few of these force quit wow there's too many of these things uh let's see okay uh all i'm trying to do is get back to my az interactive shell uh and we would need that one closed as well alright so let's try one more thing here so we had hyper open we had a z interactive something is uh has been killing my thing here collecting power usage information come on it's fairly simple what i want to do here today powershell usage information let me see here um maybe this one was cannot import yeah i don't think i want to troubleshoot that at the moment um okay cool something happened i'm not sure why exactly uh this one is going so crazy but i think we're in there now so look with az interactive so we were just taking the example we were just taking the example over here for web app so we did"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "this one is going so crazy but i think we're in there now so look with az interactive so we were just taking the example we were just taking the example over here for web app so we did a z web app but with az interactive here this is the complete um interactive this is the name states uh experience so like web app uh create uh the next thing is is that which name would you what name would you like these are this one's required this one's required and this one's required so you can basically use this to not only just do a little bit of like exploration like you could do account uh and then i'm just doing space uh yeah clear you can get access tokens uh you can lock it set it show it uh here list and then i probably would want you know maybe for example this one and if i am signed in which i don't think i'm signed in on this one it will even help you with pulling down your subscription and all of that like cool and wonderful like information that already exist in there you can do some other kind of cool things uh you can do uh these things right here of like uh let me just pick and say we want to do there we go web out actually so here's all of them uh we can do web app here and this just sets that scope so what are you saying michael i'm saying that you can come back in and you can always do uh you know the typical over here az web app create and then try to figure out the rest of those lines or you can take a little bit of advantage over here with the using using az interactive has anybody seen that before anybody been working with this before there's a few other things that you can do just raise your hand uh and i'll make sure uh make sure i just want to make sure if anybody's had it uh great it's great that's real life that's the way work is upcoming interactive extension that might fix it usually breaks when they update cloud shell image interesting yes all very very very good stuff all right um the other thing is is that i mean obviously it tells you kind of some of the things that you can do down here at the very bottom uh but uh if we wanted to um let's see let's go in here uh sorry sometimes it's like i'm like what why is it why aren't you finishing up for me um like let's just do this one uh we could do a touch there we could do boston ug uh dot text we could come back in here we could do uh ls uh we'll just do an ls dash l on the same word text and you know there we can kind of see here you know it kind of created it basically you can run a lot of those uh those type of commands that you know and love you know right here you don't ever have to kind of leave this thing so i think that's uh i think that's kind of pretty cool and yeah you can go back scopes uh you can go back scopes and a few more type of things anyway it's something that i've been using and something that i think i've been spending a little bit of time with uh you know especially like just showing people especially new to azure um this is probably where you'd want to this is probably something you may want to take a look at okay um so a little bit of a mix here um one of the thing that i thought about today uh going into what we could do is um uh there was this uh there was this thing um azure static static apps uh okay as your static apps where are you at let's see static i know this is in here static web apps okay so this is the uh proper like kind of like uh terminology here uh let me just see first as anybody um has anybody worked with or done anything kind of in the uh in the static app space anybody kind of played around with it um or anything of that nature that'd be a bit interesting uh for me to know because i was going to show you a few things that maybe we could do with it uh not used az interactive awesome if you learn one thing i'm feeling pretty good uh green screen.websites on static apps uh let's see what this is is that just the name of it green screen dot is it a dot website is this it now i'm hoping that this doesn't pull up anything crazy security fell yeah there's definitely a security"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "uh let's see what this is is that just the name of it green screen dot is it a dot website is this it now i'm hoping that this doesn't pull up anything crazy security fell yeah there's definitely a security bill you know what thankfully i'll let this uh finish resolving but um whatever the little thing that's slowing down this pc is uh greenscreen.website i love to see stuff people built um kind of with this uh for the others uh have you done anything or seen anything with it um okay cool well i was trying to load up your site robert but it's just not liking me at the moment or maybe there it is uh okay cool i'm gonna get rid of all these red errors these things are just like not good like leave me alone uh see yeah yeah yeah so so there it is so um let me just show you something kind of uh quick here so um we just were in uh we just did a web app um showing az interactive uh if we come in here let's just see um i can kind of show you i think how fast you can kind of like start to work with something like this let's just go uh hugo boston let's go into that same uh directory here and so um hugo if you're not familiar with it hugo is a static uh is a static website like generator and so you know if you've got like windows you know you can use like chocolaty to install it if you're on linux you know you can use like brew to kind of like install it and kind of get going from there but um it's a very simple format and one that i actually love because i can kind of get up and running with this thing pretty quickly and so like um uh you can go hugo new site blog okay now we've actually got a blog created uh we can go into this folder here we can see okay cool we've got kind of like a layout of that uh the first thing is i'll go ahead and do a get in it here because um where i'm going to do is i am going to copy and paste a theme that i like uh it's at least my starting theme whenever we need something kind of like up and going that's fast so um i'm taking just this uh this theme right here it's uh it's just a generic theme that i think looks pretty good uh just because i want to go ahead and kind of get my my system my environments and everything like that uh up to speed so now that i've got a theme i've also got a site uh that's here and so i can go in to um i can go into the code config.t.o.n.l let's see here okay and so right here is the uh let me just go yeah that's fine uh nope i don't want that one coming back over here i can come into this right here and i can just add in a tiny bit of text um i can go so we can use this theme and then we'll just run it uh i could do theme here we could uh type in if we wanted to this was a n a uh let's say a-n-a-n-k-e let's see if i got that right okay so uh we just added in a theme you know all that we're going to say is like my boston ug hugo site and yes i'll capital laws this year uh and i'll make sure we got one more space over here and we'll save that file uh once we save that file um we could add like a new post here so um it's basically uh you can do hugo new post that's the folder and then we could name this like whatever we wanted to like um first post dot md and now we've got a post and now all you got to do is just run it locally so it's like um hugo server d and since i'm using uh uh hyper i actually have hyperlinks uh for this thing uh so this is basically the structure of that site um pretty simple uh inside of this you can you know you can see here's the first post um the reason i kind of like that this theme and this thing is that like you know social sharing stuff like that's kind of already built in numbering and it is super lightweight the speed performance on this thing is uh is pretty amazing so um let's see we'll mix in that we're gonna mix in a few other things this time uh let's see so there is that site it's running it's great it's wonderful we're going to do a command c here and we're going to stop it so let me go back a folder here uh okay so we got blog and let's just go hugo"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:45:35",
        "seconds": 2735,
        "text": "it's great it's wonderful we're going to do a command c here and we're going to stop it so let me go back a folder here uh okay so we got blog and let's just go hugo okay and the reason i'm just running hugo is i'm looking to get the uh a public site built um yeah and there we go i got a public i couldn't remember kind of how it was kind of like figured out okay so we're in the blog folder everybody good here so far we just created just a simple hugo uh site nothing nothing kind of crazy or anything like that uh let's put in here um one of the things that we can do now that we've got uh now that we've got this we're gonna need to put this in a repository anywhere um let me know has anybody worked with the new uh clr gh or ghclr if you have it'd be interesting to know because if you haven't i'm going to show you a little bit of magic here that hopefully will help your life uh if you're working with get a lot uh okay cool i don't see anybody that raised their hand here so uh with the github tool it's just gh and this tells you what some of the things are that you can work with uh the main i will admit the main reason that i use it is because i don't want to go to github.com and like fill fill out uh anything there so what a traditionally do here is is that i would uh go in and i do gh repo uh create i would give it a name and so we'll just use uh boston ug uh we'd want to make this directory public uh we want to give this a description and i'm just going to put this home page for boston ug and then i think i could set up some more things um on this one we we're going to yeah let's let's get rid of the wiki so enable uh wiki uh-oh hopefully i didn't do that right that should uh be a false and maybe i can just go from there okay uh oops hopefully it didn't mess up let's see here if it did that's okay uh take this let's just go home h-o-h-o-m-e home page for boston ug maybe i didn't break out of that uh before command ctrl z uh yeah don't you just love it when these things break out of it there we go uh so that obviously totally did not work create we did what uh boston uh ug here we're definitely go we need it to be public uh and then uh just for a description you know boston there we go there's something with the wrapping here um what's kind of neat is is that using the github tool and this is using my ssh key that i've already got uh i can create a repo uh i can set it to public by default it's private i can give it a description i can do things like turn on the wiki turn off the wiki i can add it to a team i could um turn on and off issues i could actually create an issue completely through the command line so since uh i did this whole step to avoid using github now i'm actually going to github so here is the here is the repo and we're going to go over here to the repositories uh just kind of show you how kind this thing works there is my amazing description and as you can see it doesn't have a little profit mark uh here anything like that so we're in pretty pretty good shape um at the moment so uh what we would need to do in order to start working with like static websites or whatever is is um now that we are here uh we do have our public folder which looks good i would probably uh i'll probably go ahead and go into public um and then let's just look here for a second okay i think i'm okay uh i'm just gonna go here and then uh get ad period because we want everything uh we'll go we probably want to get commit uh a.m and then initial commit does anybody like put good messages in here i don't know if you look at like some repos uh putting a good solid message in here seems to be like missing a lot initial commit like okay that's a that's great uh and then i"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:50:38",
        "seconds": 3038,
        "text": "here i don't know if you look at like some repos uh putting a good solid message in here seems to be like missing a lot initial commit like okay that's a that's great uh and then i can do uh git push we're going to do dash f because we're just going to just force it actually we didn't have to do that and then it's like the get at github.com uh let's see here in the crump you know you can get the ssh you can get this kind of url if you wanted to uh through um uh the github uh type of browser dot get and then we want to push this into our master so uh if everything worked well uh we should have something kind of going on here um one more other kind of cool thing you can do with just gh is you can also uh do a gh on a view and be able to like view read me's and a few other things um okay so let's refresh here and okay so the main thing that i pushed in here was uh was the public the reason i went in and just pushed everything in here is we're about to use github actions does anybody use uh github actions or is played with any github actions yes thank you bill that's awesome that's the link that we needed uh if anybody's played with like github actions so um github actions by default uh they're kind of hard if you click over here in github actions there's a couple level on this like okay you know you can start with some of these workflows one of the things that we do with azure static apps is is that it goes ahead and it takes care of the hard things like build processes um uh you know when there's a new change to the repo recompiles uh redeploys recreates that public folder and stuff and so i don't know one of the reasons why i thought that we'd swing over here kind of fast uh just to look at it was that with the static apps i can come in here and just want to walk you through a tiny bit of this uh create resource groups if you're like me uh i use this one rg underscore delete me primarily because uh i usually have like scripts that will run that will delete this resource like tonight my time uh i there's probably i think there's another one in here yeah delete me one uh anyway that's just good practices uh there's automation tools and actually i've got scripts i can share with you if um you're like me and you don't forget to delete resources uh for the name here boston ug oh yeah you can't put that you just do this one uh for the region i'm over here on the west coast uh oh i forgot so um i'm gonna have to refill this out a little bit because uh you have to be in the production portal and where i'm currently at is one of the previews of this thing let me sign back in uh it's okay i wish it carried over but it does make me refill that out but it doesn't take for just a second all right switch it over to the production portal do anybody have any questions as we as we're going okay just wanna i wanna make sure um of course uh yeah yeah yeah of course of course of course this is uh the wonderful things of everything uh asking you to re-sign in again let's see here uh let me get this one going for us you can see i don't really spend a ton of time in the production portal uh let's see here gosh uh yep let's see where are we just at here let me try this one more time let me just hit this button actually we'll go to our portal.azure.com actually it's this one oh this is actually kind of another um tip in and of itself is that as you can see right here we do have features that you can turn on and off uh you know while it's already doing this um there is a feature flags that you can turn on and off and just while you're here if you are ever in the preview and you want to get into the public portal that link right there if you examine that that will take you back over to the public portal and i'm just going to run it while we're here don't you just like tips within like tips aka ms uh no not that one"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "00:55:44",
        "seconds": 3344,
        "text": "if you examine that that will take you back over to the public portal and i'm just going to run it while we're here don't you just like tips within like tips aka ms uh no not that one i want to go to public portal uh we'll run this one uh as you can see this is the well it just flew by but this uh there's a feature flag that gets rid of all the preview stuff let me see if i can log into this one it should let me into this um i don't work that often in the in just the public one but it should allow me into this you need to use appropriate certs okay so that's okay i've got i've got another way we're going to get around this aka.ns public i tell you um one of the cool things is that you get used to like finding alternative ways of getting around for roadblockers uh yes i do have a couple of private accounts as well security for the win and i've been doing all these streams on like security because i'll just save this default password uh awesome you know it's kind of like people that like do like lawn work or whatever their own like house looks like a complete utter mess but like what they do for other people it's like amazing uh okay so we're gonna go static web apps again click here uh inside of this i'm going to go add and this is i'll be able to kind of show you a little bit more of it now this way uh resource group we're going to do delete me if there's not already one maybe i've created looks like we're good there we're gonna go back to paulston we're gonna go back uh just west for now we're gonna sign in with github uh now i'm signed in so why did i do all this really i really want to show you a bit about how easy it is to kind of switch over and do this so uh mb crump here uh inside of this uh let's just go for what was it paulston yeah this one boston eugene uh we deployed this on that on the master branch if i go to this next screen right here this is a very important screen it's looking for the default location ours is just in the github root uh the folder and that folder was just called public so we look over here uh this one we'll see this is the public folder and we're supplying the path without now what's interesting here is that this is for azure functions so you can have a static app and call azure functions um we're not going to do that here and i'm just going to leave it as just api uh here is where you can go ahead and set up your tags we'll hit review actually we don't need review we just need create and then create and our deployment is starting so what's happening behind the scenes here okay there's a bunch of little things that's happening um if we uh if we look at it there has just been a github action that has been uh completed uh inside of our repository because we have it rights uh that it can go into that repository the next thing uh that is happening here is now this static web out has given us a url so this url that's over here uh it says hey it's live and waiting for your content all people are like why is it why aren't we getting anything in here yet and that's just simply because um if we look at this one and we go into like configuration let's see here um let's go into environments it's one of these uh what yeah so here it is this one so what this is saying right here is that hey there's one production environment for out uh it checked and it's waiting for a deployment so uh going back and taking uh let's see let's uh let's take a look at our directory again so we're gonna go into content and now that we're in content we're gonna do an lsl we're gonna go into post and let's see what we got in here okay cool so i'm gonna do code first post dot md let's load this one up into visual studio code and this one i'm just gonna put um boston ug first post and then hello hello world uh or save that one out that should look good there um let's see what else will we do now uh yeah we can come back over here and we can do the um i don't know just the quick version to kind of get it back in to our repo we can do our get ad here"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:00:48",
        "seconds": 3648,
        "text": "yeah we can come back over here and we can do the um i don't know just the quick version to kind of get it back in to our repo we can do our get ad here um we could just do that just to get commit again um you know update blog post uh and then we can run the command that we were just running to push um uh yeah actually let me just back up a few lines and see if we've got it still in there uh that one and uh yeah we're done it should be in there so what we'll see now is over in our uh over in our uh screen here we do this refresh button uh okay by that time you just saw it's already says ready i come back to overview and then i'm just clicking on this one we should have our site uh okay we've got our site uh cobblers good tip within the tips my company has some things on private preview cobbler shoes uh so we do we have our site uh the reason you're not seeing a post come up it's prob this is probably a good thing uh i think that's gonna be a date related issue so uh coming into this one let's just refresh this again let's go boston eugene we're going to go into content post we will look at this first post here uh the date on the server isn't the same uh current date so if we what we would probably want to basically this time so-called hasn't passed yet so instead of it being um let's just do this let's take this one i'm just gonna make it easy go back here we'll do this uh for like a month ago we're gonna go paste we're gonna go copy and we're going to switch back over let's see how fast it can do it let's go with this one nope not there yet i just wondering what the speed is from picking it up recompiling it and then putting it back out there and being deployed i did that in line i think yeah i did commit that online okay so uh it's not showing me the crazy speed unless i've got another error uh in this uh somewhere else go over to the environments and then what do we have here uh still sounds ready browse okay so there may be something else that i'm missing uh why that first post isn't showing up there does anybody know oh there was a flag in there that said draft you know what i'll do since i kind of like i really want to show the speed here let's go edit uh edit and let's change this that was totally it false uh and let's scroll on down let's commit now let's see how fast it picks up this time commit all right done let's go back over here on this one uh we're gonna hit refresh i'm pretty sure this is gonna do it refresh that was totally set to false interesting there's something that totally has uh that has to do with that that's why it's not uh returning back i thought it had something to do with the date uh but maybe not also it could be caching uh we could go right over here we can go with cognino uh and then we could try it one more time over here but basically i think you kind of get that it's pretty easy to get up and started especially running with these static web apps okay let this finish loading okay it doesn't show it but the one last thing i'll show you on this topic is that back over here uh inside of the repository if we go in and we look uh actions here's the workflow uh [Music] yeah there's a little bit of um a delay here uh here it is it's down here at the bottom yeah so here you can see here is the current job so build and deploy job uh here you can see what did it just do it set up a job this is the virtual environment it came in here and it built a container just to use it ran a checkout so it checked out everything that was the latest stuff that was in here so you can see this was the commit number uh it did a build which we totally needed this build the build looks good same sort of build output that we saw over here when we ran just the hugo thing when you run uh hugo actually i need to go back a folder but um uh i"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:05:52",
        "seconds": 3952,
        "text": "needed this build the build looks good same sort of build output that we saw over here when we ran just the hugo thing when you run uh hugo actually i need to go back a folder but um uh i actually need to go back to folders okay uh basically this sort of thing right here uh you can see this came over here knew what it was knew what to do um and we have our post run actions then we wrapped up a bit here we're just completing uh the job so um i don't know cool what do you think does anybody think this may be kind of um a useful thing i think where it starts to really shine is is that when you kind of get over here there is a so john papa created a angular let's see what was it it was angular learn dots azure static web yes all of those words to find what i'm looking for uh let's see what this comes back with if you want to learn more about the function like piece of that totally could uh learn more about the the function of you know the function piece he's probably got a link to it in here and it's probably even in this post um right here anyway he did some kind of cool things where he wired up um an azure function uh to talk back and forth uh to the database and stuff so um could be some kind of cool stuff for people to uh to talk about let's see how much time we got i think we have uh what about 11 more minutes um i tell you what if anybody has any questions like i said feel free just to drop them in kind of as we're going uh so i think this probably would be the link to that um that site i'll take this one paste this in here uh and there that goes yeah anybody's got any questions let me know the github cli is totally something that you should take a look at uh using and i think that would be uh i think that some of that would be a ton of fun uh okay very cool so um i kind of liked the whole thought of kind of like playing around seeing like some of these other sort of stuff uh one button that i didn't uh i didn't check out or i didn't show you was that let's go back into uh this folder and i'm gonna go into boston ug uh and now that i'm in there there's this button um does people have this button yet maybe i don't know uh this i thought is supposed to be special but maybe it's not special anymore or has anybody seen that button i'm just going and verifying uh over here like the demo thanks to you um uh so okay so i don't know if this is by default what i did was i just took a uh incognito here but um if you don't uh you know you can totally check take a look and look here but um you may or may not have access to this green button uh but then there's a couple of pieces in here that i think is a bit interesting and kind of you know like new kind of like um you know kind of like as we go oh the beta limit two's been reached uh that's okay uh i'm gonna delete that one uh i'm gonna delete some of these other ones there we go we're gonna hit new uh oh i've already eliminated all those um yup delete this one code space uh that one's okay i'm gonna delete it i'm still saying it's like okay you gotta get rid of another one i want to get rid of that let me in please so this is going to be a cool kind of like experiment that we could look at um let's see here looking at bill's screen here is is that uh github desktop yeah so what uh what was missing or what's missing on that one is is that um i'll just take this repository here uh is is that this little drop down there's this thing open with code spaces so um this is uh this is something that was talked a little bit about that build but i thought it may be kind of interesting just to kind of go in and show you a few things with this you know i apologize about the internet speed uh i'm not sure maybe i've got to kick my son off of a fortnight fortnite's killing it i don't know the whole computer's having a bit of an issue um but think of it like this um is everybody still able to hear me okay one thing i need to check is uh up for four percent let's do this really quick let's see if i can get this to work uh okay i bet you can hear me pretty good now hopefully you can hear me"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:10:55",
        "seconds": 4255,
        "text": "is uh up for four percent let's do this really quick let's see if i can get this to work uh okay i bet you can hear me pretty good now hopefully you can hear me pretty good now make sure these picked up okay uh disconnect those other ones perfect okay uh so we have a repo that was yes i'm good at keeping a bunch of stuff open uh let's do this let's go over to github and we're just going to go right back into the repository we were looking at uh repositories and then we're going to go boston and uh we went here and we went open with code spaces uh when we did that this is what we have now so um what's kind of interesting here is is that you know if you have like you know visual studio you know code you know you can think of oh okay cool so there's a bunch of things uh here that looks really similar to the things that we have over here in this one um and with this uh code space uh what's interesting is is that this is basically visual studio code within a browser connected to your github repository that can have all of the existing extensions that you already have it can have all of the like the live share functionality uh that you would probably want if you're gonna let people collaborate and so what i'm going to do here is i am going to start a actually we'll just do read only for today uh i'm going to start a read-only session here and let's see now i've got an inbox code and so i kind of like to having something sometimes interactive for us to kind of play with together and you can teach me things too because other totally i don't know at all but if you click on that link you'll be invited to a read-only kind of like session with me and there is nothing in this repo good night uh ricardo thank you for spending time here with me but if anybody clicks on that and they join in we can see them adding in uh which is a bit interesting because when they're starting to navigate throughout this code that we have here uh so look this is just the good old fashioned html file and uh we would be getting color highlighting but i think there may be something that's preventing some of that color highlighting we can see like we've got uh uh an m for modified a file over here uh there's a site map that's also been modified um but what's kind of interesting is is that if i run into a problem and i wanted to get some additional help on it um let's just say you're with your family you're at a red robin which is uh which is uh it's a kind of a popular thing over here in washington um you're in red robin and uh you need to connect to your code base for whatever reason uh your uh husband or your wife is like screaming at you for like connecting up but you've got the kids or whatever you can basically take your environment with you wherever you're currently at so uh yeah so hey sean uh vs code online is it being served or running in assembly that's a really good question um so i don't really i couldn't really tell you the answer there so this uh uh this is a well it's a complete web browser based uh experience so um you know web assembly is what i'm thinking there uh yeah i don't know if that helps or not but um yeah it's just a web browser base so it looks like we have a guest uh and so let's see let's go to our uh let's go to our collaborators here hey there's jason so uh jason um if the two of you uh bill there we go that's what i wanted to show was that if i have a couple of you in here um as you're kind of like highlighting stuff or maybe even as you're working now i should have turned it to an edit session um as you're starting to type stuff in here or highlight or whatever i can kind of see where you're at um in the code and so obviously this is you know you've got an application you know you may"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:15:59",
        "seconds": 4559,
        "text": "um as you're starting to type stuff in here or highlight or whatever i can kind of see where you're at um in the code and so obviously this is you know you've got an application you know you may want another person to jump in and kind of like you know learn understand more uh you can do that let's see let's accept uh steve jones you're in everybody's in actually this repo could have been added because there's it's nothing in it but just our a little bit of like sample code um okay cool so uh here's kind of obviously like where the files are at uh this is the current like changes um uh this is when we want to do things like run we want to do a little bit of debugging there uh these are the extensions that i've been using at least so far these extensions do carry on with you um for the cloud hosted spaces uh so yeah i said that i'm in a beta so i only get two but what's kind of cool is that down here you can re-forward ports um what is the name of the tool that will allow you to uh put ports local ports back over to um ng uh let's see oh this is it's uh this one uh ng rok let's see you know there you go grog yeah so i use this one uh quite a bit uh so tunneling and stuff like that yeah there's a ton of them there i mean there's a ton of these things um this is just the one that i've been using for forever uh they also let me use it for free forever so yeah it's yeah you can use this forever but instead of having to use this tool obviously you wouldn't need to do some of that because you can re-forward those ports we have a few videos i think where we we kind of dig into that like issues uh we come in here we could hit this one uh we could add an issue to this repository here we could save it out you can close out of those uh this just shows uh yeah this is just me signed in uh and then down here uh user snippets so think of this you could like share oh yeah jason is doing a feature here on focusing uh my attention and so i believe that's you right there i believe uh but you can you can bring somebody over to it so while i can't show you there's uh uh the others like shared screen uh but i could be in here into a document uh oh that was just that other thing i could be like inside of a document here and if i want to go in you can see like timelines uh this timeline right here shows when the initial commit was yeah there won't be any changes to this one but if i go in and drill down into like this one for example and i open this timeline uh timeline it should be starting to show a couple of different actually let's go into the markdown file where markdown's in content this one maybe this will work uh let's take the uh timeline here there we go so this is another kind of quick version where you can tell kind of hey here was a couple of the changes uh that we made here's the ones that we made you can kind of do it all within uh all within this code space there's a ton of stuff that i kind of left out but at least it was one thing that i thought that um whether you may kind of enjoy you know seeing that you can do a lot of this stuff through your browser and that um i've also spent a little bit of time using this on my um ipad so uh there's many many ways uh okay i think i'm about at time for today uh i did have a few things that um that may be kind of interesting uh to to explore um i did a tips and tricks on security i know all of you are like i dude i just watched this like there's no security going on there that may be true for my personal like uh uh workflow here but there is uh there is some like security best practices it's something i've been doing and enjoying a bunch kind of on the stream here uh so yeah there's some of these uh i recently did this one on secure using azure functions with key vaults and the one that i really wanted to show you uh was this one right here and this one is that basically you can work with the billing apis you can set up different things um to make it easier i don't know does anybody here even use the the billing apis or even know that they like existed um the billing"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:21:04",
        "seconds": 4864,
        "text": "can work with the billing apis you can set up different things um to make it easier i don't know does anybody here even use the the billing apis or even know that they like existed um the billing apis um they're very interesting let's see if we can find one uh let's see if this one does it uh cost yeah actually this one should get us there uh see looky there i've just found a bug in the program or in the application uh here are some of the queries sometimes it provided you a sample of how to grab uh the data let's say try it uh so here's an example of doing a post request external cloud i may not have any data in here uh but the billing apis really it's really a lot of it is just it's inside of this uh this post right here where you can query these things you can set up all the different types of parameters i've got a few samples of how at least i was playing with it just to return back some data but totally totally worth um taking a look at um and then you know talking a little bit about you know maybe like you know personal like stuff is uh this one for certifications um so certifications obviously there's a lot of different ones probably most of you already have uh some of those um those type of certifications or you may have some of these but like um i was looking at a way you know i know most folks are wanting to get some sort of jobs or you know i work a lot with one consulting company and they are strictly they were heavy aws and right now they're trying to meet some of the demands that they're needing for azure and so um anyway these sort of like certifications is at least some of the things that they've been thinking about um i've only done two of these uh i did this one which which it's pretty easy and then just the developer one um but yeah this is also just something else uh am i doing any live sessions talking through azure security best practices you know no not at the moment we do a tips and tricks um on wednesdays on twitch and during that time tomorrow for example we were going to spend some more time back over in the command line uh there's a bunch of stuff i think we've kind of not never really spent time with there but yeah i can totally see in us doing a wednesday episode uh of maybe diving into this one a bit more and also i mean i've started spending a little bit more time with the security team okay so i do have a present for everybody and i get nothing for you downloading it but um last week yeah friday um myself uh and uh chris from build five nines we released an updated version to this book now i'm sure a lot of you probably already knew a lot of the basics and stuff like that but um this is a book that um i think is is is especially good you know if you are in the consulting kind of like world uh we just updated uh this uh so all of the newest latest and greatest stuff uh is in here uh and then uh obviously um and by the way i'm just friends with chris uh no nothing else outside of like there's no like other uh hidden things there uh but chris also writes about it um and i also think that chris's uh site here is probably a very useful uh resource um that you could uh go to um and then uh yeah and so uh there so there's a couple of uh you know you can kind of see you know he does a lot of write subs i think chris just spends like all of his day like authoring content because he's like so much faster uh than i am on a lot of these things but um he has a great sight um the last few little pieces and by the way jason you can tell me to be quiet if you want me to i will of i'm trying to keep going man i'm on i'm on pretty well uh i have had a couple of folks that say okay where do you go uh where's kind of your favorite few places to go for um like azure news where do you go um i usually go over here into alvin ashcraft's site here i look at alvin's site uh primarily i spend more time in the web and clout development piece uh obviously you're probably familiar with like morningbrew.net uh what is it i think is that the name of"
    },
    {
        "speaker": "",
        "title": "Michael Crump: Azure tips and tricks: Become more productive with Microsoft Azure",
        "videoId": "J1kjBFXLAuw",
        "description": "This is a recording of the August 11, 2020 virtual meetingAzure tips and tricks: Become more productive with Microsoft AzureJoin this fast-paced, demo-heavy session, which takes you through some long-standing favorite Azure tips and tricks (http://azuredev.tips) since the series started. Whether you’re interested in learning quick ways to navigate the Azure Portal, making the most of the Azure CLI, or working with IDE and editors, there’s something for everyone. Spend the time now to shave hours off of your coding tasks tomorrow.SPEAKER BIOMichael Crump works at Microsoft and is a coder, blogger, and speaker of various software development topics. He has a passion for a wide range of technology stacks that involve software development and ethical hacking. You can find Michael on twitter at@mbcrump or on Twitch at https://twitch.tv/mbcrump.",
        "start": "01:26:11",
        "seconds": 5171,
        "text": "i look at alvin's site uh primarily i spend more time in the web and clout development piece uh obviously you're probably familiar with like morningbrew.net uh what is it i think is that the name of it morning let's see what it says uh chris alcock is his name the morning brew i always get these confused morning dew morning brew anyway um he has a nice little site where he doesn't focus completely on like just azure content he has a lot of net uh kind of like stuff that's in here that's a bit interesting um you know i totally go to like one of these the last few sauce i'm just trying to give you a few resources that i think could be helpful um azure weekly dot info uh this is a newsletter um by engine uh i met these fun folks uh we actually got to hang out a little bit uh they have a weekly newsletter if you don't want to subscribe don't subscribe uh but you can always come back in here and you can grab the latest issue and it has a nice little roundup of what have what has everybody been kind of like talking about in the last last little bit so um just drop this one in here too uh come on paste and there you go uh i don't know those are just a few of the sites that just comes up off the top of my head uh well cool uh yeah i think that's pretty much it uh i'll stop for for now uh yeah we can there's there's so many like avenues to like explore and uh and to learn more things so um yeah i think i'll stop there cool make sure everybody's okay here uh if anyone has a question you can answer yourself yes don't be shy and also if you just want to type it that's fine as well too i have had folks that prefer just to type so it's totally up to you looking to see if there is anything um anything else that maybe we could sneak in here but i think i may stop there for the moment anybody uh cool so uh excellent so um if you want to find this repo again hey i saw somebody light up go ahead and talk sorry azure dot tubes oops this one right here uh that one and then also http s uh twitch.tv and b chrome uh those are the those are kind of the places if you kind of want to find me i love twitch we do ridiculous uh things on twitch all the time uh my raid video uh it's basically reading the concept of a bunch of people coming in your chat room or coming to your stream all at once uh i did some funny stuff with fbi raids there so yeah i don't take myself very seriously at all so hopefully this uh helps oh that's a nice list it's a very nice list love it bill that's great oh yeah the other one that i didn't mean to include is uh let's see dev.2 uh this one sometimes i post over here um i don't know i just kind of try to find out where the kind of community is at but this is one place that i've been posting some stuff to um and for all of the cloud shell like colorization and some of that other stuff all that's documented in here i think my computer now at this point is like i'm done with you uh let's see here loading uh yeah anyway i'll just give you the short version here and that is just this link oh he's already got it i see it now yes i see it excellent get a pc i do if you watch me on my streaming i've got two really powerful pcs uh and i totally totally love my pc uh it worked you know what's funny is that like so this this isn't my computer this is a work computer uh i own a variety of different pcs um but yeah uh love it love it love it yeah for work we have to do a bunch obviously you got to be on there you have to be on every platform and so there's some days that i need one machine over uh the next and as you can see my vm is is sad it's like please work and it's not uh working so uh yeah i gotta see what's uh what's kind of going on there uh well very cool uh i would appreciate you know anybody's got any uh comments or anything like that after after this uh you know you can always find me on twitter um i usually uh i'm on there quite a bit um i have pulled back a little bit uh but you can send me a dm my dms are completely open well to love to have love to have you that was awesome thank you so much michael it was amazing people are happy i am super happy we learned a lot um and i think we'll just stop there recording no yeah so thank you all thank you all for this i do greatly appreciate "
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Application Insights The Tool You Never Knew You Needed. This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.. at the uh boston um the local meetups um back when i lived on the east coast i used to live in a little town called norwalk connecticut and i used to um come up occasionally to boston for work and if there was a scenario where i could presented a meet-up i i definitely would do that um but yeah so my name is isaac levin i think bill did a really really good job of introducing me so i will not bore you with the gritty details what we're going to talk about is app insights um these are my social handles if you do want to follow me i do stream on twitch as well um that's not listed here but i think one of the things that i just want to call out a couple of few things so i used to work at microsoft so folks um might know me from there if you've heard my name before h work on microsoft now work at a company called elastic which specializes in my opinion and probably the best search out there lots of companies use it even companies have built other search products using elastic technology so what i do is i run up marketing for uh a product they have there i'm also the the chairman or not the chairman the the chair of the marketing committee for the dot net foundation so if you feel like you have a passion for dot net and you really want to make net better you know join the foundation whether you're a member paying dues or part of one of the committees the marketing committee is always looking for people to chat with and have great conversations about how we could do better with the foundation in dot net in general so yeah so let's get to the real meat of it right so quick thing this is not supposed to be me talking for 45 minutes to an hour by myself if you want to come off mute if you want to use some of the cool emojis that exist inside of teams please feel free to do so uh i can't imagine listening to myself for 45 minutes to an hour so i please beg of you to give your colleagues a little break um with maybe your voice or just some conversation as well so before i start talking about what app insights is and the value proposition it is i just want to get um a quick test of the room and two people know what telemetry is so i'm gonna say this uh phrase or this word a lot through our conversation today um so whether you wanna come off mutants and say it or if you wanna drop in the chat what you think telemetry is because i'm gonna be talking about a lot of one make sure there's a pretty good grasp of what the term means cool there's silence all right so that's fine uh so what telemetry basically is uh in a nutshell is it's collecting data on an instrument it's typically used in the the physical world uh but when we talk about telemetry it also means that what is the the data that our applications create not the data they leverage you know whether that's data in a sql database or in mongodb or cosmos or some other non-relational data but like the actual data that your app creates so for instance cpu utilization error messages stack traces miscellaneous logs that exist you know whenever you use some login providers right so these are this is stuff that your your application creates and you don't especially leverage it by default and this is an opportunity for us to talk about how we can leverage it better by default somebody talking about telemetry a lot and when you think about telemetry it's just the app or the data that your applications create all right so moving on so we have a quick poll here uh please put stuff thumbs up in the chat or use emoji so who here writes web apps anybody does anybody write web apps here all right yeah it looks like some people are right right web apps that's great so client server both i think for the most part in this day and age if you work in.net you've done some development in the web space so apps deployed to the cloud right so who here has the opportunity have deployed their apps to you know different cloud providers obviously the one from microsoft probably being the most notable especially for this group um but who also is deploying their stuff just on-prem just servers that exist in their local infrastructure great great and and who uses an existing apm application performance management utility so some really really well-known products out there new relic at dynamics elastic the company i work for also has them survivability platform who's used these in the past awesome so when we talked about telemetry earlier and kind of the data that your application produces who's used telemetry collection mechanisms you know there's a handful of great packages that exist for net analog log for net uh who have used those all right and who here knows about app insights hopefully some people know about it otherwise i don't think there's any real reason to come to this talk other than maybe learn more okay so as we get started i want to just think about some rhetorical questions some questions that i feel like after this"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "hopefully some people know about it otherwise i don't think there's any real reason to come to this talk other than maybe learn more okay so as we get started i want to just think about some rhetorical questions some questions that i feel like after this talk we'll have a better understanding of how we can potentially answer them i'm not going to go through all these obviously i think one of the things we really want to come out of is that how can we bring value to folks um you know whether that being you know get an understanding of where peop where our apps are being used all over the world like if you have a web app you know you obviously can have customers all over the world you know where are the areas of our application that are being used frequently and unfrequently right do we have an opportunity to better our user experience based on some data what is app insights so app insights its holdest form is the application arm of azure monitor which is the monitoring or observability platform that's built inside of azure so what it allows you to do is it allows you to collect all that data that i that i've been talking about and and store it in azure for a place for you to be able to query and gather insights from in app insights it supports a plethora of different technologies right obviously uh in a microsoft world if there's not if there's not great.net support there's probably something to be concerned about there but there's also existing managed um packages for java for node regular static javascript which includes html and css and application insights in its purest form it's a set of rest apis so there are a handful of different um i guess deployments or in developments that have existed that use app insights you know whether that's a desktop application um or python or php wordpress there's some really great examples out there on the internet um of you know using different technologies to consume app insights when i talked about what kind of telemetry right the application insights collects and this is by default right i want to be 100 clear if you line up app insights today you will get all this telemetry being collected by default for your application so things like request response data right so being able to see load times and routes and all that sort of really important information dependencies so any of the things that aren't in your app that are cons that your app consumes whether that be sql or azure storage or anything else reg caching page views and load time this gives you the ability to get a better understanding of where users are coming from and their experiences as they use the web application of your site user information uh not pii or personalized personal identifiable information but information that can really help glean you know what kind of users are using your application exceptions so being able to see things like stack traces error messages things like that performance data like i mentioned a bit earlier cpu ram uh network and one really interesting thing about app insights is that the structure for it is a is a is non-structured json so what that means is that you can actually send any sort of data to app insights for to collect and those are called custom metrics and we'll talk about a little bit about that in a little bit but just think about business data or domain data that your application might look to leverage that you want to include as a part of some of the things that you're doing with with app insights this is an overall flow of what app insights actually does i think what this is really really valuable i stole this from the docs on microsoft.com section of app insights so everything on the left-hand side are kind of the things that that happens that your application collects right you know whether that's information http requests from your web apps or dependency calls from external services it sends them through an api call into app insights which is that big purple box in the middle and on the right hand side all the different ways that you can expose app insights data for yourself and for your customers okay well i'm interested so it's got to be super expensive right you're talking about collecting all this data giving me all those great insights like there has to be a pretty good price tag no it's pretty um cost effective at scale right so when we talk about what the pricing is for app insights it's five gigabytes of ingress and outgress data so that means data going in app insights and data coming out of app insights of up to five gigabytes per month and if you need more than that it's two dollars and thirty cents per gigabyte per month you also have some additional things like multi-web step tests and ping tests that are available depending on your needs one thing to call out is that it by default it says 90 days of data retention so that means how long your data stays in app insights well you can actually configure this up to two years in the azure portal so in the situation where you need do any historical data you have the two years of that that you can store um and one thing that's really great about app insights it's it's free to use for pocs say for instance you're at a company and you want to take advantage of app insights but you might be concerned about the price point or things like that i can rest assured more than"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "about app insights it's it's free to use for pocs say for instance you're at a company and you want to take advantage of app insights but you might be concerned about the price point or things like that i can rest assured more than likely you're not going to go over five gigabytes per month per instance of app insights per month um just doing a poc and then obviously if you have a web application in production that's using it over time yes you might need to scale to over five gigs but like i said it's fairly cost effective and like in what like i mentioned you can have multiple app insights resources in your azure subscription and they don't all use that five gigabytes they all each have five gigabytes to use all right so it's got to be complicated right turning all this stuff on lighting up all these different things to be able to collect all those different kinds of telemetry well obviously it's not very challenging so there's a handful of ways to set up app insights and i like to use kind of two canonical personas right so there's the individual who has access to the code base aka their developer or maybe they're somebody who just has access to the code basically configuration changes there's that individual and there's the individual that doesn't have the code at all and they can make they can't modify the code they can't deploy the code again to their environment maybe their source code is gone for whatever reason so both those personas have options to survive app insights and depending on where your app is hosted it can get even easier so the easiest way is you can enable the app insights extension on azure app service directly so in the situation where you have your application already hosted in azure using what uh app service you have the ability easily to go and click on the purple banner or click on that little app insights box and that's going to take you through a wizard and that wizard is basically going to say turn on the site extension i'll do that it's going to ask you to configure a location resource group for your app insights resource to be created and then once that's done it creates the resource and then your application your web app is actually wired up to send telemetry data to that that's it nothing else you need to do obviously that's the quickest scenario um you don't have all of the i guess you could say full fidelity experience with app insights like being able to add custom metrics and things like that but out of the box you're able to collect a lot of telemetry right away which i think is super valuable so if you don't have the code that's an option for you if you do have the code you can use your your favorite ide you can use visual studio to actually configure app insights locally um just right there from within visual studio so you right click on a project you click on application insights telemetry or you click add and then application size telemetry it'll take you through a wizard of setting up the app insights resource um in azure or you can actually do it locally as well if you want and then after that you have three green bars of success you have the sdk that's been added your application has been registered and published annotations have been configured which allows um some really really interesting data to be sent through to when um application insights ingest some of those things like exceptions finally don't have the code not an azure what can i do so you can actually take advantage of app insights as well from on-prem iis using a powershell module that exists called application insight status monitor so like i said it's a powershell module it's coolest instrumentation of dotnet web apps hosted on ios so basically it's powershell comm powershell commands that allow you to instrument your apps that have already been built so these are built binaries applications so just dlls or maybe some exe files and some configuration files right and along some and though that allows you to instrument them in a way that allows you to get some of those features that we were talking about earlier so like i said there's a handful of different options depending on what your scenario is and i want to one of the things that i want to do when i showcase this demo right here is that i want to point out it's not just like the newest versions of net right so i know a lot of people probably think oh this is probably only available for like dot net 5 or net six right this is my web app it makes me a lot of money like as you can tell it's hosted in azure it's got great ux experience it's written in.net framework 4.7.2 i need this app for my business to run effectively and one of the things i think is really important to call out it's hosted in azure yes but it's dotnet framework so i want to be able to get some better gleanings of telemetry from this application so what i can actually do here is i can actually open up my web app in in visual studio so as you can see here this is the dot-net framework way of doing things so there's a global asx file and web.config and there's all these things like app data and appstart these things that honestly i haven't looked at in"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:15:10",
        "seconds": 910,
        "text": "in visual studio so as you can see here this is the dot-net framework way of doing things so there's a global asx file and web.config and there's all these things like app data and appstart these things that honestly i haven't looked at in probably three or four years but i really want to show you that you can light up app insights for dot-net framework applications as well so the first thing i'm going to do is i'm going to go and i'm going to right-click on web application and then i'm going to sorry configure application insights and then after that it's going to ask me a couple of questions it's going to say do you want to configure application insights locally or do you want to actually spin it up and use azure right so you have two options here right so i'm just going to say i want to do it in azure so i click next and that's going to reach out and look at my different environments i'm going to pick web application here which is the name of my app insights or my app inside resource that already exists i'm gonna click next i'm gonna specify that connection string in here click next and then it's gonna tell me what am i what it's actually doing right so as you can see here so whoops so oh man i'm losing it today so there we go so it nuget packages update some project properties put some stuff in the store put stuff in settings so basically it lights up your app for you i click finish here and that's going to actually do that it's going to add some dependencies to our application and then it's going to add some settings to our configuration variables and then after that we're going to basically have an environment that's lit up with app insights right out of the box and then i can deploy this to azure and then my application that makes me a lot of money that's written.net framework it's still going to work and it's still going to have all these great things tied to it so i can just show you here so as you can see let's just zoom in so there's a handful of microsoft.ai and microsoft application insights right so these are these nuget packages that were added to our application in order for it to run successfully there's also some changes that were added to our web.config right so like there's some secrets information there's telemetry correlation html module these are things that allow us to actually work with app insights in the dotnet framework world and after that it's just a deployment and things are good to go so that's really really really cool um but there's probably more interesting scenarios right so i'm going to close out of visual studio here and i'm going to open up a different application let me just close some tabs here as my computer is starting to get really really slow for some reason all right go away go wait i think we have a couple of questions in the chat sure oh wow there's lots of questions okay we can take it we can take a second and answer some of these let's scroll up to the top uh catherine moss i understand how it works app insights is somewhat like the devops monitor sentry except the latter is on premise versus in azure um that is correct right so century actually is an apm as well and the only real difference between you know whether it's elastic observability or new relic or app dynamics is where the data is actually hosted in sentry world yeah you can specify you know an agent that's you know somewhere in your environment that stores that data app insights the data's just stored in azure so pretty pretty solid so can this also be used in a hybrid environment or azure setup along with your on-premise stuff i just showed um using the app insights status monitor you can actually light up um on-prem non-azure instances of your web apps to actually send data out there the data sits in azure though so i want to be 100 clear so if you're not using azure today it might be in your best interest to look at other options but if you're already in azure and some of your apps are in azure some of your apps are on-prem take advantage of app insights in the greater azure monitor um umbrella could help you out a lot there now does that work for other stuff so like uh you mentioned about uh you know exe files and dlls but what about like what about like php and python because a lot of a lot of my stuff is on like wordpress and a bunch of other random stuff yep like i mentioned earlier right so there are libraries that exist for a plethora of different technologies not just.net so php python i believe there is a wordpress one regular javascript no i will have to play with that i think that's going to be fun all right so moving on uh what is the recommended deployment scenario do you deploy one instance of app insights per say a region or do you deploy it to a specific workload it's definitely workload uh workload based jeff um and so you know one example that i like that i see a lot is depending on environment right so you have an application that has three environments has like test staging and production you can have different app insights resources for each of those different environments and"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "so you know one example that i like that i see a lot is depending on environment right so you have an application that has three environments has like test staging and production you can have different app insights resources for each of those different environments and that way your telemetry is separated out and you have that ability to granularly look at different scenarios um one also thing that's great about app insights is there's this concept called distributed tracing which allows you to connect lots of different resources all into one app inside centralized resource and then you can see um and i'll show that what that looks like in a second kind of like the dependency flow between all these different applications um and that's really really powerful all right what else do we got here adding insights to app service does trigger an app restart the one time that's good that's a good call out if you do go down the path of doing a deployment or you do anything in the um azure portal usually in configuration for an app service you do need to restart so it is one of those things that if you do decide to do it make sure that you uh have some maintenance schedule or you notify your users that your site's going to be going down for an app restart which you know can be a little bit you know roughly probably like a minute or so for it to come back or quicker what is the recommended setup for an app that has dev qa prod should um i mentioned that a little bit jason i think that it's kind of your mileage may vary i personally like to have different um app insights resources per environment just because it gives me the flexibility and it allows me to leverage that five free gigabytes a month right that's one of the things i want to call out if you're just playing around with this stuff you definitely don't be paying for it so all right uh currently spread over a few resource groups you currently use one we like the nice day of separation that's a great callout howard i really appreciate the commentary there i think they're recommended by microsoft for a microservice setting is to use one ai for each i think hey i can still create application map spanning that's right i was talking about distributed tracing a little bit ago and that's the exact use case right so say for instance you have um a kubernetes cluster or you have a handful of different azure functions and you want them to all wire up into one holistic topology of what your apps are doing and the different data sources they're using um you can leverage distributed tracing for that one thing as well that's really important to call about app insights is that um now it's being rolled up into the broader open telemetry principles that exist in technology right now so a lot of companies are notably google are building on top of this concept of open telemetry so the same schema for all of your different telemetry points and that way it allows you to get better fidelity across different services right so there might be a day in the future where you can have some data that sits in some proprietary service and one that sits in app insights and they can actually see the data flow between them using um any sort of tool which would be really really valuable for a lot of folks all right any other questions before i move on sweet all right um so just add one i just had a word so costs are we saying that multiple instances of app insights say blah blah blah is cheaper well so you have five gigabytes per month per resource so if you have one resource that uses 20 gigabytes um you're going to pay money for that and source is one instance of app insights i'm sorry i over talked to you i'm sorry one resource is one inside one app insights instance correct oh thank you you just saved us a lot of money so so i'll definitely take a consulting fee okay suggesting that say for a scenario of a k8 cluster plus like four wrap services you might say plus like the infrastructure itself that writes like say you know storage accounts iot hubs stuff like that would you how would you you see that as like five instances saying i mean so in a situation where you're talking about um i would just make sure that you know obviously test that in the lower environment and see if you're still seeing that holistic topology right so if you have five or six services in in a cluster and they're all talking to each other you want to make sure that the data flow telemetry data flow is good between all of them so make sure that works correctly make sure that distributed tracing is going through um you know and obviously though microsoft does great documentation on how to monitor kubernetes app data with kubernetes clusters as well so make sure you're following um you know those recommendations thank you cool all right going once going twice all right moving on so i want to show something a little bit more interesting right so this is a net six application using uh angular version what days today angular version 603 um this application uh just kidding there's only thing like 12 versions of angular um but this application basically is a dot six preview back-end hosted in azure with a angular front-end so it's as you can see it uses the um if anybody has learned angular in the past this is very very similar to people this is like the tour of heroes canonical app that"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "basically is a dot six preview back-end hosted in azure with a angular front-end so it's as you can see it uses the um if anybody has learned angular in the past this is very very similar to people this is like the tour of heroes canonical app that exists for angular apps so as you can see here i can hop around and look at different things i even have search um so if i search but my search isn't working so we'll need to figure out what's going on there that's strange um but as you can see here if i go go over this is my application it's wired up with app insight so i can click on the app insights blade and i can look at some of the things that have been going on for this particular app um so what i'm going to do is show you what this app looks like in visual studio so come over here so don't be scared this is this is the new.net 6 templates so um a lot of stuff that you're probably used to seeing when you write c sharp isn't there anymore this is this isn't a talk about that i do have other talks about dot net six and what's coming out and all that sort of crazy stuff but now things like startup.cs are no longer required 4.96 you can do all that stuff inside of one application one file called program.cs there's no more namespaces there's no more classes it's just all the way down an application cool all right so this application it's wired up with app insights here so as you can see due to do app insights telemetry um and one of the things is really really cool is i can actually start this app here let's set donenet 6 as my startup project and then here so if i click this and i apologize this might take a second because there's some regular stuff going on too but basically what this is it's an angular app so and with a dot net 6 back end and once i click that button what you can see here is app insight showed up automatically right so super super cool um and i want to show you some other cool things that i can do in a second right um let's hop back over to the presentation i just want to show you app insights lighting up for dot net 6 applications it's as easy as one line of code and adding a nuget package right all right so back to the slides minimize this minimize that minimize that all right um any questions before we kind of move on to the next thing which is talking about different ways to use that data sweet all right so different ways we can consume the data so we're in azure so we have access to all sorts of cool things that exist in azure already right so like dashboards so you can easily create a dashboard from your app insights resource that creates something like this for you so being able to see all of the really high fidelity information about your app in one page is really really valuable i also talked about like this topological view of what our applications are doing and something like appmap allows you to be able to successfully see that so as you can see this application hits a database it has an azure queue it hits some other service it hits another database like being able to see everything from like one top down and all the different requests and what their timing is is really really valuable so another really really cool thing about app insights is that you have the ability to look at profile data so being able to look down by execution path like where your application is slowing down and being able to get a better understanding of ways that you can add more efficiencies and look at percentiles and say why is my app in certain scenarios running so slow maybe it's a region issue or maybe you know my code isn't really effective in certain scenarios right so being able to see that at a glance is really helpful one thing i love about azure is the ability to create like these really rich visualizations right i'm not a uh data designer so being able to do these things really really quickly has saved me lots of time and headache so another cool thing to take advantage of i'll show this in a little bit but you can actually see data in real time coming across the wired app insights so one thing i didn't mention that should be called out is that there is a little bit of an there is an ingest period for app insights data so from this from the time that you send it to the api to the time that you actually see it in the azure portal is roughly 90 seconds that's how long it takes to get sent through all of the ingestion ingestion process which includes some machine learning and and insights instructions and things like that but if you need to see in real time what your app is doing you have the ability to do a live metric stream so you can easily like in real time glanced at like the usage of your application which i think is super impactful you can export all the things in app insights to power bi so and again like being able to satisfy the needs of business users with reports is really valuable and not having to leverage you know data designers and other folks is super impactful you can take a look at app insights in visual studio too so like when you have a local environment going you can actually see some of the different telemetry points of your app while it's running inside of visual studio and you can actually connect it to azure as well consumers export when i mentioned a little bit earlier that you can store your data up to two years that might not be long enough right"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "actually see some of the different telemetry points of your app while it's running inside of visual studio and you can actually connect it to azure as well consumers export when i mentioned a little bit earlier that you can store your data up to two years that might not be long enough right so you might want to be able to look at historical data over time um you know maybe if you have particular track web traffic data and things like that so continuous export allows you to take that json data that exists for app insights and send it to a blob store and then once it's in a blob store it's just flat json files you can do whatever you want with it forever so a way for you to get um you know that historical data that's really really invaluable so i want to show a couple of different cool things you can do using app insights so i'm going to go back into visual studio here let me just open this up all right so as i mentioned earlier i have that app running so here's that app it's local so as you can see it's just localhost share and i want to and since this app's been running for a little bit i have app insights wired up that shows actually in visual studio when i'm debugging and inside of here i can actually take a look and say like okay like in the last 30 minutes like what's all the data that's been created right so as you can see here like there's some really interesting information so there's some dependency data so it looks like i'm hitting some dependencies um i can actually take a look at requests as well so like this is stuff that you can actually see um when you're playing around the app insights before you actually take the step and deploying it to azure so i can actually take my app i can light it up with app insights locally just installing the sdks and then i get this experience and i can say like oh at a glance like this is the sort of data that my app will be producing and be storing in azure so that's super impactful i'm going to stop this really quick and i'm going to go back to my azure portal for a second i'm going to close that close that all right so as you can see here so this is the the main um blade for app insights for this particular instance and as you can see here i have things like app map which shows me a holistic view what my app is doing so i have some availability zones that are calling in and just testing this particular app and then as you can see here i have different different instances of this app running in different environments so i have this instance that i have this instance and they're both using the same sql database one's localhost that's just for me testing it just now but as you can see like i have all this really really you know invaluable to telemetry from a topological perspective i can also i can also change this into kind of like a more workflow based thing if that suits your needs but at the end of the day like it's super valuable to be able to see the flow of data between all the services that your app is using and if i click on live metrics here let me just do this let me just pin this to the side right and as you can see it'll say live metric stream is coming up right so as i'm going through here and i'm using this app things are going to start to light up like in my my requests and my request rates and things like that in my dependency call rate i know that it's kind of small let me zoom out a little bit just apologize it's going to be a little bit smaller but i you know i want to make sure that everybody sees everything that's going on here um one thing that's super cool too is if for instance i mentioned earlier that i'm getting an error message right so i'm getting these error messages and if i open this up i have error messages here that i can see oh index had a range right so this is in real time so my application's actually throwing an exception the back end is and app insights is actually tracking that exception and it's actually showing me in real time what the exceptions are so that's really really impactful and you take a look at that i wonder why this particular exception is happening so i can actually go into failures and look like for instance i can look in the last hour and here i could say okay well it looks like this particular operation name get heroes is um not working right and there's the main exception is this argument out of range exception so i can click that and then it gives me this which i think is really really cool and then i have like this transaction details of what all the things my app is doing okay so a request came in and hit the database and then i threw an exception that's strange so i can take a look here and look at the index out of range exception i can see this i scroll down a little bit and then i see a call stack right anybody who's looked at call stacks a lot saying okay there might be some things here that are valuable but i just want to look at my code well i have adjust my code button so i can click this and then it actually shows let me just click here the la the line number of where my code is actually failing so i can actually go back to my source code and say oh line 57 of heroservice.cs is not working so i can better triage my applications right now without having to get very far which i think is really valuable cool and there's all sorts of really interesting things that you can do as well with app insights like for instance i can take a look at all this telemetry and i can at a glance just start running queries against it so for instance like let me just um let's do this let's x out of this i just want to create a new query let's say for instance i want to see who's using my app across the world so i can just and this is using"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:35:26",
        "seconds": 2126,
        "text": "queries against it so for instance like let me just um let's do this let's x out of this i just want to create a new query let's say for instance i want to see who's using my app across the world so i can just and this is using a query markup language called kql custom query language which is which is how login linux which is the data mechanism for all of a lot of azure monitor stuff this is how it's stored and it's using this query mechanism to be able to work against it so i want to take a look at all my requests i want to summarize and let's just go count and let's just go by let's go by country right so in the last 24 hours who has gone to my act um let me just mute this person sorry about that for muting you um so as you can see here i have like you know in the last 24 hours these are all the people that have used my site so that's really cool um so i could actually take this to a business and say look these are all this p these are all the places that people use our app and they'll be like okay that's great that's a table that's not really valuable but then i can say okay well how about like a chart and they're like oh bar charts are cool but i really like like donut charts like could you like make a donut chart and then you say okay well that's gonna i'm gonna send this over the day designer it's gonna take like six months for them to actually write up a donut chart or you can scroll down and then you can change that here it's like okay cool so i have to go into this tool every single time if i want to see this report oh not really you can actually export it to power bi and then i right here i have a particular file a power bi query that i can actually embed into my report and this data is now live in some report somewhere so just imagine how long and how much time has been saved by something like that right so taking data that exists and getting a report for it almost instantaneously so that's super super valuable cool all right so i'm going to go back to the slides um i'll pause to give people the opportunity to ask any questions if they have any isaac i get a quick one this may not be fair so i just tried to do a similar thing to what you did against my data and i just um i have a whole bunch of uh country i have a whole bunch of rows where i don't have a value for country or region i mean most of them do but yeah so in some scenarios depending on what country it is uh microsoft can't collect pii for that particular country oh germany um yeah so okay so in the situation where you're not getting data um there could be a handful of reasons one it could be cache data one it could be um data that's being filtered out by some pi filters that um app insights has in place um also in general from my experience you're always going to get some data that is a hundred percent like full like there's some data that's empty occasionally um but predominantly you should see a majority of data without with of data points with actually fully populated data in there thanks all right okay so on to the last part and um quick check jason and bill veronica how much time do i have ten minutes five minutes one minute um you you you have uh i mean assuming you you want to go if you want to go like 15 20 more minutes that's all fine from my point of view well i just want to make sure that people aren't bored like maybe this is an opportunity for people to take naps um i know it's later in the day over on the east coast so you know hopefully i can wake everybody up with this next part right so i have production issues so give me a thumbs up or a hand raise or whatever in teams if you've ever heard that in your professional development career i'm looking i'm looking all right so there are a few people here that's good so that means about other people's apps oh okay only oh not your apps though right bill okay that's fine all right cool so you know what we've all heard eye production issues or there's issues in production we need to take a look at there's a fire drill whatever right so what are some of the things that we can do or what are the some of the things that cause production issues well first off more than likely anything can cause a production issue right but i think one of the things that's really important to call out is that there are some main things that cause typical production issues whether it being data that's not uh you know that exposes issues in our source code different uh configuration differences per environment that may be causing issues issues with scaling like maybe your app just can't handle the load or really anything else you know maybe for instance i worked at a company and their app went down because they it was um at a data center and someone was doing maintenance on the data center and dropped a screwdriver and shorted out the whole rack and their web app went down that's something that wasn't accounted for and source code wasn't accounted for like things happen humans happen right so really anything else can be uh you know the cause of production issues so what are our triage options right so i think there's a handful of different options that exist for folks that allow you to get better assimilate to your issues that you're having in production so you can so in some scenarios you can"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:40:30",
        "seconds": 2430,
        "text": "the cause of production issues so what are our triage options right so i think there's a handful of different options that exist for folks that allow you to get better assimilate to your issues that you're having in production so you can so in some scenarios you can copy down some version of production data to some local or lower level environment right that's really really valuable in some cases probably not the best approach in a lot of cases because of customer data or just the scale of the data that exists um some in some companies or some uh individuals have um the luxury of having like production staging environments where you can actually test things and kind of have a better fidelity view without kind of affecting production data um you can read logs if you hate your life like you can read is logs or database logs or event logs if you really want to and then you can do something like this give me a thumbs up if you've done this before attach the debugger and visual studio to production all right no one is thumbs upping so that means that everybody here are liars cool all right so i think one thing that's really important to call out is we definitely don't want to do that we do not want to be in a position where we're taking down our production applications to figure out what's going on because if anybody's done that they know how many people are staying behind them if they're at their desk and they're hacking away trying to look at some stuff and the production side is down you have everybody and their grandmother they're watching you and that's not a good place to be or trying to figure out an issue especially a complicated one so it has to be a better issue option right well there is it's called snapshot debugger so snapshot debugger holistically gives you full stack trace full locals window the time of exception in a visual studio debugging experience from visual studio from an exception that happened in azure i just think about that for a second see me telling me that i can actually take an exception that exists in azure and i can actually look at that exception and all the variables that exist for it from visual studio no that's not a thing that can't be a thing well this is what it looks like so you can actually go and i'll show you this in the azure portal too you can go through the azure portal click on a snapshot of an exception that existed and go exactly and get a better understanding of what you're trying to do there's a couple of uh there's a call out gabriel in the chat so snapshot debugger is in preview for linux apps for in azure so this is a windows only thing also um there are parts of snapshot debugger which are enterprise version of visual studio only so if you have the professional or the community edition of visual studio you're not going to get to party on all of the cool things that exist in snapshot debugger but also going to kind of get you an idea of what you could get so this is what it looks like and as you can see there's a lot of cool information here so i want to show you actually in real life what it actually looks like so let's actually open up do to do all right so i'm going to go back into my failure section i'm going to close out of here and i'm going to go to this failure section again i'm going to click on one of these so as you can see here a similar exception that happened that fast but i have this right i have this cool thing open snapshot or open debug snapshot i can click on that and that's going to actually do is it's actually so one of the cool things with app insights is that by default most applications are now sent with pdb files and those pd files you can actually take they can actually get extracted um with with some mechanisms to actually get a better understanding of what your source code looks like and kind of rebuild what your source code looks like so as you can see here there's some cool things going on so i have a call stack so i can actually look like multiple methods down and i can actually see okay cool i can see there's an exception uh index out of range index three i can see the exception itself i can keep going down the list line 57 there's like it looks like source code it's um it's not actually it's not it's not official official source code it's decompiled source code so it's not um 100 accurate but it gives you a pretty good understanding of what's going on right and then i have this ability to download a snapshot so download that snapshot allows me to actually open a file in visual studio which will give me the same experiences if i was debugging locally in that through an exception these debug snapshots can get kind of big so what i actually did is i downloaded one earlier today so i'm going to open that up so i'm going to go open in visual studio apologies open file i'm going to go to my desktop i'm going to open one of these files it's going to give me this really friendly message saying this comes from an untrusted source that untrusts the source is azure so i'm just going to go ahead and click yes and that's going to give me this diag session breakdown and i think one of the things that's really really important to call is it gives you all sorts of really valuable information like i mentioned this i downloaded the snapshot yesterday so i can actually see the time of the exception i can see the process name so w3wp which is the is process and then i can debug with manage only so"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:45:33",
        "seconds": 2733,
        "text": "sorts of really valuable information like i mentioned this i downloaded the snapshot yesterday so i can actually see the time of the exception i can see the process name so w3wp which is the is process and then i can debug with manage only so if i click that it's actually going to load all my symbols and then it's actually going to open visual studio in a similar experience as to if it was to throw an exception so let's look at my source code here and let's figure out what's going on so whenever i run a search i'm getting that exception right like that index out of range exception i wonder why so as you can see here like i'm getting some here i'm getting a list of heroes based on a particular name and then i'm doing like this so what do you think could be the cause of why i'm getting an exception you get to come off mutant tell me if you want how about if there's only two things in the list that's it's a pretty solid point like you should never be getting like the a particular number of an array without checking the length of it first right so i'm getting the the fourth item in an array and there could be less than four and that's always gonna throw an exception right so in that situation i can see here i can get faster to um my solution and again i was able to triage an issue really really quickly i actually have hover over so like for instance right so if i go name it shows me like oh this is what the parameter was at this particular exception time right so super super valuable stuff and like i said there are other things that you can do with snapshot debugger if you have an enterprise version of visual studio i do not have an enterprise version of this video anymore because i no longer work at microsoft i don't get things for free um but you have the ability to do things like attaching to azure and not taking down your production applications but still getting real-time debugging that's something that you can do you can also do things like you it's it's you know how i mentioned a little bit earlier like don't ever attach to production like this is attaching to production so it takes a clo it takes a shadow copy of w3wp the ies process and connects to that so all the traffic flows both ways so you have that ability to actually debug a live azure instance without it actually affecting production and one quick thing you know if you don't believe what i just said like i did a video on.net um probably like two years ago now that actually shows how to be able how to do this sort of thing um so please take a look at that there's there'll be a link to it at the end of this um and yeah that's kind of my talk so i really appreciate you know bill veronica and jason for inviting me to chat with our lovely folks of boston hopefully it's um it's not too late that you're taking a nap and you're excited to learn some more things about azure and app insights so um let me paste this particular um scroll [Music] down this is um a link for all of the so a bunch of valuable things about app insights so the source code for what for the app that you saw is there some interesting docs are there the video that i did for channel nine is there as well and yeah so please take a look at app insights you know and if you have any questions let's i'd love to hear the conversation on twitter um yeah we can have questions for the rest of time or you can tell me how terrible of a presentation this was but i appreciate your time and thank you so much for having me jason isaac that was terrific that was really terrific thank you well thank you a question quick question um two things one or two quick questions one um we had observed a lot of times that when we had snapshot debugging turned on that it seemed to be introducing additional load to the servers um and so we wound up having to turn it off because we didn't like what we were seeing um do you expect that you'd not that be a surprise or expected i mean i mean so in all honesty there's going to be some performance um degradation using snapshot debugger the the last thing that i've ever heard from the the debugger team is that it's less than five percent performance segregation that can meet that could be a lot for a lot of applications right five percent um i personally have seen it running on really big applications um and performance using it was not terrible but again i think that's probably one of those your mileage may vary sort of things um it also could be that you know your application could be doing something really intensive and snapshot debugger in the process of you know having to kind of decompile that source code does take a little bit of effort um but from my experience it's around five percent at least that's what i've been told um and i've never really seen it fall down in practice but i mean there's always an example of everything right i think they try to limit like how many snapshots they take if they see the same exception but we found that that wasn't working right we'd see the same thing over and over again um but that's"
    },
    {
        "speaker": "",
        "title": "Application Insights The Tool You Never Knew You Needed",
        "videoId": "kdlat6VA1-U",
        "description": "This is a recording of the November 1, 2021 virtual meeting.Application Insights: The Tool You Never Knew You NeededUnderstanding how our applications function in the wild is essential for developers when issues arise. With the power of knowledge, we can enable ourselves to provide the best experience to our fellow developers, and our stakeholders. One of the solutions that supplies this power is Application Insights. Application Insights is a service provided by Microsoft allowing you to monitor your application live, detect performance anomalies, and observe this data with powerful analytics. Together we will see how easy it is to add Application Insights to our applications, whether we have access to the code-base or not. Once instrumented, we will dive deeper into the capabilities of Application Insights and show how to leverage all the rich data collected from our application. Finally, as developers the last thing we want to do is troubleshoot an issue in Production, with everyone watching and the stakes are high. Watch as we monitor a live application that is throwing exceptions and how Application Insights can be used to help us solve the problem faster. When we are done, attendees will be empowered with the knowledge to leverage Application Insights to be more productive with their work.Talk resources can be found at: http://isaacl.dev/appinsights-talk## SPEAKER BIOIsaac Levin is a Product Marketing Manager for App Search at Elastic. He has over 10 years of experience working as a developer for the web, mostly in the Microsoft Ecosystem. Outside of work, he contributes to Microsoft Documentation in the .NET and ASP.NET space as well as other open-source projects, and occasionally blogs about things that interest him. He likes to wind down from work with his wife Ariana and his 2 sons Isaac and Avery.",
        "start": "00:50:36",
        "seconds": 3036,
        "text": "fall down in practice but i mean there's always an example of everything right i think they try to limit like how many snapshots they take if they see the same exception but we found that that wasn't working right we'd see the same thing over and over again um but that's neither here nor there we the other question i wanted to ask was about profiling i know that's also a feature but we found a lot of times the profiles that we wind up downloading aren't very helpful you know they just yeah it's like all dotnet code there's none of our code in the profile and we can't like figure out okay why are we slow because it's none of our code yeah i think one of the things that's really important to call out with any profiling right is that more than likely you're gonna have to get to this weird state of having to deal with unmanaged and managed code at the same time right um and i think that you know depending on what so what can you give me a little bit of insight as to what the technology stack of your app is is it framework yeah yeah it's done it's right that framework um azure um you know with a lot of other azure services um not the most latest you know like 460 time frame yeah and i'd imagine one thing too is that and this is obviously not fair to anybody but i imagine if you were to have it be like four seven or four seven two you might get a better profiling experience um but i think one of the things to call out is that you know profiling is an art and i think one of the the reason why a lot of developers including myself and you have jobs is our ability to kind of re look through the noise and get a you know with the tools that we have and get a better understanding of what we can do um but yeah no i definitely hear your point about profiling not being accurate not not being accurate but profile not giving you enough contextual information and that's why i think snapshot debugger is really interesting too is because it does give you that fidelity in exceptions um but again i think it's one of those things where it's your mileage is definitely going to vary if you do want to have a kind of continued conversation i could potentially introduce you to people in the product groups um you know to kind of maybe you know drill down as to how we can resolve your your use case right i think that might be an option too thank you appreciate that yeah um i'm kind of scrolling up through the chat and i see gabriel asked a question that i love um so i'm just gonna answer real quick so i know elastic has many overlapping capabilities in doing what ai's doing right so i'm gonna talk about elastic for like one second so if nobody cares please just shut your ears so elastic observability i think is really interesting because it gives you kind of that you know one stop to do a lot of things like say you have you know maybe you're using some hybrid cloud approach maybe you have stuff in google cloud maybe you have stuff on on-premise maybe you have stuff um in azure as well so what elastic observability allows you to do is coalesce all that data into one place and be able to search on it really really effectively so the number one value prop of elastic is that we are a search company so getting answers to your queries as fast as possible and as accurate as possible is why it's so it's why we have these products so i think the long and short of it is one would i offer one or the other i think if you have all of your stuff in azure don't go outside of azure like don't do get no relic or don't even get elastic um i would love for you to get elastic for a lot of reasons but i think at the end of the day if all of your stuff is in azure just use the tools that azure has because i think you know azure monitor and app insights does a great job but as you start to have like more and more like external data sources that are away from your app like maybe you have data that sits somewhere um in some other system or maybe you have an app that runs in three different clouds like good luck trying to coalesce all that data in a meaningful way using like one of the cloud providers apm tools so you need something like alaska observability to be able to do that i hope they answer your question it wasn't too much marketing speak but um cool all right so tim has a question do you have any recommendations about data sampling with app insights when to use it when not to use it so i didn't talk about data sampling but i think there's a really good topic to talk about briefly right so i mentioned a little bit earlier that you kind of pay for the in and out of your data right up to five gigabytes is free but after that it's it can at times get expensive right especially if you have a high traffic app um what data sampling allows you to do is it allows you to kind of i guess prune similar requests in a way so like say for instance i have 30 web requests that are all the same what data sampling allows you to do is filter out them by a percentage like maybe i only want to keep half of them or two-thirds of them or whatever the issue of data sampling is one would imagine is that it doesn't bite for bite to compare different pieces like it takes similar it takes similarities and and prunes them um so in situations where i think data sampling might be really valuable is that if if your app is really chatty and is creating lots and lots of telemetry like highly recommended that you take a look at some data sampling options otherwise you're gonna be paying you know two dollars and thirty cents per gigabyte per month for lots and lots of gigabytes um so when not to use it if you're nowhere near that five don't date a sample like period like it's not worth it to you um also in scenarios where data sampling is not valuable is if you're seeing data the data that's coming through your sample isn't matching up with the experience of your users then you know that's definitely a situation where data is being sampled out that you definitely don't want it to be hopefully that was helpful i know that's probably a little bit of your mileage may vary too but i mean at the end of the day a lot of the stuff is your mileage may vary and it's about tools and the tool belt to help you be more successful so and also just another plug um veronica mentioned it i'm speaking at dot net comp too so i'm gonna be talking about githubactions.net and azure so please take a look at that i did a similar talk last year i'm doing like the next version of that talk which is a bit of more advanced topics but you know if you like devops if you like dot net if you like azure you know definitely check out that talk that's on day two dot net conf or maybe day three i don't remember it's during.com watch the whole thing watch all 24 hours um three days a week three days of it cool so if anybody didn't have any other questions i again want to thank the organizers and thank you folks for tuning in this has been great um and yeah again if you have any other questions or you want to follow me to like bill said i i'm very high energy on the on the tweets so isaac r11 is where you can find me um and yeah it's been a pleasure so thank you again isaac thank you very kindly this was uh really excellent uh some really great insights so thank you uh thank you for that uh folks um you have the in the chat area you can follow the link to get the resources from the talk and more info on doug on isaac and then we have doug and david coming up in the next two boston azures and um ignite is going on if you want to tap into that that started today and it's a couple more days this week i think that's free uh streamed and uh then uh granite state code camp saturday and then dot net conf next week uh yeah get your get your nerd on there's plenty of plenty of stuff going on with that anybody have any final uh comments or one last question um how do we get the if one of my colleagues wasn't able to see the whole thing and i know we recorded it how how do we get to the recording yeah that's how it's paying you some money yeah uh youtube.com boston azure and it'll probably be posted to tomorrow might be posted as early as the morning but usually it takes about uh one day to get it posted but you can find it there boston azure.com i mean uh youtube.com boston azure there's also there's a link in the meeting invite too thanks so much bill yeah i'll tweet it out with the if you follow uh boston as your twitter handle thank you thank you thank you everybody thanks everybody yeah have a great night thank you everybody thank you "
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts. This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come .... i'm going to turn on my camera because that usually what i what i do um so yeah as jason mentioned so um i've been involved in the in actually when i back in like two three years ago um i i got introduced to all the usher um meetups and being as a presenter in a few in a few occasions and that was uh thanks to jason so he's one of the um the um the guys that helped boost my career and now uh so as he was mentioning i joined microsoft back to 2018. so a couple of years ago i've been in a couple of teams now i joined the arm deployments team so i am a senior software engineer so let me go and start um my presentation and hopefully you guys can see okay so my name is jorge codillo i'm a senior software engineer uh microsoft azure in the arm deployments team so arm as you may know is a is a big service and one of those services is the deployments piece of um piece of the service so the this is basically all the arm templates that you're going to be deploying so those go through a deployment engine so now the team that i'm working in is basically in charge of that specific slice of the service so today we're going to just be talking about what is the infras code using arm templates of course using deployment scripts which is uh we're going to be talking about what development script means and we're going to be talking about the template specs so for those that know azure blueprints this is going to be really similar to you so let me go and check the agenda so for today just a brief introduction on what an arm template is right so there have been other talks that talks about what an arm template is and what you can do and all the different tricks and tips that you can um do in an arm template but today we're going to just give a basic idea on what that is and then we're going to look into the infras code usually means declarative approach we're going to see what declarative means we're going to see deployment scripts right so what it is so what is used for on some of the considerations that we can have we're going to see a powershell demo i won't be running those scripts but just rest assured that those work i'm going to be sharing my github repo as well so all the all the demos are over there so yes um for time sake i won't be running those demos but i'm going to be showing you what is what are the outputs of some of those so powershell bash demo uh deployment scripts considerations what you need to consider what you need to account for uh when you want to meet compliance regulations so azure policy right so that's one of the compliance regulations then we're going to look just getting into um into temple aspects we're going to look into what a monolithic versus a modularized uh template means then we're going to look into how you can share a module and modularize your templates by using temple specs and then some q a if the time allows hopefully we're going to have some time for q a in case there is any there are any questions so let's dive into what an art template is right so an art template is just a resource group and a collection of resources right so a resource group is a just a logical grouping of the your different services so please if you're working with azure and you're creating different resource groups try to just group a logical grouping the resources that are that are related right so if you have networking uh resources just put those in a resource group the reason is because you can go and manage uh the access on those resources right so now you have an isolated building block that contains related resources and then you can give for example access to your networking team to yes manage the firewall the udr the nsgs and the different networking services that azure offers so i'm using the the example of um aks here because that's a complex a complex deployment right so if we deploy just um let's say a v-net by itself it doesn't mean much right so what you need is you need an environment right so you need an aks cluster you need a connection from kubernetes rbac to your azure id you need udrs nsg you need to connect to keyboard so key rotation a bunch of stuff right so that's what what an environment means right so and how you can get to that"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:05:06",
        "seconds": 306,
        "text": "from kubernetes rbac to your azure id you need udrs nsg you need to connect to keyboard so key rotation a bunch of stuff right so that's what what an environment means right so and how you can get to that environment is basically using the building blocks or the arm templates right so that's the relationship right so as i said so i won't be diving deep into what you can do with an arm template um i assume there have been other talks about that but if you have any questions about that um just feel free to reach out so then let's move into what you can do to actually deploy the environment right so to deploy the environment like all those building blocks you can use an arm template you can use azure cli you can use azure powershell you can use terraform right so all those are acceptable approaches right so it's going to depend on which tool you're going to be using depends on your team right so if your team knows terraform then let's go with terraform if your team knows uh powershell maybe you can use powershell right so we know that um authoring some of the arm templates are not that simple but we are working towards simplifying that experience but something that you have to be aware of are the pros and the cons right so if we have arm templates cli powershell and terraform let's see some of these four items that i usually account uh when i'm making a decision so first is you have to recognize which tool is going to get the resource providers or the rps or the services um basically for free right so if we are working in an arm template because every single service goes through arm then usually arm templates are going to get those services by default cli powershell and terraform they won't be getting those for free so if you don't know about how the cli and powershell works basically they use the sdks right so for powershell is the net sdk the azure sdk and for cli is the azure python sdk so how the sdk gets generated is actually an automatic process right so if you don't know about the rest apis and all the different aspects that every single service has we have a basically a repo and it's open source and i'm going to be sharing the the link at the end but that's basically the contract of every single operation for every single resource in azure so what that means is the um the swagger spec is going to get translated into an sdk an sdk for python an sdk4.net an sdk for go anything right so we have a bunch of sdks so that's an automatic process but to get to the cli uh and to get to the powershell commands you have to actually code those commands so you have like maybe 90 of the work done by just using the sdk but you still need to do some work to just get those uh new services to be exposed through cli or powershell in terraform if you guys know about terraform so basically you need to code the provider then another approach is uh single api calls right so which one is going to make one single api call to just go and provision your environment so usually an arm template is one single call and then you just delegate to the deployment engine to schedule the different resources and how orchestrate basically the the deployment of the different resources in cli powershell on terraform usually no right so you need to go and make different api calls to just be able to provision an environment if you know about the limitations there are some well no limitation but there are some there is a quartal limit on how many api calls you can make per subscription per tenant uh for the put operations um if i'm not mistaken it's like 6 000 calls or something so it's a high number um it's unlikely that you're going to get that um that restriction so that you're going to be making that many api calls but you never know right so if you code something really wrong then you might reach out to quite a limit and then you are blocking basically anyone that wants to deploy anything into azure so something just to consider the learning curve uh yes so arm templates we know is from medium to high especially if you're deploying a really complex environment it's going to be a high bar to just go on and learn how to author an arm template even though we have the vs code extensions we have a bunch of additional tools that can simplify the authoring and i'm actually working on those um it still needs some additional knowledge on how to author an arm template for the cli simple powershell is simple so granted that you know in cli you know some bash and then for powershell you know powershell"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:10:10",
        "seconds": 610,
        "text": "um it still needs some additional knowledge on how to author an arm template for the cli simple powershell is simple so granted that you know in cli you know some bash and then for powershell you know powershell and for terraform uh i put medium because usually it's almost the same right so it's not really easy to just go and deploy a complex environment into our form multi-cloud so this time i'm going to start from terraform i have nothing against terraform i i like them but terraform is not multi-cloud so please i i hear multiple times people saying i use terraform because it's a multi-cloud no right so the engine is agnostic of a cloud is cloud agnostic but it's not a multi-cloud solution right so if you deploy something in azure uh if you create a terraform file or transform template that one you cannot go and switch flag and say now deploy to aws that won't work right so therefore it's not a multi-cloud solution rice cloud agnostic which is totally different um for powershell cli of course no for arm templates um we're giving i'm giving some additional credit here sort off the reason is because we have azure arc right so you can go and deploy hybrid compute for example which is a resource type service through an arm template right so now you can go and deploy to different clouds using one single template so that's going close to being a multi-cloud um so let's go and check now that we discuss a little bit about like the different options so now let's go and check what infras code and declarative means right so that's basically all the infras code right so it needs to be declarative so you have to declare a state of a resource right so if you deploy or you let's say you create an arm template that has a vm and that vm has five disks so that's what the end result is going to be right one vm with five disks if that doesn't work i'm going to give you guys my email at the end because that's an issue and you guys should be contacting us of course it's not going to be directly me um but customer service is going to get involved um if something like and that nature happens right but the um the the result is or the idea is that you have to declare the estate of a resource so what you see is what you get right so it's like similar to html right so in html you have a bunch of text boxes that you know how many are going to be you know that are going to be there but you have no idea how they are going to look like or how the user is going to interact right so that's basically what declarative means so is declarative actually sufficient to provision an environment so let's go and take a look at the aks example again right so if i want to declare this um usually i'm going to start having like maybe a really long uh arm template uh that is going to start getting really complex maintained so maybe i need to focus on something different and that's something different is basically functions right so that's why arm templates uh we expose different functions but now we're just losing the declarative approach right so declarative if you are just talking about like a copy loop that should not exist because you need to go and copy the same uh resource multiple times and that sometimes is not good for end users so that's why we introduce different functions but now we are realizing that being fully declarative is not sufficient to provision an environment to configure the environment so enter deployment scripts right so we realize that because it's not sufficient to be declarative then we need some functions then we need more uh tools to just go and maybe configure my r back maybe configure my uh my keyboard keys and the key rotation and a bunch of that those stuff so then we said okay why don't we go into uh putting that as a native construct in the platform right so that's how deployment script was born so we realized that declarative approach is not sufficient to provision an environment to fully configure an environment a couple of examples here is um well the development script is just a resource deployment that is going to just finalize the environment configuration so you can go and think about like for example um accessing azure ad the graph api you can create keys in keyboard you can create users you can associate kubernetes are back to azure adr back right so there are items uh or let's"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:15:11",
        "seconds": 911,
        "text": "example um accessing azure ad the graph api you can create keys in keyboard you can create users you can associate kubernetes are back to azure adr back right so there are items uh or let's say some operations at the control and data plane layer that you cannot do through an arm template and you before you were forced to just use maybe a powershell script or you were forced to use a bash script to just go on and account for those missing operations usually those operations are post operations all the put operations are most of them are going to be included in an arm template it depends uh if one is going to be included is because the um the contract has been specified in swagger and then you allow that operation to happen there are some rps some services that they don't allow uh some put operations through an armed template so that's um that's basically um depending on the different service team but that's what deployment script is going to allow us right so now we can go and configure uh the environment control and data plane operations uh in azure right so now you don't need to go and and expose an additional create an additional service principle and then associate that into your azure devops um pipeline so some other another user can go on and access azure and start running some operations so now by using an arm template you can accomplish the same let's see how it works right so how the plumbing script is going to work right so if you see this image so we have a container instance aci and we have a storage account so what deployment script is going to do is going to create two resources two supporting resources aci and the storage account so i put some of the um the settings for this rush account yes locally redundant uh standard sku and of course https enabled and the aci is going to uh the storage account is going to get mounted in in and the reason is because aci is the container running your script and the storage account is let's say the container that is going to be hosting your scripts right so aci runs the storage account hosts the information so now it's up to you to how many files you want to share how many files you want to download so basically you are in full control so i i'm adding here in customer subscription right so these two resources are in inside the customer subscription we've been asked multiple times about um why microsoft doesn't create these two resources in a microsoft tenant such that those resources are not created in the in the customer's subscription um that's something that we are analyzing right so it's going to be clean of course because now it's not polluting your resource groups uh it's not polluting your resources so now there is nothing that gets created but there is going to be a cost associated that we need to go and analyze so even though it sounds like a simple request to just go and say hey microsoft go and you do this uh on my behalf i don't want to just host any of these services so even though it's a simple ask is a complex engineering task right so that there are there are different uh considerations that we have to account for um for for us to just provide that type of approach so let's see now what are the what are going to be the permissions right so now what are the permissions that you need to have in order to create those supporting resources right so because i'm saying that deployment script is going to create two resources now someone needs to have that type of permission or the specific permission to be able to create those resources so in deployment scripts we expose a user manager identity so now you can go and control that specific user manager identity is going to have specific permissions uh to go and execute whatever your script is going to accept plus the creation of a container group and the creation of an storage account right so that's how we can manage we can manage that that specific level of permission so that's in a nutshell what a deployment script is right so just to recap really quick so we realized that being fully declarative is not sufficient uh we saw different customers doing different clever stuff to"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "of permission so that's in a nutshell what a deployment script is right so just to recap really quick so we realized that being fully declarative is not sufficient uh we saw different customers doing different clever stuff to just get to that last mile of configuration of the environment configuration but yes um maybe using a vm and i saw that multiple times so people were creating a vm with a custom extension so they can run specific scripts inside the vm and then at the end of the deployment they just kill that vm so um or some other teams and and actually in the previous team uh that i that i was part of uh in the azure vtc of the virtual data center uh we created a custom engine that can run powershell and bash scripts right so inside a container a bunch of stuff but you see like there are multiple ways to accomplish um this common ask so that's why we said why not we just go and create a service so every single customer can use instead of like doing something on their own so that's how a deployment script was born so let's look into um a few demos so i'm going to check the powershell demos first and and the idea is you create a script in your local computer you can copy that script in your arm template and it should work the same right so there are some considerations that we're going to get into that um but the um the the process and the execution of the script should work on the same so we're going to analyze uh two scripts in powershell as i said at the beginning i won't be running those because there is not much benefit on you guys in uh running um script um but i'm going to show you what the uh the end result is right so i'm going to show you how you can go and create an inline script with no outputs and then an inline script with outputs so let's go and take a look into those first so here i have my simple i have my simple um wait i think i'm not showing that so let me share again because i need to share my whole screen the thing is this one okay so now you guys should see so i have a simple just inline script just a powershell script uh really dummy script that is just receiving two arguments right so if i'm receiving two arguments and i'm writing those two arguments then uh of course if i run those locally i should be able to uh see a result right so i have my inline script which is this one right here and i'm just passing my first argument my second argument and then i get this information so if i go into my deploy manuscript then so here's the resource this is an arm template again i'm not going to be going into into details here um but the same script that i have right here i just pasted that over here right so you can just go and copy paste and then pass some arguments so in this case the way that i'm passing the arguments just to show that again uh through my command line right so i'm just doing this i'm passing fu and bar so now if you're passing the um the arguments via a template you can just go and inline them right so just by saying arguments you can go and pass expressions so now we are in an arm template right so all the all the different goodies that you have in an arm template now you can use them here right so because this is a resource now i can sequence the deployment right so i can go and see how i can go and set that this deployment script is going to run after a vm creation or it's going to run after um a key vault creation so i can go and create keys and then do a key rotation right so now i can go on and do that stuff i can go and get uh information from a different resource right so i can go and receive i can use any function for example a reference function to just go and get the resource id or a specific property from a from an already deployed resource right so it's an arm template so now whatever you want to do with the arm template or whatever you you've done in the past with an arm template now you can do the same in in in deployment scripts it's just another resource there are a few uh properties um i'm going to be explaining about those uh later but just take into consideration that i have my"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:25:16",
        "seconds": 1516,
        "text": "template now you can do the same in in in deployment scripts it's just another resource there are a few uh properties um i'm going to be explaining about those uh later but just take into consideration that i have my force update tag i have my what is my version of powershell uh what is the timeout so when i want this script to just time out and then what are my arguments and my script content then i have cleanup preference and then this is a retention interval how long is going to get retained that information so there are some there are some properties um that i'm not showing here um but again i'm showing the documentation at the end that explains in detail every single property and what we use those proper properties for um so yes take a look into that i'm trying to cover as much as i can because i know that just reading a documentation sometimes it's not that fun um so that's why i'm trying to just cover some of the um some of the information that you guys might want to consider so if i just go into into azure uh i have this one right so this is my powershell with no outputs that's the one that i that i run right here i saw a script with no outputs a script with no outputs so this is the one so if i check the outputs of course what i'm going to see nothing which is in line to what i was expecting but we can just go and take a look into the template so you guys uh can check that i'm not lying to you that this is the same uh template that i uh that i that i showed to you right so you have the user manage identity of course the script content it was uh multi-line in uh in vs code because the extension is allowing that but json by default doesn't allow that so that's why when you export the template when you see the template you are not going to see those uh break lines instead you're going to see these return next line characters but this is the same right so i have my parameters i have my first my last my right host so it's the same right so i run this and then what this this uh actually created this is going to create my resource which is deployment script or in this case is powershell with no outputs here so if i look into this one then i'm going to see what my script actually did right so executing a script and then he's saying i'm executing this script and then it's executing or it's passing foo and bar so but wait a minute so this executing a script is not part of my outputs right so the script that i that i created so if i show you guys again i have nothing about debugging information so what's happening right so who is adding that information well it turns out the deployment script has something called a bootstrap or let's say a system script that is going to orchestrate your script right so it's the one that is going to be in charge of logging you in to azure is going to go and download any file if you if you instruct deployment scripts to download a supporting file uh is going to grab your content right so this is just an inline content all right so showing again the script so this is just an inline content and of course i cannot pass this inline content to my aci i need to just go and grab this content create a file and then upload that into the storage account that is mounted into aci right so that's how we can go and pass information and read information uh from from azure right so once i was asked uh why we are creating um a storage account and why we're creating uh an aci when aci already contains some storage so the answer is simple right so the answer is aci has some limited space but the main reason is if we push let's say the script content into an aci instance there is no way for usher to just go into aci and read the file system right so we need something something a shared location so that aci can access the files and azure can access the files right so we need to access the files because we're going to we're going to see in the next demo we need to go and access outputs right so when your script output something how azure is going to get that information right so the only way is to just have a shared uh a shared service in this case that we can go and and retrieve information and that's the storage account so here's the aci right so as you can see it's a cryptic name it's a hash name a bunch of stuff and then ac scripts at the end and then here we can see the"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "information and that's the storage account so here's the aci right so as you can see it's a cryptic name it's a hash name a bunch of stuff and then ac scripts at the end and then here we can see the container right so the container so in this case i'm just showing the cli but uh it's the same for powershell so it's going to uh tell you about the image what is the state of the container and then it's going to show you some log information all right so this is now inside the container and then if we look into the storage account really quick then the storage account also has some cryptic name uh that's basically to just prevent any name collisions right so if you run um if you run one deployment script and then you run another one we don't want to just conflict with the names right so that's why we create a hash of a specific information so this is this is the storage account uh here's the file share that i mentioned so now in this case i have two file shares because i run this multiple times then i can just get into one of them and then i'm going to see what is my input and what is my output right so if you take a look into the input this deployment script.sh or deploymentscript.ps1 for powershell that's the system or the bootstrap um script that i mentioned before right so that's the one in charge of downloading the files the one in logging you in the one in charge of checking uh if there was a script failure right so is the orchestration is the brain behind your um your deployment so if this is already in in the user's storage account so you can go and download this and then make modifications and if you see something that needs to get modified please feel free to just uh reach out there might be maybe better ways to to do the orchestration and then what is in the user script is basically the inline content right so we need to go on and grab the inline content from the template and push that into uh into the storage account and then we use a specific name naming convention so this is just the user script um so that's for um just a simple store um powershell without any outputs so if we want to see a powershell with outputs so let's go and take a look into the next um example so the next example is going to be a little bit more complex um let's say that now i have a module right so i have my psm1 in powershell and this module is just running in some function and then the function is just accepting some arguments or parameters and then is going to just assume that it's going to manipulate the data and then it's going to output an object right so in this case it's just going to output a hash table so so we have this information now how can i just go and import this module in my deployment script so i can execute this super awesome function so well that we can go and take a look now into the next demo which is uh the inline script with outputs so what this is going to do is again just unscript content and then in the script content i can go and say just import the module this is my the name of my module so i can i better use the same name so i don't think the deployment script is going to change the name so if i'm just uploading one file deployment script is should honor that name so that's why i can just go and say import module so yes notice that i have to just escape the backup slash so now we're getting into these escape weird scenarios so this is one of those so we need to just go and escape uh the bucket slash and then for powershell the way that is going to work is there is an object again the system script creates an object and shares that uh with your on the user script so basically we just dot source um the the user deployment script so we can access those variables and then we can just go and initialize just basically clean up the object just in case then i can because i already imported my module so now i can just go and invoke my module and i pass on some parameters right some some arguments uh in this case i'm just passing the same for one bar and then what i'm going to do is i'm going to say so now you deployment script output i want now uh to write something into my output so this is the way that you can write an output from a diploma script so you just go and say this is a hash table this is just an object so you can go and add what the key is and you can add the value the value can"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:35:22",
        "seconds": 2122,
        "text": "output from a diploma script so you just go and say this is a hash table this is just an object so you can go and add what the key is and you can add the value the value can be um basically needs to be an object right so that's the only requirement uh so the value cannot be an array it needs to be an object but of course the object can have a value of an of a type array right so that's the only um one of the considerations um so i think i'm just jumping ahead um but i think it's worth uh mentioning that that every single output needs to be an object if you don't pass an object we're going to try to parse the information the parsing is going to fail and the exception is going to tell you look your output is not a well-formatted json object so we try our best to just go on and put some um error information that is going to lead the user or the customer towards what the uh what the issue is so they can find a solution um in this case um i was saying that i need my module right so now my module is a different file different than the then than my script right so the one that is going to be in my entry point so now if i want to if i want to access this file then uh deployment scripts exposes something called uh supporting script uris which is an array of files right so here you can just go and put any file that you want to you want deployment scripts to download again so these files are getting downloaded inside the aci instance they don't get downloaded in azure right so again the system script is the one in charge of just reading this information and it's going to be in charge of just looping through every single item in the array and it's going to start downloading the information so which means by the time that this script is going to run of course we need to run the download first and then run the script uh when we run the script then the script already contains this file and then you can just go or your script is going to work as expected so if i show you really quick what are the steps so the steps are mostly the same right so i'm just importing the module and just setting the um my result to whatever function i'm invoking and then what i'm doing is i'm just accessing for example in this case i'm just accessing uh one of the the keys from my from my object my result in my deployment script case i don't want to access just a value i want to just go and push this my result object as a deployment script output and that's what i'm doing right here so just to print that output you can go and use of course in the output section you can use a reference function to your uh resource in this case the resource name and then don't forget to add dot outputs and then you can give the output name right so in this case it's a script output then that's the script output name that i'm going to use so if i have a different name of course it's going to be a different name but this dot outputs is something that doesn't change right so that's something that should exist always so if we look into powershell with outputs uh so now if i click in the outputs now i can see my result which is again let's go and put that maybe right here so we can see so that's my output right here my result and here's my output my result which is an object right so now that's the object that we are showing right so just having this uh printed as an output is is okay you can access the deployment outputs from a different um from a different maybe template but usually you have maybe another resource inside your template that is going to reference the um the the deployment script output right so one of the examples is uh let's say key vault and you create a keyboard first then you run deployment scripts to create a certificate and then you run another step uh let's say to create a vm and then you can use that certificate as the login information right so that's uh what what you can use right in this case i'm just doing this output uh it works just for visualization purposes or if you want to access the uh deployment outputs but usually is everything inside the same template so that's um that's for this one so again let's go and take a look at the overview so it's going to take a look at the inputs something um if you notice i'm passing this utc"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:40:27",
        "seconds": 2427,
        "text": "so that's um that's for this one so again let's go and take a look at the overview so it's going to take a look at the inputs something um if you notice i'm passing this utc value that i'm going to be explaining why that is and then if we look at the template again just one more time so i'm not lying to you guys so i have my script content that is now having a reference to my deployment script output and this is the one with my outputs and that's what i was able to get right here so that's for powershell with output now let's go and get into another example uh that i didn't include in in the um in the presentation but i think is is something that you guys should be aware of is escaping right so deployment scripts is written in c sharp right so what what it means is we need to double escape um any escaped characters right so we need to basically double escape the characters so the reason is because we pass so when we read the template the first escaping is going to be from the template to deployment script service the second uh the second escaping is going to be from the deployment script service into aci right so if you guys know aci the way that aci works is uh aci receives a command as an array of strings so that array of strings needs to be um so every single space is going to be basically be a new is going to be the delimiter to say this is um a next item right so if i pass this argument to what aci is going to receive is this one two three and four right so it's going to receive four arguments uh as part of the command right so that's why we need to double escape so the first escaping is from the template into deployment script service and the second escape is from the deployment script service into aci so that's how we can go and preserve uh the escaping of any character so if i do this then if i show you not this one but if i show you this one right here so now this is what i'm passing right so now i'm executing this and i'm passing foo with my double quotes on bar with my double quotes right so now that's that's what we are passing uh here's the information about what is the storage account that has been created what is the container instant that has been created so if we look really quick into the container instance we can go and look into these containers we look into the properties and here is what i was mentioning to you guys if i just increase this a little bit so is just an array uh is the command is an array of strings right so every single item is going to be an array of string okay so here's the as you can see so now this is the levelscape okay perfect um so if at any time i don't know if you guys have any questions just feel free to interrupt me we do have some questions okay let me grab you before we get too far here so [Music] we've got um this was asked i think it was around the first demo or maybe before is it possible to create an aad app and set application delegate scope for any resource using arm template um that's a good question i have to take a look because i i need to look into what the manage identities can do so i don't know if that can fall into that category maybe yes maybe no so i can get back to you on on that one cool um another one was just what about desired state configuration i'm not quite sure what context i was asked in um let's see so for dsc yeah sorry to stay configuration because that's i know kubernetes does just desired state configuration but so you know i assume maybe in the vm um so if it's in in the vm um so dsc is um so those can be as just as some as an extension of a vm um i don't know if maybe the question was related to um just when i was mentioning about some of the clever ways to run scripts inside azure one can be to just have a custom extension on a vm so maybe a desired state configuration is another clever"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:45:32",
        "seconds": 2732,
        "text": "when i was mentioning about some of the clever ways to run scripts inside azure one can be to just have a custom extension on a vm so maybe a desired state configuration is another clever way um so i'm not sure about the um the question yeah i'm not sure so we're also capturing these in um in the slack channel so we can um definitely make sure that we can revisit answers afterwards there there were a couple other questions around um it was when you were going through that second the powershell with the one with the output demo about whether or not you could download an app package and copy it was it can i use this feature to download app package and copy web app or function app yep um whatever you can do to just go and download is is up to you right so you can go and download a zip file you can go if there are if there are no tools available inside the container you can go and install those tools for powershell you can install any modules for for bash you can go and do an apt get and then start getting some of the um the packages that you need so yeah so it's is it's up to you there are no limitations on that front cool and then there was a kind of a follow-up will this be available as part of a commercial marketplace publishing application solution template so for publishing a solution template um so i think that might be more in line to template respects uh because this is just another resource uh template specs is a consolidation uh of resources that i can show later and that might be more in line to uh to to this question okay cool and there was um so if ricardo is still here he's the one that had the question or brought up the desired state you could come off mute if you want to ask your questions a little more with context hi how are you hello i'm good how are you yes doing great doing great um the question was uh uh when you were explaining uh on the arm template uh um maybe uh maybe i got it confused but the desired stake configuration it only applies to the vms or uh the the the whole um declaration of the resources that we that you are or we are um uh stating in the uh to create to create that's that's what uh my question was aiming for so if i if i understand um your questions well this dsc is is a powershell stuff as far as i know um for vms right so you just to go and run you create a vm then you run the desired state configuration which is basically as part of the vm creation is going to run um those set of scripts okay i got i got it i got it mixed up with uh since you're you're declaring we are the player on the on the arm template the way that you want it you know the way that you want the resources uh then i got a mixed up i'm sorry okay yep yep so thanks no no problem so yes so you can see the plumbing script as another alternative for dsc right so now you can go and access your vm and then you can go on and install any package that you want so you can do basically a bunch of stuff so it's is it's up to you um maybe dsc is better for other approaches so i think at the end is more um for for you guys to go and see what tool uh is best right so this is another approach for you to configure your control and data plane operations cool okay um any other question uh jason i think that's it right now cool so now let me go into uh into the next set of examples which are going to be now um bash specific right so for bash um just a few considerations right so i don't want to just go and uh and show stuff that can be simple for for you guys to to get but some of the considerations and what are the differences between the powershell version and the cli person or the bash person in this case so in powershell to throw an exception you do throw in bash you have to do a redirect"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:50:33",
        "seconds": 3033,
        "text": "considerations and what are the differences between the powershell version and the cli person or the bash person in this case so in powershell to throw an exception you do throw in bash you have to do a redirect right so let's go and take a look really quick into how that looks like and again all these different templates are going to be available in my github account and i'm going to be sharing that um at the end which i think i didn't include but um so anyway so here's the um here's my script again uh another simple script uh if you know bash this is the way that i can go and like lazy execute a specific function or an expression in this case and then i can go and check my result i can echo my result and then i can check if this is not zero in bash everything that is different than zero is an exception then i can go and say echo and then redirect this is a standard output into my standard error right so again bash specific zero is a standard input one is a standard output and two is a standard error so what i'm doing here is i'm saying whatever i just capture from this uh from this response just print that into my error in my error stream and this is important exit one right so again because we are in bash just doing an uh and or throwing an exception means doing an exit with a non-zero code so that's what you need to do so exit one so what that means is i can do an exit one without doing this echo uh what that is going to instruct the system or the bootstrap script is that there was an exception but there is no message so that's why it's really important for you if you are handling bash scripts uh inside a diploma script to go and uh do a standard uh or just redirect on the message and then doing the exit one as well right so these two needs to be hand by hand otherwise you can maybe scratch your head saying yeah this script is failing but doesn't give me any information and you might be blaming deployment scripts uh yeah that's how bash works right so for those of you uh really uh well-versed in uh bash this is something uh that you might already know uh some of you like myself i wasn't that well-versed in bash it took me some time to realize this information um so and of course what i what i did was just an az keyboard unknown there is no unknown key so that's why this is going to throw an exception and then the last one is cli running python right so remember that i mentioned that we have uh supporting a script you can also include a primary script right so if you don't want to have any script content right because maybe your script content is really long it doesn't make sense to just go and copy that and then paste that in your template because it's going to be confusing and if you want to go and test your main script there is no easy way to do that so that's why we expose another property which is called primary script uri so the primary script your eye is again another location that is going to point to a file right so if i'm in a bash you might find cli it should be a dot sh or it can be actually um without any extension it depends on uh on how you you author your script uh this is not a bash uh session um but just just wanted to to mention that um and again supporting scripts right so now i can have my main.pi i can have my requirements.txt and then i can just go and and have another class that my python script can call right so now as you can see so now the the options are are multiple so now whatever you were used to do inside uh your local computer to just go and maybe finalize the configuration of an aks cluster just by importing a bunch of packages and running a bunch of bash scripts or maybe a bunch of python scripts so now you can just push them into supporting script your eyes have the engine to download all the files and then you can have your primary script that is going to be the entry point to just trigger uh the execution of your script right so now this is another way that you can just go um and execute your your scripts so and again i have in this case my python script actually outputs uh some some stuff so now i can access the output um as"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "00:55:37",
        "seconds": 3337,
        "text": "that you can just go um and execute your your scripts so and again i have in this case my python script actually outputs uh some some stuff so now i can access the output um as well right so the way that this is going to work is my my main on my primary script is going to read the outputs from my python script and that's the one that is going to output um the information right so that's how it works right so there's always an entry point is your script content or your primary script uri and then any supporting scripts so to write to outputs in bash is a little bit different than powershell and again in the documentation side everything is is included so feel free to just take a look but as i mentioned before sometimes it's really boring to just go and and look into the documentation especially we have tons of documentation so here i'm just showing you uh what is the syntax to write an output in apache script so this is what you need to do you just need to redirect any uh any echo so like any any any stream into an a z a scripts output path right so what this is going to do is it's going to create a file that we already expose as an environment variable so we know the information of this and then basically this is going to say all this information right here just put that inside this file right so that's how it works so why bash and powershell they are different because powershell has a notion on just sharing uh the the environment variables right so you can share them and then you can read information in bash is a little bit tricky because yes you can share a state you can dot source information um but the problem is how you can go uh um basically bash it is not a strongly type that's i think that's the easiest answer right so bash is not a strongly type whereas powershell is strongly typed so now in bash you don't know if um an output can be a string value you don't know if the output can be an adjacent object you don't know if the output can be an array it's really difficult to create that type of um type of object in powershell no right so in powershell really simple so that's why in powershell we share a specific variable in bash you need to write the outputs right so that's the only way uh that we we said like there are so many ways that someone can write an output and so many checks that we need to do so we said okay let's go and and have the end user to write the outputs in the way that they they want and for bash people jq is a way to just go and construct a json object or json string uh in uh in bash right so and the the container for cli already contains jq right so this is the way that you can go on and output this so i have um an example right here so if we go into my cli if i check my outputs so there you go so now we have a well formatted json object that contains the information from my keyboard cli command all right so that's how you can go and um and get the information all right so again yes so you guys know that i'm not lying to you here's the here's the same template right so here's the template where my script content is this um so this can be a file yes can be a file uh but this is the script content with the same uh redirect uh to a file in this case right so then here's my output which is just an object i can do an output of a specific array index and a specific value if i want to right so that's another option um as well okay so let's continue um are there any questions on this on the bash part it's really similar to powershell so just a few considerations yeah it looks like we're good right now okay so let's look at some considerations um and i already mentioned a few of them so it should be uh already a little bit familiar with you so bootstrap script right so powershell and bash right so we created a set of powershell uh one powershell script and one basher script that is going to orchestrate the um the deployment script"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "01:00:39",
        "seconds": 3639,
        "text": "familiar with you so bootstrap script right so powershell and bash right so we created a set of powershell uh one powershell script and one basher script that is going to orchestrate the um the deployment script so it's going to download uh it's going to download the the files it's going to execute the files so this is important right so there are some properties that i've been just showing you but there are properties that you have to um that you have to consider so clean up preference so this is really important the reason is because we have three clean up preferences we have on success one expiration and always so what cleanup preference means is let's say in the in the happy path right so your script got executed you got the outputs then we don't want you to have just like resources sitting around what we do is we go and we delete the supporting resources so we go into aci we kill aci we go into the storage account we remove the storage account so but to do that there are different flags right so unsuccess basically means if your script succeeded we delete the supporting resources if your script didn't succeed then we won't be deleting any of the supporting resources and instead the bootstrap script is going to uh keep your container alive for one hour so the reason is you can now log in into your aci instance and then you can debug the information right so that's why uh we have this just keeping alive right so if you know a little bit about aci when you execute this like something like a fire and forget right so you fire something and then finishes and then shuts down so if it's if it shuts down then you won't be able to log in you won't be able to get into any debugging information so that's why the script fails we keep the container alive for one hour so with on success as we said so if it fails um then we just keep the container alive on expiration we always keep the supporting resources alive and then is up to um your timeout uh and your retention period just go and say how long those resources are going to uh are going to still be sitting around in your subscription right so basically on expiration it creates like a background job that you tell in the deployment script how long you want those uh those resources to um to exist and then once that expiration uh comes then we clean up the resources and always so basically if your script failed if your script succeeded we basically don't care we just clean up we clean up the on the resources so escaping right so i show you how aci passes an array of strings so we need to do a double escaping because as i mentioned we go from c sharp in from the from the arm template into c sharp from c sharp into aci right so c sharp is a diplomatic script service so we follow this escaping model so we we didn't like go and create our own escaping model so we just use a system call to just go and unfollow some standard so that's the standard you can go and take a look and and i usually use this tool to use that will escape my arguments so the timeout as i mentioned so timeout is going to say how long your script is going to run force update tag so now you have to know that azure receives millions of requests millions millions of requests we are going to just go and analyze every single script and start just triggering jobs so at some point is one of the jobs is going to say you know what i'm i have to do nothing because this um this script is identical to the one that you already deployed then we're just wasting resources so to do that what we do is we go and do some pre-flight checks so we analyze the content of your deployment script right so the script content and we check um against our database and we say like is this the same right so if it's the same and is using the same resource name then most likely this is the same script and we're going to do something that we call no operation or no op so we're going to say you know what i'm sorry this looks the same to me i'm not going to be wasting resources but what happens if"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "01:05:41",
        "seconds": 3941,
        "text": "and we're going to do something that we call no operation or no op so we're going to say you know what i'm sorry this looks the same to me i'm not going to be wasting resources but what happens if you are not passing a script content and you're passing a uri to a supporting script then at that point we're going to say the file names are the same i won't bother going into your uri and analyze your stuff to find any differences because that means that i need to store the previous version so we won't be getting into that business so that's why you use the force update tag so force update tag uh if you look into the templates uh so you said so those are going to be shared uh we use the utc now function so basically it's just going to get a new value every time that you run a new deployment script so what that means is get into the habit of using the force update tag because if for some reason you just change from a script content into just a file then the next time that you run you are going to be guaranteed that your script is going to always run again versus if you don't put the force update tag and you use the same file name then we are going to say this looks the same to me i won't be running this script and then you're going to again be a scratch in your head saying how come i updated my script i fixed my stuff and deployment scripts is still failing right so that's because we're going to say you already deployed something that failed i don't know if you fixed your file so i'm going to just do nothing so that's why you use the force update tag and then the job timeout right so as i mentioned so the way that azure works is everything are jobs uh a bunch of asynchronous calls so nothing like you're going to just be waiting right so when you run an arm template it's not that you're sitting there just waiting for that response so it's basically going to respond at 201 saying accepted and then wait or just do some polling to just get the information uh of the operation but of course we we're not going to be running um diploma script forever right so we have a timeout right so it's roughly one hour um so what that means is you might want to be inclined to say now that i have deployment scripts let's go and create a full environment with one single template because that's what i did in the past my answer would be no because we are not going to be running forever your deployment script right so as i said before so i should receive millions of requests we don't have we we won't be able to be or give you the luxury to just go and run something forever we're going to just be timing out a specific time so that's why if you if you say yeah so now that we have deployment of script so now all my scripts the provision my aks cluster and provision my application gateway uh and everything i'm going to just move into deployment script so you think that a couple of times before doing that and then only move whatever is necessary into deployment scripts and not move like everything as a lift and shift type of approach um so to meet compliance regulations um so i mentioned and you guys saw um the deployment script is going to create some cryptic names uh for the resources for the supporting resources so what that means is if you have a policy with enforcing a specific naming convention uh deployment script is going to say i'm trying to create something and you policy you're blocking me so for that specific situation we offer the way um to just use an existing storage and use a custom aci name so to use an existing storage account then you just go and create the storage account you just need to make sure that supports file shares there is a combination of skus on um that you can that you can use to just create file shares uh and then all what we need is we need just access to the file share so we can go and create file shares and delete file shares so when when we do the let's say again the cleanup process right so the cleanup preference let's say that you said always and then you're using an existing storage account we are not going to delete this storage account right so that would be really bad and it's going to look really bad on us and that might uh cost my job so what we do is we just go and delete the file share that's it so whatever we created that's what we delete right so if we created the file share that's what we delete if you have a storage account for some other stuff just rest assured that"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "01:10:45",
        "seconds": 4245,
        "text": "the file share that's it so whatever we created that's what we delete right so if we created the file share that's what we delete if you have a storage account for some other stuff just rest assured that all the other stuff is going to remain the same all what we're going to do is we're going to try the file share and we're going to delete the files here right so if for some reason you get into a deletion of a storage account um just pick up the phone call me right away because that is going to be really bad hopefully we just run a bunch of tests we have a bunch of um monitoring and everything that we just account for for this not to happen for using a custom aci name that's um that's that's tricky in the sense uh when when you use let's say two diploma scripts one for bash and one for powershell uh and you use the same aci name and you go to the same resource group right so if you remember as i mentioned deployment scripts create supporting resources so deployment script is going to create an aci with a name equals to full and it's going to create that in the resource group bar so that's for deployment script one is deployment script two deploys to resource group bar using full as the aci name then deployment script is going to say i'm trying to create an aci that is already in use by another deployment script so we are detecting that race condition and we're going to say we're going to block the second deployment script whoever gets second right so maybe it can be the second deployment or script can be the first so it depends so the one that got scheduled first is the one that runs and the second one is going to just uh get denied right so that's that's super important for you guys to to to be aware of that that we are running a bunch of checks to go and say um if aci is being used then uh we're going to prevent the execution you might be lucky if the two um if the if you run one deployment script and that finalizes just right before the second one then um then it might seem like both went through but if there is a race condition we're going to capture that race condition um so what is the work in progress so i didn't talk about service endpoints right so service endpoints are really important for uh compliant regulations um so service endpoint is in the works right so it's in the works and it doesn't depend entirely on deployment scripts we use a storage account which already supports service endpoint and we use aci with manage identity that they are working on fully supporting service endpoints so when that happens then we're going to just turn on the switch and deployment of script is going to be fully integrated with service endpoint as well uh token forwarding or on behalf of that's another important feature um so today if you have a deployment script with the manage identity is the manage identity that you specify in your script the one that needs to have access or permissions to create the storage account on aci when in theory it should be the logged in user so we are working on uh on having that token forwarding which means whoever logged in that's the the authorization and the token that we're going to use to create the supporting resources and not the uh the manage identity from the deployment script so those are in the works um so hopefully in two three months we're going to have an update uh and maybe this can get uh fully released and supported so i'm i have a few more minutes and i'm going to just be talking about template specs just um and the demo is just um show how how that gets created um but let's go and finalize with this um approach so monolithic versus modularized templates so if we look at the aks example i can go and create one single arm template a big arm template that configures my environment end-to-end that's acceptable it depends i think from the maintenance perspective it becomes a maintenance hell uh and we don't want to get into that so usually you go and break those down into multiple templates and that's when link templates come into the picture but link templates have some challenges right so you need to stage you need to push those files in a public location and the reason is because azure needs to access those files right so those files should reside somewhere uh somewhere in the public maybe protected with some password or protected with uh if it's a storage account with"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "01:15:48",
        "seconds": 4548,
        "text": "and the reason is because azure needs to access those files right so those files should reside somewhere uh somewhere in the public maybe protected with some password or protected with uh if it's a storage account with some keys but protected right and public and then you need to synchronize with your maybe your source code management right so if you make an update to your template you better want that to get replicated and if you're using a storage account and you want like uh geo access multi geo access then you might start thinking about putting a cdn uh but now you're just adding a bunch of stuff right so why needs to be really hard for customers to just go and share a template so now we show template specs so now you can use you can share and modularize your templates using template specs so i put the um the icon of blueprints for those um that are familiar with that because is is the evolution of a blueprint definition not a blueprint assignment but a blueprint definition so it's a new way to stage your templates the nice thing is is a first-class azure resource which means you can apply azure policy you can apply our back right so it's another resource you can just do whatever you want just manage access to your resources and they are going to reside in a resource group because they are what we call track resources so azure is aware of that resource and it's going to replace the azure blueprint definition when we uh go into public preview and maybe into ga so for now we just use a cli but soon it's going to be uh powershell and the azure cli that are going to be supporting um the creation of um template spec so before i go into this demo jason are there any questions on on this part not at the moment uh you have anybody with questions please add them to the q a sounds good okay so let's go and take a look at the demo of template specs and that's almost towards the end so in template specs so we have an isim private preview which is right here on this screen so there is a cli as i said um so you can go and say new az template spec you provide what the resource group name is what the name of the resource is going to be version which is super important uh location and what which one is your file so i use some of my um so my azure cli deployment scripts template and that's what i uploaded so now if we take a look right here so let's go first into my resource group and if you can see right here that's my template spec so if i go into my template spec what i'm going to see is so this is the latest version when it got created what is not my name the name of this uh and then the template and from here i can go and choose deploy if i want to or i can just go and say you know what i'm going to just restrict access or give access to a specific resource group i can apply policies right so i can do whatever i i want with an azure or whatever i can do with an actual resource so it's the same so now this becomes an actual resource what what means is if you have access to this subscription onto this resource group then you can go and deploy this template spec into any other subscription so now what that means is you can have one repo in your resource group in subscription foo to say this resource group is for all my networking templates so now my networking team is the only one that can maintain those templates and they have access to um to that resource group and then you can go and say now networking team you're going to have access to all these different subscriptions so you can go and stand up new networking infrastructure and then just go and use your template spec uh resource cs go and stand up a new uh a new maybe a new you know v-nets or subnets or whatever you need so the um this is the repo so i'm going to share this is the um you know link the link is over here that i'm going to be sharing with you guys um so this is private preview so if you want to sign up you have to go and fill out a form it's a simple a few questions that you can fill and then you're going"
    },
    {
        "speaker": "",
        "title": "Jorge Cotillo: IaC using ARM Templates, Template Specs & Deployment Scripts",
        "videoId": "kOMOOMVpQMI",
        "description": "This is a recording of the July 30, 2020 virtual meetingIaC using ARM Templates, Template Specs & Deployment Scripts - the last mile to configure your environmentARM Templates are used to provision environments using a declarative approach. Often, people find themselves needing to use some tooling to configure Azure Control or Data Plane of provisioned resources to finalize that last mile to fully configure an Azure environment. Tooling such as Azure DevOps tasks (Powershell or Bash), Github Action tasks, or maybe CustomExtensions executed from within a Virtual Machine (for those more adventurous).All these approaches work, but usually mean to grant additional access to external public IPs to access Azure Control and/or Data Plane operations, and don't forget the need to create a Service Principal to control RBAC permissions.Now, with Deployment Scripts (in Public Preview), you can run scripts (Azure Powershell or Azure Cli) inside an ARM template, and the best part, you can expose script outputs and pass them to other resources in your same template. Deployment Scripts are modeled as an ARM Template resource, which means, you can use all the goodies you have available in an ARM Template (e.g. copy function, dependsOn to describe dependencies, nested deployments pointing to different Resource Group and/or Subscription).We'll analyze a few scenarios on what you can achieve with Deployment Scripts in both Powershell and Bash, we'll import modules, run python scripts, install dependencies, escape script arguments - pretty important - and how to ensure that your Deployment Scripts resource complies with your Enterprise Compliance regulations - super important as well.Finally, we'll talk about the new way to share this template inside your organization by using Template Specs (Private Preview - soon to be in Public Preview), Template Specs is a new way to stage your ARM Templates (and version them) as first class Azure Resources, which means, you can apply RBAC and Policy to manage Template access, it also means, no more Azure Storage Account to stage your ARM templates.Github with the samples and presentation: https://github.com/jorgecotillo/boston_azure_2020SPEAKER BIOJorge Cotillo - Jorge has been coding since the age of 10 when he first printed a green square on a screen using Basic on a Commodore64, this event settled his passion ... passion for coding.He's been in the consulting industry for around 12 years before moving into a position in Microsoft Azure as a Senior Software Engineer as part of the ARM Deployments team.Since joining ARM Deployments, he participated in different implementations/enhancements of the following services: Azure Blueprints, Deployment Scripts, VSCode Extension - Template engine evaluation, ARM Schema repo, bug bash session of Template Specs, the new ARM Template Language and much more to come ...",
        "start": "01:20:52",
        "seconds": 4852,
        "text": "um so this is private preview so if you want to sign up you have to go and fill out a form it's a simple a few questions that you can fill and then you're going to get access to on this repo so you can go and check how to do the quick start how to deploy the template spec how to create a template spec right so here the creation of template spec this is how you can deploy a template spec right so you can go and get the id of the template spec and then you just do like any normal resource group deployment the only difference is instead of passing a template file or a template object now you pass a template spec id and the content is going to be basically the resource id of your template spec right unknown participant is now exiting up okay um so that's that's how you can go and deploy now um a template spec across multiple subscriptions right so now no longer staging stuff into a storage account or in github or any other place now everything becomes azure construct and azure native for you to go and use and i think that finalizes um the the session and then i think we already covered the q a but i don't know if there are any additional additional questions and here are the references that i'm going to be sharing again uh but i don't know there are any questions yeah there's one more question um basically just wanted to verify that the blueprints are more or less going to be called template specs when everything gets solid yeah yeah um blueprint as a service is going to remain uh what is going to change is the inner uh so the shell of blueprint definition remains the same but how you can author on and blueprint definition is going to be a template spec right so blueprint service is not going to get retired is going to now ingest template spec to just create a definition uh and when that happens we can go and say template spec is g8 and then deploy um blueprints is j um as well and we're going to be offering um some translation mechanisms that if you already invested in creating the blueprints or blueprint definitions we're going to offer some way to translate those into into template specs any other question that's it in the uh chat at the moment if anybody wants to uh come off mute and ask please feel free to do so otherwise i guess um we can wrap up sounds good and um i think i'm going to be sharing this um this presentation with you jason so you can just publish so everyone can access so here's the sign up for template specs uh here the documentation the templates pick repo you're going to get access when you sign up uh that's my email uh if there are any issues uh feel free to reach out um i think that's that's pretty much it awesome thanks cool oh thank you man been a pleasure to just uh talk again in what was my home meetup yeah i was born in in the boston meetup so it's good good to see you yeah i know great great to have you back and and presenting it it's great i know a lot of people a lot of people disappear into the microsoft machinery and they never presented meetups again so it's it's great to see that you have been chewed up by the machine no so yeah so there are um maybe you know in a future event i can talk about what if which is the uh how to man well it's the state is similar to the estate uh machine from from terraform but being an usher uh construct so it is going to show you the deployment plan and what it's going to do is going to create or update resources um delete resources depending on what you're doing uh it's pretty cool um that's for what if and then maybe later we can do a more deep dive on template specs right now it's just private preview all right awesome man cool okay well there are no other questions so here's 4 30 i have to go um to the next meeting in 10 minutes so so if there are any questions here's my email just feel free to reach out sweet awesome cool and yeah thanks for thanks for uh coming and uh thanks for all the uh the good questions tonight everybody it was pretty interactive group tonight and it sounds like a lot of you guys are really into this uh infrastructure code code stuff so it's good oh and anyone has uh topics that they want to hear in the future please uh feel free to either reach out to me via email jason jasonhantley.com or veronica bill or i on twitter were easily to catch there or you can just mention on any of the meetup groups in the comments there but we're we're always interested in what people are want to hear these days because so azure is such a big topic there's so many um there's so many areas and corners to cover you know we don't want to necessarily put together a talk that is just interesting to us we'd like to have a more educational or learning platform for attendees to come and actually learn something and provide some good content and plus with the youtube channel um you know if you don't get to make it to a talk you can actually go catch it later or if you find it really useful you can go back and watch it again or parts of it that you found useful so um i'll just go ahead and wrap up here real quick we've got um uh michael crump on deck to present uh august 11th it's on a tuesday um same time 6 p.m eastern and he's going to be doing azure tips and tricks you may have seen his blog where he does uh he was he was doing several a week but i don't even know what number he's up to these days but he's he he's really focused on um little tips that are easy to digest but are very um very much useful for improving your productivity with azure and also just learning the platform more so please join us august 11th and um i'll just wrap it up here thanks for coming everybody thank you guys for attending see you you "
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Alex Frankel: Bicep. This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.. for the recording banner to pop up yeah hopefully it'll pop there we go cool um awesome thanks jason and and thank you all for for having me i wish i was really in boston i really like the city of boston um but this will have to do for now and maybe at the next meet up next year or something we can do it in person um so yeah as jason mentioned um i'm a program manager on uh what's called the arm deployments team so arm core the arm api that kind of backs azure is broken into a few uh sub teams and one of them is this deployments team that's responsible for all the native declarative deployments to azure so that includes the things that jason was mentioning blueprints arm templates this new bicep project anything kind of adjacent to that there's uh capabilities that we've introduced like deployment scripts and what if all that comes out of out of our our team and today we're obviously talking about uh bicep we'll do the overview we'll do um kind of give you a sense of where the project is at my current status what what release where we're at uh we'll do some demos and then um we can talk about future roadmap um but please uh interrupt me as much as possible these are more interesting when when i get interrupted so whether you want to ask questions in the chat i'll have the chat open or if you want to come off mute and ask that way either works for me um so let's get started let me move this slide here i'm not in presentation mode i'm on i'm not usually on this monitor it's one of those ultra wide screen monitors and i'm just presenting the window and i don't know what's going to blow up if i go into presentation mode so we're going to stick with this one for now um so to start out you know what is bicep um are most folks here familiar with with arm templates maybe a virtual raised hand or something in the chat if you do have some experience um arm templates are just a way of deploying azure resources declaratively is what we say so basically you describe in your arm template your goal state what you want the x number of resources you have in your template to look like when the deployment is done sometimes we describe that as taking care of the what versus the how um so you with an arm template just describe the what of what you want you don't have to be responsible for how that actually takes place you don't have to care if the resource exists already or or not um is the idea there uh with bicep we're basically it sits on top of arm templates uh bicep is is most literally a transpiler so it takes bicep code and it turns it into arm template code and at that point it's just a regular arm template there's some extra metadata littered in there but for the most part it's just a regular arm template and that means that anywhere where you can use arm templates you can use that with bicep generated arm templates we have this command in the bicep cli which i'll show which is the build command which is what literally takes you from bicep to arm templates but we do a bunch of things now to basically force you don't you don't have to see the json if you don't want to or the arm template if you don't want to so when you're deploying or creating deployments to azure you can use the bicep file directly and when we see that we know to turn it into the json arm template before actually sending it to azure to be deployed but at the end of the day there's always an arm template involved if you're familiar with the relationship between typescript and javascript it's exactly the same story here why are we doing this so uh what's what's funny is um you know before we started this bicep project uh arm templates were certainly not the most desirable tool to use um and i i think we lost quite a bit of mind share in terms of people thinking arm templates was a good or helpful tool to use but the reality is that they are by far the most widely used tool for doing these declarative deployments to azure and that's comparing tools like terraform or pollumi or ansible or things like that those are what we consider to be the declarative tools arm templates is the one that is most commonly used and so really the point of the bicep project is to lower the kind of pain levels and the barrier to entry for customers that would otherwise or are using arm templates so if they're already using arm templates we we definitely have an interest in getting them over to bicep because their experience generally is is better but also um for you all or if if"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:05:05",
        "seconds": 305,
        "text": "otherwise or are using arm templates so if they're already using arm templates we we definitely have an interest in getting them over to bicep because their experience generally is is better but also um for you all or if if you're consulting and work with customers for customers that are transitioning between the portal to infrastructures code for the first time i think in the world that we're in and going to meetups and being really active in in the community we tend to think that infrastructure as code and kind of modern deployment practices are very common or universal but the reality is that there's a long way to go um in terms of maturity so there's a lot a lot of users of azure or the cloud more generally that just haven't made that transition yet and at that point we want bicep to be a great tool in the sea of options that you have for for deploying to azure um this is a better way of saying why we're doing this um so this meme circulated on reddit i guess closer to two years ago at this point um just saying you know azure's awesome there's all these services that we make available and we're constantly iterating and coming up with new new things but arm templates leave a lot to be desired when it comes to accessing those capabilities so our goal is really to make this this dog happier and not have to deal with these gnarly functions um i'll talk through the the benefits like i said and then and then talk through the state of the project um so don't worry about paying too much to the like literal syntax on the left and right hand side the important uh bit here is that the left hand side is bicep code and the right hand side is equivalent arm template code um and this really speaks to one of the first benefits is just that the code is a lot easier to read it's much terser there's no what we sometimes call json noise the the kind of biggest challenge with arm templates was that we kind of had to stuff the arm template language into json and it had to be a valid json document so all of the arm template language if you have experience with it anywhere where you're seeing syntax highlighting inside of these open and closed square brackets that's the actual arm template language and it's inside of a json string value and all that really means it just makes it all much more difficult to offer good tooling it makes it more difficult to do good validation good intellisense all these sorts of things that we expect from modern programming languages were really kind of fundamentally difficult because we had to fit inside of a json file so with bicep on the left hand side we have our own file extension we have a very deliberate syntax there's no none of this extra noise and that just ends up making the the code a lot easier to work with on a day-to-day basis day 0 support is is the next big benefit and this is just as true of of arm templates as it is with bicep so both arm templates and bicep are very thin abstraction over the arm api and and what that ends up meaning is that as resource provider teams create new resource types or new api versions of existing resource types all of it kind of just works in in bicep and with arm templates there's no uh onboarding step that these teams need to take uh beyond what they're already doing to make things work properly in bicep that's great if you are on the bleeding edge and you want to take advantage of the new azure orbital service and push satellites around or whatever that service is for but where it ends up being more important is new api versions of existing resources so if you're using virtual machines or websites or what have you there's new api versions of those services all the time um and they usually contain a new new feature that you may want to take advantage of or a critical bug fix or or what have you um and so being able to consume those new api versions when they're available um ends up being being really valuable uh the next big one um is is a first class modularity and code reuse story this is one of those things in arm templates that technically you could do but was really difficult and really error prone and very much like a duct tape and glue kind of solution it was not well considered when arm templates were created um and so this was just a tricky kind of thing to get right with link templates where you had to stage files to a storage account some of you may be familiar with that process pretty gnarly with bicep we have a very straightforward modularity story that should feel familiar if you've used kind of any any modern programming language or scripting language so if you're familiar with powershell modules or or typescript modules"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "familiar with that process pretty gnarly with bicep we have a very straightforward modularity story that should feel familiar if you've used kind of any any modern programming language or scripting language so if you're familiar with powershell modules or or typescript modules or terraform modules they all happen to be called modules but there's you know code splitting strategies and and uh uh features in any programming language these days so this is is much closer to that than what we had previously um and this one is probably my most important point or the one i'm most passionate about um is that bicep was really built for two ability from from the start it has really really good uh intellisense and validation um and the the context here is that when we worked on arm templates there's a vs code extension called arm tools um and like i mentioned earlier we being forced to fit into a json file really fundamentally limits how much you you can do in the tooling space and so when we started bicep we really knew that we we wanted to focus on this that this was really important but we had no idea how to do this and so we consulted with some language design experts here at microsoft that we are very blessed to have access to um so so c-sharp was was designed at microsoft but you may not know that typescript was also designed at microsoft uh in part by the same person that we've had an opportunity to talk to his name's anders heilsberg and he gave us a lot of really good insight into how you make a language toolable um and he gave us really really excellent advice and we were able to kind of build on that and that's all a really really long way of saying that the tooling experience is great and it feels much more like a traditional modern programming language than a declarative config type language um it shares a lot of dna with how those modern programming languages are built so even though it doesn't look like a traditional programming language it feels on a day-to-day basis like a programming language in kind of the the best way um the next benefit no state management so if you are using terraform or polumi those tools require you to have this this state representation because they work not just with azure but with a whole suite of providers and so they they need some representation of what those providers look like and they do that with this concept of a state file with bicep and with arm templates we use azure as the state so if we ever need to get information on a particular resource we do a get request on that resource id and we get the latest information so there's no need to have a state to to track um and we can have experiences like like what if where you can predict what the deployment is doing by clearing the current state of the resources whether they exist or not and whether that state matches the state that you're going to submit uh with the arm template and so if you you know submit your bicep code to azure and then throw your laptop off a cliff you've already sent what we need in order to carry out your deployment so that we'll all finish versus some other tooling that does that all client-side so goals and non-goals goals i kind of spoke to with the benefits so certainly we want to lower the barrier to entry and improve validation as much as possible um we want to be that transparent abstraction where you can leverage the entire platform and we want to be modular so that you can make sure your your code is maintainable over the long run and then the non-goals we don't want to be one language to rule them all so we don't have any kind of intention of saying the only way the only good way to deploy to azure is with bicep and all the other ways are bad we like i mentioned earlier with bicep we just want to be a great option in a sea of great options so we invest a lot to make sure our terraform provider is really capable if you want to use powershell or coi to do your deployments to azure if you want to do port use the portal to do your deployments to azure all of those are valid it just depends on on what your use case are what your scale looks like and so on and so forth so we really just aim to make all the clients to azure as good as they can possibly be um and then bicep is not a general purpose language so if you need to do a lot of number crunching or data processing or transformations or things of that nature you may find that you still need to write a powershell script or a bash script to do some of those things in a pipeline either as a pre or a post action or something of that nature [Music] cool so this normally animates but i'll just get right to it so uh the project is about a year old right now so we had an 0.1 and an 0.2 release that we got out"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:15:14",
        "seconds": 914,
        "text": "nature [Music] cool so this normally animates but i'll just get right to it so uh the project is about a year old right now so we had an 0.1 and an 0.2 release that we got out really quickly and that was just to get it out there and to get feedback and to get people's reactions uh on the goals of the project and it wasn't really until our 0.3 release which was in march of this year where we declared ourselves production ready that microsoft support would take support cases for bicep issues and that we had parity with arm templates so that anything that you could do in arm templates you can do in bicep and right now we're kind of in the later stages of our 0.4 release so that the o.4 release has been out for a little while we've done a few kind of releases within 0.4 to ship some new features but really the focus for this one has been on quality and stability so there were a handful of bugs um that emerged with with 0.3 or on our way to 0.3 and as we've seen a kind of big increase in usage post-production we've really just wanted to make sure that things continue to be stable and usable there are a handful of other other features like speeding up the inner loop with a winter that i'll i'll show today and then we just this past friday and i'll demo this as well introduce a private module registry so that you can share code not just within your your repo but you can set up kind of a essential source that people can pull from uh awa nuget or or npm uh that that sort of thing any questions i'm about to go into a demo but this is a good time to to stop and any any clarifications or questions i can answer okay then i'll keep going um so let me stop sharing this window and now i'm going to share a different window you are able to see this yeah i can see it good cool bigger um okay so uh i'm in vs code right now and i have the bicep extension installed um so you can and actually let's update it to the most recent version do this live um so like i said this this came out on friday and so i happen to have not installed the most recent update but you can go into the the vs code extension tab and install it today it's all public uh and then once you've done that vs code will recognize the bicep language and that just means that the bicep extension or what we sometimes call the language service is running and providing assistance and validation to you so what i'll do is just start by authoring a really basic uh kind of raw resource declaration um so i'm gonna author um a an app service plan or server farm it's gone through many different names at this point um so we'll we'll call this an app plan so we have a resource keyword and then we have what we call a symbolic name this is like a variable name so i could have called this foo i could have called this my app plan i'm just going to call it app plan and you'll see where this is useful in a second and then it's going to ask me what type of resource i want to create and this is when we say transparent abstraction this is what we mean so all the different uh resource types and child resource types and api versions they're all represented here in this very long list and this is all the things that azure and arm exposes now i can filter this list down just by typing and i can search for server farms and if you didn't know uh in the at the api level uh an app service plan is actually called a server farm so this is the kind of information you need to know if you want to use use arm templates and bicep and then i'm going to pick an api version and 99 times out of 100 i'm going to pick the most recent api version unless i have a reason to pick an older one for some some reason so i'm going to pick the most recent one and the reason that we have these api versions is so that the bicep code uh is maintainable over time so as the resource provider ships new api versions there's a commitment from microsoft to maintain these older api versions for a long time so you should be able to leave this code alone come back to it a"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:20:20",
        "seconds": 1220,
        "text": "maintainable over time so as the resource provider ships new api versions there's a commitment from microsoft to maintain these older api versions for a long time so you should be able to leave this code alone come back to it a year later and the behavior should not have changed sometimes things slip through the cracks and breaking changes get into old api versions but that's the exception uh not the rule and the reason that you pick an api version for each resource type is because these resource providers are all different teams it's a completely distributed system and so if one team revs their api version it has nothing to do with another resource provider revving their api version so you want to generally speaking keep these separate and contained to the resource types that you're using um so now i'm going to do equals and then i'm given some options to kind of make writing certain scenarios easier so i have options for doing loops or conditional deployments and things like that i can insert all the required properties or i can just do an empty object which is what i'll do for kind of pecking out the whole resource so we can understand kind of how that works i can do control space at this point and i can see all the top level properties that the server farm resource makes available so i need to provide a name and a location so i'll say this is alfran app plan and for the location i'm going to use the location of the resource group so in bicep we expose a a library of built-in functions these are the same functions that you have access to in arm templates if you're familiar with those i need to set a kind which is going to be linux i need to set a sku which is going to have a name property and the skew in this case it's going to be b1 um you'll notice sometimes like when i when i did kind here i got no intellisense options and the reason for that is because the api specification that the web team publishes with their api does not have that information so going back to us being a transparent abstraction we are at the mercy of the resource provider for making sure that they specify their resources correctly i'd say web is is more of an exception than the rule in terms of uh resource types doing this correctly so we're working with the team to get this uh updated in most cases uh the the values are pretty accurate um and you'll get intellisense as you're you're typing through all these things but for for server farms you have to know a little bit more than than you otherwise would um and then i need a property um called reserves so these are all the properties that are exposed for this api version this is actually just a great way to explore what the resource type offers but in this case i just want the reserve property which lets me make sure that it's going to be a linux app service plan um now this is everything's hard-coded this is not kind of a typical way i would author a resource normally i'm going to offer some parameters to make the the code a little bit more dynamic and useful for a broader set of use cases so i'm going to author a parameter i'm going to call this name prefix and it's going to be of type string and we can see here i get a yellow squiggly telling me that the the parameter is not used that's the linter doing an extra set of checks for me to make sure that i'm doing what is expected even though this code will deploy it's probably not what i intended i do want to use this name prefix so what i can do here is do string interpolation so this should look familiar if you've done string interpolation in other programming languages this is the equivalent of doing the concat function in arm templates so it's just a west verbose way of describing that if i wanted to set a variable or another parameter i could i could do that for something like the sku so i may want to say the sku which is also going to be a string and i want it to have a default value so with parameters if you do equals that's the default value of the parameter and so that just means that when the code is deployed i don't need to input the the sku necessarily so i can do sku here uh i also have the ability to set variables so i may want to do var kind equals linux and i can just replace that with client here as well so you have a set of different things to help you make the code more dynamic and variables can help you reuse code just like they do in any other programming language and then the last thing i'm going to do on this file is set an output so for most of these resource types you want to get information either out of the the module which is what we're going"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:25:22",
        "seconds": 1522,
        "text": "and then the last thing i'm going to do on this file is set an output so for most of these resource types you want to get information either out of the the module which is what we're going to do here or you may want to read that from the deployment itself to get some output in a pipeline that you use somewhere else in the next next task in your pipeline so in this particular case i want to get the server farms resource id because we're eventually going to create a website that sits on top of this app service plan and we're going to need the resource id so i'm going to do output is the keyword in this case and i'll say plan id also going to be a string and then here's where we get to use this symbolic resource name for the first time so we have this thing called app plan it's different than the actual resource name it's just for referencing inside of the bicep code so what we're going to do here is say app plan dot id in this particular case if i needed another property from the app plan i can go to properties and i can look at all the properties that they make available and this will include read-only properties properties that you can't set when you're creating the resource but do exist when the resource is created and so bicep understands that distinction and will show you the right list in the right at the right time but like i said in this case i just need the id and now i have a complete bicep file that will deploy the server farm that we're going to consume as a module in a second but i will stop and and take any questions if there are any any questions on the code that we've walked through so far any clarifications or hopefully i'm just being incredibly clear the only question i have as i see you type in this is um is there a is there something where i can take my existing arm templates and come back to um to biceps so that because this definitely looks like a lot cleaner way to store my scripts versus the arm templates that are just have so much junk in them right uh great question uh so there's a couple different things that you can do uh with your existing arm template code uh one is you can use a command we have called decompile so you can do bicep decompile point it at an arm template and we'll convert it to bicep for you it's machine generated code so it's not going to be perfect your variable names might be a little wonky and things like that but it should be working uh bicep code at that point so that's one option the other option is with modules and i'll show this in a second is you can consume a bicep code in a module or you can actually point this at an arm template so if you're if you don't want to go you know whole hog and convert all of your code to bicep all at once you can author a bicep file that's kind of like an orchestration file that pulls in your existing arm templates and that can be kind of like a half measure to getting getting started with bicep without having to convert everything all at once awesome thanks any other questions okay so the next thing that we will do is create a file called main dot bicep and actually let's show off the decompiler so this is decompiled code and i will sometimes demo this um so i have this folder here that has an arm template it's a regular arm template there's nothing special about it it deploys a website um and it deploys a container-based website that exists in docker hub what i can do is do az bicep decompile so bicep is is built into the azure cli now so you can call the bicep coi and do things with it from from the azcoi uh az bicep decompile and then we'll point it at uh this site.json file and it will spit out uh site.bicep um and i'm getting some warnings saying hey this is not perfect if you run into issues you can file these um in our github repo uh bicep is an entirely open source project so we have a pretty active community over there and we definitely encourage participation filing issues all that sort of stuff um so now i have my converted site.bicep file and it'll do things like take advantage of features like string interpolation and things like that so i'll move this over here just so it's easy to get to and now what we'll do is author a main.bicep file that will use these other bicep files that we're creating so that we can just"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "and things like that so i'll move this over here just so it's easy to get to and now what we'll do is author a main.bicep file that will use these other bicep files that we're creating so that we can just kind of orchestrate the deployment together so we're going to do a couple things one is we're going to set the target scope of this particular file to be a subscription by default it's a resource group most deployments target a resource group but increasingly we're seeing people deploying their templates at higher scopes and doing more complex orchestrations so we're going to target the subscription and the main reason for that is because we're actually going to create the resource group as part of our deployment so i'm going to say resource again and i'm going to call this rg and i'm going to search for resource groups that's the type that i want and i'm going to use the most recent api version and then i'll do equals and then i'll just let bicep fill in the required properties for me um so i'll call this alfran rg boston and then for the location i'm going to use a function called deployment which exposes a location property so i don't i don't need to hard code that location here and then i'm going to start consuming the module so i'm going to say module is the keyword in this case and i'm going to call this app plan deploy and then i get intellisense to see all the bicep files that i can consume as a module so i'll say app plan.bicep i'll do equals and then i will skip the required properties and do that myself so the module needs a name um so i'm going to say name uh plan deploy this is not the name of the underlying resources this is the name of the module um so yeah not super critical but good to be aware of and then what's interesting here is this app plan bicep file is designed to be deployed to a resource group so i can't deploy an app plan to a subscription i must have a resource group and if i hover over this one of the things that it's going to complain about is that it's missing the following property scope because it's saying this is not valid where you want to deploy you need to give me something somewhere else to deploy it too so i'm going to set this property called scope and i can see that bicep is telling me that it's one that's required and two it's expecting a resource group as the value of the scope and what i can do very simply is just say rg i can say this is the resource group that i want you to deploy to it's another use of that symbolic name that we have and then the last thing is the parameters so these are the parameters that we set up previously and it will know which ones are required so we have our name prefix and our sku sku has a default value so i don't need to do anything if i don't want to but name prefix i do need to set so i'll just say alex here is is my name prefix and so very simply i can consume a module fill in whatever required parameters there are and the business logic the hard part has been done for me whether i'm the one who authored that code or someone else made that code available to me and then the the last one we'll do is another module to deploy the the website um so i can say another module and then site deploy i'm going to consume site.bicep but i could also go and consume the arm template site.json and this would really work just as well so if i didn't want to convert it i can use my uh arm template instead um but i would like to use the bicep file and we can fill in the required properties automatically and then i'll go through here and and fill out the rg scope because again i'm going to deploy the site to a resource group um the name so i'll just call this site deploy the app plan id so this is why we expose that app plan id and the other modules because we need to say for this website it's going to target this serv app plan so what i can do again is take advantage of that symbolic name and say app plan deploy do dot property access in this case i want to get the outputs of this module and then if i do dot again i see that that planner id is there and that's expected because we made that output available the docker image uh happens to be called nginx demo slash hello the tag we're just gonna do the latest tag and then i need a name prefix for the website itself and so i'll just say alex for the name prefix there and so very in a very straightforward way i can uh uh bring all these all these code samples together uh with modules um and tie together kind of a larger deployment"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:35:29",
        "seconds": 2129,
        "text": "for the name prefix there and so very in a very straightforward way i can uh uh bring all these all these code samples together uh with modules um and tie together kind of a larger deployment in this kind of main dot bicep orchestration file one thing that if you're familiar with arm templates you probably have some painful memories of that we didn't see in this demo is the depends on property so in arm templates you have to know what had to be deployed first and you had to set all those dependencies correctly and that was a really error prone exercise with bicep in most cases you don't need to set dependencies anymore so we can know um because of references like this that the app plan must be deployed before the website and so you don't need to manually author the app plan or the the dependency to the app plan module we'll just set that for you automatically same with the resource group so we know that the resource group has to be deployed first and just to check my math we can actually visualize this code and this is kind of like what the bicep language service is seeing at any given point and we can see that it understands that there are some modules here the directions of the arrows is a little confusing but what this is saying is that the resource group needs to be deployed first and then the app plan can be deployed and then the the website itself can be deployed so this can be a useful tool for kind of understanding how the bicep language services is processing your code any questions that may have been a lot so i have a quick question yeah so you said that the it there's a trans compilation involved do those files actually ever exist or are those done on the server side and we wouldn't see the the arm templates good question um so the uh the bicep code needs to be transpiled or compiled into an arm template client side before being sent to arm so the armed service still only understands arm templates but what happens is if i do a z deployment group or in this case it'll be sub create this is the regular deployment command uh no changes to the the structure of this command and then if i point it to a file i can point it to my main.bicep file and it will transpile it in memory send it to azure so i will never see a json file on my local machine it'll all happen in memory and gets sent to azure so you generally just don't need to worry about it but it is always happening client-side under the covers okay cool cool any other questions i have a question on um creating resources across subscriptions or accessing items from other subscriptions in the code looks like you you have to set the um scope at the beginning but if you have resources that need to be either deployed or accessed across subscriptions how do you do that yeah great question um so if you need to get a reference to an existing resource in another subscription or in general um for scenarios like i need a secret from a key vault or i need a reference to a container registry or some of these like centrally managed type things you can use a feature called existing so i'll go we'll do it in our app plan file we'll get a reference to a key vault so i'll say resource and i'll say existing key vault and then i'll type key vaults pick the most recent api version and then i will add this keyword called existing um and when i set existing um the only property that i need is the name so my existing evals which if it's in the same scope as the target of your deployment you don't need to set anything else but if you do have that resource in another subscription or another resource group you can set this scope property and you can use a function called resource group and this has actually a few different uh function signatures one with just the resource group name if it's in the same subscription but a different resource group or you could also pass a subscription id if it's in another subscription id so you can say this is my sub id and this is my rg name [Music] and so you can provide that information and this will translate to a reference to that existing resource does that does this make sense i know i have another part of"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:40:31",
        "seconds": 2431,
        "text": "and this is my rg name [Music] and so you can provide that information and this will translate to a reference to that existing resource does that does this make sense i know i have another part of the question to answer but so far yep cool if you need to deploy a resource to a different subscription uh the only way to what we say is cross a scope boundary so if you need to escape out of the scope that you're currently in uh you do that with modules so just like we uh declared the the scope of this module to be this resource group um i could instead say i don't want it to be the resource group we created i want it to be a research group in another subscription uh and another resource group and so as simple as that as long as it's in a module you can target that module to any uh scope that you have access to in azure so you have to create the a module first you can't just create a resource in another subscription yeah you can't say resource um and do something like this uh you can't say scope here and then point it somewhere else uh we aspirationally would like to be able to do this but you can't do it today okay thank you any other questions um one thing that i have not demoed is the ability to do loops or conditional deployments of resources so you can do things like i guess i guess down really quickly should deploy site is my variable and i might say it's true or false let's say false in this case i can do something like this pretty easily and they should deploy site and now this deployment is going to only be done based on the value of this condition so you can use parameters or anything like that to set the value of this this boolean which will determine whether the thing will will deploy or not in this particular case the other thing that you can do is iterate and do a loop to create multiple resources so if i created a variable called sites and it was an array of objects i need the website to have a name so we'll call this fancy and we'll give it a tag which is latest and then i want to do another one which is plain and the tag is going to be plain text so now i have this this list of things and i want to use that to create a set of resources so what i'm going to do is add this bracket statement so i'm going to say foresight in sites and i'm going to add one more bracket here now i have this site iterator that i can use to make sure that the the each iteration of this website is unique so one thing i want to do is say cite that name here so that the deployment name is unique or the module name is unique and then the other thing i want to do is use site.tag as the tag for my docker image and i'll use site.name as my name prefix and so now i can create n number of websites really easily if you're familiar with arm templates and the copy property this is the equivalent of that in bicep but hopefully it's a little saner and easier to read and easier to to manage and of course this list of websites can come from any source this can come as a parameter we have a function for loading text content so you can load in a json file as part of your bicep project so if you have a list of subnets and ip addresses and things like that in a json file you can consume that pretty easily with this function called low text content so just some of the ways that you can make your code that much more dynamic depending on the scenario that you have any questions about some of those more complex expressions thank you so much just answered it but we use a lot of we're in terraform place and we um we reference what we call like a subscription default which would have you know a ton of outputs that's used in other parts of our code um so that mechanism you just explained would that kind of be somewhat of the equivalent of like trying to get all your um dynamic like subnets from your subscription network defaults yeah i think so i want to make sure i understand the scenario before i say yes uh is that is the idea that i have"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:45:34",
        "seconds": 2734,
        "text": "your um dynamic like subnets from your subscription network defaults yeah i think so i want to make sure i understand the scenario before i say yes uh is that is the idea that i have a set of like constants that i'm referencing throughout the code uh they're mainly constants but like i'd have sorry i have a code like say i created i'm creating a landing zone that has like my my network so i have a v-net and it has five subnets on monday and then tuesday i create a sixth subnet output changes um if somebody wanted to reference that sixth subnet in their code they've already would have had that tf state file loaded into their terraform code so all they would have to do is just reference that output they wouldn't have to really change dynamic uh too much of the code so i'm not sure if there's some mechanism within bicep similar to that i think it it'll it would depend i guess so one thing you could do is uh if you're creating all your networking resources in one module you can output whatever that thing is going to create so the list of subnets and consume that in another module so as you create more subnets if you need to do something else based on the number of subnets that would already be kind of coded into the other module with a loop like this so if it's dynamic in that way and it's being created by this code base that would if i if i think i understand what you're saying correctly that is how i would go about that and if it's constant information or if it's something that would be populated by like a pipeline in advance of the code executing it may be in a json file and at that point i would consume it with that low text content function and then it would be set up so that i don't need to care what's in there as long as i know i can iterate through the list properly okay thank you yeah hopefully i'm helping but um totally sure it sounds like it's the same thing there would it be the equivalent thank you yeah any other questions i have one more trick up my sleeve to demo before i wrap it up i have one quick question you can definitely save it to the end if you've got like some resources at the end so when i was starting out with azure arm templates early on there's just azure quick start templates um github replay i believe yeah that has a lot of um you know arm templates where i would kind of mix and match parts from known templates that they have on those sites to stuff that we've had on on our subscriptions to kind of come up with what i wanted do you guys have the equivalent for a bicep yet yeah we actually have started uh populating that very same repo with bicep code um so uh wherever you in the same spot that you would go to to find a particular arm template there may be a bicep equivalent there and one thing that i've started to take advantage of is this tool called azure charts and let me see if i can find template explorer [Music] here we go so this website that i'm about to share was not produced by microsoft um it uh has a way to explore all the quick start templates and it has a little indicator if there's a bicep equivalent in that same directory so it can be a good way to explore what what code is out there we also have and it may not be here forever we built up a pretty decent library of examples in the bicep repo so you can also pour through those but that's what we've moved to the quick start templates and eventually we do want to retire this or move it into somewhere else in the repo that we just use for for testing we we'll eventually move it from the location that it's currently in but a pretty good way to explore some options there as well awesome thanks yeah okay so i did mention that uh we just released the the bicep private registry capability so obviously this site.bicep is local it's right here and the only reason it works is because i have it represented in in this file structure but if i want to consume this from somewhere else if i have a"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:50:37",
        "seconds": 3037,
        "text": "site.bicep is local it's right here and the only reason it works is because i have it represented in in this file structure but if i want to consume this from somewhere else if i have a central uh center for cloud excellence team that's producing assets that i can use in my projects i may want to consume it from a central location so what i can do is actually take this in this case we'll do site.bicep i can take this file and push it to a registry and then consume it in another project so what i'll do is i'll do bicep publish is the command and i want to publish site.bicep and then i have a argument called target and the syntax is a little funky but what i do is br for bicep registry and then i have my um url of my registry which is actually an azure container registry there's a capability that i guess has been used for a long time but they've since made it a pretty official thing you can push non-container content into a registry and there's an official spec for it now and if you're familiar with helm charts those are are being pushed to ac or container registries in the same way so we're kind of in taking advantage of that to distribute this content all that means is you stand up an instance of container registries and then you can push content to it so it's adoutfrank.azurecr.io and then i'm going to call this docker site and then i give it a version so i do colon and then i can give it whatever version i want i'll just call this 0.1 and then i can publish it wait this comes back somewhat quickly and so that got published and i can actually go i happen to have the docker extension in installed and you can load up your registries from a particular source i'm going to load them up from azure and i can actually see i have in the subscription this uh acr uh registry and i have a couple of items here and there's nothing that we needed to do to wipe this up it all just kind of worked because we're we're fitting in with the specification that the container registry governing body set up so i can see that i have this docker site here and it says 0.1 and it says invalid because it's not a container but it gets you pretty close um so i know that this successfully up uploaded which is great and now what i'll do to prove that i'm not cheating is i'll delete this um i set up so this this fails which is good i would expect that to happen i set up an alias just to make this easier to author so there's this concept of setting up a configuration file and i've set up an alias that points to the same location and this just means i can use this friendly short name when referencing and so now when i come in here i can change my reference a little bit and i can do br slash a dot frank and i can reference docker site 0.1 um and it's going to pull in uh that reference and it will validate everything in exactly the same way so it pulls it in puts it in a cache and then we can do that full validation so if i were to get rid of a required property it would yell at me and say hey you need this required property and so on and so forth so it's pretty easy to set up a registry now push content to it share it broadly and use azure rbac to regulate who has access maybe they just have read access all that sort of good stuff that that we're familiar with so that's that's the whirlwind overview tour of of bicep there is a lot more there um i'll post a link to the the learn modules we have pretty good um teaching materials by microsoft worm which if you've never used before is a pretty great platform as well as general documentation in microsoft docs so i'll put links to both of those things here is the general documentation well getting the google link here's the general documentation and then here is the learn documentation so lots of good content there if you want to go deeper there's lots of videos on youtube um we've been pretty pretty happy and pretty amazed at the community and kind of picking this up and running with it so there's a lot of really great stuff out there already any"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "00:55:40",
        "seconds": 3340,
        "text": "on youtube um we've been pretty pretty happy and pretty amazed at the community and kind of picking this up and running with it so there's a lot of really great stuff out there already any other questions i can answer about modules module registries or anything else that i've walked through i think i i may have missed one of those pieces but like in your screenshot here you have module site deploy and then you have a a url basically that's the um container registry and then the last piece is an actual docker or a container and then colon is the version of that container correct yeah sorry i didn't i didn't make that very clear so this is i think in container parlance this is a tag uh but it's it's a version um so you can set this to any string that you want uh we certainly encourage semantic versioning but you don't have to do it um we're eventually going to stand up a public registry where we will have pretty strict semantic versioning for for this field so you could have um in your in one say main.bicep file um different versions of modules and in order to pull down those modules you have to pull you'll essentially be pulling down you know potentially multiple containers versus like the way terraform kind of does it it's like you could either have like a module repository or you know a repository of multiple modules so just wondering it seems like this might be a little more heavyweight than you know use just using git um i don't know it shouldn't be at the end of the day what this maps to is a particular bicep file or set of bicep files so if you do have multiple versions that means that you would pull all those relevant files on onto your machine i don't know i guess i'm struggling to see a way around that at some point that code needs to exist on your machine in order to resolve that reference to use this do you now have to have the docker utilities you do not yeah all you need is is the bicep coi which is okay included in your your accli so there's only one dependency for all this stuff basically we're able to use an sdk to talk to the container for you yeah thank you and from what i understand it's not really creating a container it's it's it's the uh the container registry is an oci artifact registry so you can just shove artifacts in there it doesn't have to be like a runnable image of any sort exactly it is it is it is not a container image it's exactly what you said jason it's an oci artifact i think i'm still learning how to talk about these things um so i don't know what i don't know what people know about oci artifacts it was weird for me when i first learned about it but yeah it's literally it's kind of abusing container registries to shove arbitrary files in there and so we're just shoving bicep files uh into a uh a registry yeah i shove helm files in there when i started doing it's like this seems weird but right i guess it's weird especially because you know there's there's all this pre-existing history of containers and you use this thing for containers but now they're trying to expand it but they're still called container registries and so i think there's still some like friction that needs to be ironed out just from a terminology perspective but the technology is fantastic i mean it works really really well as a distribution mechanism cool it's been very helpful for me definitely cool any last questions i'll talk about the road map as well cool so let me go back to my trusty slides and i'll talk about what's coming um so 0.4 i mentioned that's the current release that we're in the next big releases we have 0.5 which is relatively soon and really the main thing that we're focused on is this ability this public module registry so it works just like a private registry but we're going to populate it with content that hopefully will be helpful for for getting started um making resources easier to consume with more default behavior and things like that if you're familiar with the terraform uh public registry it's not not far off from that and then roughly"
    },
    {
        "speaker": "",
        "title": "Alex Frankel: Bicep",
        "videoId": "LVV4HjLg77s",
        "description": "This is a recording of the October 19, 2021 virtual meeting.Bicep is the future of native declarative deployments for your Azure infrastructure. In this session, we'll go in-depth on why Bicep is important to deploy and manage your Azure infrastructure, how it advances the state of ARM Templates, and demo all the new capabilities of our production-ready release.## SPEAKER BIOAlex is a program manager on the Azure deployments team responsible for Bicep, ARM Templates, Blueprints, and a variety of associated deployment technologies like What-If and Deployment Scripts.",
        "start": "01:00:43",
        "seconds": 3643,
        "text": "will be helpful for for getting started um making resources easier to consume with more default behavior and things like that if you're familiar with the terraform uh public registry it's not not far off from that and then roughly january maybe february we're shooting for a 1.0 i mentioned that bicep is production ready and supported by microsoft 1.0 in a sense is largely a marketing exercise but we still do want to get there the big thing that we want to get done is have a stricter breaking change policy so we've been a little bit loose with our breaking change policy although not egregiously so you'll know if there are any breaking changes coming but we want to have a stricter policy where we only do breaking changes and major revisions the other is we want to ship updated types separate from the core bicep compiler so everywhere where you're getting intellisense on the resources that are available and the properties that they expose all of that comes from our type system and that the available types we have for azure resources which are constantly being updated as new resource types exist or new api versions exist so we want to be able to ship those separately and have them be backwards compatible so you should be able to stay on 1.0 and get all the new type updates going forward um we're going to have a preview of this thing called bicep extensibility this is the ability for bicep and arm to talk or armed deployments to talk to non-arm resources really what this is about is enabling end to ends on azure uh which often involve things like creating a service principle or doing a kubernetes deployment and other things like that so we're going to start kind of dipping our toe in the water and experimenting with what we can do there it's not going to be it's not ever going to be a broad provider ecosystem that's really not the intention we really just want to make the azure end to end easier where we can and for things like uh microsoft graph or aad or kubernetes where they're really well modeled and they already work kind of declaratively already it lends itself well to working with something like bicep where we can give you the same type validation and intellisense and all those things with those other uh resource types so we're pretty interested in where this could go but it's it's really a preview at this point um and then this is kind of nitty gritty but today uh you can only pass simple types between modules so strings and ins and objects we want to actually allow you to pass resources between modules so if you create a resource in one module you should be able to consume that resource in another module without having to like re-establish the reference so this is just going to make it a lot easier to to work with resources across modules um and then god knows what happens after that this will be a very nice day to get to our 1.0 release the only other thing uh worth sharing um is we have a newsletter uh that you can sign up for arm news so if you want to sign up for a newsletter we will spam you very infrequently but the other thing that we'll tell you about if you sign up for that is uh our community call which we do once a month now where we'll talk very casually um about what's kind of the latest and give the community an opportunity to get to to to demo things that they're interested in or working on or ask questions um it's a pretty good forum uh to stay involved in what's going on and so if you sign up we'll just put that calendar invite on your on your calendar automatically and that's all that i had any final thoughts questions anything at all i can help with i got a couple guys typing but i think it's pretty much just all positive feedback uh official twitter all right bicep lang got it yeah just positive feedback and we're pretty good about putting updates there as well that that channel is pretty good for us it's just really easy to reach us and and pretty easy for us to push out updates um so good one to pay attention to the other thing is um one this is probably a lot to digest but if you get deeper and you have more questions and uh uh you want to go back and forth uh please don't hesitate to reach out you now have the ability to reach me on teams um or if you'd like to set up a deep dive or anything like that with with the rest of your team or something like that we really do like to make ourselves available for those sorts of things so so please don't hesitate to reach out and we'll do our best to to accommodate that awesome well that has really been good it looks like uh we're getting more thanks again so i i i thank you answered everybody's question there's really really good intro level um you know sparking the interest uh in me because i've done arm templates way way too much and they're always more complicated than it should be so this really really looks nice to me cool so thanks a lot thanks for uh coming and present and uh doing a good job awesome thanks again for having me and and hope to to cross paths with you all in the future good luck to the red sox the yankees are out so i'm encouraged you know it'd be great for you guys to go far awesome well thanks everybody and have a good night and we'll see you next time see you thank you take care "
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Well Architected Framework featuring Vaibhav Gujral. This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.. yourself ask me anything you might have or you can raise your hand post it on chat window whatever works for the group sweet do you see the screen yep i see it oh i think you get on mute man thank you for letting me know hey everyone very good morning afternoon good evening good night depending upon wherever you're joining us from i see people joining from new zealand from dallas from san luis from uk so i welcome you all to my session i hope you and your family are staying safe and staying healthy in this pandemic my name is weber gujral and in this session we will be talking about microsoft azure well architected framework the session is a very high level discussion on what microsoft azure well architected framework is as bill was mentioning earlier it is not possible to cover everything in depth within one hour but i would like to assure you that by the time you will leave this uh presentation you will have a fair understanding of what azure well architected framework is and how you can get started uh quick intro about me my name is i have over 15 years of experience i was born and bought up in india i moved to omaha nebraska in 2016. i currently work for kevit corporation which is one of the north america's top construction firm as a cloud architect i work in the technology group i'm a microsoft azure mvp and a microsoft certified trainer i have several certifications that i've earned in azure i do speak at different user groups and conferences like this one i do run omaha azure user group if you are interested in checking more about that user group head out to the website that i have listed down there we do conduct meetings every two weeks and i would be sharing my contact information towards the end of the presentation just in case if you would like to reach out to me offline after the presentation with that let's get started with today's presentation uh before we jump on to azure well architected framework uh i would like to ask everyone who is in this meeting to answer a question for me do you think is your cloud environment well architected do you think it has all the characteristics required to be qualified as a well-architected or a well-designed environment you can raise your hand and mute yourself if you have no answer for that or you can unmute yourself answer a chat put it on chat too there's always room for improvements that's a good answer safe answer okay gary has the right answer thank you for the reason all right so yeah let me take a step back and uh first ask you actually what is a well architected cloud environment before you answer if your crowd environment is well architected or not but here is in my personal opinion uh will architected cloud framework has five main characteristics it is very cost effective it maximizes your return on investment it is built and designed using modern devops practices it delivers high performance and uses the right set of cloud resources in achieving that level of performance it is certainly reliable and fault tolerant in case of an outage or a disaster it fails over and ensures my business continues without a major impact and last but not least it is secure so now you have got an idea whatever architected cloud environment might look like so if i go back to my question can you answer it now can you say that your cloud environment is cost effective reliable and secure can you say that it offers high performance and it is built and designed using modern devops practices if your answer is yes then awesome if no or if you don't know maybe if your answer is maybe then don't worry because that's true for most of the organizations and likewise if you are new to cloud you are still trying to move to cloud or you are in middle of migration to cloud then it becomes essential for you to architect and design your environment the right way with the considerations for all the"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:05:03",
        "seconds": 303,
        "text": "are still trying to move to cloud or you are in middle of migration to cloud then it becomes essential for you to architect and design your environment the right way with the considerations for all the different characteristics that i spoke about in the last slide so in a nutshell if you well architect your cloud environment it will certainly pay you off really really well let's touch about a touch upon a shared responsibility model so when you speak of any public cloud it is very very essential to understand that cloud works on a shared responsibility model if you think that moving your workloads to the cloud will make the cloud provider responsible for everything then you are highly mistaken so i'm here to break that myth cloud works on a shared responsibility model between you as a consumer and microsoft as a cloud provider unlike a traditional on-premises environment that you can see towards the very left where you are solely responsible for everything based on based on the cloud service model that you opt for as you move towards the right the cloud provider manages certain aspects of your workloads so if you are running your services data in infrastructure as a service or iis then the cloud provider or the cloud vendor is responsible for certain aspects like the physical infrastructure and the virtualization layers and you as a consumer are responsible for patching your operating system updating your middleware and runtimes and last but not the least you own your application and data hence you manage those if you move one step further up and you start using platform as a service or pass in short then you just own and manage your application and data the underlying infrastructure the virtualization layer the operating system the necessary times and libraries are all managed by cloud provider then under the last service model known as software as a service or sas in short cloud provider manages everything from the physical infrastructure to the application deployment to everything in the stack and you just consume the application and data over internet and so as you can see with each service model the responsibilities are shared between the consumer and the cloud provider and why i'm touching upon this is because the shared responsibility model plays a key role in your architectural decisions before we discuss well architected framework it's always good to be aware of the shared responsibility model why because these decisions can have implications on your cost on your security on the technical and operational capabilities of your application and by shifting some of these responsibilities to cloud provider you can certainly focus on bringing value to your application business and move away from activities that are not core to your business so let's let's jump on to the topic for tonight let's talk about microsoft azure well architected framework the azure well architected framework is a set of five core principles i did touched upon these in one of the earlier slides where i did listed five characteristics you can see towards the right i have pictures showing those five pillars these five core pillars help enterprises to build uh high quality solutions on azure and to be very clear microsoft has not invented any of these pillars for architected framework instead these are built on top of industry standards and recommendations in fact if you will go and check it out amazon and google also offers similar frameworks to help the customers design their cloud environments the right way in fact my amazon also calls their architect well architected framework as well architected framework now that being said this is all based on industry standards and applies to generally to all the public clouds but be aware that there is no one-size-fits-all approach here when you are designing your cloud architecture there are some universal principles that apply regardless of the architecture you are designing or the technology you are using or the cloud provider you are using these concepts are not all inclusive in themselves but baselining your cloud architecture on top of these principles can really help you build a reliable and scalable and secure environment the five pillars as i was mentioning are cost optimization operational excellence performance efficiency reliability and security under the cost optimization pillar the recommendation is to design your cloud environment so that it is cost effective for your operations and development teams basically you ensure that you are spending money where you are getting maximum return on investment in the process what really is happens is you bring in efficiency in your overall cloud expenditure and you avoid"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:10:06",
        "seconds": 606,
        "text": "basically you ensure that you are spending money where you are getting maximum return on investment in the process what really is happens is you bring in efficiency in your overall cloud expenditure and you avoid any wastage of money you don't spend any money which is not needed moving on to operational excellence pillar the recommendation is to take advantage of modern development practices aka devops which results in faster development and deployment cycles you need the right monitoring strategy in place so that you can detect failures and problems before they happen or even before they are noticed by your customers in production environments another aspect that you should consider under operational excellence pillar is automation under performance efficiency the recommendation is to properly match resource capacity to demand so that your workload can perform well and can scale as needed azure offers a feature known as auto scaling if any one of you is aware of which lets you scale resources up or down dynamically based on the load in your application in a nutshell under performance efficiency the recommendation is to design your architecture with performance and scalability in mind next on list is reliability as the name suggests it recommends that you should design your system while anticipating failures at all levels now any one of you can can you tell me what is the greatest fear of any id team what what could be the greatest fear of it teams who support these enterprise systems microsoft crashing azure crashing outage so yeah security breach is one of those for sure so in my opinion the greatest fear is the fear of system going down with no way of recovering it so bcp dr andrew good point so systems can go down essentially it's running in microsoft's data center things can go wrong even though our application is designed correctly but it can still if there is an outage it can result in loss and revenue so in a nutshell failures are inevitable they are bound to happen somewhere sometime you cannot really escape failures so what essentially the reliability pillar focuses on that it recommends to design the cloud environment in such a way that it doesn't fails at the first place and if at all it fails it recovers from the failure in a graceful manner within the stipulated time lastly uh security i think security is underrated always people overlook security it is uh even though everyone understand that why security matters i was showing the shared responsibility model in the earlier slide so based on what we as a consumer are responsible for we really need to architect our cloud environment with the right set of security mechanisms in place the security pillar essentially focus on focuses on securing different areas of our cloud environment ranging from the infrastructure to the platform services to our applications and data it might mean encrypting our data protecting our applications against ddos attacks identity is another piece of security that plays a key role in this pillar and so in the upcoming slides we will certainly touch upon each of these pillars in details i will share certain principles that we can follow under each of these pillars to reveal architecture well design our cloud environment i will show in a demo but be aware that if microsoft does offers an assessment uh review which you can conduct against your cloud environment and you can generate an overall score and extra actionable recommendations on where you stand against well architected framework i will certainly show you a quick demo how you can get started with that assessment towards the end of the presentation so now let's start uh jumping onto each of these pillars in details and see what each of these principles each of these pillars entail to and what are some of the high level key principles that you can follow to ensure that you score high under each of these pillars so let's talk about the first pillar in more details which is the cost optimization in my opinion cost is always a fascinating factor whatever decisions an organization is taking cost always plays a key role same principle applies for cloud when you are opting for a cloud provider or you are deciding to run your workload in cloud cost certainly plays a key role so utilizing cloud computing for your business needs essentially needs a shift in mindset to start with quite essentially it requires you to shift your mindset from capex to opex model capital expense to operational expense in traditional on-premises environment"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:15:08",
        "seconds": 908,
        "text": "cloud computing for your business needs essentially needs a shift in mindset to start with quite essentially it requires you to shift your mindset from capex to opex model capital expense to operational expense in traditional on-premises environment if you manage any on-prem data centers then you will be aware that you have to pay upfront cost for procuring any physical hardware and other equipment you can certainly claim that as tax deductions by showing showing them as capital expense expense on your tax returns but when you move to cloud that changes the dynamics completely you literally don't pay anything upfront instead you move to a model where you pay for whatever you use the capital expense in that case is zero and you essentially get a regular operating expense in your invoice microsoft sends your monthly bill with all the charges for the resources that you have consumed in the past 30 days so shifting to an opex model forces you to be very cost effective in cost efficient in your choices the primary reason being [Music] you will really not realize until your invoice shows up that it might be surprised i've seen and heard from so many customers that they don't really plan for the cost well upfront for cloud and when the monthly bill shows up in their email box they really get a huge shock so in a nutshell you must consume your cloud services in an optimized manner be aware that it's not free it's based on a pay-as-you-go model and that is one of the motivating reasons to consider the very first principle that i have listed there under the pillar uh before you provision anything in azure it's critical that you go and plan and estimate your costs upfront you can use any cost estimation tool of your choice which gives you a holistic estimate of your total cost to move to cloud uh microsoft offers a couple of great tools that you can utilize for this purpose it's known as pricing calculator which is offered by microsoft on azure's website you can utilize the same to get an initial estimate of uh how much it will cost you on a monthly basis you can pull all the resources that you are planning to provision and it will give you a rough estimate you can apply your enterprise agreement discounts and msal discounts and see how how much it will cost based on your billing model you can also use something known as a tco calculator that microsoft offers to calculate total cost of ownership of running your workloads in cloud so what it's essentially these tools ensure is that you are prepared for how much your consumption will be in cloud and you will not get a shocking monthly bill so it as per first principle it's very very essential that you estimate your costs upfront and inform business about the estimated cost for running your workloads in azure or rather any public cloud next principle is around cost optimization so it's not just enough to estimate your initial costs you should also keep looking for ways to optimizing your cloud spend by optimizing your cloud spend you can maximize your roi return on investment there are many considerations to optimize your costs for example you should answer questions like should we consider in iis vns to run sql server or are we better off running an azure sql database which is a pass offering can we utilize options like reservations and hybrid benefits to bring down some of our costs so always keep looking for such opportunities where you can optimize your existing spend the third principle is around monitoring and analytics to gain access into your azure spend you must leverage monitoring analytic tools available at your disposal to monitor your cloud spend and generate meaningful insights out of it by looking at some of the historical cost information you can easily trend and identify the areas where you can reduce cost and eliminate any wastage azure offers a full-fledged cost management solution known as azure cost management and billing it gives you all the cost information in a rich interface with embedded inside azure portal it lets you see just not the historical cost but it also lets you see future costs based on your historical usage you can further apply different kinds of filters you can filter based on reservations based on subscriptions based on resource groups in a nutshell you must have enough visibility into your cloud spend and you must understand how you are being built for consuming whatever cloud services you are consuming that is what the third principle relates to by saying monitoring analytics lastly the what hurts the most is those unnecessary expenses within your environment that could have been easily avoided the last pillar addresses that"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:20:10",
        "seconds": 1210,
        "text": "services you are consuming that is what the third principle relates to by saying monitoring analytics lastly the what hurts the most is those unnecessary expenses within your environment that could have been easily avoided the last pillar addresses that concern you must put in time in identifying these leakages the sooner you identify those the better it will be in most of the cases the reason for wastage i have seen in my in some of the projects i have worked on is people go ahead and choose wrong sizes for their resources for example resources are provisioned with way more capacity than what they really need for for example i have seen people provisioning virtual machines which could be highly underutilized meaning the average cpu consumption or the memory consumption is not even 10 or 20 percent and on organizations still keep paying for those higher sizes so it might be an ideal candidate to be downsized any virtual machine which is underutilized so and it's just not the infrastructure cost you can also look at some of the operational costs you can automate your deployments you can automate your resource provisioning to save some dollars on your main hours to provision resources in azure so what last principle really talks about is whatever you are spending ensure that it's efficient and always look for ways how you can make your cloud spend efficient so in a nutshell in conclusion for this particular pillar uh cost certainly plays the most important role in your architecture while designing your cloud environment always be aware of cost always be aware of how much it is going to cost you before you go ahead and provision those resources here are some of the quick ways you can optimize your overall azure spend i believe most of them are self-explanatory but to just talk about them i think it's not unknown it's a no-brainer that you should shut down any resources which are not used always remember that you are built for what you provision regardless of the usage so that's where it gets tricky whenever any of these cloud provider companies advertise about their public clouds they say it's a pay-as-you-go model but be be aware that it's not pay as you go it's pay-as-you-provision so you go ahead and provision your azure resources microsoft starts charging you microsoft doesn't care if you are using those resources or not till the time those resources exist microsoft is going to charge you so always be aware of your usage and shut down any resources which are unused the second thing you can do is right sizing i did touched upon wrong sizing in the last slide as well so always right size the underused resources don't allocate capacity more than what is needed by your resources as a thumb rule what i personally do is i always start with smallest size that i think is right for my workload and then i continuously monitor my workload and as and when i get enough data to justify scaling up i certainly go ahead and scale up the resource to the next year my next size but as a thumb rule as i said i always start small if you are an enterprise customer for microsoft you can leverage uh reservations and hybrid benefit to certainly bring down your overall costs and reservations can really bring down your cost substantially i've seen where customers have saved up to from 50 to 70 percent of their costs on their virtual machines and storage accounts if you are not aware of what reservations are reservations lets you book capacity upfront at a heavy discount meaning you pay for certain capacity upfront and microsoft offers that capacity at a heavy discount then against the pair if you will consume the same capacity at pay as you go charges it would be expensive to you if you're not aware of what hybrid benefit is it lets you bring in your existing windows and sql server licenses to the resources that you are running in cloud to uh move forward to handle any variable or fluctuating workload i did mention about auto scaling in my last slide too you can certainly utilize auto scaling on the resource types that supports it to scale your resources up and down based on the activity next on list is budgets and cost allocations which helps you make costs visible and make people accountable for azure spend i think in the pa in my past experience i have seen till that time leadership and business don't pay or see how much money they are spending on azure they don't really feel accountable for any of the azure spend so try utilizing budgets and cost allocations that will really help you in making people accountable for what they are spending in azure last but not the least always choose the right compute service you might be better off using a pass sql database at 10 10 a month compared to"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:25:13",
        "seconds": 1513,
        "text": "people accountable for what they are spending in azure last but not the least always choose the right compute service you might be better off using a pass sql database at 10 10 a month compared to running a full-blown virtual machines at few hundred dollars a month so always always choose the right service what fits in your solution moving on the next pillar is operational excellence so i'm keeping an eye on chat as well if there is any question you might post it on the chat window or feel free to unmute yourself to ask me if you have any question talking about operational excellence it is all about ensuring that you have full visibility into how your application is running and ensuring the best experience for your end customers operational excellence includes making your development and release practices more agile which allows your businesses to quickly adjust to changes there are like the cost optimization pillar there are several principles that you you can consider under this pillar the first one emphasizes on designing building and orchestrating with modern practices aka devops you must leverage leverage processes like infrastructure as code automation testing automated deployments wherever possible always remember that devops is more about culture than technical areas you you really need to drive that cultural change in your organization so that devops can be embraced regardless of the data of your organ regardless of the size of your organization or the development practices that are followed in your organization i strongly believe that devops can be embraced and built into the system the next principle is or talks about monitoring and analytics sorry similar to the cost optimization pillar monitoring and analytics plays a key role in this pillar as well you must have a monitoring logging and instrumentation system built into your overall architecture so that you can gain visibility into what is going on in your environment you can use cloud native uh tooling like azure monitor which includes log analytics and application insights or you can most certainly go and leverage third-party monitoring solutions as well to integrate with your system but the idea is to have that appropriate monitoring and analytics tooling integrated in your architecture why because having a stable monitoring solution established in your architecture can really help you multi-fold it can help you troubleshoot and resolve performance issues it can help you generate insights into usage information of your workloads and so on next on the list of the principles is automation i can keep telling on about the benefits of automation and the rest of the 30 to 40 minutes will be over but i'm not gonna do that i believe automation is no brainer i remember the very first thing i was told when i started my first job by my lead was that anything that can be automated should be automated so i still follow try to follow that principle it why because it helps bringing operational costs down and just not the operational costs down it also helps reducing errors in your process if i have to do something manually twice chances are i will end up having two different outputs but if i automate it if i run it run the same script multiple times it will always return the same result so it essentially does reduce his errors in your overall process as the amount of overall human interaction goes down and automation can certainly help you ensure that any activities that you are performing as i was saying those activities are performed in the same way no matter how many times you execute those activities you can utilize automation in areas like application deployments where you are deploying your codes or where you are provisioning these resources in azure automation can go a really a long way last and but last but not the least the fourth principle i have listed under operational excellence uh talks about testing i would be surprised if anyone who is attending this session today comes to me and say they have not seen an angry customer finding bugs in the production system i would it has happened with me i'm sure it would have happened with most of the people who are in this call and trust me 99 of those situations can be avoided if testing is included in our process to catch mistakes before they impact the real customers in production so essentially the last principle essentially focuses on testing it essentially says that having a reduced number of reported issues by having a right set of testing tools and testing integration in our process can certainly improve overall user"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:30:15",
        "seconds": 1815,
        "text": "principle essentially focuses on testing it essentially says that having a reduced number of reported issues by having a right set of testing tools and testing integration in our process can certainly improve overall user experience and operational excellence now i'm sure everyone here who is on this call would have seen a message like this when you when your application goes down for example i'm sure you would have faced the issue when you would be shopping on amazon during prime day when the amazon website sometimes goes down the primary reason is the volume of users for these e-commerce websites during these days go hundred or thousand fold it has nothing to do with their application code essentially what it essentially relates to is the underlying resource capacity and scalability what happens is whenever the resource or the volume of users goes hundred or thousand fold due to the increased volumes the underlying resources are stressed and as a result the overall website becomes either too slow or it becomes too unresponsive too unresponsive and the primary reason is that kind of load was not planned for by the organization and to address that exact situation i want to move to the next pillar called as performance efficiency in a nutshell performance efficiency refers to matching the resource capacity with the demand performance efficiency includes scaling your resources identifying and optimizing potential bottlenecks optimizing your application code for peak performance there are some core principles that you can certainly leverage under this pillar as well the first one is around scalability which is the no brainer it speaks about scaling up and scaling out it is very essential to understand the difference between scaling up and scaling down compute resources in azure can be scaled in two different directions you can either scale them up or you can scale them out scaling up is adding more resources to a single instance for example adding more cpu power or adding more memory to an existing virtual machine where scaling out is adding more instances what i mean is instance instead of making a single instance more powerful if you are scaling out you create replicas of your instance and load balance the incoming request now be aware that scaling up also comes with certain limits because obviously you cannot scale up your instances to the capacity more than what is available in the underlying physical host that is hosting the resource that's where scaling out scores big time because theoretically you can add as many instances as you would need be aware that costs play a key role in your decision making here i know it sounds very fancy to scale up or scale out as the demand increases but be be aware that it also increases your cost you can leverage a feature i did touched upon in earlier slides called as auto scaling for some of the resource types that support it if uh if it if the resource type you are working on it does support scaling auto scaling then you can certainly utilize auto scaling to dynamically scale up our resources scale out your resources up or down and based on the activity in your application and whenever your application is not seeing the usage it reduces the number of instances and you can optimize your overall cost by utilizing auto scaling up we have been utilizing auto scaling for things for resources like app services where it automatically scales out to between 1 to 10 to 20 different instances in a nutshell the idea is that you should uh provision resources as and when they need not like you should just spin them up and leave them running even if they are not required the next on the list is network performance when you are working on achieving an optimal performance out of your environment networking resources play a key role you have to plan and design the right set of networking resources to ensure that there are no network latencies or any kind of performance issues related to networking you might also leverage messaging patterns to make your systems loosely coupled the benefit you get out of having a messaging layer in between your subsystems is that if you if your receiver takes more time to process each request than the rate at which the sender is sending the messages your system doesn't fails because you have a messaging queue in between your sender keeps writing messages in"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:35:18",
        "seconds": 2118,
        "text": "if your receiver takes more time to process each request than the rate at which the sender is sending the messages your system doesn't fails because you have a messaging queue in between your sender keeps writing messages in that queue and the receiver keeps picking up the messages from the queue and they both work independently similar to networking and messaging storage performance also plays a key role in your overall performance speaking of storage you must choose your partitioning strategy wisely so that you can maximize your benefits using cloud if your partitions are not balanced it might hit the performance of a system really hard having right partitioning strategy also makes it easier to scale your system and improve overall performance you must also consider caching to improve performance of your systems if you have been using radish there is a radius cache offering that microsoft has that you can probably utilize in your applications last but not the least uh it's also important to identify the performance bottlenecks in your system these days systems are complex and they can have many subsystems performance of each of those subsystems can contribute to the overall performance of your system it is important to have right set of performance monitoring tools in place so that you can measure performance of different parts of your system be it storage compute networking or your application not only at the infrastructure side of things your applications themselves might be the cause of a low for a low performance hence it is critical to have right side of monitoring built into your environment so that you can pinpoint the bottleneck and you can fix them you as i mentioned in one of the earlier slides you can utilize things like application insights or azure monitor to integrate with your system to have better monitoring in my opinion it is no brainer that your cloud applications must deliver high performance and you must utilize the right set of principles and design patterns in your architecture to ensure that you receive optimal performance for which you are paying for the next pillar on the list is reliability in one of my starting slides i did ask about the greatest fear i.t teams have and as i said it's the fear of system going down completely down without being recoverable and most of the businesses are going digital and global now any of these businesses cannot afford systems going down whenever there is a failure or an outage the reliability pillar addresses that particular concern reliability pillar does provides guidance on how you can make your environment reliable and fault tolerant it helps you make your applications resilient and highly available so that they can handle both localized as well as broad impact broad impacted incidents if you will think about it it is actually a very scary and a very critical aspect a downtime directly hurts revenue imagine an e-commerce website like amazon if it is down for half a day just imagine how much revenue it might lose so in a nutshell the reliability pillar doesn't say that you should not expect failures instead it says otherwise it says failures are inevitable no matter how much prepared you are failures are bound to happen and no clout provider including microsoft or amazon or google offer 100 slas on their services the maximum sla that you can get is five nines so what really matters is how prepared you are in case something goes down or if something fails now it could be any component of your architecture that might fail it could be your application code it could be your data it could be a networking misconfiguration which might result in your application becoming unreachable it might also be the physical infrastructure like the physical hard drives might fail there are a couple of principles that you must consider while you are thinking about reliability of your cloud environments the first one says that you must build a highly available architecture when you are designing your environment always consider the sla offered by microsoft or rather any cloud provider for whom consuming cloud services be of double sure that you consider the sla for every service you are going to consume and if the sla doesn't meet your business continuity requirements you must plan for high availability by adding appropriate redundancy in your systems the other principle speaks about recovering from a failure so what high availability focuses on by having highly evil by having high availability chances of failing is reduced but just in case if there is a failure the second principle talks about recovering from that so you must design your environment so that it can recover gracefully whenever a failure occurs as a best practice you must always have a recovery point objective and recovery time objective defined for your workload rpo and rto in short if you are not aware of"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:40:22",
        "seconds": 2422,
        "text": "that it can recover gracefully whenever a failure occurs as a best practice you must always have a recovery point objective and recovery time objective defined for your workload rpo and rto in short if you are not aware of rpo refers to the maximum duration of acceptable data loss it is measured in units of time and not actually the volume of data that is lost likewise recovery time objective or rto refers to the maximum duration of acceptable downtime or the maximum duration that this system can be down for example if the acceptable downtime duration is four hour in the event of an outage then you're out to rto is four hours so why do you need to establish rpu and rto because it will essentially help you in designing the right capabilities in your architecture to meet reliability objectives so in my opinion that's the first thing that you should do in your cloud architecture identify and establish rpo and rto and then follow those two principles that i have listed there all right the last pillar this one is no brainer security is all about protecting your environment from outside thread so it starts with protecting your data that your organization uses stores and transmits the data that your organization stores or handles is at the heart of your securable assets now the data exists on some kind of infrastructure which also needs to be secured along with the identities that are used to access the data it is highly important to have your complete security poster right so that your data is safe and secure in cloud like the other principles there are a few key principles that you might utilize like to utilize under security pillar to start with you must develop a defense in-depth approach to securing your architecture i have my next slide on defense in depth approach to talk about what it is all about but in a nutshell what it says is it requires you to make all the layers of your architecture secure the other two are pretty straight forward you must always choose the right set of technologies to secure your azure infrastructure it could be as simple as using network security groups or using an azure firewall also as i said earlier it's important to secure the identities that can access your data you must leverage industry best practices for managing your identities you must also utilize features like azure role-based access control to restrict access to your azure resources and things like privileged identity management to manage control and access to important resources in your environment let's talk about defense in depth it is a security risk management approach that defines multiple layers of security controls in an idea environment it's just not specific to cloud but we can us we can apply this to a cloud environment too the idea is if a security attack is not caught by one layer it will most probably be caught by the next the multiple layers that you are seeing here increase the overall security score of your environment and reduces the probability of a security breach by a huge margin sometimes defense in depth is also referred to as castle defense as it resembles the security defense technique employed in the castles historically where an enemy had to cross multiple barriers at the castle's periphery before attacking the castle with the rapid expansion of cloud computing the need for defense in-depth strategy has increa increased many folds and what i'm showing you on the screen is a snapshot of the different security layers in an environment at the very core as i was touching upon in the last slide and is data which must be encrypted both at rest as well as a transit the next is application where you must secure your application access by using services like azure application gateways or web application firewall the next layer is your compute layer which must be protected against potential threats like rtp brute force attacks or sql injection you can utilize services like azure security security center to generate a secure score for your overall security posture then is network which enables different components to talk to each other it is no brainer why you must secure your networks and why you and for doing so you can utilize services like network security groups then comes the perimeter from uh which forms the most common form of attack one of the example could be distributed denial of service attacks or ddos attacks azure comes with a basic tier of ddos which is enabled by default but you can certainly go ahead and opt for standard tier that comes with additional support options then is our identities we did talked about earlier as well we should certainly secure the identities that are trying to access our resources and data and lastly the access to the physical data centers must also be authorized since it's a cloud environment that we"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:45:24",
        "seconds": 2724,
        "text": "about earlier as well we should certainly secure the identities that are trying to access our resources and data and lastly the access to the physical data centers must also be authorized since it's a cloud environment that we are talking about uh which is hosted by microsoft and azure's data center the physical security is managed by microsoft which doesn't which only allows authorized personnel to have access to the different areas of their data centers i have listed a link down there for a blog post i have written some time back you can certainly check that out if you want to read more about defense in depth security model lastly uh i did touched upon share responsibility model and i would like to refine it to security so that it gives suppose sets a perspective what you are seeing here is a shared responsibility model that i have tweaked to reflect the context of security what you are essentially looking here is depending on the type of service that you select some of the security is built in into the service by the cloud provider microsoft in this case while other remains the customer's responsibility as you can see it is absolutely essential to use the right set of services and then have the right set of security controls to ensure that your overall security posture in the cloud is intact i did mention about the myth where people consider that once they move everything to cloud its cloud providers responsibility to ensure everything is secure that's not right as you can see part of that responsibility lies on the consumer so be aware of that and apply appropriate security controls to keep your system environment secure now i did briefed about all the five pillars of the will architected framework as i've said earlier there is no one-size-fits-all approach when it comes to the cloud architecture the five pillars we talked about offers the guiding principles that we must then we that we can include in our design whenever we are architecting our cloud environment and as i've said in the past cost plays a key role in that process regardless of whichever pillar you focus on it might be reliability security operational excellence or performance efficiency any principle that you for any pillar that you focus on and any corresponding changes that you make in your architecture be aware that it impacts our overall azure cost for an example let's take an example to make your systems more reliable the recommendation is to introduce redundancy now redundancy means adding more resources in your design and the more the resources you consume the higher will be your azure cost and microsoft is going to charge you for that so it's kind of a balancing act between cost and rest of the pillars you must always consider the trade-offs between the cost and the other pillars whenever you are architecting your cloud environment and once you have identified the priorities for your organization and the trade-offs always remember that there is always a scope for cost optimization any questions so far i don't see anything on the chat feel free to unmute yourself if you would like to ask anything so moving on on top of the guiding principles and the five pillars that we talked about microsoft does offers an assessment review which you can take yourself it is essentially a set of questionnaire targeted for different pillars in well architected framework it essentially asks you to provide different information once you provide all the required information it generates a score depicting where you stand against each pillar and it also provides a set of actionable recommendations that you can take a reference from and you can go ahead and make appropriate changes in your environment this is where once you go through the assessment this is how it shows the result as you can see the different recommendations that it's showing as well as some of the actionable recommendations let me go back actually to browser and show you some of the things we have talked about so if you have not seen azure architecture center i would strongly encourage you to go and check out azure architecture center under azure architecture center you will find a separate section for microsoft azure well architected framework and under that section you will find essentially everything we have spoken today it talks about all those five pillars cost optimization operational excellence performance efficiency reliability and security and if you will go inside each of those sections you can find all the pillar all the principles that are recommended under that pillar i did picked up some of the key ones from there but you can certainly find few more here you can go to either of those read about each of those pillar in details you can certainly find more principles and check out which it's very vast"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:50:27",
        "seconds": 3027,
        "text": "key ones from there but you can certainly find few more here you can go to either of those read about each of those pillar in details you can certainly find more principles and check out which it's very vast it might take some time for you to go through all this and digest this information if this is too much for you another option for you is to go to microsoft learn there is a learning path for learning as about azure well architected framework it has an introduction module then it has one module for each of the pillars that you can walk through and each of them is roughly around 45 to 50 minutes long and you can learn you can go through it at your own pace here is the assessment uh page but that i was referring to in my slide deck microsoft offers certain different categories of assessments that you can go through one of them is azure well architected framework i was trying to go through this link but it's once you click on that it opens up a azure well architected review page for you as you can see it asks you what all do you want to assess you can choose one or more or all five of these pillars if you want to assess you can certainly sign in with your azure portal credentials which you have used to create an azure account you can give a name to your assessment once you will give it a name if you go back here you will see all your past assessments listed under our assessment section if i go back here you will see i didn't do anything but i'll go ahead and click here i will go ahead and choose let's say cost optimization pillar so you will see it this does list down all the different questions that it asks i can go and click on next and to the best of my knowledge for of my cloud environment i can go ahead and answer them all these questions it if you are not aware of how to answer microsoft does offer some video sources that you can go through to and develop an understanding on how to answer some of these questions so let's say if i go through some of these questions the first question is like how are you modeling cloud costs of this workload so i cannot for whatever let's say if i'm trying to use hybrid benefit i'm trying to utilize reservations and i'm clear on the price model and i know cloud costs are modeled so i can go through roughly each of these and try to answer like based on certain options whatever it works for my environment i'm not going to go through in depth for each of those and based on whatever understanding i have for my environment if i go here and fill it up it will generate a set of score for me and a set of actionable recommendations that i can go ahead and act upon to make my to make my overall well architected score go up let me quickly go and wrap up this question there and if i'll click on view guidance as you will see it rates my overall design to be moderate and if you will see i have not really accessed any of the other pillars ma it has assist me to be in moderate against all the against all the principles under cost optimization pillar it has given me a score of 38 out of 100 and if i will go here here are all the recommended actions or the active actionable recommendations that it has for me i can certainly go through each one of those and evaluate what makes sense for my organization and certainly utilize them so going back to the slide deck another tool that you can utilize to assess your well architected environment is called as azure advisor it's a free offering available in azure portal it's embedded in azure portal if you'll go to your azure account and search for azure advisor it comes up with this interface oops as you can see it gives you a set of score as well as recommendations of against well architected framework where your cloud environment stands what you are seeing here on the screen is against each of the pillars you can see in cost and azure advisor has assessed my cloud environment and it recommends certain changes in my environment one of high impact three of medium impact one of low impact and if i would go ahead and make those changes it can result in roughly two thousand dollars of saving per on a yearly basis and the security pillar there could be there are 63 recommendation and it impacts 522 resources and so on what i can do is if i go and click on these recommendations i can see each of those recommendations in detail what each of those recommendations are for example here you can see the recommendations i"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "00:55:32",
        "seconds": 3332,
        "text": "and so on what i can do is if i go and click on these recommendations i can see each of those recommendations in detail what each of those recommendations are for example here you can see the recommendations i have opened for reliability and it does says that i should add more virtual machines for improving fault tolerance or i should use availability sets for improving fault tolerance i should use premium disk to improve my overall i o performance then i can go up level further and i can click on one of these and i can see what resources it impacts for example the screenshot i have here shows the virtual machines which are either not which are wrong sized which either either i can shut down completely or i can right size them to save some good dollars what you are seeing here on the screen is all the list of virtual machines and the appropriate recommended action of resizing or shutting down and the potential saving i can have by react by acting upon each of those recommendations recently microsoft not recently i guess a year or two ago microsoft also introduced what is known as an azure advisor score what it essentially does is it helps you provide a score so that you can assess your overall posture of your cloud environment as you can see it gives you an overall score here towards the left which is shown as 88 percent then it also shows an historical trend of your score which might be very helpful in in ensuring that you are on your right if you are on right track or not for example you can see i'm doing 82 i'm 82 percent on track for cost on reliability i'm on 82 percent and security is coming soon but it's already being released so you can find same in azure portal under security as well now uh that's pretty much about azure well architected framework as your advisor how you can assess your cloud environment against well architected framework and how you can get started microsoft on top of that has also provided a good chunk of design patterns that you can use in while designing your cloud environment in accordance with the well architected framework each of these patterns describe the problem that the pattern is trying to address it also provides certain considerations that you should have while applying the pattern in your architecture and for most of these patterns microsoft has also provided examples on how you can implement these patterns in microsoft azure using different resources now do note that most of these patterns are applicable to any distributed system whether hosted or on azure or aws or any other cloud so these are again industry standards but you can certainly utilize them in your azure environment another thing that you cannot you should not get confused with uh in addition to azure well architected framework you can also leverage what is known as cloud adoption framework if you are moving to cloud or you are in halfway in your cloud journey cloud adoption framework can really help you better align your business and technical strategies to your cloud implementation uh it provides you with best practices documentation and tools that your cloud teams and including architects and id professionals and administrators and any decision makers in your team can utilize to successfully achieve the objectives that you have from your cloud implementation as you can see there are six main phases it all starts with defining your strategy understanding the motivations why you really want to move to cloud why do you want to create resources in cloud what workloads do you want to migrate and why once you have that then you start planning how it should how you should get started you look for skill readiness you work on a cloud adoption plan how you're going to adopt the overall cloud services then you move to the ready stage where you start with your landing zone you start with small you set up the base resources you start with the basic uh necessities so that you can get build your other systems on top of it then you move to the adopt stage where you roll it out to different themes to run their workloads in azure once that's done once you have an up and running azure environment you go ahead and start governing and managing your azure environment so i provided a link down below there if you are interested you can check out that link to read more about cloud adoption framework in addition to everything we have talked about today there are some consistent design principles that you should consider throughout your architecture to start with always enable architectural evolution so no there is no architecture that is static technology always keeps evolving so always allow for the evolution of your architecture by taking advantage of new services new tools new technologies whenever they are"
    },
    {
        "speaker": "",
        "title": "Well Architected Framework featuring Vaibhav Gujral",
        "videoId": "MiknzSECs5s",
        "description": "This is a recording of the July 29, 2021 virtual meeting.Microsoft Azure Well-Architected FrameworkIn this online event, Vaibhav Gujral (Azure MVP) will be digging into the Well-Architected Framework which is part of the documented architecture guidance provided by Microsoft.How do you ensure that your workloads running in the cloud are well-architected? Join us in this session where Vaibhav will introduce Microsoft Azure Well-Architected Framework and explain different architectural excellence pillars within the framework. He will talk about different principles under each of the pillars and will share some architectural best practices that you can use to optimize your workloads running in Azure.By the end of the talk you will understand enough to start leveraging the Well-Architected Framework in your own work##SPEAKER BIOVaibhav Gujral is a seasoned cloud architect currently working at Kiewit Corporation. He has been awarded Microsoft Most Valuable Professional (MVP) award for the Microsoft Azure category and is a Microsoft Certified Trainer. He is a Microsoft Certified Azure Solutions Architect Expert, and he holds numerous other Azure Certifications. Apart from being a regular speaker at several user groups, events, and conferences, he also runs the Omaha Azure user group. He regularly blogs at https://vaibhavgujral.com/.",
        "start": "01:00:36",
        "seconds": 3636,
        "text": "always enable architectural evolution so no there is no architecture that is static technology always keeps evolving so always allow for the evolution of your architecture by taking advantage of new services new tools new technologies whenever they are available you should use data to make decisions whatever decisions you make ensure that those decisions are data driven you should collect data analyze it and use it to make decisions that surrounds your architecture from cost data to performance to user load using data will certainly guide you to make the right and informed decisions in your environment educate and enable cloud technology evolves quickly so educate your development operations and business teams to help them make the right decisions and build solutions to solve business problems document and share configurations decisions best practices as much as you can with your within your organization so that people who work on cloud have appropriate knowledge to work on that automate we touched upon automation in a couple of our principles in our pillars in well architected framework automation of manual activities reduces operational cost minimizes errors introduced and introduced by human intervention and it does provides consistency between your environments so some general design principles that you can certainly consider along with the architected framework with that let me quickly jump back to azure to my browser so i don't have literally any resources running in my environment today in azure that's why you are seeing in azure advisor i'm in the blade for as your advisor you can go and certainly search for azure advisor here and go to azure advisor that is where i am in based on your environment it will automatically assess and it will give you all the recommendations and score across the five different pillars you can check out your advisor score here so it shows hundred percent because i don't really have anything running it says i am 74 in reliability but i'm doing pretty good in cost operational excellence and performance i can certainly go and dig into each of these pillars if i have recommendations that advisor has for me it will show up here likewise for any other pillar you can head out to azure advisor documentation to read about what recommendations it makes against each of the architect well architected framework principles if you will head out to further documentation you can find out different recommendations that it makes against different pillars for example i'm into reliability page what it does is it gives you recommendations across different resource types for example if you are using application gateway ensure that you have fault tolerance ensure that you protect your virtual machine data from accidental deletions by having resource locks or backups ensure that you have access to azure experts when you need it so all different kinds of recommendations that you can go through here for your review if there is anything that applies to your specific azure environment it will show up here so in a summary uh we have talked a lot in last hour or so so i would like to conclude now with an overall summary of what we have discussed so far architecture is the foundation of your application design so using the azure well architected framework can give you the confidence that your applications can sustainably meet the needs of your customers both now as well as in the future the architectural priorities and needs of every application is different but the five pillars that we discussed today in azure well architected framework are an excellent guide post that you can use to make sure that you have given enough attention to every aspect of your application again as a reminder the five pillars that we talked today cost optimization operational excellence performance efficiency reliability and security focusing on those pillars will certainly ensure that you are laying a solid foundation for your application in the cloud with the solid foundation you will be able to drive innovation through your environment you can build solutions that your users will love and you will certainly foster the trust of your end customers here are some of the resources that i was showing you earlier and that i have referenced in my presentation today i have provided link to the azure well architected framework documentation i've also provided a link to the microsoft learn uh learning path that i was showing you i've also provided a link to the assessment that i was showing as well as the link to the azure architecture center i have provided link to the cloud design patterns and cloud adoption framework too you can i can share this slide deck with bill and uh veronica and the organizers you can set it possible they can share it with you so that you can get access to these links while i was preparing for today's session i came across a new document with new documentation for partners which i found to be really interesting this is essentially for partners who support different customers they have a page for well architected framework and it essentially covers pretty much what we have discussed today but i did really liked it does it does refers to all the how-to guides and reference materials that talk about architecture framework all the how you can start with assessment how you can learn about that and it talks about all the five different pillars and talk about how you can get started with each of those has certain videos that you can watch and certain other resources that you can utilize for helping your customers if you are a partner and with that the floor is open for any questions that you might have for me you can feel free to unmute yourself and ask me or post that in chat i see a question so gary asks does advisor tells you when you should move to cosmos db and moves away from sql server i guess no but it does recommence when you should optimize your cosmos db and sql servers but it doesn't suggest any migrations between cosmos db and sql servers just in case if you don't have anything to ask now but you come across anything later you can certainly reach out to me offline i've listed my blog there you can check out the defense in depth article i have written some time back as well as some of the other articles i have written you can reach out to me on twitter and linkedin i've provided my twitter handle as well as my linkedin profile i'm pretty active on both of those social media platforms i try to be active on my youtube channel trying to build up on it it's still not where i would like to see it but you can go and check out some of the videos i have published before and if you would like to reach out to me over email there is my email address you can feel free to send me email and i'll try my best to uh respond back as quickly as i can and if there are no other questions there's no question so anyone has nothing to ask i guess i can conclude my presentation and thank you once again all for joining stay healthy stay safe i believe delta variant is going nuts so mask mandates are coming again so if it comes back start wearing your mask and enjoy your evenings thank you very much yeah thank you uh big time uh it's such a fascinating topic uh architecture making technology decisions and operational decisions and i i would guess that if we had a whole day or three days you could have kept talking the whole time because there's so much uh depth to this material microsoft conducts one or two day workshops on the architected framework if you're getting started with it so makes a lot of sense well you've certainly given us a fantastic uh set of like the principles are all there the framework we understand and the uh and there are tons of details that we can uh drill into uh because we know where to start now so i'm gonna give you a big thank you and uh let everybody know that this uh talk will appear on the youtube channel it's um i think it's just youtube slash boston azure and um we have talks a bunch of talks coming up we were we have um um the the talk on uh by serbia on august 5th uh that's a locking down sql tv and then we have uh several other talks that should be appearing uh soon after that so watch watch the meetup space uh by um thank you again and uh everybody stay safe and we'll see you next time hey bill i will descend across "
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Alpa Buddhabhatti: Azure Functions 101. This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .. thank you all and welcome to my session azure function 101 for um everyone and it's like for beginner as well so it's like introductory session and it's here at virtual boost in azure so purpose of this session is to provide you a very quick overview of azure function and show you how you can create your first azure function you can debug it you can test it you can deploy it in various different way using like video studio or maybe azure portal and many other techniques so let's start with myself i think you now already know so i'm just uh giving few information regarding my social media network so you can see you can find me in linkedin or you can find me in github so i have a repo there is an end of the session i'm going to upload this repository there as well and you can find me on twitter as well so let's now move into today's agenda so today's agenda is mainly divided into three parts in first part i'm going to give you a quick overview of azure function so you get idea why you need this and how you can how it works and how you can start using it then i'm going to show you a few tools uh like list of tools in second parts and third parts we're going to see series of demo so here we are creating a azure function using azure portal visual studio 2019 and we debug that we test that and we deploy that and we also test it using the postman as well so let's start with first one which is the azure functions overview so what is azure functions i'm sure you all know about functions you may have using programming language like c sharp or python java or go or any other language or a programming language like a database and oracle and many other programming database language so function is a small piece of code which execute independently and it's written results and mainly we do it for usability purpose so azure function is the same similar but here function or small piece of code on azure cloud so azure function is a solution for easily running small piece of code in a cloud or you can say function in a cloud it has a few characteristics so it's like it's even driven even in our normal functions if we have it then someone need to call that maybe in some program in different line in a in your programming you will fold that so your function will execute but in azure function it even driven so something should happen there should be a trigger which satisfied a particular condition and based on that your piece of code will execute so here you have a few i think various triggers is that like it's a time-based trigger events it uh attp triggers it's like other azure services like prob storage related triggers available and there are many more which we're going to see that so once you have the trigger and it's trigger satisfied condition your piece of code will execute so here it's event driven next one it's a serverless so you don't need to worry about serverless as well as is a platform as a service so you don't need to worry about compute infrastructure software installation operating system or implementing any monitoring solution azure will do it for you so you can fully focus on implementation and you can quickly build your function and it's a scalable so it can scale up and scale down automatically uh when like for example when there is a season seasonal come demands comes for example in summer you can see that you have more ice cream sales so at that time it has a more traffic and you need more complete power as well so at that time it can be scaled up automatically and when it's winter or when there is a no demand then it can be scaled down as well so ultimately it save your ghost as well and it's lightweight because it's a small piece of code so in short we can say that function azure function is a serverless solution that allows you to write less code maintain let's infrastructure and save on a post and this is a symbol of the function so it has three piece of things it has a code it has an event and it has a data so now let's see why you need azure function few of the things you already know based on my previous slide it's a platform as a service so you don't need to worry about as i said earlier as well uh compete infrastructure or software installation web server configuration or implementing monitor solution or like that azure will handle it for you so you can quickly build your solution and this small piece of code you're writing and you don't need to worry about infrastructures you can just write it"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:05:07",
        "seconds": 307,
        "text": "monitor solution or like that azure will handle it for you so you can quickly build your solution and this small piece of code you're writing and you don't need to worry about infrastructures you can just write it and then you can deploy into portal and it you can use it by other triggers using the triggers so you can build it very quickly rather than waiting for infrastructure you can easily integrate uh with other uh this azure function with a solution like azure data solution as your app solution or azure or iot solution and once you have this piece of code you deploy it in azure it can be used by your any solutions if you have in your organization you can easily integrate with third-party services as well and it give you a choice of your your programming language like c sharp apes up java javascript python or powershell etc so for example if you are familiar with c sharp then you don't need to worry about to learn into java or a python you can write down as your function in c sharp code and then you can deploy it and it's a cost effective so these are the main reasons uh we can use azure function now let's move into how azure function works what are the key components it has like chatting for coding according to execution so like let's say imagine that we have a piece of code and this piece of code maybe do some calculation for example eddy addition of two number or name is maybe it's ordering the file when file have in your drop storage so i have a code piece of code so now i want to execute this function based on some condition based on some trigger so i have a user http request trigger and based on when file i have a file in my blog storage so this trigger will execute and it piece of code will execute and it's written a result i'm saving that result into returning that result into block storage as well so i have at the moment this is a very simple example it has http triggers request trigger and piece of code it's reading data from block storage and writing into block choice as well without any other extra components so now let's say that i have a azure table service storage and i have even a cosmo dp as well so like there is a requirements that i need to read a data from different azure services and then my piece of code works and then it's returned the results and is stored into different azure service as well so at that time you can have input bindings you can have input bindings and you can have output bindings as well so these are the output by output binding for example so i'm saving into three different places so you can see that here you can have more than one input bindings you can have more than one output bindings however you have only and only one triggers so this way azure function works and there are four components like trigger input binding output binding and uh your piece of code so now let's move into next one oh yeah this is the link which provide you more information regarding which azure service you use as a input binding or output binding or as a trigger and now let's see a tools which you can use in order to create your azure function you or you can deploy your azure function using those tools so before we go into into tools uh you need as your subscription if you are first time using azure then you need as your subscription which you can get it free or as a first time you as your subscription user or you can have it as a part of your organization or you can use as a part of visual studio subscription or you can use as a pay as you go so once you have a subscription you can have your uh you can you can go to portal.azure.com and then you can start create your azure function the first one is you can create a function using azure portals so if you are very new then you can start creating function using azure portal first so you get conceptual idea then after you can use a visual studio 2019 or latest version of video studio it can be done in older version but in older version you can't there is some limitation so you can't debug it locally or like that uh you can use a visual studio code as well you can use azure powershell you can use azure cli which is a command line or you can use azure arm templates so this is uh if you want to do a completely automation hundred percent then you can use azure arm"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:10:11",
        "seconds": 611,
        "text": "you can use azure cli which is a command line or you can use azure arm templates so this is uh if you want to do a completely automation hundred percent then you can use azure arm template so you can deploy your uh azure function apps and functions when you need it and then you can delete your function app and when you need the needed again you can do it again using the ci cd which is one button click survey so that way you can save your course as well uh if you do that and it's 100 100 automation automated so you don't need to do manual things if you have more than one environments as well so these are the uh tools which you can use to create your azure function now let's start with demo so let's go to portal so for that let's first create our first charge your function so for that we need to create function f first you just search function if and then you can create by using this way so here you need to select a few things like your resource group you can create new resource group or you can use existence one just selecting existence one for example and then here i need to give my function if name so just giving an issue table name and you can select your option that you want to publish via code or by docker so i'm just using code here you can select your different language runtime so i'm just selecting.net and you can it's automatically select latest version you can change as well and you need to select a location which is closest to your data and uh wherever you have so you need to select the closest one but i'm just keeping default one at the moment and here you select operating system you like to do window or linux so i'm just keeping window and this is a very important part which is uh which is related to your compute infrastructure as is serverless but we can select here based on that so we need serverless or we need a function premium which is a dedicated and its enterprise level so here you can have your own dedicated resources as well and you can have app service plan as well so we are selecting a serverless one then we going to next here's the storage account so when you create your function app it creates a storage account as well because that storage account hold your code so you can have a default one or you can create your own as well just a keeping default one then we go to next here we are not going to change anything uh and then we're going to takes and this is application insight so it's also create application insights as well which help you to give you uh when your function run and if you want to troubleshoot or monitor it it help you on that time so you can say no as well but here i'm just keeping it and here is the default name but you can give suitable name as well if you want to give and then we're going to next here we are not changing at the moment anything and now we see it create and review so now let's create it so while it's creating it let's go back to uh here so we have just created azure function first not a function function if so function name has four components first one is storage account so these storage accounts hold your function actual code you know in its file shared area then it will create another component which is an application inside which help you to provide some monitoring and troubleshooting ideas so if you have that you can troubleshoot and monitor your function while when it's running you can check history data as well and this gave you a lot of other things as well uh the next one and third one is the function name so here you are actually creating your function in your function app so it's host your functions which are in which should have a same runtime and same versions so for example if you have a three function in your function f then all three function should have a same dot net was whatever version you choose it should be same and it should have a version also same runtime as well as version both should be same and fourth components which is the app service plans which is related to a compute infrastructure as we said earlier it's a serverless but it need a compute"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:15:13",
        "seconds": 913,
        "text": "runtime as well as version both should be same and fourth components which is the app service plans which is related to a compute infrastructure as we said earlier it's a serverless but it need a compute when it's execute so here you are predefined yours compute infrastructure you need a serverless or you need a dedicated one or you need a fixed one and you can share this with other app services as well so these are the four components now let's go back here and see if it has created or not so it has successfully created so let's go back to here i think i created on here so you will see that these are the four component it has created these four components storage account uh functioning application insight and plan which is a related to coast and compute infrastructure so this is a storage account and as i say that it should save here it should create this one so it's giving exit name of your function if and it's uh add something random things here and your code will be here your function code will be here inside the sites in here so here reside your azure function code so that is a function that is a storage account and this is a function app so you can see that this is the overview of your function if you will see more information here your service plan and other things it's running or not and here you will see so many things in buildings which azure is providing but you don't need to worry about worry about it for beginner level so you just you need to think about functions and function key so if you want to share your function with different azure services like azure data factory or as your cnips analytics or as your logic apps and you tell them to execute your function then they need to have this function key so you need to provide that function key it's like a connection string that is a one thing and also it has a config so here you can configure your function api as well for example you want to change your block storage connection string or database connections ring or you want to change some version so by default it has this that you can do it here and there is edit buttons is here so you can edit it because sometimes you need to change your storage account then you can directly come here and you can configure it because it's different based on your different environments but if you do automatically by cicd pipeline then this will be done automatically you don't need to change manually anything so that is a config and this is the excess key uh sorry f key and you you can click here show value and this value you need to share if you want to use this function using the function key rather than serious principle or other different way and let's go now function so this is a functions and at the moment we don't have any functions so we can create it by portal first time this is first time we're creating so we selecting here option which is uh uh developing a portal and these are all triggers as i said earlier it's even based and it can allow you to triggers so these all are triggers you can see that there are so many triggers available these all are triggers which can execute your function once condition is satisfied so if you don't find your trigger here you can customize it or you can use http triggers so let's see is http trigger uh so we we have selected our trigger we selected that we are creating into portal so you can see that it has a created and you can test it using azure portal using here and these are the code it has created automatically for you so you don't need to worry about syntax if you knew and you don't know so this is the function and from this way you can write down some log as well if you want to write down log in your insights this is a request it's passed as a query string or maybe body of that function and here we are de-serializing it and here we just returning it that's it you can add here your own logic some steps or calculation and then you can read and read just a different way not this way this is very simple example so here we are checking that if is"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "can add here your own logic some steps or calculation and then you can read and read just a different way not this way this is very simple example so here we are checking that if is my input if we are not passing any name then uh it will give it this result uh sorry is this one but if we passing a name then it will say hello our name and then it say this is the triggered function executed successfully and it's written response in object so this way you can do that you can test here by using portal in here i just clicking here it has already given the name as well so it's use that name which is azure you can see it's written the result as well here you can check some logs as well so let's close this one and if you want to use this one in your local machine as well then you can just copy this and you can go to i think maybe here in postman and you can run it like this way it's simple because there is no other parameter so like that so you can use it use it like this way otherwise you can have a like a body body message or like that in here so now let's go back here so this way you can create your function in azure portal you can paste it by using here you can can you can have url using here and you can monitor it here because we have just a trigger of a function so it should become here sometimes it take time i think it's used five minutes or like that so you will see history here after some time but if you want to see immediately then you can go to here and this is the app service insights and here you can see that one history that it's triggered it's success it's written code and you can see more information as well this whole information you can see it and you can see parameters and many other things and you can even find out if there is any exception as well a fail or anything so this is app insights which we have used during uh creating a functionable so now let's go to here so yeah so this way you can create azure function using azure portal now we're going to do same thing in using the visual studio as well so let's go to video studio so i'm just going to use a visual studio 2019 you can use the latest version as well so we are creating now azure function using visual studio so you're going to create a new project which is a function a project so first of all we creating a function f and then we adding function into our function f so you need to select as your function and then you can click next here you need to give suitable name but i'm just keeping as it is you can select location and you can give a solution name as well so these are all trigger you can see in here as well i'm just using default empty trigger and here you can select your run runtime as well so if you're creating new then always good to select latest version and this is a storage emulator which is like a storage in local when you want to run in your function locally then this is work as a storage account so let's create here so this project is like a function f which we done first time which is a function f which have four different components we had that earlier so we're just creating that i think it's still doing that so it's now ready so this is my function if project and you see here that it has a package as well which is related to microsoft.net.sdk functions so if you have input bindings like block storage or table or queue then you you have here more uh packages as well related to table storage or queue or even grid so that is one thing this file is like related to your function app hosting uh information and this file is a lock this file is local.setting.json so here you have information like your connection string and if you want to have something related to configuration then you can edit here so that is a local.setting and now let's add here function so i'm adding new function here i'm just doing quickly because we done same thing in a portal as well like you selecting triggers"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:25:19",
        "seconds": 1519,
        "text": "so that is a local.setting and now let's add here function so i'm adding new function here i'm just doing quickly because we done same thing in a portal as well like you selecting triggers and that's it it's create automatically this code for you in visual studio and you see that this is a function attributes this is my function name and you can see this is my definition of function so here i have used http trigger i have used authorization label level as a function but here here you can have anonymous or there is one more option also available uh and these are the gate and post method like which method is allowed so i'm allowing to get and post and i don't want to customize any url so it's by default null and this is the this is the request data because i have used http request and here i will get my request data as well so now and rest of the whole things are same which we have seen in azure portal so this way you create your function and you can run your function in here and if you place here debug you can trigger it you can debug it as well so let me close now this solution because i have already solution running so if i run same solution then it will give me error related to port number uh so let's see it you know here this solution so let's say i already have this function here i have placed debug points and if i use now this function because i am debugging this function in my locally so it's coming into here and you can debug it in your local as well by using f11 or like that i'm just doing continuously and it's returning results as well but if i add here query string like name then it will return different reasons as well different result as well like this way if i pass then it will run it and it will return as a different results because it's coming into this this part i think i did something wrong in here it has to be yeah so uh now so this way you can deep uh using visual studio as well locally and you can publish as well if you want to publish uh using let's go to solution and here using manual using visual studio you can deploy by this way by clicking in here and it asks you to select your storage account f service plan and few things three to four things so that's now let's go back to here in presentation so we have a created function apps and now we have edit function as well we tested that function in azure portal and we did same in local machine as well and we use visual studio as well and we use the postman to test that function as well so now let's go to scenario a few demos so in this demo we are going to read file from block storage and then we are generating a manifest file and then we are saving that manifest file into block storage so here what we are doing because there are few things is not possible in our data solution or iot solution or or app solution then you can create function as well so it's function uh reading the list of file from blob storage and that is generating a summary of the file or like regarding those file which is already in block storage and it's creating new file with the summary of the whole list of files and then saving it to same blob storage so that is one and now let's go to here like what it used so it's we have a piece of code which reading the file list of file from blob storage and it's generating one summary of the file which having the e takes and md5 and md and modified date and a few more things the counts and name of the file and it saved that file into block storage but here we are not using bindings so we have a piece of code which has everything written there and this we have used a trigger which is http request trigger and we are saving the result into azure block storage we are creating a new files in azure block storage so in my blog"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "and this we have used a trigger which is http request trigger and we are saving the result into azure block storage we are creating a new files in azure block storage so in my blog storage i have a car car.csv file you can have a list of file like you have five files and your file have accounts as well so in my files i i have only two counts at the moment two record at the moment but it can more than one record as well and you can have more than one file as well so in my c function code it's the c sharp code and it's a read a file content uh e take count md and there are a few properties related to file from block storage and then is generate a separate new file having the list of the summary of the each file in that blob storage and it's saved in a block storage in a same block storage or you can have another block storage or you can have some other azure services as well so this is the high level design uh so now let's go back to in a portal so so this is my azure this is my resource group and in my resource group you can see that i have a same information which we had in a previously created uh azure function and functioning so this is my storage account and in my storage account you can see that i have a input container output container and this test container so let's see that at the moment it has a card.csv file and now i'm running you will see that here one new file will generated so now let's run the function so this is my function if and my function f has a four functions and i'm going to running this manifest file i have a parameters in my notebook so you can see that this is my container and i'm passing area value but at the moment i have only one file so that there is a card.csv file and it has a two counts so i'm passing this message and i'm it and it's successfully run and if i go to here if i refresh this it generate new file and this is a new file it's a manifest file and you see that it has uh this summary information so if i had here five files then i have five entry here like file each file name how many count it has and this is the itake and this is a modified date so if i search this deck let's go to here and search so this is the file you can see that it has a tag here so if i copy this header and if i search in here it's matching it so it should be exactly match that was the requirements because this manifest file is used by another third-party solution so they have that requirements as a part of our data solution so that's why we have created this and uh let's go to uh here so yeah so this way manifest function run and i think you can monitor as well it's here quickly maybe i forget to clear enable this but anyway so if you want to use that manifest function by other services for example azure data data factory or azure synapse analytics then you need to use this function key unless you're using different mechanism so here you can find your function key this is your function key so now let's go back to let's close this one because we have done now let's go to see a code in visual studio for that function so this is a create manifest of file without any input and output binding information otherwise it it much is higher if you use binding then because they are azure services and they allow binding as well as possible so so this is my function function name this is it's a it's it's used at ttp trigger and it's have a request data here which is array which we are passing uh it's it's allowed for both method and its use of function authentication author authorization level is a function and there is no any customized url so it's dc realizing it my input data which is here and then it's used uh dictionary because i it's a input data is in array format and then it's creating"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "there is no any customized url so it's dc realizing it my input data which is here and then it's used uh dictionary because i it's a input data is in array format and then it's creating here so here it's reading this file from blob storage and it's generating a summary and saving it to blog storage so this is that function which do all things but it's a little bit more code because you need to specify everything your blob storage name and then you need to you create few things like this way pointing like manually we creating them by programmatically rather than using binding so so we need to go through loop by loop each file in a container be reading that file and then we're reading the particular properties and like this one this way we take properties and other properties and then we're saving it to new file and then we save that file into block storage so that's what this function is doing and yeah so you can learn run locally as well and actually i have already here in a postman okay i think i need to copy url it's not here so this is the url open azure function which is in portal as well you can see this one that one also you can run here locally if you want to do so this is url from your azure portals function url and you can pass it but let me do it my local one which is um which is this one unless i have debug point so this way it will read under the result which we have the same result in our portal as well and it's running this code as well it's running this code i don't think i have any debug point so it should written uh yeah it's already written okay so you can see that it returned successfully as well this is local url and if i go to that folder again it has a file as well i go to that container let's go to here i think it's a storage indeed here it has two files now these two one which we run by a portal and one which i've run using my local postman um so that is the one now let's go back to here with the second demo as well i think oh yeah so this way it's create a file as well uh so if you want to use this same demo in your environment then you need these resources you need to create resource group you need to create function app then you need to add a function in your function app and you need a block storage as well so this is now second table so here we are using input and output binding so it's very easy it's you have a piece of code ready you just few lines of code and it done your it's done your purpose so so here we are resizing the image so i have an image in my prop storage and particularly i'm looking for dot jpg image so any name with dot jpg as soon as is arrived in a block storage it has to execute a piece of code which is as your function and it resize the image into two different sizes small and medium and store into different container so that is my requirements and for that here we have piece of code which doing the resizing resizing image here i have input trigger which is a blob storage trigger and i have a binding i have a azure blob binding as input and i have azure blob binding is output as well so here i have one image like car name plate dot jpg as soon as this arrive into my prop storage specific container automatically piece of code run and it's re resize this image into two different size and it's placed into azure block storage and here i have used input and output bindings so i have a c sharp code which converters size in two different size and save into another blob storage like this way so it's name name should be like same as what you have in here plus it's adding the few things like it says space or slaves or days sm which is small and nowadays medium and it's saving like this way so now let's go back to portal and here you can see that this is my function a uh this is function and this is a reason sorry this is the resizing image function before run it uh i would like to show you what"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:40:36",
        "seconds": 2436,
        "text": "and here you can see that this is my function a uh this is function and this is a reason sorry this is the resizing image function before run it uh i would like to show you what i have in a container so you will get id after deployment so let's go to storage i think this is a storage account container and my input container i don't have anything and my output container i don't have anything at the moment so okay so i'm just it's using this one so as soon as the file arrives here it resize it and it's stored into output folder so let's add here file so i'm just adding one jpg file you can have a 100 jpg file at a time as well so now what happen if i go here and i click here and i wait for some time see timestamp also you can check here to this time step it's generated two files and it's resize as well so you can see it here it's this is a medium size image file and this is a small one you can have a various different version as well here but i just use the basic one so this is used by bindings and if i go to here function even i don't know you need to run this function because it's automatically it's a binding one and you can check here as well history as well if you want to see that it auto oh yeah i again haven't configured this but you can check it here as well if it's run or not so for that i don't need to run that function it is automatically running as soon as the file arrive into that folder in that container so if you want to see a code for that then this is a visual studio and this is a resize image so here you can see that you will see here now more information i have a blob trigger which particularly looking into that input container and is looking for any file which is dot jpg file so this is expression here you can have a various different expression as well you can have concatenation and many other things so this is my trigger so when this condition arrived as soon as the file arrived into your blob container piece of code will execute this azure function will execute so this is the trigger trigger has a input file information and it has information regarding connection string which storage is looking for and i'm giving its name as an image so this is original file when it's coming to block storage and this is the output binding so there are two output binding because i want to save two files i'm passing one if i have one file but it's returning two files so here also we giving same name but we here we can have a days or may a space so i have a space here and i have permission given to write permission and i'm writing into same storage account you can have a different storage account as well or you can have not a storage account you can have like table binding or q binding or something else and this is just its name that's it and here you can see that i'm resizing those images and for that i have this is a resizing logic and see this one line of code is writing a file into blob storage that's it you don't need to write down anything because you have a binding you have user binding and for resizing i have used just enum for three different size that's it that simple this code it is and you can run locally as well um so now let's go back to presentation so for that second demo you need azure resource group you need azure function apps you need a functions in your function app you need a blob storage and you can have key volts as well if you want to store the secrets in keywords then you can use that one like that way as well so now let's see how azure functions integrate with azure data factory or azure synapse analytics or other azure services so i have given example of azure data factory here so this is my azure data factory and this is my azure function and i an azure function i have of four functions as you seen earlier so here you can see that azure data factory has azure function activity so it's just a calling that activity is passing the function name and function key function execute independently and it's written result into your data factory which you can use for as"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:45:40",
        "seconds": 2740,
        "text": "azure data factory has azure function activity so it's just a calling that activity is passing the function name and function key function execute independently and it's written result into your data factory which you can use for as a part of your extract cloud transform or modern warehouse you can use as a part of orchestration or pipeline so it's that much easy same way you can use for geologic apps or other azure services as well so before conclude i if we have a few minutes then i can show you here how you can integrate it with the azure data factory so this is my azure data factory and it has activative function this is activity called you can drag and drop so similar way i have already let's delete this i have already here and you can see i just passed a few information i'm creating a link service which use a connection string in order to connect function with azure data factory i need to create a link service which is a connection holder and here i'm passing function name hello function which i have in here you can even i can use manifest function as well i use this function and you can see that i'm using method and i'm just passing the message body that's it you don't need to do anything much and it when you run this one it will execute your azure function and as your function return reaches into here and i can store into my variable as well it's executed very quickly and you can check result as well here whatever it has written and here you can see what is input and what is output so this is my function name this is method and this is a message body as well and here you can see reset as well what it has if if there is error also you can see error as well and uh connecting them i created this link service i created keywords because this time i have used this keyword which hold the function key in a keywords because it's in central place and then i have used this keyword in my azure data factory and then i have this is a link service which is a getting secret from keyboards that's it and this way you can connect your azure function in as your as your data factory and same way similarly you can do it in um like logic apps or maybe other as your service like azure cnf analytics as well so with that i would like to conclude this session so we have seen a quick overview azure function and we see why is needs and how does it works so azure function is a small piece of code you can write down into different languages it is a trigger based event base so you can have a timer trigger a ttp trigger block trigger and there are many more triggers available which execute your piece of code or a function uh it's a platform as a service and it's easy to integrate with other azure services for example azure data factory even create azure logic apps as your cns analytics and many more and it has azure ad security because it's azure service and then we have a scene tool like azure portal visual studio 2019 the powershell uh cli and arm templates as well and then we have seen series of demo by creating function using the portal and creating function using visual studio debugging them using their visual studio testing them using visual studio and postman and azure portal and then we have seen two demo which is uh width binding and without binding like resizing image with with binding and manifest file which which is with which is without binding and it's just using http request so with that i would like to thank you for attending this session and i'm open with a question great uh thank you alpha uh le as uh as she said if you have any questions please uh please jump in you should be able to put them in the meeting chat or you can um come off mute and and ask um i have one question alba which is uh with with the image demo where you uh you uh you a trigger uh an image was uploaded into blob storage and a trigger um was used to execute some code that created a medium version of it and a small version of it what is the um can you say anything about the limitations of azure functions in this context so for example what if there was a i don't know a a five gigabyte image that you put in that was incredibly memory demanding to load um into the code that you know uh that did the transformations yeah that is a very good question"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:50:41",
        "seconds": 3041,
        "text": "i don't know a a five gigabyte image that you put in that was incredibly memory demanding to load um into the code that you know uh that did the transformations yeah that is a very good question i think i haven't uh done that much like bigger size because i don't i have used the same uh small dummy files so at the moment i don't know but i will test it and let you know i will place bigger file and see how it's reacting but as far as i know block storage can contain a bigger file more than 2gb or 5gb or like that and azure function is resizing it so it can be done but i need to taste it i will definitely taste it yeah okay yeah just curious yeah i would imagine blob storage doesn't really have a meaningful limitation here it's more the function about how much memory it can be allocated to do it's uh to do its work yep um it's a very good question yeah i will definitely test and let you know yeah right sure no no no pressure but i mean i am kind of curious um there's a question in the chat i'm not sure if you're looking at it i'll i can read it out um uh uh kritika is interested in how to trigger http functions using a logic app logical for http using logic logic f so logic caps has a function action function as well so we can do like that way or we can use custom connector so there are two way you can do that custom connector or you can use the action there is a function related action will be available in logic apps okay so um for the um you know for the http that you have created so if i have to trigger that using the logic app uh what would be the way that i can trigger should i have to use a http or as in you know create a logic app with the http request and then process it or yeah actually logic yeah yeah go ahead because like i have a scenario wherein i am receiving a trigger from a ui okay so whenever i get a trigger from the ui i have to run the function app that i have written okay so in that case if i am getting a request from the ui which is a http request so i have to trigger my function app so this function app that i have written has um you know some validation which again connects with a different end point and sends a request and uh receives a response and i write it into a blob storage yeah so how can i like i i'm not now into the creation of logic app but what i would like to know is if i have to test it manually like without any trigger i'm facing some issue so i would like to know uh if i create a manual trigger how can i test it uh for that function okay so first of all in logic we have a logic caps also have a trigger so at the moment i think you may be used attp trigger when you create your logic apps yeah so in after that you step a operation and action you will select so in action you have a function automatically you have azure function action as well or you can have your custom activity the custom connector you can create your custom connector is and that one is like it works when your logic apps run by http request it your function is executed automatically in in your yeah steps because logic itself has a trigger first of all because you have to choose a trigger in logic apps and then you have steps so in steps you can use direct azure function or you can use a custom connector for that so if it's custom connected then you don't need even a function like it's like function normal function like it has a piece of code individual code and it can run as a part of executing your logic apps okay thank you okay thanks do we have any it's a q a is it yeah there's there's one other question in there from uh jeffrey if you if you can see that oh yeah you've got any experience with the requiring auxiliary authentication to trigger the function so it's there a way to return a info for your user principle that triggered the function it did not get much about this question i i think jeffrey you can come off and elaborate if"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "00:55:43",
        "seconds": 3343,
        "text": "so it's there a way to return a info for your user principle that triggered the function it did not get much about this question i i think jeffrey you can come off and elaborate if you like i think what what he's asking is um effectively first of all it's a two-part question but the first part is is there any other way to um i know you showed us the the api key or the function key that you need to pass in if you want to invoke it um as the um as the way to authenticate the request and can instead of using that key can you use anything related to azure active directory yeah i i got it now yeah you can have like client id like you create apps or registration and then you have a client id and client seek grades and that way you can use it when you write down code in c sharp and when you're creating this way azure radio authentication then yeah you can have that one client id client secret tenant id 10 secrets and those way you can generate a token and then you can execute a piece of code as well means you write down that logic uh before someone execute your piece of code yeah so yeah so you can use that service principle at that time and as your ready user as well is there um do you have any idea would does that also answer the second half of the question if you happen to know anything about that second half of the question is the way to return the info as you ready user principle that triggers the function um that one i think we can check you know application insights we get logs there who has run an ip address and there are so many things is available because here is generate vr token as well so i think it has those information in app insights after execution of your function but i haven't checked like tried this one but i can test it and let you know yeah but i have definitely used the service principle and generating token and then if that user is authenticated then and then execute a function so that things we have used in c sharp yep yeah and it may also be the case that in c-sharp code you can look at the um it's been a while since i've done this as an eye principle that um from which you can just see whose context this is running under so it's an authenticated user i would suppose that that that's who that um eye principle would point at as the the user who was authenticated throughout your id yep and one one question is like considering my function app has a multiple function within it it is possible to debug in vs specific function without involving the other function yeah you can debug your individual function because here you can see that i have a total i have a four function but one three function but one is a triggered base like input binding and output binding related so it's not coming here because it's automatically run we don't need to do anything for that same as a timer trigger as well but these two function is like individual one so i can have this url and i can run you know wherever i want to run using browser or postman or like that but i think you have a function f so function ap so continuously running so even though you're not running individual three functions you run maybe one function at a time but function f will run so but you can individual run function and you can debug individual function as well and yeah you can debug it in visual studio even you can debug azure function which is already in azure you can debug into local by changing uh in the settings here for example this function i need to go to function if and config here is a setting so that way if your function is not working correctly it's working in your local and it's not working correctly in a portal or any in your dev test or sit environment then you can have here settings so there is a debug option is available here remote debug on and off so if you do own and you use this visual studio and then you can have this function in your postman you can"
    },
    {
        "speaker": "",
        "title": "Alpa Buddhabhatti: Azure Functions 101",
        "videoId": "n8KFDUo7kUg",
        "description": "This is a recording of the August 11, 2022 meeting.In this introductory session, Alpa Buddhabhatti will provide a quick overview of Azure Functions. Later, she will show a quick demo to create Azure Functions using Visual Studio and the Azure portal. And finally will provide basic use cases of it with other Azure services.Following services/Technology/Tools will be using during this session:Azure PortalVisual Studio 2019Azure FunctionAzure Key VaultAzure StorageAttendees will leave with knowledge of Azure Functions so they can start using it in their business use cases.About the Speaker:Alpa is an Azure Consultant with a passion for data and technology at Cluster Reply UK. She is Microsoft Certified Trainer and certified in Azure Data engineer and Azure Data Science. She is working on Azure services such as Logic Apps, Azure Functions, Azure Key Vault , Azure , Azure Data Factory, Azure Storage and Azure Data Lake .",
        "start": "01:00:47",
        "seconds": 3647,
        "text": "so there is a debug option is available here remote debug on and off so if you do own and you use this visual studio and then you can have this function in your postman you can run in postman or in your local using visual studio 29 and i think latest one maybe or it's allowed but not sure in 17 it's a work or not but 19 or 22 is definitely will do and then you can have that url and you can run in locally so that way you can debug it value and everything in your local machine yeah is that answer your question yeah yes so one more question i have bringed you so yeah okay so if you want to move your function from local machine to your portal then for example i can show you here in my visio studio let's close this so here you can deploy various different ways so you can create amp templates as well so like i have created here so this is the json file you can get ready man template from github as well because microsoft has that list of everything so here what happened it will create your uh these are all parameters which you can have different for per environment so this way its parameters here you have calculated variables and then here you are creating resource without creating in portal so you creating your storage account which is doing automatically when we created then it's creating the service from it's creating the function apps and then it's creating the app service inside so this four component which we done automatically like by creating portal so these are the components here we have amp templates for that so you can use arm templates and then you can use your ci cd pipelines like i have here now you can create it and it will deploy into many environments because this is very very good when you have many environments or maybe you don't want to remember things because sometimes you do setting if you do manually then you have to remember it and when you deploy it you will forget it that what setting was there and what you had to change as well so this way you can deploy as well and another way if you are beginner and you don't know about amp template and like ci cd pipeline and devops then you can do it by here but this way is not good because it's uh override your things so you can publish it and it will automatically create for you many things you don't need to worry about creating them so here you can see that um if your first time doing because then it gave you few options as well these are those options it will suggest you that what you need to do so this is my code here zip code and then when i click on publish it either complain if something is not matching or if he's happy then it will publish successfully so this way you can publish it but it's asking for storage account mainly and if because you have connection string or if you have event grid or something like that so yeah so this way you can do that but at the moment i think these are the options so we are select yeah you can oh you can do like this way or you can have new one i think so yeah this way if first i'm doing then you do new one and you're selecting which option so you use azure one we are not using other one import export or container or like that then here you need to select similar way when we created in a portal we selecting this option so it will automatically create for you uh when we did earlier it's asking your subscription and these are the old information use resource group and those things if you do and then after it just you just need to click next snakes after that so let's select this so for uh the deployment um using that is the devops i should should i have to have the installation like extensions installed or how can i do that like the arm template generation which you know okay so in for that uh i think you will get this template from our githubs because microsoft has already that list of templates based on our requirements so once you get templates you need to add here project which is uh you need to add a deployment project which is arm template projects here new project and then you need to place that json file and parameter into there yeah this project azure resource project but if we need in c sharp it's here this first one so if you search as your resource project for deployment and then you gives you table name as well i'm just clicking next so that way it will it will have for python as well correct item no amp templates this project is uh only in a json file so i don't think you need a python or anything it's just a json file yeah but it's c sharp or like that so here you can see that yeah but its code is a json code and it's a simple code like everything what we done in portal similar ways we are doing here and this is a very good because when you have more than one environment or even you don't want to remember because this is menu always and it's always updating your config area and many things so tomorrow or after one month you maybe not remember so it's not good and another reason is that you have three environments and you deploy your function if you test it like in testing environment and then after that you can delete your function app so it you saving cost as well and tomorrow you need again then you just click here in devops you just click here click create release and it will automatically create for you everything so it's like few minutes job by releasing using this button and it save a cost as well and it's 100 automate so it's like you don't need to have any headache uh okay so while creating this template um i mean on template it would also have a storage account those keys everything resolved storage that we use everything resolved in it so we don't have yeah okay yeah yeah so here you can see that um let's see i think it's this one no type inside uh i think it's maybe here so these are the properties you can see that here these are the ones so we are all already configuring here everything's like storage account and everything uh so it's like automatically done after that and it has a connection string also set up correctly in your function app and everything is done by that but if you do manually then you have to do manual change yeah yeah i am facing with that issue yeah so that's fine okay i will try with that um template yeah yeah and you let me know if you need more help on that yep sure because i i have one video in youtube uh where i have uploading using uh these arm templates as well so i will send you that link as well yeah yeah sure i will connect you with link in linkedin yeah okay all right um good exchange uh i thank you um uh i thank you everybody for joining and uh alpha is it um is it like 20 past midnight in your local time zone okay we should wrap up let you uh return to your uh life uh it was great that we were able to have you join us uh and um uh jason did you wanna let folks know what's gonna happen with the youtubes yeah so for those of you who are asking questions i'll have this video uploaded to the youtube channel probably within the next hour so check the meetup site for the link in the comments i'll i'll drop the link where you can find the youtube link at that point so if you want to re-watch it and uh help yourself out it'll be out on youtube soon right um and that's it okay thank you everybody thank you all thank you for question as well bye take care "
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:00:06",
        "seconds": 6,
        "text": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall. This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).. okay welcome to virtual boston azure as most of you probably know we've been meeting for the last uh six months or so virtually and we've you know pivoted to this new format and um trying something a little different tonight that i'll mention in a couple of minutes but uh welcome everybody this talk is on uh turning on your web application firewalls in azure and i i'm i have a day job at a at a company that runs entirely on azure and we have customers around the world and one of the responsibilities i have is to keep an eye on cyber security threats so i spend quite a bit of time on that we have other people here uh my company who spent a lot of time on that and i've been personally leaning into the web application firewall as one of the tools that could be added to my toolbox or or certainly my personal knowledge was was low so i've leaned into that recently to learn more about it and i thought it would be good talk to bring to boston azure or virtual boston azure and share the [Music] share the experience with you all so i'm bill the most relevant part here is i i founded boston azure about 10 years ago and i've been enjoying their community and all of you all the interactions with all you all ever since um i mentioned this i don't think i mentioned that it's a combination of virtual boston azure is a combination of boston azure and north boston azure it is so uh veronica and i run the boston azure side uh jason runs the north boston azure side and of course we've always collaborated some but we've totally joined forces here and i think veronica was mentioning this earlier on the call if you have topics you'd like to see speakers anything like that please let us know we're always interested in more ideas so first a warning um i'm uh i'm not going to talk about money beyond this slide uh azure features cost money and go i'm encouraging you to go and play around with azure front door and azure laugh and uh get to know them but be aware that there are consequences to that exploration financial consequences potentially there are free options in azure some services are free and some if you're new to azure you can get some non-free services for free for at least uh an amount of time that allows you to explore them so i'll leave that link to otherwise speak for itself okay so uh security awareness we've just gone through a presidential election four years after the person on the bottom left was uh infamous let's say anybody i should mention if you if you want to um use the the slack channel for um i'm sorry use the uh the team's uh messaging for for any um any kind of questions or comments or anything and i'm sure jason uh and veronica and uh will keep an eye on it now let me know if there's anything that should um draw my attention and um that's a benefit we have over um over an in-person event where we can actually have these uh side conversations to answer questions and so forth so uh because i i can't ask you directly to answer my question if you're virtual so i was going to say does anybody know who the person on the bottom left is if you've seen this talk before or you've followed the news closely back in the prior u.s presidential campaign you you might be aware that that's john podesta i believe i believe is the gentleman's name he was the campaign chair for the hillary clinton presidential campaign and he was phished by uh believed to be russian hackers i think fancy bear is the um the the code name that some some refer to them as and they got his email uh exposed and they used that to mine it for lots of interesting documents that later showed up on uh wikileaks and they didn't know this happened it took a while and the uh i believe the fbi had to uh call the dnc and say hey do you know some of your stuff is out here on the bottom right we have target the u.s clothing retailer other things i guess and they were hacked uh a few"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:05:08",
        "seconds": 308,
        "text": "uh call the dnc and say hey do you know some of your stuff is out here on the bottom right we have target the u.s clothing retailer other things i guess and they were hacked uh a few years back and famously the the the attackers came in through uh hvac vendor and they hung out in the target network for a really long time because target wasn't aware that they had been attacked capital one recently had a it was about um well a little less than a year ago at this point maybe a s3 bucket on uh s3 hacked or exposed with some sensitive data and problem again and equifax on the top left there many of you may have been affected by this where equifax was hacked and they didn't know it either and i think it was also the fbi that had to knock on their door and let them know that they had been under attack unaware and hacked and we're all um you know part of that victim pool here so clearly security awareness is an industry problem these are just some really high profile examples but um there are some things we can do to be more aware of what's going on and again that's part of the there's more dramatic examples of course but that's part of the impetus for this talk and why i wanted to become personally more savvy with the web application firewall and security visibility and awareness generally in the security world there are often uh considered two teams the red team and the blue team who take different postures in trying to uh uh uh like understand the the um the effectiveness of uh of the security system and in the case of what i'm going to walk through today you can imagine that uh i'm part of the blue team kevin who's uh help helping me with this is uh part of the blue team and our job is to try to figure out and prevent from getting in the red team who are the in this case friendly attackers so rather attackers blue as defenders and red and blue exercises are useful in uh getting us a perspective on your security posture whether you're more or less secure you know how if the red team has an easy time of attacking and the blue team has no idea what's going on they can't stop anything you know it's probably um you know you you have some work to do and um so anyway that's that's kind of the mindset for today is uh i'm the blue team and some of the folks who um uh signed up um to get access to uh some to the azure subscription who that invitation went out uh uh two or three hours ago i guess so hopefully everybody has access and you you have access to some of the visibility that i have as a blue teamer and you also have uh some insight into ways that you might interestingly uh attack because you know what the defenses are so so thank you for the for the folks who are these right along guests uh this is experimental by the way this is the first time we've done this where we've posted a meeting invite and said hey if you want to play along at home uh send you know let us know and um i don't know 15 so people maybe 20 um did so and they've um they've been given access to a little more uh inside information on the system so and i absolutely want feedback for many of those participants and if you have any ideas for doing this kind of thing in the future trying to make this uh covet virtualization virtual meeting mode more effective in some ways than the in-person mode can't wait to get back to in person but when we can't let's try to make this as effective as possible and as a general point to the anybody in the audience i mentioned use the teams chat if you have questions and i just uh off the top of my head i poured out some of the buzzwords that i might mention during the talk here so if you don't know what they are it's it's okay to ask and we're we're here to help and to educate and uh uh me not having answered everybody's question uh jason veronica may or may not uh kevin may or may not uh but maybe somebody in the audience does so we'll do our best but if you have questions on stuff don't be shy and you can follow this link if you want and this has a link to some resources that you can use even if you haven't been given the prior access i mentioned you can you can help by visiting the site if"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:10:11",
        "seconds": 611,
        "text": "and this has a link to some resources that you can use even if you haven't been given the prior access i mentioned you can you can help by visiting the site if you like so a bunch of links are at this address this is a bitly link and it reads boston azure december 2020. that's how to remember that bitly slash bba dec 2020 and again so a few resources of interest there okay let's get into it firewalls we like to protect our cloud or you know ancient public internet facing assets with firewalls and firewall is a means of protecting at the network layer and i want to mention this network security group concept uh so i can contrast it with the web application firewall that we'll talk about in a minute this is a firewall that's built into azure and it's uh com i believe it's free in all cases and it is a simpler firewall than waff as we'll see it's aware of ip addresses ports protocols and i i'm maybe somebody on the call here who's a little more savvy with network uh uh understands networks better than i do but i believe it's a layer three layer four i don't know which uh on the uh uh i uh uh iso network stack it's both layer three and four it's essentially the socket uh the port protocol socket bind itself thank you yep no wonder i'm confused it's both okay so it's layers three and four very good so like i said it only knows about that it's the classic four tuple the classic what sorry for tuple port protocol source destination port protocol uh iport protocol oh protocol okay got it as here so okay so you can block an ip address you can block every ip address except let certain ones in you can block all ports except for say port 443 it's common and you can block the protocol you can allow in tcp and refuse udp for example simple but pretty effective contrast this with the web application firewall the web application firewall is aware of http and https of course and it knows the concepts for the uh lower layer so actually i'm going to stop this for a second and put in a point here because i think it's important let's fire that back up uh i thought the point here was worth seeing this is known as a layer seven firewall and that is the what's known as the application layer and that's what it means to be at the http layer so if the firewall is aware of more than just ip addresses ports and basic you know much more primitive networking protocols like tcp and udp it can't do a lot of things that a layer 7 firewall can do so when we get into layer 7 and it's aware of http it can it can look into the http and you can build in interesting web application protections now so based on patterns that that the security community has figured out over the years you can 110 a web application firewall can notice that wow this construct looks like a sql injection attack or a cross-site scripting attack in other security attacks we often look at the owasp top 10 as uh as a list of the most important ones but they're they're not limited to that and the wa functionality is not necessarily limited to that either uh so so in the reason that you can't implement a waff at the layer 3d or layer 4 layer is because uh web web application concepts like html look just are like uh you know noise to this layer it doesn't really know what they are there's no concept of that they have to go up to layer seven here and the the uh if you look at this diagram you have the um the humans in in bots and services coming in from the top and they hit the waf and anything that is deemed a uh undesirable request is rejected it could be by ip address which the layer 3 firewall could also do but it could also be a rejection because for more sophisticated"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:15:13",
        "seconds": 913,
        "text": "hit the waf and anything that is deemed a uh undesirable request is rejected it could be by ip address which the layer 3 firewall could also do but it could also be a rejection because for more sophisticated reasons like for example it looks like a sql injection attack looks like a cross-site scripting attack that is um it's accessing uh the the website too fast so you might rate limit or it might be coming in from a location that you don't like or some ip addresses that you want to blacklist things like that can all be um handled in this waff realm okay ask questions along the way if you got them uh i'm gonna i'm gonna forge ahead the azure ecosystem has a weft but it comes in three different flavors it can be deployed with azure front door that's the variant that we'll use today it could come in through an azure gateway or it can be um deployed an associated student with uh azure cdn they're they have slightly different profiles and we're not i'm not going to talk too much about that other than just to mention it that the feature set is interestingly it's just slightly different across the three variants i don't know if they'll converge in the future or not and when we put resources we deploy resources to the cloud we think about as good security practitioners we think about defense in depth and defense in depth as all these layers of protection in reality if we don't think hard or don't aren't diligent we sometimes end up with um you know basically void or no op layers even though they're present they might be useless for example a firewall that lets a an nsg layer 3 layer 4 firewall that lets in all ip addresses in all protocols on all ports isn't really doing anything interesting and a waf that's not turned on isn't doing anything interesting and so forth so the tools are there azure provides a great toolbox but if you don't use the tools it's as if they didn't exist that's kind of a problem i saw a talk from somebody at microsoft where they said something like eighty percent of azure customers or maybe this azure subscription something like that uh did not make use of any non-free uh security features and you know spoiler um some of the good stuff uh costs money you can end up with a shallow defense and uh so we're gonna bring azure front door into the picture here and that again is going to be the vehicle through which we can deploy uh an azure web application firewall how about that huh it took me like three hours to get that animation to work right so add your front door and a little more detail uh this stock isn't really about azure front doors i don't want to talk too much about it but i want to give you an idea of what's going on because there are a couple of interesting aspects here so you have on the top left you have traffic inbound it is reviewed at the waff and i already talked about some of the things that we have can do it can say oh this is a looks like sql injection and could refuse it uh assuming it gets through there's a rules engine that um can be brought to bear we'll talk about that again in a second and then it um uh it can pass along the request to back end servers and it says origin a here but they could be many servers on your back end and it would load balance across them if you if you did and in the case of this uh the demonstration i'm going to be giving here that the back end is a an azure container instance running a container i pulled right off the shelf from the owasp juice shop sample application and we'll talk about that uh a little bit more that's that's what's at the back end so it hits the back end the back end does its work it's a web app returns some data and it sends it back to the client one of the other things with this rules engine is that the rules engine can also work on the way out and we'll see later that we can use this to bolster our security visibility beyond just the waff here and that that'll work like i said we'll get back to that and then the payload is returned to the um to the client okay so we're going to get into demo mode uh as i mentioned with the the system that we're going to exercise"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:20:15",
        "seconds": 1215,
        "text": "okay so we're going to get into demo mode uh as i mentioned with the the system that we're going to exercise owasp juice shop app on an azure container instance this means we pulled a docker container out of the public docker registry published by owasp and we deployed it and we fronted it with an azure front door and then we configured within azure front door the optional firewall the optional left and then what we're going to look at specifically are azure monitor to see the signals that we're getting from the firewall log analytics is part of that that will in there we'll look at the cousteau query language kusto to review the signals uh we're going to attack it live here in the during the talk and just to see the burst of um of traffic and see what the the waff default rules can pick up we're also going to talk about some other factors like custom rules and um various kinds of rules so we'll look at that in a little detail so you get to know what what what the waff can do for you and also look at a scenario where where we might want to correlate as an example storage access with application access to maybe you have the same uh attacker from afar okay i'm gonna hop into uh demo mode here let me get off of the slides and i'm going to just hit the url here and we got a pop-up that says welcome to virtual boston azure uh for any of you who know much about web development you may be concerned that that's not how um web applications are supposed to work because this pop-up actually was achieved through i'll do it again live here through uh the search actually let me do a search for apple first and this is a juice shop you can buy juice online i guess is the premise this is the oauth usop app it's an intentionally vulnerable app it's an application that somebody built that doesn't work very well from the security perspective but it was done on purpose so i think if i do iframe source sql javascript colon alert hey virtual boston azure ah we're gonna type um that enough not enough um all right i'm not sure what i did wrong there yeah well uh take my work for it if you type something in here um um iframe source equals let me try this one more time kevin if you're there and i'm doing something wrong let me know maybe i need quotes you wouldn't quote the round ball there we go okay so this is supposed to thank you whoever helped me out there uh so this is a search string through you know a search interface and this is a what's known as a cross-site scripting attack where the web application is not properly escaping the"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "helped me out there uh so this is a search string through you know a search interface and this is a what's known as a cross-site scripting attack where the web application is not properly escaping the data that it's uh that it's handling and that results in this um vulnerability okay so that that's kind of the problem and even though this is an intentionally vulnerable application um uh we haven't but our co-workers have all deployed uh code with uh with security bugs in it so it's something that we want to raise awareness of we want to do something about again which is why we have this talk so a quick a high level on laugh again we talked a little bit about it this picture we saw so a waff can be in detection mode or prevention mode and this is an interesting common security pattern with other security services like conditional access policy as and and content security policy as two others that where you can have a mode where you can learn how your system would behave if um if you're in detection mode without actually breaking your app it's actually not that hard to break your app if you put on a bunch of rules and you're not really aware of especially with older or more complex web apps that you you might actually be putting your the crack functionality of your web app in jeopardy not just protecting it so the the recommendation is to start out in prevention mode run it for a little while look at the logs and you'll know how to look at the logs shortly before flipping into detection mode and um i'm sorry i just goes backwards detection mode tells you you know keeps you aware then prevention mode actually blocks um actions okay so that's that's the at the level of the weft the waf is running in detection or prevention mode so you can have all the rules all set up and you can neuter them all at once individual rules however can can have different uh actions uh there's a rule for the most obvious rule is block and that's where a cross-site scripting attack or a sql injection or something or a rate limiting might be detected and just that particular request is swatted back uh it could be an allow you might wonder why there would be an allow action the allow action is because uh rules are evaluated in a certain order and suppose there was a wef a built-in rule that was useful and you didn't want to turn it off but there was a specific scenario a particular construct that you wanted to support because your application needed it the way to work that would be to create a custom rule that had an allow action that allowed that that made it so that that particular uh you know request could go through and reach the uh application because once it hits a rule and it's uh and it matches and it's allowed then it won't process any other rules so it won't be blocked that's why that's there then you can have an action that says just log it or you can redirect to a different url so even if you have a block action down here if the if the waf mode is detection it won't actually block but it'll tell you in the logs that it would have blocked okay uh there are different kinds of uh rules there's a there's a whole rule set that comes with the waff and we'll have a glance at that and i think the rule set is slightly different depending on which flavor of waff so the gateway rule set is i think a little bit different than the um web app within the azure front door waffle set but here are some things you can do in the azure front door variant ip allow list and block lists geographic base constraints so we can have it so that only for example us-based ip addresses allowed it are allowed in and all others are rejected you can do things based on parameters like there are string matches within the both the uri and in the body you can do a string match like substring and you can also use a regular expression a regex you can you can have rules that care about whether it's a get or put or whatnot post et cetera you can base on size so if uh if you're worried about if your application doesn't need any http requests larger than a certain size you can block based on that and rate limiting"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:30:21",
        "seconds": 1821,
        "text": "post et cetera you can base on size so if uh if you're worried about if your application doesn't need any http requests larger than a certain size you can block based on that and rate limiting so this is from a single client ip address if they're using too many of your resources this might this is unlikely to happen with a human on the other end a single human but is um you know more likely would happen with a bot or a scraper or something and for the i mentioned there were there was um uh different kinds of rule sets azure has some these are the ones you can customize these you can build your own rules but the azure ones uh come out of the box uh that they have certain rules that deal with cross-site scripting java you know some of these are language or platform you know toolkit specific interestingly and some are regular you know web uh oas top 10 sorts of uh protections there's a whole stack microsoft manages these you can turn some off but i don't believe there's any way to edit them and i also don't believe there's any way to see them to see what the rule is at least not through the portal ui they have coming on board some bot protections so if you want to defend against bots that's coming attraction too that's really all i wanted to mention there so let's go um and briefly mention what juice shop itself is i already talked about it a little bit and this is the the page you can you know deploy this in just a couple of minutes with um with azure azure container instance for example like i did okay we're almost there and i do want to mention one thing that when the when you've configured the web application firewall and it's either in prevention or detection mode it is um every time there's a there's and also you can configure azure front door to it also has its own logs that are not waft related because azure front door is bigger than waff waff is one feature so there are lugs available for afd that logs available for the waff but the thing is those logs are not stored anywhere unless you ask that they be stored and this diagnostic setting is pretty common in many areas of the azure portal so if you have a resource that has logs you have a decision to make about how to configure that so you go to the diagnostic settings and you would add a diagnostic setting and depending on the resource you would choose the logs that you are interested in and and you can see there are two flavors here front door access log so as those are the the generic front door ones did somebody approach azure front door was there a web request and uh front door web application firewall logs so i could click both of these you can also get metrics if you want and you have so this list on the left will vary on which azure resource you're talking about if you're talking about azure key vault the the options will be different and then you you can choose up to three destinations you if you want to use the cousteau query language you will want to select sending them to log analytics workspace this is also what would enable them to be available uh if you do a little more setup to import your workspace in sentinel and you choose your subscription and you choose the login analytics workspace i um there's probably one called choose shop yep uh so this is one set you could do this um for accessing crystal if i didn't mention it cousteau will keep the logo linux will keep your data around for 90 days and then it will fall off the end another option is to archive it to azure storage and azure storage um as you know when i popped it up here let's see um oh yeah it popped up for uh for retention retention days and this only applies to azure storage but if i want to keep it for 90 days that would be the same as log analytics but if i want to keep it forever i can just say zero and i'll have them forever so this might be more useful for auditing purposes somebody's going to come in at the end of the year and wants to see your waft logs you might want to uh do to do it that way so i've already configured a log analytics workspace and i've already"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:35:24",
        "seconds": 2124,
        "text": "come in at the end of the year and wants to see your waft logs you might want to uh do to do it that way so i've already configured a log analytics workspace and i've already specifically configured my settings so i'm not going to uh save this but that's how you would do it uh and um this this one at the bottom uh stream to an event hub if you wanted to have an end point or you know an event hub that was shooting out um uh events as things are happening uh you could you could also do that uh most of mine uh in my experience tend to be both of the first two are checked we can discard and um you give it a name and you're done and you can see we've already got one setting set up in advance so that's uh diagnostic settings it's useful to know generally and it's important to realize that log analytics is a log analytics workspace is the backbone to azure monitor that's that's where the goods are kept generally and again it also fuels sentinel which is the thread hunting sim uh feature that was added to azure maybe i think it went ga but a year ago okay so we're now in [Music] the juice shop waff here hey bill start interrupt is there anywhere you can make that a little bit bigger oh of course yeah thank you for telling me that you don't always think of that cool that looks better thanks okay yep getting old yep so um i'm in uh juice pop juice shop waff that's just the name i gave it this is a front duo waff policy notice it says a front door lap policy because the wav policy for a gateway for example would be would be slightly different and although i can take one frontal weft policy i can use it in multiple fronto-waf situations i just can't share it with the gateway so the interesting things to look at here are the policy settings and i've sent it that this waf is currently in prevention mode uh it's worth noting that um empirically it takes maybe five minutes to make changes to the weft so if i switch this from prevention to detection or i changed the you know any of these values and uh put them in there uh you know and saved up here it'd be about five minutes before it was realized in the in the live instance um it was interesting i i was um i was gonna put let's see i'll choose a these are the supported status codes i didn't actually know that 999 was a thing and i looked it up and uh apparently linkedin uses 9.99 to uh tell scrapers to buzz off they don't even pretending to you know sometimes when you want to reject a suspicious uh connection you would give it a a 500 or or 403 or something to you might obscure the real reason why you're rejecting them it's not for you know the endpoint they hit it's maybe the pattern of things that they did to hit it but 9.99 is uh yeah we're not even pretending to trick you we just we're telling you to buzz off so i i kept 9.99 because i thought it was useful because it made it easier to see in uh in the chrome tools when you're looking at the waterfall chart uh on the network tab it's the the 9.99 pops out because there's nobody else using 9.99 then in those connections and then you can put any message you want here okay so i guess it's actually virtuoso measure uh actually i don't want to save that it'll take it takes like a minute to save so i'm going to discard that let's go down to the manage rules these are all by microsoft i don't get to change these although i can enable or disable individual rules or i can change it to a from a block to like i could take this one i could change it to a redirect or it's a block now i can change it to allow and again i didn't mean to do that that probably take about a minute to uh to finish i'll scroll on this page while it's doing its work um uh again these are all these are all managed by microsoft so you can see that uh some of them are a little bit esoteric i don't know what they all are i"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:40:26",
        "seconds": 2426,
        "text": "uh again these are all these are all managed by microsoft so you can see that uh some of them are a little bit esoteric i don't know what they all are i know some of them are uh but just scrolling down here cross-site scripting php no script cross-site scripting injection some ie internet explorer specific things sql injection and so forth so it's a bunch of them here and it's pretty rich set suspicious java class detected i don't know is that java applets i'm not even sure so you can see that it just finished now updating the policy so it takes a little time to save but then it's going to be about another five minutes before whatever i changed from uh block to allow this first one is before it takes effect in the actual left you can hop over here to custom rules and these are a bunch of rules that are in this um in this tenant you can have up to i believe it's hundred custom rules so you can't have an infinite number uh one of the important things about custom rules is is this use case imagine a scenario where your red team and blue team are doing their thing and they actually discover a vulnerability but your application is out in the wild it's deployed how do you so one way to deal with it is to go fix the vulnerability and redeploy your application everywhere but that's not always possible and one common uh if i understand it correctly a use in the industry of a waff is to surgically block attacks on those vulnerabilities while your dev team is fixing the underlying code so you might you know maybe you're um you can't deploy till you know next week for good reasons you could create a waff custom rule to craft um maybe one or two or three custom rules to to craft a defense for the uh for whatever issue you know was at hand it was discovered and let's um tried lots of lots of stuff here so this is what uh i'll just create a new one here actually uh add a custom rule you give it a name uh virtual boston azure test the rule that the rule itself is enabled or disabled uh and there it's a a match rule is a rule that looks for something in the payload and a rate limit rule is a rule that is independent of this request but relates to the pattern of request so you may limit to a 100 requests per minute for example from one ip address again so this isn't the same as a ddos protection here this is a a focused rate limiting where you know ddos protection would um be more sophisticated to handle uh broader range of attack ip addresses uh and a priority so every one of these rules is evaluated in order the highest priority one is the lowest number so at the top so number 21 29 is evaluated and the last one would be block iframe so we have to give it a number and i think if we give it a number that's already in use it complains so we could call this one 99 put it in the middle and we'll go with a match rule here match type is can be geolocation and in that case we can choose for example type here united states we could ch say united states and mexico and canada so we could block all of them or block anything that isn't them so the way this is currently crafted it would say if it's um uh if it's any of these three countries then down here deny traffic so it's probably not what i want i probably want an is not or you could pick you know if it was um you know a particular country attacking you you could choose the countries that are attacking you or that you don't want to accept traffic from and do it the other way but oh you probably get the point there and"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:45:29",
        "seconds": 2729,
        "text": "countries that are attacking you or that you don't want to accept traffic from and do it the other way but oh you probably get the point there and you can add the rule um and um you can also have compound conditions here so if i want something else to also be true if they're coming from you know this country rule and um probably doesn't make sense to have two geolocation ones but i could have a string based rule where if the maybe the payload the request body contains something you know xyz whatever um you know that your red team blue team has come up with or um anyway so so you can have this multiple rules and you know you can go on it can be a little more complex and then you can add the rule and it becomes uh part of your um your defenses discard that and look at let's add another rule again just look at different options and we could do one that is based on a string and and that when you're doing a string you can again these can be compounded so you might want to do only http gets i believe that would do the get and so the request is a get and then you might want to add a new condition again we'll stick with the string here and the condition could be have to do with the um the uri maybe in i'm looking for a match of just uh maybe some sql commenting string uh we could you know this could be anything uh it could be contained so this is no matter how big the string is if this sql hyphen hyphen which isn't a real attack value but you get the point i think um uh anywhere in the anywhere in the uri which is the whole url uh up to the um fragments indicator then it matches you can also go with um you know other things like begins or ends with or you can do a regular expression a regex and i think this has the same effect as contains but you can also do something like more sophisticated with a regex like um like that so this would be an sql hyphen hyphen preceded maybe not immediately by an open angle bracket and then this dot asterisk is regex syntax for we don't know what the characters are between the left angle bracket and the sequel but whatever they are if you know any character will do so um so not to belabor the point but this would match but this um you know this wouldn't uh this wouldn't all right enough of that um i think we've got the point there let's go and um see we can do here so we have a block rule that says i don't think i mentioned you can transform too you can do lowercase trim url encode and decode might be handy so we have a block rule for uri contains word search actually i'm going to ignore that one um let's go to this uh tour blocker i wanted to talk about and let's let's show an example this is geo-based and it says you're if you're coming from not the united states then deny traffic so this is rule as a name the name is tour blocker so just so happens i have tour running here tour is a pretty handy tool for for anybody who wants to test an application that is that we want to test it from a variety of locations including other countries so tor is very nice that when you get a what's called the tour exit node that tour exit"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:50:32",
        "seconds": 3032,
        "text": "that we want to test it from a variety of locations including other countries so tor is very nice that when you get a what's called the tour exit node that tour exit node will likely be um in not in the u.s so this is tour itself it's helping me realize that there might be a problem there but i don't care i'm i'm attacking anyway or i'm trying to hit the site so welcome so you might recognize this string from um from the the waff properties so this was rejected by the waff and [Music] and i believe this is firefox this tour browser so we can look at the network traffic i guess we don't need any of this we can just go try and hit it again and we can see the 999 status here and um and the the the page never made it back there's no page and you can also see that the browser just because that's what browsers do it went looking for the favorite icon you know fave icon ico file and that was also rejected because it's not accepting traffic from outside the us and if we [Music] [Applause] yes google or whatever search engine is here maybe it's duckduckgo for my ip address we'll let that think uh and we'll hop back over here and we'll go into um we'll go into a query mode so now i i've moved um over to the log analytics workspace this is the log analytics workspace that's attached to that azure front door and i'm in um an editor here where sorry it's kind of messy i had some handy stuff going on there um but this is a what's known as a cousteau query k-u-s-t-o this is a sql-like query language you can see that many of these lines are commented out all the ones with double slash at the beginning of comments but all the other ones are uh are real so from azure diagnostics which remember we configured to go to a log analytics workspace that's why we're going to find them here i want categories where of uh front door web application firewall log and this is exactly the string that you saw when configuring diagnostic logs and this was the other string you saw then there's a metric string these are exactly the same ones these are the categories and i'm going to say actually i'm just going to delete that rule um order by time generated okay so we'll do it in the last hour actually last 30 minutes now i'm going to run this everybody hanging in there well cousteau gets our data okay so it is um i'm in local time and i probably did this three minutes ago and and we have a hit here so i did three so i guess two of these are actually let's see what they are um so let me make this bigger some more space here now that we know where we are so this let's go from the top down so the most recent record the one that we saw here showed two um two rejections and the very top one in the list that's returned is so this yeah this is azure um detail says this is in the azure resource group juice shop and some other information about that's specific to azure but here it gets into the deployed applications this was the url that we hit note that um just it's another part of its interestingness says the juice shop application is http based there's no ssl certificate because of course there isn't because it's insecure and the rule name is tour blocker rule name underscore s and if we go back here uh no actually here we'll see that that's the rule rule number 300 that uh that we put in place so this actually got triggered and this is how we know it got triggered it tells us the client ip this looks like a ipv6 client ip that came from tor and um and the action was blocked that was on the rule and then the policy for the"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "00:55:36",
        "seconds": 3336,
        "text": "this looks like a ipv6 client ip that came from tor and um and the action was blocked that was on the rule and then the policy for the whole waf is in prevention mode so as long as these both are true it's going to do whatever the policy says when you block in prevention mode and what did it say to do it said to send back status http status nine that's what we got oops what have i done oh sorry i actually clicked on let me uh hide my toolbar so i don't accidentally hit it again um so okay so it's still still there okay so let me just run this again so i lost my uh context so the first one was to a blocker and came from magic diagnostics good thing we set that up otherwise we'll be blind and is there anything else interesting here i want to see the url um there's no look at this one so yeah so this was the fave icon the other one was just the root so we we've identified the two uh hits um these two were they correlate and then um the third one was uh just plain i don't know why the third one didn't hit the um didn't go for the favicon that's i'm not sure why it did it the second time not the first time anyway there you have it that's what um uh taurus uh what that's what uh accessing from tor gets us so we can let's go explore here a little further so if anybody who was given access who signed up for the extra access i don't know if you if you've or anybody at all i also gave the link at the beginning if you access it from tor i should be able to see your requests pop up here as rejections as long as the tor exit node is outside the u.s which is most of them so not 100 though so um i can i can expressly look for rule name equals block.js so i can look for a particular rule this is cousteau again it allows me to filter based on any of the attributes in this record i can look for policy mode or i can look for uh azure diagnostics is actually the higher the bit up here very first thing in the kuso query but i but you all these things are fair game to include in your analysis including ip addresses so um so now i'm gonna do a couple things so i'm gonna switch to only look for the block.js rule and i'm going to go beyond last 30 minutes i'd go last week and i did something wrong [Music] there we go and there are 19 uh tour blocks you know for that rule uh recently and 844 i'll actually go to uh mn local time so oh i don't have a um i'm confused as to why i don't see the ones that i just had where'd they go oh i'm sorry i i uh uncommented the wrong one i meant to unblock uncommon uh tour blocker um so we only want to see tour blocker ones um here are just the tour block one so this has the couple from last um should have a couple from last few minutes again it doesn't 6 35 and it's 7 10. all right what have i done wrong oh and again i edited the wrong one so it's because not equal instead of equal all right this is what you got to deal with me being uh up for i usually stop my days pretty early uh tired so 701 we got"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:00:40",
        "seconds": 3640,
        "text": "because not equal instead of equal all right this is what you got to deal with me being uh up for i usually stop my days pretty early uh tired so 701 we got the three that looks like it ties down okay and then you know we go back and we can look at some from earlier and he has one from a different client ip address and so forth okay so let's um let's let's attack this application kevin if you're standing by could you unleash the um i unleash the um the fuzzer so what kevin's gonna do is i'm gonna take all the filters off here let me rerun this what kevin's gonna do is he's gonna run a commonly used web you know attack tool a white hat attack tool typically where you use it to attack your own site and the the there's one from the owasp community called the zap or the z attack process the zed attack proxy it works in conjunction with your on your desktop with your web browser it serves as a um [Music] it creates queries and it sends them off to attack a website and it's pretty cool because it it allows you the fuzzing aspect allows allows many different uh input formats that you don't have to hand craft so that if you have obvious sql injection or cross-site scripting or other similar vulnerabilities the fuzzing is um plausibly going to reveal them to you so he's presumably kicking that off let's we're going to see if we get any more traffic here so oh we got just got a a lot at 7 11 okay so it started to come in it usually takes like a minute maybe a little more than a minute sometimes two minutes for traffic to stop showing up from the um you know from activity five minutes to make a change to the profile in a minute maybe maybe two minutes sometimes for it to show up but it's pretty pretty quick let's see what this is here so default rule set it tells us what the rule name is and we can go back to the rules this is a microsoft rule and we can look up exactly what this is uh i think this is rce is remote code execution and it was blocked so a 999 was sent back and yeah here it is remote command execution uh direct unix command execution and some details matched exact xp found that's nasty okay so rejected this is the waff doing its thing and telling us that we're under siege this is blue team noticing that the red team is up to no good detects basic sql authentication bypass bypass attempts one of three rules i uh looks like and this is doing some fanciness to um with the the tautology in sql and you know again blocked nice try kevin let's try attacker and i could go through this and let's actually look at it in summary form and we'll see how many different rules are being um tripped up there so we'll look at the the request uri the rule name and the time generated so that'll take the subset so we have you know 50 uh fields here but i want to i want to do a projection which is kind of like a sql select for just these three let's run that again and see what the mix is actually let's um let me try i'm gonna i'm gonna add one more field i guess i think there's a um a verb that tells us whether to post or put or get um oh is there not anybody see it i know you could create a firewall rule that acts on the the verb okay i was going to put the po put the verb in the in the summary output here so you know over together a post that i was going to suggest that um me again yeah so i was going to suggest i think these are probably gets and these are these are probably posts sql injection and this is block java and payload this is a custom rule and this is an interesting one well we'll talk about this a"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:05:43",
        "seconds": 3943,
        "text": "these are probably posts sql injection and this is block java and payload this is a custom rule and this is an interesting one well we'll talk about this a little at the end so that's most of the talk um where i wanted to show you um i'm not going to show you how to set up a waff like the azure front door and stuff that's not the interesting part of this that the key i want to focus on is the the the the waff how to use it what you can do with it um how to exercise it and um this this is most of what i wanted to say about the uh the weft let me see so there's now there's um there's other functionality that you might want to weave in so i'm going to pivot over and talk about a couple other points there so one thing i shared was um oops let me get this off screen i gotta so imagine that your web application was attacked and maybe through a sql injection let's just make up a scenario that the the attacker was able to get a storage key and therefore was enable was able to attack another system so and i set up a fake simulation here this is an azure blob that is is public i don't really need a key but just to to have the scenario my ip address is 108 men's and 134 and if i also do something nasty with juice shop i can let me just go back here from the same ip address and one thing i'm going to do i know this will cause it to get upset so so i've just uh i've just accessed juice shop and the waff blocked me and of course i could look at chrome tools and i'd see the 999 http status and um and i've also accessed i wasn't blocked because there's no waff in front of it um the um the the blob you know website that that i mentioned um over here it's just a you know a simple one-page website that i put up just so we'd have something to to visit and again it's at 108 to 134 so again if i look at this we should see the 999 here um there it is and our friend fave icon so what i want to do is go see if i could actually do a correlation or if i can find this in um uh juice and um with cousteau so i'm gonna let's call it the um simple way which is i'm gonna search for the ip address that um actually what we could do we could do this let's see if it's showing up yet our snake that's uh i don't know dude with a hacker handle our snake um i'm going to go here and just so you know like cousteau isn't just for laugh logs couso is for all kinds of lots and i'm going to look at storage blob logs and let me go to local time 642. so my the the blob access i did over here hasn't shown up in cousteau yet so it needs you know it needs a minute or two like i mentioned earlier however this should be from the same ip address so this probably serves as a good um example um oh no that was not that is not a good example that particular one let's let's beat on this a little bit in order by okay that's better so 6 42 that was still too long ago oh that wasn't a good fit so i think that was probably from tor i was like authentication"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:10:58",
        "seconds": 4258,
        "text": "okay that's better so 6 42 that was still too long ago oh that wasn't a good fit so i think that was probably from tor i was like authentication type was anonymous this is the same thing the same website and here's the vip address that i mentioned earlier it started with 108 and ended 134. so if i know one side of this either the storage side or the left side you can correlate across them of course right because you have the ability to search by ip address in either one so i can say where caller ip address equal equal double quote paste it in i'm gonna dim it um so i have to remember how to use cousteau trimming i'm afraid because it attaches a port so bear with me for a second you see the caller ip address has a port number attached to it so i'm just gonna trust me that we could do this with cousteau if we wanted to um actually anybody know cousteau enough to what the sequence here to substring this [Music] okay so um and here's the one i actually just did live so it took a couple minutes and showed up so we'll go we'll pivot over to this one so there and we can take this over to this side and i'm just going to add this as a condition on here is it the same it isn't um client appearance i think it's called contains and we can run that and we should get the same thing so so we correlate it's not an elegant correlation but we can correlate that the information from one stream of logs storage and another stream of logs waff are coming from the same source and i'm not smart enough to know how to do this yet but i'm pretty confident there'd be a way to do this in a single custo query and i'll figure that out at some point and i believe you can all you you would also expect you do the same exact thing in sentinel and sentinel also allows you to bring in further security signals so a really interesting one might also be for example an address from which they authenticated to azure active directory so you know you're building a bigger uh picture here and while i'm in here i'm gonna hop over to okay so um let me go back to this mode here so i think we we've seen what happens with the um with the uh the fuzzing so this was a big blast of all kinds of stuff rejected all kinds of different um uh rules and and i do want to make the point that we can do the same thing [Music] over in um so let me grab this over in sentinel where a sentinel is as i mentioned this is the sim s iem which is a security and event incident manager or something but it doesn't really that seems like a poor name these days so let's go to the juice shop workspace in sentinel which i've added to sentinel previously and i can go look at the logs here and it is the same cousteau query environment and i can blast this in and hopefully get similar results same same data except in sentinel i also have the possibility of other data connectors for example let's see which ones do i have connected so azure security center and about it here that's what we're you know that's the one we're comparing but i can also add uh awkward um um any you can even add from outside there's azure arc which can bring signals from other places i don't know if that's the same thing as this you can bring in signals from"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:16:04",
        "seconds": 4564,
        "text": "uh awkward um um any you can even add from outside there's azure arc which can bring signals from other places i don't know if that's the same thing as this you can bring in signals from outside a lot of vendor stuff here azure active directory um you know you see them all i won't read them all to you azure activity is control plane logs that is somebody took a control plane action like created an azure front door or configured um you know a resource in some way that um uh that this control plan like maybe uh scale the website scale the vm and those will all show up as activity uh logs where whereas data plane logs are within the resources themselves so that so azure activity wouldn't show me that a a url came in through sent through um through the waff and was picked up as you know well it was a uh detected by a waft rule wouldn't tell me that but it could be used to correlate for example if the same ip address was used for both so you know this you can see how big this list is uh dns bunch of vendor stuff and so forth so so this so sentinel can serve as a um a unified place to to look at all the signals and another factor here another thing to know about sentinel that's very very interesting is um let me see um azure security center is good at certain things for example for what's sometimes called posture management which says that i have 100 virtual machines but 73 of them are no longer up to date they need a patch and i have a sql database that has a firewall that's wide open and i have another vm that doesn't have the hard disk encrypted so these are kind of static kind of snapshot things that tell you the the posture of your assets from a security perspective and azure security center will determine those things and will in what you get imported into sentinel isn't that you have a hundred virtual machines and the version of the operating system they're running what you get imported is the baked analysis done by security center which says hey it looks like these are vulnerable because they're out of patch or this you know this doesn't have the right firewall setting or this isn't configured isn't uh uh encrypted so you get you know security signals not raw data which is better i i would say and uh same thing with azure active directory for example imagine if you some of you may be familiar with the impossible travel or risky sign-in signals that azure active directory is able to you know determine those are the kinds of signals that would be brought into sentinel not somebody logged in here and there and there and there and then it's up to you to write a query to figure out that it's a suspicious sign in no aat is going to figure that out for you and send you that pre-baked signal so you have more powerful ability to combine you know true security signals within sentinel all right so i am going to look at one more thing here and you know one with an open we we do so i'm going to come back to that in a minute let me leave that open we hop back to slides and we're going to talk about some some lessons learned briefly so in my uh travel so far and this had a travel i've been uh kevin who's uh been helping with this we've been on this uh together so he deserves uh a lot of credit for stuff we figured out uh so um here's an interesting one so we we made this i made this mistake uh set up azure front door flipped on the waff put it in you know i put it in front of the azure container instance running the app the os view shop app and i thought i had this um let's say can i am i cool enough to do this let's say pen color azure so this is what i thought we had and but that's not really what you get by default what you get by default is is um if somebody enters the front door you know comes through the azure front door cool and then they um uh that'll pipe them through the waff and then they'll go to azure container instance um but also what they can do is they can basically go around that"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:21:06",
        "seconds": 4866,
        "text": "cool and then they um uh that'll pipe them through the waff and then they'll go to azure container instance um but also what they can do is they can basically go around that because um because of in part because of azure front door's flexibility it's happy to be a front end for workloads running pretty much anywhere it could be an aws virtual machine so what you need to do is you need to at the network layer in the aci in this case you need to configure it to only allow ip addresses that are coming from the azure front door otherwise if it's discovered and it's the public internet it will be discovered and attacked um uh people can go you know even though this is what you intended attackers can come directly in there they can just skip the weft because this has a public endpoint so be aware of that that was a oh that's what's going on kind of moment and content security policy so if you don't know much about cross-site scripting it's uh it's a pretty big topic and it's one of the oauth top ten has been for forever probably since there's been an os top 10 i would imagine and it's a encoding challenge a coding an encoding problem that could happen in the um you know various points in the browser or on the server side you know the number of errors that can lead to this and it can lead to some bad outcomes so um the industry has come up with this um content security policy thing that's now maturing i think it's in its second or third generation now and it's got very broad support across the relevant browsers and it's implemented as a a header an http header and an http header is something that you know is part of a lot of applications iis knows how to return it nginx knows how to return it uh your application code can typically return it like in something like asp.net or whatever your favorite web stack is they all can all do it http headers are just a standard thing one of the constraints that you might be under uh with um a deployed application is that maybe you don't have the controls in the places that you want to have it emit the http header that you want and kevin and i faced this with the juice shop situation where we were deploying a container from the public docker repo we didn't want to change it but we also wanted to be aware of http headers uh for a reason for this to to because we wanted to be able to have this content security policy header so um so what we did was we used the rules engine in azure front door to add this http header so let me hop over to here and change this to one that won't be blocked and i guess it can be um any of these so this is the header that was added to the azure front door rules engine and it's a report only uri it could also be an enforcement that's not we made the during this demo the waf was in enforce mode not report mode not detect mode and similarly i'm saying that content security content security policy also has the two modes but it is reporting to something so we've given a report uri here let me just briefly show that in um actually i don't think it's in here it's in the it's in the front door rules entry configuration one rule this is the rule the rule has a name the content security policy injector it's a response header as opposed to a request header it appends it as opposed to say replaces it or something else and this is the header name and the header value and you know they're the same as what we see here header name and header value and what this does is if a if the content security policy enforcer that's baked into the web browser chrome supports it firefox supports it all the all your phones support it everybody supports it these days uh if it detects a violation it will report it to this url cspcatcher.azurewebsites.net http"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:26:10",
        "seconds": 5170,
        "text": "supports it firefox supports it all the all your phones support it everybody supports it these days uh if it detects a violation it will report it to this url cspcatcher.azurewebsites.net http trigger to etc so if we go back here and actually we look at the network stream we see this http trigger 2. that's the same thing that's mentioned here so what's happening is the the browser detects cross-site scripting and then then it follows the directions and it reports it here to the um via this spike by invoking a http post out to this um this trigger endpoint and that one didn't work i don't know why some are failing um at any rate um so it might be something currently wrong with it uh but what it's been doing all the time and we bring up slack here is we've configured it to go to an azure function and then to an azure logic app and then the logic app integrates it with slack which is the thing that logic apps are pretty good at so if we look at this so these were from earlier today so you can see that these were reports you know the same the csp capture and all this and if you follow this if you understand what content security policy is like these are actual resources in the um in the page some of them are noisy like not interesting but some of them actually point you at a line of code that um that is that might be being exploited and your web developers can um like but it's column numbers almost 800 000 because the it's a it's probably a um uh an angular file that's been um uh you know compressed uh as uh to minimize it uh for you know jss content javascript content uh so um that's why it's this line number so it's really a line number i followed some of these i found actual code okay so so that's a that's um the interesting part there is that you can do this with azure you can use azure tools to do it and this is the code for the azure function somewhere here and you just create a default azure function and just replace the default and see sharp um and just replace the the the default one with this code and you should be in business it's not very sophisticated it parse is what's coming from the browser and it packages it up and basically it forwards it to logic app and the reason it forwards it to logic app is because logic apps have this nice integration with um slack you can also have the logic app forwarded to an email or i think a a cool one would be if it could um even forward it back to sentinel so that you would have browser only signals included in your attack profile and on that point let me jump back here so i showed those okay go to the next page so this this url actually this this url here so for the for the web developers out there how much of this url gets sent to the server the domain slash stops at the pound yeah so i maybe relearned this while setting up rules and banging my head against the wall on um on the weft because i was looking for things like well what if they're searching for something suspicious and that was the first example i gave if we hop back over here i should have consulted jason who's a very experienced web developer among other things was my so this one somebody else is somebody's hacking juice shop right now because it gives you these um this leaderboard stuff uh it's kind of cool so if we do this and in this cross-site scripting attack um it turns out that because this is all due to data to the right of the um fragment indicator which is the technical name"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:31:15",
        "seconds": 5475,
        "text": "and in this cross-site scripting attack um it turns out that because this is all due to data to the right of the um fragment indicator which is the technical name for the for the pound there is um it doesn't go to the server so you're not going to detect that with the waff so this application has vulnerabilities that are cross-site scripting result abilities that are not visible to the waft no matter how hard you try if waff is your only tool thus the content security policy is super valuable to supplement your visibility that you get from the wef to add this kind of visibility through that reporting endpoint as uh as we just showed it can show up in slack but would be nice if it showed up maybe in back in a log analytics location where it could be brought into sentinel and let's get back here and as it turns out this is a url that um uh this is a you may also recognize this is i don't know if this is uh because it's angular the the the juice shop app is um angular based uh i don't know if this is because of that but i know socket i o is a is you know separate from angular but might be used by but anyway it uses this to routinely send back signals to the server about the leaderboard i just showed you um which one was it one of them had um there was a blue indicator maybe i dismissed it had a blue indicator that said that the leaderboard uh you know a new um skill was unlocked or new level was reached by bayou it's constantly sending signals back so it actually turns out that not for reasons that you thought but you could actually look for this stuff as long as you looked for it in a url like this because it's in the payload here because it's it's sending this just as a coincidence for its leaderboard stuff it's um got those annotations oops um so it's sending them back uh made sure skin so over here that url um it is going back to the server and if you zoom in on it it sends this payload and it happens to have this um this stuff here the abc xyz is the payload and it could even be the java one so so it's blocking these requests even though it doesn't block the um the search thing so it blocks it because it's it's trying to send it to the leaderboard to say hey somebody has successfully uh done a cross-site scripting attack and and i want to track this on the server even though um you know that would be a feature that would never show up in a real application so so that was kind of interesting and we just got those and that reveals itself i hope that made sense it's kind of a a non-intuitive point but if i research for this now these are that rule that's blocking for javascript embedded javascript in the in the uh sort of here now in the url javascript but it's picking it up in the wrong place but it is picking it up and if we look at this um uh oops what's the wrong one if if we if we look at this um rule the rule name block javascript and go back here rules engine note to um so let me go back here and we'll go to left and custom rules and find this rule it's right here zoom in go in and have a look and it is looking for the word java um in the request body and it's finding it so that's why it's blocking those again that's a kind of a tricky case uh but i thought it was kind of cool uh worth pointing out so"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:36:19",
        "seconds": 5779,
        "text": "um in the request body and it's finding it so that's why it's blocking those again that's a kind of a tricky case uh but i thought it was kind of cool uh worth pointing out so getting getting blocks we're blocking the right things for the wrong reason and we're about to close down time here let me make a couple more points so this is what jason said if you're looking to trap things in the waff make sure that they're left of the fragment not right of the fragment because the fragment doesn't go to the server so this is this is not really much to say here other than that some of these signals can be a little tricky i don't know what sql hex encoding is but this is a waft rule so so if you're going to turn on the waff it's going to be up to you to kind of figure out what all this means and whether it's safe to leave on or dangerous to turn off and um and there's another one that came up as a as a hit uh anybody have any comment on this so this is a cookie that was blocked for having a sql comment sequence this this thing here so so the thing is it's it's noticing this uh but this came up sporadically and only um for a short amount of time because i think this was just random data this isn't an attack this is actually what this cookie value was generated to be so you know this this would be pretty hard to find in the real world and ultimately could cause a bug in your application right if if accesses happen to include this legitimately and very rarely because it's random you could you know that's one of the tricky things about a laugh your the people analyzing your waff signals would need to know this too like to know that it's a false positive so thanks again to kevin for all your help um uh let us know at virtualbostonazure on twitter or you know how to email us or um uh tweet at us or post in the meetup or you know anywhere there's a hundred ways to reach us these days it seems um if the talks or or whatnot if anybody has comments on this and what i tried to do which i don't think i was very um successful at but first try is to uh give some people you know additional access and so if they want to try some of the stuff at home and uh you know run some of the the crystal queries and see their own signals showing up there etc etc that they they have that as a little more of a you know deeper exploration so with that i'll stick these slides on um coding out loud blog the coding out loud and um i will take questions and um otherwise that's it so are there any questions i think we had a couple of questions from ajit so if he's still around and wants to ask them i just feel free to admit yourself hi sorry about stepped away for a while but it's perfectly fine if you're wrapping up um it was more a question of the the one of the slides you had defense in depth um you were showing you know the whole did um stack itself didn't notice any edr in there i was just curious is this is this a concept within azure where there is an understanding of azure native and point detection remediation response etc or um it's not considered a part of defense in depth within azure it's it's a non-code question i was just curious sure thing um let me let me give it a try and maybe others can can help answer so if i understand correctly the question incentives around does azure know what is part of azure like which endpoints no no no not not that when your your slide that you had for um depends on depth right i mean it showed uh kind of a a layered approach to security right so you have the firewall then you have the ssl offloads uh then you have laughs load balancers etc etc um but i i just didn't notice uh endpoint texting response itself uh so i was just wondering is this uh understood as a native tool within azure or i think that that was it again like i said you know it's a non-question but sure so uh so i think the so first of all that that diagram was not intended to be fully comprehensive"
    },
    {
        "speaker": "",
        "title": "Bill Wilder: Under Attack and Unaware Turning on Azure's Web Application Firewall",
        "videoId": "OWXTtCUNmes",
        "description": "This is a recording of the December 2, 2020 virtual meeting.Under Attack and Unaware: Turning on Azure's Web Application FirewallMicrosoft Azure offers enterprise grade security for the platform and great security tools for customers. In this demo-heavy talk, we will first use the OWASP application as a foil to illustrate basic web application vulnerabilities. Then we will show how a WAF can be inserted in front of the web application firewall and how that can help improve awareness. This is not a deep talk on WAF rules, but more focused on why you might want a WAF and some basics including triggering the WAF and looking at signals.Bill Wilder is CTO at Finomial which is a born-in-the-cloud SaaS company running on Azure, an Azure MVP, a book and course author, adjunct professor of cybersecurity (focused on Azure), and founder (11 years ago!) of Boston Azure. You can follow Bill on Twitter (@codingoutloud) or check out his blog (https://blog.codingoutloud.com).",
        "start": "01:41:21",
        "seconds": 6081,
        "text": "native tool within azure or i think that that was it again like i said you know it's a non-question but sure so uh so i think the so first of all that that diagram was not intended to be fully comprehensive just kind of like okay there's a lot of good tools you can bring but but for the um like would microsoft um or windows defender be the like i think that's microsoft's endpoint protection tool so if you're on a windows server or windows client for example windows desktop that you know i guess in azure would be windows server that windows defender would be the the endpoint like the agent would be running on that endpoint and then you would use um uh well i i it's not a tool i personally use somebody other people cover that my uh my shop but uh but i know there's a um there's another set of tools where you can you know aggregate the signals and they can pour into azure security center so so i think it would be that tiered thing where from an azure point of view the um uh your security center would be happy to receive the signals but it doesn't but uh it doesn't know about the endpoints in that same sense and if it's a you know a vm kind of a client you would install the other solution which is windows defender does that is that um remotely answering your question because i think no it does it does you know immediately when you clarified that it wasn't a comprehensive list it wasn't meant to be a comprehensive list of the i'm not an azure person i'm more on the aws side so i was just curious how that transitions i'm curious um if a if anybody has any anything to add that's um you know to to to the uh to the conversation here and uh you say um you're more of an aws person i'm curious if um if aws treats it differently then so on on aws well we use crowdstrike ourselves because well we're technology partner crowdstrike as well so we end up using that but but the point more relevant point is you have one comprehensive um log analytics source itself so the edr traps events logs etc can actually funnel in there as well right so if it's a pdr starts telling me that there was uh some kind of policy violation then i could perhaps add it a little bit further up in the chain itself on the left side generally i try to keep raf rule sets to the bare minimum because performance is of great importance right so that's that's the whole idea around tiered security model tiered approach um and with wafts in general i mean you know in the cloud it's a different matter but laughs in general um you know you you can't optimize in hardware like you know what you can with classic classic ip port protocol firewalls like you know you can embed them and tcam etc wafts will take up memory and cpu right so it depends how you're paying for it um as well so i try to keep raf as a bare bare minimum um still you need it but things that you know are okay not to do that deep a packet interaction i'll let that go because i know there is edr protection further down then i'll just let it pass and not take a performance hit on the raf itself okay okay um and i should say that um so that the the two concentrators for security signals in azure are our azure security center which is both posture management like my vm's out of patch or you know other configuration kind of things and uh active threats so if um my you know i'm just going uh or somebody's you know uh trying to brute brood a password for my rdp connection or there's a data exfiltration suspiciously you know looking uh activity with a sql database that looks like a data exfiltration that's not normal you know those kind of signals will pop and um so that's that's security center it says those kinds of things and in regulatory compliance like is it um you can set up policies or you can just use the existing policies that say is this compliant with you know choose your off-the-shelf compliance standard like uh sock 2 or iso 27001 etc and then there's sentinel which is a concentrator for um signals from security center and i guess you know signal signals might come directly from an edr solution and other places like the waf and that's where you would do the um the correlation across them cool no not not a area of great expertise for me at this point still in uh i'm doing a translation as well between aws and azure right now uh what i didn't notice was direction is there a concept in azure of direction inbound versus outbound in the west yep i don't think so um uh the azure front door uh knows about directions that's where the rules engine can come into play inbound outbound you can do port i'm sorry like you can do url rewrites and a bunch of that functionality but it's not part of the waff i don't think there's any outbound um functionality yeah i mean usually you try to keep it as minimal as possible again right unless you have some compliance reasons as in you know some data exploration or you have you know some pci compliance you know if you're not handling it on the server side not scrubbing on server side if you see like a match of a credit card number going out you block it right there but generally again right inbound where user input is coming in that's where you're really looking for deep packet inspection um is there a notion of is of outbound within the azure lab yeah not that i'm aware of it's a great question right if you had something that was shaped like a credit card on the way out and credit card number that's an interesting azure does have this aip azure information protection which is a um you know i guess it sort of plays in the dlp space where it would do rights management for access to uh you know data that's that would uh under the hood be encrypted until you authenticate yep cool thank you yeah thanks for the questions uh and uh yeah uh if you uh if you figure out the difference between azure and aws and you'll want to come share it with us uh glad to glad to be educated lovely thank you bill sure thing any uh further questions folks all right well uh thank you um do we uh to jason and veronica uh can you remind me do we have um i don't know what we have teed up but i do know that we are um we're talking to a number of people uh and some of whom may be on the call uh to set up a calendar for uh six talks in january february march and we we have a handful then we we haven't finalized a schedule yet we're gathering a few and we're going to herd the cats and line them up and publish but that's coming soon i don't know if we have another talk schedule before the end of the year however oh good jason sorry i i'm going to get the aks talk on the calendar probably the third week of this month i it's going to be a tuesday though i'll post it on the meetup site but it's going to be an extended version of what i gave at the new hampshire code cam fantastic so was that uh is that a rep books i guess that's a wrap so thanks everybody for joining our um our event uh feedback welcome and um uh stay safe out there and we'll uh talk to you uh see you in a couple weeks at the jason jks talk and have a nice holiday okay thanks bill thanks "
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:00:00",
        "seconds": 0,
        "text": "A look at the Azure Developer CLI. This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/. welcome everyone um there's i'm presenting to one guy here it's a very intimate session this evening here in burlington but tonight we're going to take a look at this new preview product called azure developer cli so the things to think about are as a developer when you need to do or learn something new how do you learn the new product or service um and of course as a developer you know how do you learn the pieces that you need to do it in the language that you choose to do it in and then of course you're playing around with the product or service in azure how to you deploy that configure it and then of course how to get your code out there because you need to get your app out running cloud and then of course after you've got that figured out you need the other aspects to it which is really not really day two because day two is um the whole stuff after it goes to production but the whole let's develop this thing for real so you need your infrastructure's code and you need your ci cd pipeline and then of course you need monitoring and observability how do you learn that stuff and often when a new product comes out you'll be evaluating it and you'll be doing one or two of these not necessarily all of them but every now and then you need to do all of them so that's what we want to kind of look at tonight so let's look at the landscape of learning stuff in azure these days there's quite a few um options there are quite a few places to find information that is relevant in some scenarios but not in all scenarios of what we just looked at so first thing everything everyone thinks of is your product documentation that's where you'll find your quick start your how-to guide your tutorials this sort of stuff that'll walk you step-by-step through hello world stuff i was asking a question as well as okay let me check the questions here as well as um oh check the questions here try to get the other all right cool that's better all right so james why don't you continue maybe he can ask it again hey folks john okay so john's here so john's actually here from the the cli team so we'll have an expert to actually answer some questions if anybody's got questions uh so quick starts that's where you often start off learning a product or technology a new one like takes take for instance um azure container apps it just came out just g8 anyways at um what was it microsoft build so if you want to get up and running on that you first thing you do is go to product documentation and then learn it step by step you start off with your hello world and then you go into the features that you think you are relevant to use that's where the how-to guides come in and the tutorials will also often come into scenario specific stuff so let's uh i guess move on here so microsoft learn is another place you would go to learn um maybe a new technology like for i don't even know if container apps is a good example yet i'm not sure if they've got the learning path there yet but if you're trying to learn a new technology and it gives you some context and a whole learning path to learn these technologies often some of them are developer related uh so that it'll be language specific you give you a lot of background on products and and the relevant stuff learning um a path not just a specific scenario a hello world then there's microsoft developer which is kind of a level abstraction of it gives you a kind of a landing page that organizes tools documentation samples um it kind of focus use focuses you as a developer and different gives you different ways to find things that be relevant to you as a developer so those are some of the things that you might go to to learn a new technology in azure but taking this a step further fighting with so um ways to learn about architecture and infrastructure because not only do you need to learn the product but you need to learn how to build the app and the architecture and design all that stuff starts recording but tonight oh no one man shows a little rusty here uh so um azure architecture center that's where you will go to find the patterns and practices the way that you should design your application when you really want to get something up and running"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:05:05",
        "seconds": 305,
        "text": "one man shows a little rusty here uh so um azure architecture center that's where you will go to find the patterns and practices the way that you should design your application when you really want to get something up and running in the cloud and you know the right way to do identity those sorts of things are going to be available in the azure architecture center and it goes into a lot more detail i mean even industry specific like if you're in the financial industry where does it go in the azure architecture yeah the azure architecture center is one location you can learn patterns and practices about azure so we haven't got to the the main show for this evening but these are ways that you would learn about different aspects of an application that you would want to get up and running in azure there's also the quick start templates that's where you would go if you want to find a specific way to do uh arm template so how would you configure a firewall settings and front door you'd be able to find an arm template to do that in azure quick starts and the key thing about azure quick starts why it's even on this list is oftentimes you'll you'll you'll learn the product you'll get it figured out through the azure portal but then you need to do the infrastructure's code so it's like how do you get to that step one way of course is to export it in the portal but another option when you need to find specific scenarios is quick start template location and then there's this lesser known product called azure devops starter which i've shown in my azure kubernetes talk because it it does a fantastic job about walking you through a sample app's code the infrastructure running in azure um the build pipeline that builds the code and the release pipeline that sticks it into the infrastructure in azure and it gives us a monitoring dashboard as well i think it's a fantastic tool i wish they would have made it pluggable allegedly they've made it so that you can bring your own code i've not actually done that demo to get it in to get my own code up and running but to the best of my knowledge they don't give you the ability to provide your own bicep files to to customize the resources in azure that you want so that's where i think um the azure developer cli really fills a need for me is it gives me what the azure devops starter did not give me it gives me the ability to plug my own code in really easy and it gives me the ability to put whatever bicep files in there to create the resources in the configuration that i need in azure the great thing is is they've given you some sample apps that allow you to get something up and running relatively quickly much like the devops starter did but the drawback to the devops starter was it was a pretty simple um hello world app that it deployed and there wasn't any best practices involved in that but with the develop with azure developers cli they've gone the other route they've they've put in a lot of the best practices and they've given you that level of sample app that's a real app it's it's a web app ui it's well most of them the to do app that we'll look at is a react front end and it calls an api that runs in the back end which uses the cosmos database on for storage persistence which is a real application it's not just this web html page that's it's really easy to deploy so it gives you more of that closer to production sample that you can you can get to a poc that you can modify your own production scenario pretty quick so that's what we're going to be looking at to see this evening is this ability to help you get an app out and running in azure a lot faster than those other resources that we showed on the previous two pages so before i before i get started are there any questions so um azure developer cli and tools uh there is the azd which is the command line utility tool and then there is the visual studio extension which provides all of the functionality that the azd command line tool does and they're starting to integrate the functionality into visual studio 2022 it's you can currently turn it on in the preview edition of that but i won't be showing the visual studio this evening but i will be showing the visual studio code so once you download and install the azd command line tool you'll get you type it out you'll get this this screen that shows you the main commands that you'll be using so deploy is going to be the way that you would deploy this template that you've got on your machine uh i guess it's really difficult to go in the order that the alphabetic or they have it because it's not really the mindset that i have whenever"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:10:10",
        "seconds": 610,
        "text": "template that you've got on your machine uh i guess it's really difficult to go in the order that the alphabetic or they have it because it's not really the mindset that i have whenever i'm utilizing this tool so but i guess since it's in this order let's go in this order so the deploy would be what you would use to deploy the template out into azure so it's going to do the build if it's going to container apps it's going to do the docker build so that it can then push that up to azure down so azd down is going to pull down the application it is the reverse of up up is the single command that you can get your template up and running in azure it will initialize the template it actually does multiple commands so it will do the initialize which pulls the template down gets it ready on your machine ask you a few things necessary to deploy it in azure like what do you want to call this environment what do you what location do you want to go to and then what subscription do you um wanted to go to in azure so that would be the net so the up runs three commands together it goes inits gets everything ready on the machine and then the the provision which will deploy the azure resources and get those running and um materialized in azure and then it will do the deploy so then able to push the code up or build the code and push the code up into azure so that up command has the reverse down so that's where we were the env will show you the um environment variables that are being used for the build um actually before interacting with the command line tool so i can show you that a little later help will display this screen or if you say azd one of the commands and then help it will give you additional information about the commands infrastructure will are infra i should say will help you either create or delete the infrastructure that you have out in azure i mentioned init it will set up the template login allows you to log into azure so you wouldn't have to actually go through az to log in monitor is a part that will allow you to see like log analytics uh app insights dashboards those sorts of things pipeline which i'll get to in my last demo will show you how to get the ci cd wired up in github for template provision that's an alias for the infra so that's what that will actually nail is for the in for create it will provision your resources out in azure so materialize those restore is just to restore the dependencies for your template a template you can list out your templates with that keyword and then of course open version so that's the quick overview of what we're going to be looking at so now let's see if i can get out of powerpoint and show you what we've got here let's do a demo first we'll say okay i hope i haven't used this before all right so we'll say azd like i showed that the outputs the um options that you have with the command excuse me the commands you have so let's see what we have for templates so we say azd template list so there's uh an existing list of templates um you can create your own you can put them in github you can utilize other people's but these are the ones that are tied into the command line at the moment i'm going to do the c-sharp one if if you're utilizing the templates from azure samples you don't have to type in azure samples a slash so i can say azd go straight up and do because actually you know what i'm gonna do in it so we can talk about it when it's gone you have to log in first right ready to how do you do the login i'm most likely already logged in but we can try that so acd login so you can see it's integra it's integrated i didn't have to go uh so if it was like something like that right it gives you the code right so how"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:15:19",
        "seconds": 919,
        "text": "login so you can see it's integra it's integrated i didn't have to go uh so if it was like something like that right it gives you the code right so how do you do that just start spying because you're on windows right correct and what i'm showing tonight is only on powershell okay i don't have it running on the linux right now uh i would have to test that one so it um it's coming back it takes a few seconds so you see i didn't have to go to a z to log in so i didn't have to go to the azure command line to log in myself so we'll go so azd annette template and the name i want is to do b sharp because i'm a c sharp guy for the node so what that is doing is because i only did a is it's going out to or it has already gone out to github pulled the template down and it's asking me okay what do you want to call this play mba you'll see that soon so i've gone with east to uh us and then i'll go with that subscription so what it does is it creates a file so let's look at it and see what it actually let's kick this off first let's do it step by step so azd um provision so what i'm going to do i pull the template down and we'll look at the template while it's provisioning because it'll take a few minutes for the provision so there's our provision so let me open the demo daily demo one so this is okay so this is the template this is what a template looks like so interesting things about the template looks like i need to uh so let's look at the azure this is pretty interesting so i called it so it asked me what environment name i wanted to give it if you look at this config.js you'll see this is where the default environment name is the first location then you'll notice that there's this directory with that same name and then there is a env file which holds the stuff relevant for deploying the resources like it's currently doing in my cli at the moment so it has the name of the environment has a location the principle that it's using to do the deploy and then the subscription id to put the resources in then here are the parameters that are going to be passed that's the azure folder i'm not going to get into the dev container because i don't know anything about it uh github i'll get to that later in a later demo vs code doesn't really show us much relevant it's just some config files assets is so the assets are what is used for this markdown file so let me show you a markdown file because i didn't show you this on github so so this is um a description of what this template does what it should look like whenever it's working uh what any prerequisites are how to you know links to install those prerequisites and then it pretty much walks you through so the azd up is the fast way just to get it going it'll deploy the resources out in azure and deploy the code with just that one command it gives you a little more information about what the environment name means the location the subscription that sort of thing and then the results of the azd up will be of the urls coming back uh let me show you so this is this is the more relevant stuff because i'm looking at this as a learning tool but also a utility i can use to deploy code this is the application architecture so for the sample what it's doing is it has a node ui that's going to be deployed in one azure app service um one azure app service web app sorry there's additional part to that"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:20:21",
        "seconds": 1221,
        "text": "for the sample what it's doing is it has a node ui that's going to be deployed in one azure app service um one azure app service web app sorry there's additional part to that sentence and then a c-sharp azure web app both of those are going to be deployed in the same app service there's going to be a key vault that's used to to handle the key secret to log into the storage which is going to be a cosmos database and then there's also some app insights dashboard as well as blog analytics and the the api is the one that utilizes the secrets um from key vault to access the storage so it's got really quite a few pieces to this simple web app that you can get up in a simple web app a simple sample up and running in a matter of minutes by typing one command so there's there's quite a bit here um and there's there's more in this this markdown here but that's what that is what is in the assets folder here as we're looking through what we have so the infra is going to be the bicep files the main bicep files the typically the ones going to be started to kick off the uh deployment or not deployment the provisioning or the infrastructure create the main and this one calls the resources and that's where the majority of the resources are not all of them which i'll show you so this has as you can see the web is the uh node.js front end for this sample the api is the c-sharp back-end for the sample those are going to be two different web apps and then one single app service for those to run in and then there's a log analytics workspace and app insights but the app insights is in this bicep and it's quite long for the dashboard more or less so see the dashboard goes from 18 to 1200 so that's all stuck in this one yeah it's a lot but it does that dashboard does quite a bit so we'll have to open it up and take a look at it but that's that's it i mean this is the one thing that the azure devops starter app wouldn't do i couldn't plug in my own biceps so if i wanted to wrap anything in a v-net i couldn't wrap it in v-net if the sample didn't let me do so so this this capability to plug in your own infrastructure is really really cool and then the under the src folder and the source folder is the source code so you have the c-sharp web app under the api and then the node web app under the web and everything that's needed to build that i'll get more to the other files let's check and see how our deployment is going okay so it's not deployment yet sorry it is a provisioning so now let's look at azure and see what was created we'll open the portal and see what resources were created for i call it jay haley or nba actually so let's look for a resource group named nbas so nba demo one right here so you can see you use the res the environment name for the resource group and you can see it adds a token on the end of the resources so that it has a unique name so this is what was created by just that one command azd provision so it created the two web apps it created app insights that dashboard cosmos db the log analytics and the service plan which is you know quite a number of resources so now let's do a deploy so azd since i'm like the context of where it's at is inside of the template is going to build the source directory and deploy that build it package it with and since i'm doing a web app it doesn't need to use docker on this one but if i'm using container apps it would need docker installed on my machine so this will take a little while a little move on to the next actually let me show you the azure yaml file that's the one thing we didn't really look at kind of important here so this is what the the dev cli uses to determine what it's going to"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:25:24",
        "seconds": 1524,
        "text": "yaml file that's the one thing we didn't really look at kind of important here so this is what the the dev cli uses to determine what it's going to be building and packaging and deploying um it's this the services more or less so we have the web is a project and it's going to use the dist build uh it's javascript or typescript if you look at it and it's going to be hosted in app service the api uh at this location is a sharp language and we didn't tell anything about the the dis g so if i yeah question mark is going to be my question is what's the what's the disc for the second means a copy of the files my understanding versus this one i'm going to do a build and publish so because this is this is this is a nodejs application okay are you familiar with like node.js and react and uh only basically so typically um they'll go through a build process the typescript application will go through a build process create a dist folder that's the distributable files more or less and then that's what that's what gets copied over okay that's my understanding i could be wrong on that am i right okay cool thanks so you're so saying for the node.js app um put put your um where the uh yeah the the assets of what we want to deploy you're gonna end up in this this build folder okay and then uh with the c sharp it knows how to build it and it will publish those but with with the typescript javascript stuff it could be about anywhere you could you could have you could it may not be the same as a c-sharp standard but um typescript it could be angular it could be react could be view so they're all slightly different that's that's the way that i've uh understood it to work let's see it's this is the name of the folder where acd needs to look to find the packaged app to deploy okay so that's that's what you want to shove out to the production servers what's in that dist um okay yeah yeah i was going to show the schema i've got the link here so i showed you the the azure yaml file but what are the possible values in that ammo font so that's what the schema is okay so uh the important stuff is this so what are your options where you can deploy this the example we're looking at right now is the app service but you can go to container app you can go to function and you can go to a static web app so that's the target resources that you can send it to for their current setup and then the languages net c sharp f sharp python js and ts so it and if it's container app then you can have some additional stuff about the docker it's pretty much the the piece of not not not a lot there yeah so that's the that's that yaml file and what could be in it more or less so let's see if it's deployed fetching endpoints for that so it's out there let's go take a look at it so now let's go to the web app and go to the url so things to look at here so this is the to do app it's loading which is cool so let's uh let's look at the list here we'll say demos i want to do an a the cd onto the other machine because my typing speeds off okay so we've got three items in our to-do list and sorry we can't read that let me pump that up so we've got three items in the to-do list this"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:30:28",
        "seconds": 1828,
        "text": "my typing speeds off okay so we've got three items in our to-do list and sorry we can't read that let me pump that up so we've got three items in the to-do list this is a react application it's calling another api if i look at the network you'd be able to see that it calling the api it's on a public employee but then going to the cosmos database so let's look at that cosmos database to prove that everything's making it to the far end of the app just because i like to do that so let's go to resource group jump to the cosmos app here so is it like 20 bucks for each cosmos tv is like 20 or something like the minimum right i don't know i know you're an mvp so bill does not matter information in it i'll have to look i'm not sure if it's still there okay so this is what's stored in the cosmos database right now so this is uh azdmi1 azdemo2 and then the custom template so the stuff that i typed in on the react ui made it to the api and then on to the cosmos database so the template works i mean all of those azure resources were you know like magically deployed out there well that's uh let's let's look at the let's try this to a z d i didn't do an overview i'm not sure so the dashboard i've had some luck with smoking opening up and actually having something all depends all right cool so we here's our dashboard well it's not really our dashboard this is just our um app insights oh let me go to the dashboard that's really kind of but i want to show you the dashboard oh great so i i found that you really do want to more or less navigate my resource group we have too many demos up so let's go to the dashboard so this is the dashboard this is why it was like 1200 lines of configuration and i know i just added three items so there's really not a lot for it to go off of and it may not be anyways but we'll come back and check on this but you can see there's a lot of tiles and a lot of stuff configured in that one little visa file all right so back to the presentation here so we were at the first demo um so we went through we manually went through the net provision and deploy we didn't do the azd up we'll do that a little later so this is the current list of application templates if you go to github and look at them you'll see actually let me show you the first view of it actually i've got the link this very first link will take you to the developer hub this is where you'll find uh actually a lot of the links i have on that page go to so this is where you can find out how to use it um how to get the requirements installed for the prereqs um but here's the templates that i want to show you so it's a lot like the azure devops and the way the azure devops starter was you choose say um asp.net or net framework and then you choose asp.net core or asp and then you choose where you want to target do you want to go to a vm do you want to go to aks those sorts of things so with their applications they've got it broken down by the languages right now so the to do app you can do it for a well they're all for for node.js and python uh c-sharp is the sql so they all use cosmos database on the back end i guess that's an important thing so the node.js you can send it to or have the target resource be an app service which is what we just did or you could do a containers app or container app or you can do a static web app with azure functions backing which is a configuration i've not explored myself um python you have the same choices with c sharp right now they only have the the app service um deployment with the cosmos dpd can you"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:35:32",
        "seconds": 2132,
        "text": "which is a configuration i've not explored myself um python you have the same choices with c sharp right now they only have the the app service um deployment with the cosmos dpd can you click on the python one okay which one okay okay all right okay yeah so you you get three options on this one uh i will show you my template where i've got it going to an app service and a container app for the api so i'll show you that once um kind of back to this okay so this is the the site where you'll want to go to get started with everything so the getting started will show you give you all the links that you want or need to to develop it i've done the bare metal one i have not tried the dev container dev container options are there too that was again that's that's the templates so we saw this first one the cosmos sequel um but let's go do a different one yes code and all right so let's let's look at we've already kind of looked at vs code too so my demo orders off a little bit but let's let's do something else so let's get out of here let's go to let's go to mine it is seven o'clock so we're doing perfectly fine on time so let you let me show you mine and then we'll get into how you can create your own and mine's a little old so i need to go back through it and make sure it's all up to date with the public preview so this one right here so the readme is only accurate down to say the diagram the rest of it could not may or may not be accurate so let me see if i can open this here because this is pretty much all we need so this is the idea of this template um and demo that i want to get into is to show you that you can create your own and um completely change the way that the components that they've given you to utilize can be rearranged the way that you want to so i did utilize pretty much their same code i took the node js react application and pretty much created the react application template that visual studio gives you um copied over the react files and then that worked i needed to change the api so that it would call controller on that asp.net application not the api directly like their template does or like their sample does because i wanted i wanted to do this i wanted to wrap the api inside of the v-net so that it's not accessible outside to the outside internet so that's what this diagram shows so you've got the web app which pretty much their web app the api is almost pretty much their code i just wrote a bunch of different biceps so that you have the container app inside of a network um it uses a private dns so that it can access it via the web app uses v-net integration to get to the container now the container registry just shows you that it's container it needs to the container app needs to grab a container and then cosmos um so some of the things that could be improved here is um a private link of private endpoint endpoint for the container registry and uh same thing for cosmos and then it's pretty it'd be pretty secure at them i just haven't gotten time i just haven't had the time to get to that so this is a public repo um and let me copy this and you can utilize it from your own environment because it's a public repo i show you copy this go to here azd [Music] up dash dash uh oh i do template sorry template okay so what that's going to do is it's going to come back and say hey what do you want to call this environment and ask me where do you want to put it and then it's gonna ask me what subscription well it knows what i'm gonna ask answer and then it's gonna pull my template down from github because i gave it the url that it basically needed and then it's going to initialize it create those resources run those bicep files up in azure and then"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:40:35",
        "seconds": 2435,
        "text": "and then it's gonna pull my template down from github because i gave it the url that it basically needed and then it's going to initialize it create those resources run those bicep files up in azure and then build the docker container on my machine for the container app package the web app and then deploy that up into azure after the resources are done it's going to take a little while i won't make you wait i can show you what it looks like you know azure seems to be really slow compared to eight of those at least when it comes to the container i i don't know i haven't uh i have nothing to compare it to so this is the application that i deployed yesterday i do need to i'll show you the code but um as you can see this the private dns zone i've not fixed the i've not fixed the bicep file to actually use the naming standard so i've i need to modify my bicep so there's still some stuff i need to do with this template but it proves the point that you know this this wasn't the the private dns isn't in any of their canned um samples the dashboard is directly there's um app insights i think everything else pretty much directly there except for the v-net stuff so there's a v-net at the bottom um the app the web app settings are different because it has to do the integration with the the v-net so if i go to the web app and i go to can you go to the web app and see what you have configured as just yeah yes what would you like to see the networking i want to see like what plan have you chosen for that to get an idea of how expensive it is that's a b1 so it's a basic it's it's not a very expensive one okay the cosmos i don't know cosmos is probably a cheaper one too but if you go to the networking it totally won't be much because it's hardly you know any traffic coming in and out cost-wise yeah but but the integration or the configuration is different so it's it's set up to do v-net integration where that demo that i showed you with the the node.js was it was just public so i mean does that mean that your web app is not available to the internet or that your web app can access resources in that bin app it's it's basically setting up a vpn to my v-net from my web app yeah so so my web app can call into a v-neck yeah so then if you look at the integration if i go to the the container apps internet environment because i think that's where the networking stuff is so why just out of curiosity why didn't you consider using aci as your container or whatever instances yeah for the proof of concept i'm working on is a client wants to start breaking their monolith into microservices and they want those microservices to be wrapped into v-net they don't want them publicly available so in order to have multiple microservices the container apps the perfect service for that versus aci um you have to you have to do a lot more parent feeding it's not really designed for that so let's see if i can find thursday the app store to be publicly accessible but that the front end of the app is still publicly accessible just yes traffic is not yeah because right now what they have is they have this it's a layered application but it's a big web app we changed one little thing we had to push the whole web app out yeah versus you know instead of saying order service and you add um address to line you know where you can just update that service versus push the whole app out so that's that's the idea that's that's the proof of concept i was working with uh so if i go to forgive me i forget where go to the resource groups on the top and then it will show cost posts right cosmos is the exact same template that they use in their sample i don't i don't i know you're asking about the uh the cost i don't know what this is costing it's not doing much of anything wow 800 are using it is going to cost you something it's like what if you keep it on more like 100 bucks a month yeah i'll tear it down after this actually i can show you how we're gonna air down pretty easy that's that's another thing so see it's still cranking on the resources once this comes up i can show you how to tear that down because that's that's the other flip side to get into new technologies like great you get this"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:45:38",
        "seconds": 2738,
        "text": "that's that's another thing so see it's still cranking on the resources once this comes up i can show you how to tear that down because that's that's the other flip side to get into new technologies like great you get this up and running if it's costing you 100 bucks a month well you know that's not something you want to find out at the end of the month and i totally agree for any sort of testing and dev the ability to carry out is almost better than the ability to stand up because you can tear it down and then you can work out how to do it again tear it down quickly so that's i think tear downs super valuable part of tools like ac acd yeah once this comes up i'll show you the down just sort of curiosity right uh jason i know you are a big azure person and all that yeah but did you like when you're working with your clients too some of them ask you to use terraform instead so that i haven't used terraform okay the majority of my actually all of my clients right now are pretty small so i'm it's basically up to me and what i want to use i terraform is very popular and they do want to extend this to use terraform so that is the what i like about terraform is right you can have they have even things for azure and of course aws is there right but it gives you the end state right that's it yeah so what i mean suppose you're doing like a you know like just now this is fine for hobby right in which you can tear up the whole thing bring it up and tear it down but in production that's not the case right you need to write a script that you know if this is existing to get to the end state what do i need to do right you can't just take go and take a storage uh you know container like atls gen 2 and just knock it off yeah every everything's situational yeah that's exactly true i worked in two companies which use terraform one bigger one smaller and for the small company sometimes terraform is a disaster you have a dedicated you have to have a dedicated resource which is sitting on supporting the stair form as your environment evolves and it gives you more trouble than it's worth so jason is right everything is situational yeah i kind of agree i'm a i'm a terraform user also but i use it more for standing up infrastructure like you said defining the end state but then pulling it down because in fact if i leave something running for a couple of days it will change outside like outside of the source and then my terraform is kind of useless because um i can try and delete it but it might error out because something has changed outside it's very difficult to keep even if we're 100 strict on rules about not making changes outside of terraform as you know uh it's great for application today but not so much for like infrastructure yeah because his bicep file will be out of sync and this starts with so yeah i mean how does it keep the concept of the stack in the you know like you have these various components is it persisted anywhere or it's just well with with the resources that the acd deploys they're all in one resource group but that's how it does if you tear it down and then what would happen if you were to and this happens with terraform all the time so you create your templates you run acd and deploy and then you edit your templates and then you run acd delete but acd doesn't have state held locally or maybe it does it doesn't sound like a sensor which means that it has to delete based on a template but the template that it's deleting based on is is different from what was deployed so if you've changed the name of a resource it's not going to be able to delete that resource that's one of the things i think you have to live with like i don't know that this tool is aimed for production i guess i'm not understanding the scenario um so run that by me again so you you deploy something and then you modify the bicep let's give you a real example right suppose i have an application which has one storage container one uh cosmos db a docker you know docker app in a node and uh node and react front end okay just don't take it literally just for example now what happens is i'm i'm having like in the storage container i have certain parts which i'm persisting some assets okay in cosmos db i have some i'm using the  you know collections basically and uh you know like you're similar to your to-do so you've got data persistent in cosmos db and the heavy stuff like the pictures etc are stored in the gen 2 okay so that's fine so we go through the arm acd and you deployed okay using your bicep file"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:50:41",
        "seconds": 3041,
        "text": "so you've got data persistent in cosmos db and the heavy stuff like the pictures etc are stored in the gen 2 okay so that's fine so we go through the arm acd and you deployed okay using your bicep file which are two different things because the the bicep files will create the infrastructure but i won't put the assets or the data and no no so the first time you will just take your bicep file and use acd and deploy yep okay all right now what happens is some business changes or requirements come in in which i need to make some addition some additions like more collections or add some more properties within a collection and i need to add some more parts on the store in gen 2 okay and i have to do something on the node and the container application for the node in the container application i need to tear it down and bring it up okay for the cosmos db i have to do some um you know i like uh like what you call uh alters on the collection okay and a storage container i can't delete it right it's got too much data so i need to add a path so now what will happen is you have your bicep container it got the high level top top level items correctly got it but your node application you do not know what it is i mean you do know what you deployed but now you made the changes but the surgical you need like an upsell it jason can i help go for it all right so the scenario that was just described is a is a very valid normal devops infrastructures code scenario this is that's not what this tool is for and my product group count colleagues here can can correct me if i'm wrong think of this more like as a developer whiteboard but you sketch out what you're doing you put it out there you see if it works and the the idea here with this whatever the down was is to just basically delete the entire resource group delete everything and start and redeploy it with your next iteration now of course in a production environment that's not useful but that's not the the use case that this tool was built for does that make sense yes thank you that makes a lot of sense yeah but it's interesting because in the dev world we get into a lot of um people will build for instance a devops azure devops pipeline that deploys the infrastructure and then pushes the code and then that doesn't make a lot of sense in the production world because you only want to push the code you don't want to keep pushing and the reality is you wind up breaking up your data tier winds up being more or less in one deployment your infrastructure is in another one and the code comes down a different path because you really do for exactly that reason you can't blow things you can't blow a database away you can't blow a whole storage account away you only need to modify them so and that but that is absolutely not what this tool is built to do this is for developers to experiment and learn how to do things with azure they're ready to start using production already who is these guys they're they're poking holes in them why can't you use in production right because it's not a production tool that that's what you know azure cli is for and other tools and like i've got people here from the product group if they want to speak up and correct uh anything if i i've created a misconception i'm gonna assume if they're quiet that i've probably hit the target so so it should be deployed at this point so is there any chance of you you you have the visual studio copilot like i can just put in like you know like for c-sharp just put the comment give me a function which does this so can it like simulate like that if i just say hey give me a thing with this this this and it just writes the bicep code which i can use in azure this will run the bicep code for you it won't they won't do what you're asking for it's not a bicep code writer yeah but i'm just saying it's not yeah copilot doesn't have enough input data to actually even attempt to do that okay i have issues with deploying cosmos at the moment in my subscription so nonetheless that's the way i have the canned one that i have the demo gods gotcha yeah but this this is the exact same um code that i deployed yesterday uh and you can see all the resources are there you can just kill the whole resource and start again let's uh let's just kill it let's see let's go do a z down so you can see resources were created"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:55:43",
        "seconds": 3343,
        "text": "you can just kill the whole resource and start again let's uh let's just kill it let's see let's go do a z down so you can see resources were created so that was this one and there is a bug in my template because i didn't do the dash rg but these are the resources that were created tonight the nba demo 2 the one i created yesterday was this j haley p demo rg this is this is what we're looking at a little earlier with the the settings on the web app and all that i have had problems with the templates whenever cosmos for some reason isn't spinning up in east to often if i skip change it to just east yeah i was going to say we may be resource constrained in east too so let's just tear this down so i'm i'm telling to do easy down so it should remove and this this this the resource group we'll go with so we'll come back to that so that was my custom template that you you can actually create i need to fix some things in it um and add some stuff to it to make it more complete but it's it's available if you guys want to play with it so now let's look and see what it would take to do your own um i've got the i've kind of got some points here it's it's easy it's easiest if you already have your bicep files um so what we'll do is we'll do a quick demo so the demo here is to show you how to do your own web um i want to do a web application i'm just going to open up visual studio select the default web application make sure it works locally and then we'll put it into a template and show you that i can easy up and have it deployed to a web app but since i'm not going to go through creating the bicep files we'll take what that first demo was and then we'll just trim stuff out that we don't need all right so let's go to the visual studio first can you zoom it out and is it possible to close this slide uh this top light here the lighting the lighting controls are in the back they're not up here these are just okay i don't want to if you can just zoom out a little bit your screen yeah jason how many people do you have in the room now we have two people okay twice as many as at the beginning you got two rooms joined here fifty percent growth there you go no that's a hundred percent growth isn't it so where are you from mark in uh in cambridge or in seattle i'm in boston okay where do you work i work from home okay all right so you're an independent uh no i work for a small company okay and you're doing devops now yeah we are using azure devops yes okay i work for a um i work for f5 know them f5 okay yeah and ngnx get five and engine x and um yeah i would say probably maybe more than two percent of my customers are azure users so um i'm probably in azure you know every single day but it's always nice to stay into these these things let me go back to visual studio and create just a asp.net core app next okay demo three and i only created directory at the moment is the cloud really killing you guys no next i'm killing this it's just the demo we don't really care you're not doing a container deployment here right we're not no that's one thing i didn't show so docker could add nginx right there yeah so this was the the demo that i was trying to"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:00:53",
        "seconds": 3653,
        "text": "that's one thing i didn't show so docker could add nginx right there yeah so this was the the demo that i was trying to deploy i created it yesterday so the image was already created i guess it doesn't do a build if the image is already there not supposed to now visual studio are you done all right so here's our app verify it works so the idea with this one is we create a template we acd up it so it puts it out in azure deploys it and then we're going to create the ci cd at github so you're going to create a github action yep so that is the code i put it in the directory that we needed in so let me open this on one side yes on the other so let's pick any demo we did where do i put this jh demo okay so this was our original one so this has pretty much what we're going to need so we're going to azdev and i called that one in b103 i have the source directory was our question nope nope i was just confirming what you were thinking there i'll mute i think his avatar right we don't need that yeah i'm told it looks just like me without the gray hair so where is this accli dev team is it in nerd or is it in seattle you guys in seattle no we are in burlington okay we are mostly in seattle but it's it's really you know a virtual theme all over the company i'm going to take everything in that original demo except for the source by this so i didn't do a copy which i would have done but it doesn't matter for these purposes i've got all those files over here now so this is the demo folder i just created let me open this in code so this is good that's good so this is the one if i look on the source folder you'll see we only have web uh this is where i've got the solution for it i don't know this is the page that we just created if you look at it it's going to be our welcome message so something simple we'll change that once we get it out into github so what we want to do now is go to the info folder resources we're going to remove basically anything that has to do with the api so let me shrink these class them i should say here's an api we don't need the api service plan we need that all the analytics leave that we don't need anything to do with cosmos that we remove the api we're just doing a simple this this this so we're pretty much just left with a web app app insights log analytics that sort of thing um and let's see there's something on main i believe we need to remember so we cosmos stuff remove the api stuff believe that's all we need so that's pretty much going to be the bicep that we need to just deploy a web app well that's"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:05:56",
        "seconds": 3956,
        "text": "believe that's all we need so that's pretty much going to be the bicep that we need to just deploy a web app well that's not so now let's go let's try the um the app or the extension so control measure let's see if this works i typically use the command line so leave it all set up on my machine oh it's going to be proud now so can you upload the file using act or you have to use that az i try to cancel out i'm not sure fortunately so i didn't remove the um environment but we don't want the existing environment so let's delete that stuff actually now what we wanted to do all brand new stuff for us when didn't ask us for an environment name so i didn't delete the first demo stuff so we're going to call this one in a demo3 that goes to the environment ask me where let's try east you look best i guess it doesn't matter since just description so since it's just a web app it's not going to take terribly long to do this but as it's doing it i did okay so it's starting to create the resources let's try to do two things at once this is what we just did 635 that's about right so let's go ahead and say easy um what's the name i'm going to do a cd pipeline config this is like magic which is acd pipe let's go ahead and create one please new private github repository that sounds good to me so it's now going to create a new repo and github for me and upload the code for me and the one thing i didn't dig into is the code so it's still creating resources if you go to the github folder this is the workflow that is going to basically tell github to say hey you know this is azd go ahead and build it you know how to do this stuff take over from here and then tie it into github actions for us okay so would you like to commit yes i that's would up to github okay so now it's still deploying right so it's created that azure okay i got an air packaging the service oh yeah sorry i didn't forget that so it at this point it's done the pro it's sunday initialized it's done the provision of resources but it's choking on the deploy because i left this in say hey wait there there is no api guy you uh you left something out oh wait hold on i actually want to move this up we used the.net project i called it web so it's under web it's c-sharp and i want to go to web app so now if i go down here since i kind of broke it in the middle let's say azure developer deploy so if we go to azure resource groups crash free so there's our website apps insights plan log analytics so the guts of our resources are here but the web app publishing it so once this gets done publishing it then i'll be able to navigate"
    },
    {
        "speaker": "",
        "title": "A look at the Azure Developer CLI",
        "videoId": "OWzgJwJff4E",
        "description": "This is a recording of the July 28, 2022 meeting.The Azure Developer CLI (azd) announced their public preview this month (more information on the announcement is here). This is a new and exciting tool (with related extensions for VS Code and Visual Studio) that helps you get started with Azure even fast. By the way, this is not a replacement for the Azure CLI.In this session we'll take a look at what the azd CLI can do for you, the VS Code extension and Visual Studio tooling, look over the templates that are currently available and then look into the detail of how it all works and how you can make your own templates.Why should you care? Using the azd tool, I've created my own template and am able to deploy an ASP.NET web site (to an Azure web app) that communicates to an ASP.NET API (running in Azure Container Apps) all with one command.If you are looking to play with new technologies and start off with reference implementations - this is going to be a tool you want to check out!About the speakerJason is an independent consultant who focuses on .NET, Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:10:59",
        "seconds": 4259,
        "text": "plan log analytics so the guts of our resources are here but the web app publishing it so once this gets done publishing it then i'll be able to navigate to it we'll just see that template and then the next thing we can do is go to github change some text and then commit that and then watch it go through the action and then push it out to the website so if i go to this endpoint it's asp.net there's a startup so we have welcome it appears that i messed up the css and now but the file is there okay okay so now let's go to github one so nba demo three prior repository so here's all of our code it was the template so it's got the an accurate readme there but let's go into the web pages index let's change this text and ideally i would be doing this for you again not over here welcome yes all right so now let's go back and look at our actions okay so here's this one failed in it's not cool so it updated this one let's see if we can find any information may end up breaking again process complete extension code bummer we broke actually be all right for us i didn't clean everything out if this one succeeds receive enough of the step succeed that it will replace this message but nonetheless um check in a second the um steps that we did is you know basically we put our code in their template we modified the um bicep to do only what we wanted it to do we then after i failed the deployment had to notice that i didn't change the azure yaml the azure yaml file is very very important um as you can tell because it's it's what's telling it what it needs to do and especially what it needs to deploy and that was basically all i needed to do to get azd to deploy it for me where looking at azure devops starter if i would have gotten my code attached to it i could get it to deploy it to the target that it wanted but i didn't have any control over the bicep stuff so i mean this is this is um really going to be useful for for me honestly it's going to be useful for demos and pocs with customers yeah it'll be really useful for that we're currently building so this is going to take a while see where we're at in the presentation we'll come check on that so this is kind of the slide that sums up what we were doing i didn't go through the manual steps of the provision and deploy that when you're when you've got complicated bicep you're going to need to do that you're going to make sure that everything gets provisioned correctly and then whenever you're you've got the resources out there and you're doing the proper deployments you're probably going to need to deploy a timer to so you'll need to use the the individual commands i missed step three didn't make it very far this is the folder structure that you kind of need you don't need to do that container if you want to do the actions you're going to need the github i don't believe you're going to need the vs code unless you're using the tool you don't need the assets unless you're doing the readme file infrastructure is going to be needed if you want to deploy stuff and then of course you want to do the source of the easy azure handle that's the that was the gist of what we needed to do so the build failed again but let's see if it deployed all right so it didn't deploy i just messed up i didn't clean out all the stuff i need to clean out so apologize for that bad demo so here are the resources i will make this slide deck available as a pdf off of the um meetup page so that you can actually utilize these links the link to my github template is this last one if you're interested in the the web app calling the v-net integration there's also this which i'll upload this video after i chop off the first 15 or 20 minutes to this this is a youtube playlist that i've put together of any of the videos i find on youtube for the developer cli so a lot of them are different demos announcements for the application or the utility so are any questions thank you for putting this up together jason thank you pretty bad luck with the demos unfortunately um does microsoft see this as a tool to deploy to any other targets um like i'm assuming this is just for azure right there's no plan for this tool to be used so this is aimed at using being used for azure at the delta developers developers con or or other other developers deploying to that's azure services so they i do know they want to um get terraform as as a language of use for this for the resources but i don't know what that means for non-azure stuff but to be able to put your stuff in azure i think it would work well i don't know that they'll ever do multi-cloud yeah yeah i think i think that's a a fair assessment we're altruistic these days but uh there are limits so what about so what about uh it's a terraform that's interesting because i mean you would i always think about this tool is a little bit like terraform in that you know terraform deploys to azure um so with this coal terraform would you be able to would this work with your terraform no i don't see like the advantage right you just use terraforming you had sharepoint files but for myself who's never used it before yeah learning tool yeah yeah or i mean maybe i don't know if you if you were a terraform shop where you wanted to run azd commands i could see a terraform provider for this so i would use terraform to deploy azd not vice versa yeah then it works yes it's just kind of like lining up two tools that are similar but i guess there's probably someone out there that wants to do it yeah jason's mainly an azure swaps i don't see him hello that's what actually is i don't see him learning terraform i was addressing actually i don't see me doing amazon or google no but terraform is not only amazon it's also where you have like open shift and where you're getting a monolith application like on linux or something like that and bringing them into azure they might have this stuff already done in terre haute it's getting to be very popular i do know a lot of people who have put quite a bit of time in getting up to speed with terraform but oftentimes it gets shelved all right well anyways that's uh that's my presentation for the um please reach out if you have any questions thank you jason again thanks for everyone for attending thanks sir you can have virtual pizzas here you just need to figure out how microsoft can transmit over the wire thanks mike uh mark for uh watching the lobby for me thank you mark thank you mom even though you're in boston and you didn't make it here this evening yeah and thanks for the team members for joining yes but i'm literally in boston oh uh okay a long line it should make a plane so it's a non-trivial uh oh yeah no it's getting to that frequency is not uh it's you're right non-trivial especially yep all right good night everyone you "
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Managing IoT Devices in Azure; the simpler way. This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.. uh good morning good afternoon good afternoon everyone or good evening at the uh my name is Ron dagdag and today I will be talking about managing iot devices in Azure and we're going to talk about the simpler way of doing it so this is a picture of my daughter and that day I had a great time there was a Lego convention here in town and we attended it and you know there's a bunch of Legos and we you know that that she loves Legos and learning all those different Legos and of course you know if you're a parent most likely you stepped on one of these Legos out in the living room and all that but so I I gave her uh you know a challenge that day and said can you build me a house because there's a bunch of you know a bunch of uh Lego pieces right there and yeah she did this one and I think it's it's been nice I mean it does look like house it does not have walls but there's a small kitchen over there and and I think it's it's it's cute uh and of course a few years later you know we are I bought her one of these Lego pieces or you know Lego kit uh I guess this one is Mega Blok uh and the same approach right you build me a house from these pieces and if you compare these versus that one I mean that one is a much better toy house or dollhouse as compared to the previous one uh but it's simpler for someone that's beginning and trying to understand so that's that's my point here in terms of you know having a guide of what would make it simpler to do in order to to accomplish some tasks and today our agenda we're going to talk about what is internet of things and then iot Central which is uh part of azure I'm going to focus on that one and what makes it simpler as compared to the other things that are that are available in Azure to do on Internet of Things what is the benefit of it we're going to talk about what is a device template iot Plug and Play how do you visualize data that you're receiving from iot devices and integration with other azures services let's get started um if you have questions feel free to unmute or raise your hand you know this this is a small group I can answer them as needed and also it helps everyone in the team to to understand more if you need details so what is iot iot the way it kind of look at is there's things you have things you know this is a thing right that you send data from this thing to the cloud and then you do some transformation of that data to improve your business so it's an internet thinks is a network of connected devices and objects allows you to send and receive data over the Internet typically it's connected to the internet uh or other device systems an iot device will have some sensors that can detect you know maybe various uh ambient condition temperature or or other things all these other uh sensors and then data is collected that is used for either live monitoring or some analysis at the end of the day it's business decision making there are two goals whenever you're working on Internet of Things device right one is remotely monitor uh your your devices right this is where you're Gathering data or you're doing some minimum minimal device processing knowing that status of that model of that device how how is it performing and then also controlling that device this is when you're trying to send commands to that device or some device properties so typically when you want to start learning about internet of things that's out there a lot of resources are available um a lot of you know if you've heard of Raspberry Pi's or arduinos that's typically the ones that people start with learning more of course the difference between the two is that Raspberry Pi has a you know it's a microprocessor it has a it's a it has an operating system um and it's using Linux or you can actually install"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:05:05",
        "seconds": 305,
        "text": "difference between the two is that Raspberry Pi has a you know it's a microprocessor it has a it's a it has an operating system um and it's using Linux or you can actually install Ubuntu or running on that machine and then of course Arduino is a microcontroller it's using uh you know Bartos real-time operating system it does not have the the usual Linux operating system that we're used to and they both have different ways on how you would program them and of course whenever you know you use you install these iot systems like let's say in a factory or in an in a retail store or different uh you know different uh in different areas right or weather stations and all these there you know there's issues that you'll see in the field in in scaling these devices right and so these are different attributes of what a successful Internet of Things Solutions are one is of course you whenever you're talking about this you have to think about scaling these you know scaling not just storage but you also have to scale compute networking and you may have multi-tenancy around your your system that you have to consider another one is device management you know there's a life cycle on one of these devices it could be you know you have to figure out how do you provision them how do you connect them to the internet the Wi-Fi credentials and those kind of things or even if they're not using Wi-Fi uh you know how do you update the software on these on these devices another way is is big data management you know so there's the data that you're collecting from these devices and you have to consider them do you need to store them in a hot path and you'll hear this a lot more hot path warm path or cold path it's how you uh you store these data that you collected and how fast you can access it after it writes it to to on disk and so there's different modes and how you would uh you would manage those that data and then once you start having analytics insights and extensibility you just also have to think about some of the different rules right uh and some automated actions and some Integrations to your alerting system so think about uh you know if one of the devices are off and it's it's not working or it's it's having some issue or calibration issues you want to know that in managing that and identifying those uh actions would uh would require you to uh to to consider and plan another one is high availability and Disaster Recovery some devices out there that you know especially iot devices that are deployed in a hospital or you know some some uh Mission critical uh location these devices have to have uh High availability and Disaster Recovery they have to be resilient to failures on the network or even disk right um and then security and compliance because these devices are deployed somewhere that may be remote that there's not a lot of people who think about uh oil uh oil oil fields where they're constantly monitoring uh the the well so security we got to make sure that and and also compliance as it transfer data from that device to the cloud so think about connectivity you know integrating your data and and data protection those are the considerations and managing iot Solutions with with devops when you're building or managing and provisioning and deploying code the the more we can automate uh some of these uh you know with the with the devops in mind the better we are in building a proper iot solution and then of course after all that you make sure it's within the budget right understanding the cost and the total cost of ownership of not just the device itself but storing that data and transferring that data uh to the cloud all right and then there's a lot uh to consider when you're creating an Internet of Things application uh and then of course you know we all live you know especially in Azure uh we all live in this as developers in the I.T right the information technology where you talk about the cloud the software as a service you know we typically whenever we talk about I.T"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "live in this as developers in the I.T right the information technology where you talk about the cloud the software as a service you know we typically whenever we talk about I.T uh it's it's um asset management and HTTP all these different things and and of course you know there's the world out there of operational technology if you're not familiar with that it's been you know that a lot of these old devices out there are not just all devices a lot of machineries out there they do have program running in them right they have these these controllers and PLC devices and they have sensors especially in an assembly line or a Machinery that someone is responsible of keeping track and making sure that is um operational right that everything's doing great in in the factory or doing the doing um the sensors are working great and all the things involved in that so I did talk about it and OT right and the difference and then there's of course the one in between now as we build Internet of Things devices we're talking about the combination of it and OT and this is the world of iot and the user roles in iot things you have to consider whenever you know a successful deployment one is the administrator they're the ones responsible for administrative tasks assigning different roles and permission to our users and then there's the role of a device developer they're the ones who would program some of these devices right for the some of these iot devices and then the operator we did talk about OT right they're the ones that are managing these devices as you deploy them as it so that it can connect to our iot Cloud application and of course us and Azure Developers we're the solution Builder and where the ones that builds iot Cloud solution that these device can connect to uh so those are the so today I'm gonna focus on the role of a solution Builder and how we can uh how it's being used in azure so what is iot Central um it's a way for connecting and monitoring and managing iot assets at scale this keyword the key word here is at scale and being able to to easily scale your iot application through of course quick connectivity uh already pre-built libraries that you can you can and samples out there centralized management so a place where you can look at all the devices that are connected and then visualization it's a it's it allows you to have these reports and charts for analysis and it is a bridge between applications and iot data do we have any questions so far in the chat or anything we're keeping an eye on the on the chat Ron and it looks dumb like nobody has questions thus far okay I will continue so I did talk about you know things right and then the cloud and then the transformation so devices you have all these devices that you can connect and iot Central manages devices and acquiring and connecting and securing it to the cloud so it central can do this right now as a solution Builder this is our side which is the transformation of these data and using what data that we can collect through these devices and bring business value from there so what are the benefits there's low code environment and I did talk a little bit about data analysis and later on I will demo what that looks like it's good at dealing with non-frequently changing data uh and it also has ready to use templates to start with uh depending on uh you know the the use case that you're You're Building uh there might be already a pre-built template available for that and then it does support different types of device measurement measurement so in terms of the the um unit of measure they they have that and then it's highly"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:15:13",
        "seconds": 913,
        "text": "template available for that and then it does support different types of device measurement measurement so in terms of the the um unit of measure they they have that and then it's highly secured in authorization and authentication and we'll we'll do a demo on this one and and how to log in and all that so how you would leverage of course you know collecting information and then monitoring the devices and then you're analyzing what the data that you collected and then deciding what you want to do with that data so those are the four steps so we did I did talk about Legos and I'm going to connect you know what Lego means to to my to my uh presentation we are familiar with infrastructure as a service and you most likely you've heard also about platformer service which is infrastructure focused software development service and then you know there's a lot of SAS or software application as a service that's out there you know think about you know Office 365 that's a software application Service uh you know of course is more of like VMS in the cloud or kubernetes and those are more infrastructure as a service but there is one that's called a pass application platform as a service so it is closer to SAS but you can customize it more but it is uh considered as a software development focused um software development services so so in terms of the Lego itself right um you know because IIT Central has like ready to use templates has instructions and how you would do this uh you know IIT Central is considered a an apas or application platform as a service so because ID Central is application platform of service it's actually a collection of a bunch of Azure services that is out there so not just from The iot Hub it's actually using iot Hub in the you know in the back background right uh also using DPS or uh the device provisioning Service uh it's also as it receives data it uses Azure stream analytics it's using data Explorer for warm path uh to using SQL DB for a cold path so it has all these different services that it's using and of course it can on the on the right side on the business integration it can export data trigger alerts and query data uh through the management web experience it's so on the device side on this side right here it's using Azure iot SDK or Azure rtos so depending on the devices that you're using and then also uh you know Azure sphere or Azure iot Edge so there's different ways on how you would you would connect to uh the cloud so when should you use iot Central when should we use uh this service if your team does lack experience in building an iot application and you know we did talk about how complex building an iot application is consider using iot Central because it's you know you look at the abilities of your team like in my team or a workout that we have a lot of net developers and also uh JavaScript JavaScript developers and node developers and so that is the common skill set that we have and then we can use our Azure iot Central to to help us customize that platform with the ready to use application so instead of building from scratch we can use iot Central and start building companion apps that is custom built solution rather than custom built solution from scratch so when should you not use Azure iot Central maybe it might well worth using Azure iot Hub as a better option for you because in your team there's might be experience professional that wants to full control over the whole iut solution so it depends on what of course at the end of the day right it depends on what you're trying to do and how much data are you needing to uh to process or you know how much control you want over the iot solution so here's a question for you um you know a lot of us you know we've seen Windows have"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:20:19",
        "seconds": 1219,
        "text": "uh to process or you know how much control you want over the iot solution so here's a question for you um you know a lot of us you know we've seen Windows have used Windows most likely what made Windows successful you know it's a lot of places where Windows says is installed what made it successful is because they work with other device manufacturer to have compatible device if you think about it you know you plug something like a camera in your in your laptop and instinctively know what device driver it's going to use in order to to display it right so in order to to connect and you know and it's a bunch of different components that's working together you know you may have a different hard drive different uh Monitor and how they work together to build the whole system the same way as Alexa devices if you I treat Alexa as my home operating system because you have all these uh you know Smart Homes right and you know you have all these different lightning lighting manufacturers different plugs you have voice assistance different TV and how seamlessly you can create rules to talk to each other and you can create an Alexa skill set because I used to do that in that you know being able to to control some of these um iot devices or these smart home devices so Azure has this Azure iot pla Plug and Play that integrates smart device solution uh it the device itself advertises its capabilities to iot Central uh to reduce the hassle of configuring uh as creating templates and features and all the different things and how you would communicate to this device there is an Azure device catalog that you can look at what are available devices out there that you can plug into iot Central so I have one right here which is an esp32 iot kit and this this one right on on this screen so you can connect that it and it simplifies that process and of course you know there's other other devices that are available too so there's three different device types in iot central one is an iot device an iot edge device and Gateway devices let's look at each one of them iot device is a free standing device you know this is a free standing device it connects to uh the the internet and then it can send Telemetry data and you know it can reports values and you can receive property values in response to command another one is an iot edge device this is this acts as a standalone device or a middleman to if if a device another device can't connect to the cloud so it has the ability to process data locally so you think about this it could be a a Raspberry Pi that has Docker containers running in it and so it can process those Docker containers and then connect to the cloud so that's how it runs an iot edge device another one is a gateway device a Gateway device is the one one that manages other devices that connects to iot Central so you know there's some low power device out there let's say you know that that is using um let's say a you know a a different protocol instead of directly connecting to Wi-Fi right so a Gateway device is like uh where these some of these iot device would connect to and can talk let's say you know uh Laura or can talk some other protocol and then forwards that message then that connects to IUD Central hey there question Ron yes sir yeah uh you might have just answered it uh I was thinking of the question when you're on the iot edge device uh section I you talked about that being uh potentially a middleman for other devices that can't connect directly to the cloud uh in that I guess you just explained that like I said a Gateway sounds similar to that too yes yeah I I have a sensor in my uh house that um that collects the temperature and humidity and things like that and it can't talk to the internet it talks to a Gateway right then can talk to the internet it can have multiple sensors um is"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:25:25",
        "seconds": 1525,
        "text": "that collects the temperature and humidity and things like that and it can't talk to the internet it talks to a Gateway right then can talk to the internet it can have multiple sensors um is is that so so I get the concept of the Gateway in that context is there another context that I'm missing for where a one Edge device in the middle row could do work for another or it could be it's you know um Middleman so if you think about um what is a good example of this is it there's a there's service in Azure where you can run it uh at the edge meaning uh or trying to find that word so it can process some of the images from the camera in between uh okay it'll come back to me but but you can have these uh devices this Edge device that can that can do some processing before you send it to the cloud and typically you would run it in like a kubernetes or you would run that on that there's an Azure iot Edge that runs containers closer to you know containers in in the in the same network as your iot Edge devices so it can do that processing or pre-processing data locally instead of sending directly to the cloud so you can have to actually learn this from Veronica she talked about the cognitive Services that's right they have containers that you can stick out that's correct so and I hadn't thought about those as doing work for other devices before sending it centrally but that that makes complete sense uh yes now so you explain it wrong yes so cognitive Services can run you can actually have SQL device uh SQL Edge running on there right so instead of you know the SQL Server running in the cloud you can have SQL Edge running on an iot edge device and that's your IIT Edge deal your your processing can happen there that's a good question I appreciate the extra call everyone thank you yes there's multiple ways in how you would connect to iot Central uh of course you know this is the same underlying structure as you would connect an iot to iot HUB you can use either a shared access key signature you can use x 509 certificates or The Trusted platform module a lot of you know examples out there is using the shared access signature which is kind of like a connection string uh how we would connect to to it central that's typically the easiest way and then in terms of communication protocols uh it could be it's possible to send it through mqtt it's using mqtt amqp or https so if you know depending on the network if they block some of these uh you know these protocols you know you have choices and how to send data to iot Central device templates think about it as a blueprint or definition of what the how to talk to the device and typically there's three ways on how you would do this the three components of a device template one is what is the what's Telemetry that you'll be receiving these are device the device sends data to the cloud and sends Telemetry data another one is sync uh properties and these are you know typically we call them device twin but it synchronizes you know between the the cloud and the device if you if device changes the um some of the properties eventually it would reflect you know that information the cloud or vice versa right you change the number or the the the property in the cloud it knows how to synchronize itself to the device that it that its goal is to make sure that they're all the same and then another one is commands these are Cloud calls on device so the difference between properties and commands commands requires that the device is on so that you can send command to it properties even though let's say the device is offline and you know maybe not connected to the internet you can change the property and then eventually it would synchronize the device once it it you know it reboots itself once it's connected back to IIT Central so let's let's look at uh iot device uh iot Central device provisioning how are we on time now um how long do we usually have our our presentation classes another uh 90"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:30:30",
        "seconds": 1830,
        "text": "so let's let's look at uh iot device uh iot Central device provisioning how are we on time now um how long do we usually have our our presentation classes another uh 90 minutes 90 minutes okay now uh not another 90 minutes but um what's what's the most natural uh amount of time that would make sense to wrap it up with okay I want to make sure because I can talk about this all day I want to make sure I don't waste everyone's time so yeah uh that let's let's do a demo of what iot central would look like okay so if you go to apps that iotcentral.com okay you can actually uh build an app here um and it it's either you can create your own custom app or you can select in one of these if you just want to try it out so you know these are the templates that they have you know if you're if you want to know more about Retail Energy uh government health care so there's some examples out there and some uh documentation around it to understand to understand what uh what data would you be receiving so today I'm we're just going to create our own custom app and of course it will ask us for application name and then the URL dot Azure iotcentral.com you specify that it is a custom template and then in terms of the pricing plan each one of these have two free devices and you have to select how many messages you receive from that device and of course it cost I think the the pricing model it's like maybe less than a dollar per device per month uh in order to connect to this and there's there's different pricing models for each one of these so it just depends on how much how many messages can you receive so we're going to select uh standard two and then of course you know you need your uh your Azure subscription in order to connect to it and then just click create so I created one already since uh let me make sure I and and this is what it looks like so you know first set you you know you'll have um the application so you can do some customization a little bit on this you know change you know upload image and icons those kind of things to make it uh a little bit nicer right and then on the application itself um you can do some management for this and what here you can change the application name and application ID those kind of things so we'll focus on the connection part of it so let's go back to my other screen to the presentation we have a question in the chat okay um if we have a Gateway the commands can be routed from Cloud to Gateway to their iot device yes yes there's a way to do that because you can register your gateway to iot Central and you know each one of the devices also iot device can route those messages to the Gateway and then the gateway to ID Central and vice versa thank you so IIT Central let's see where's provisioning I thought I have my other screen here okay so on the provisioning side you know I'm gonna click create new device and this new device I specified sample device iot or sample device zero one I'm not going to assign a device template because I haven't built one and then it you know it would have these it tells me the device name it's just there's different device status right now we just created this device and it knows what organization it belongs to which is uh you can have multi-tenancy and multi-organization and this so you think about organization is where you can have uh you know Factory one versus Factory two all devices on Factory One belongs to one or sub organization and then Factory two belongs to another sub organization however you want to so you can you can manage these devices and then of course a device template uh we'll talk more on that so"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:35:34",
        "seconds": 2134,
        "text": "then Factory two belongs to another sub organization however you want to so you can you can manage these devices and then of course a device template uh we'll talk more on that so once you have your device it would tell you how you would connect to it so it would have the scope on how you would connect the device ID um you can and then it'll give you the in a way connection string the primary key and secondary key uh if you use this shared access signature so once you have that um I'll go back to I have these uh sample code and I'll give you a link on this one later on in this sample code this is just a c-sharp application and I want this one to be to act like a an iot device running on my laptop just to simplify things and it knows how you know and it knows how to connect to iot Central already because we specified some of the scope and then I'm going to run this see am I in the right folder uh temperature controller .net run so I'm going to run this and what this um application does it acts kind of like a you know an iot device like one of those temperature monitoring uh the device um to where you can you know monitor the temperature send it to the cloud and then also control and change the thermostat you know so think about the thermostat in your home and it's sending the updates every few seconds and it connects to iot Central that way okay let's go back to the other screen we have here I'm going to refresh this notice how it created this device template um so the sample device you know that the one running on my machine it connected because it's using the uh the the SAS the shared access key and is able to connect and it has it it reported a new device template and let me tell you what this device template would looks like this device template gives you information about the device itself um remember I did talk to you about Plug and Play This is where iot Azure iot Plug and Play does is it it reports okay this is how you're gonna talk to me so this the device itself says this is how you you know IIT Central can talk to me and it has all these different capabilities all the different uh uh you know values on how you would you know you have the serial number the working set you know and commands to reboot some of the properties and all that so let's look at this device going back here and this device right there foreign template it knows how to communicate so it has this temperature uh values and what it's receiving from that device uh commands if you want to reboot that temperature controller uh to get some of these values for get min and Max report uh and then also the on on night Central you can see what are the data that you are receiving from from the device to cloud and it Maps you know some of these values you know thermostat 1 slash temperature thermostat 2 slash temperature so each one is actually just sending a Json payload of uh what the current temperature is of each one of this thermostat and then with the timestamp so there's Telemetry right there and also this is when it wakes up and the event type is device connected just time step so that then right there it's it's provision it woke up it connected to to the you know from my machine that connected to to the the iot central instance and it's communicating okay let's go back to the presentation so visualizing data I think I have a slide that I have here so monitoring there's two types of monitoring the health of your application and then of course the health of the iot device and of course as you receive this data there's a historical data that you collected from your device so device monitoring is identifying the issues with them you know what's the status device status and then of"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:40:37",
        "seconds": 2437,
        "text": "of course as you receive this data there's a historical data that you collected from your device so device monitoring is identifying the issues with them you know what's the status device status and then of course the application monitoring how is the application platform as a service a pass right how is iot Central performing there's uh of course in Azure there's metrics that can provide chart there's also a way you can you know the rest apis and uh and on the Azure portal to know how iot's Central is performing so let's let me show you what device monitoring looks like so here's an example uh you can actually build a different dashboards on iot Central monitoring each one of the devices that you have in your let's say Factory floor or you know the retail store so there's ways you can create some of these graphs so let's do that let's try to go back here and go to dashboards I did talk about dashboard you can make your own dashboard or you can [Music] you can build one and there's a way you can specify okay a chart data that you're receiving you know I want to create the line chart and on here um I guess it's complaining about uh you know for some reason the device template associated so let's try to cancel that let's create a new one so you can create new and let's say I just want the personal dashboard or you can do it per organization so let's say the whole Factory for or you know the whole organization can monitor some of these device so let's go with personal and then I can edit this dashboard I can create a line chart and then I can edit this line chart and let's say okay for all devices that are temperature controller I want to specify this device and just give me a chart on that image Telemetry and which capability I want to monitor I want to monitor the first thermostat and click and then see if we add again the other thermostat and then click update notice how it builds me a line chart that I can monitor for for this so that's one way you can you can see as you receive this data it's building a chart for you another one is through data Explorer data Explorer can you can create some queries and you know if you just want to analyze what's going on with your devices you can do it here and then let's say look at you know historical values and then visualize it from there and this one is using Azure Time series uh to visualize so there's different options all right let's move forward question Ron yes sir on the um the data that the uh iot Central is as uh collecting does it have a limit on how much data it's going to store do you get to tell it you know I want to keep it forever it'll only keep it for three months does anything like that yes there's a limit I believe it's 90 days uh on on you know what it would store and then it falls off from there that's why you have all these apis and data export which I'm going to talk about next and how to get the data out for longer storage right makes sense thanks they're all temporary connected there you can build reports you know mostly status of what's going on with your device um so jobs uh jobs is a way you can manage uh connected devices at scale you can do bulk updates because you think about you know this is actively built for scale scale means thousands or hundreds you know thousands or you know hundred thousands or 200 you know a million devices it can go up to million devices that you could be managing out there and you have to think about okay how do if I want to run command on these devices how do I do them in bulk because I'm not going to do that for you know for each one each one of these device you're going to run it in in batch so that's where you have jobs and you can have all these you know these different devices uh in having in CSV file and to Import and Export so you can you can do the batching so let's let's do that let's let's try to"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:45:40",
        "seconds": 2740,
        "text": "these you know these different devices uh in having in CSV file and to Import and Export so you can you can do the batching so let's let's do that let's let's try to uh visualize what uh jobs would look like um so if I go back to IIT Central there is manage and there's jobs right here and of course you can schedule and create a job and that's what I'm doing on the screen so like in this case configure a job you specify it sorry about that I have an alarm going on okay I'm back wasn't expecting this alarm yeah okay so I configured a job I specified okay what type of devices am I going to control or Gonna Change in this case I want my temperature controller uh I want to change the property uh you know thermostat Target temperature I want to specify so this one is changing changing properties and I wanted to say okay now thermostat one your target temperature has to be 25. degrees so then that's how it's going to send it and what it's going to do is it will look for all the devices under that device group right that works on that device template under that organization and then uh start calling them each one of these device and then uh changing the the target temperature and then once it's done once it executes you know there's you know it would tell you how many failed how many got completed how many is in the process how long did it take and which one of the devices that it went through and an update so that's that's jobs right and so the advantage of this one is there's different rules where you you would batch them so you can there's also cancellation threshold or you know different uh rules that says hey you know you have thousands of devices you're updating and the first 10 failed should I continue with the 10 you know thousands of devices so you can have these cancellation threshold that if you know five or ten devices in the first run failed already yeah just canceled the whole job and don't run it because we don't want to destroy some of the devices out there especially if it's if it's Mission critical device so those one way you can you can start batching them all right so let's that's jobs let's start extending and what are the different ways and how you can extend iot Central like I said you can have a companion app in iot central so that you can you know start using some of these data that it's receiving when it's exporting the data rules and then rest API let's go through each one exporting uh you know this is how you would integrate so you can export it through um you know event Hub service bus blob storage some of the this information um and let's go through each one so on the data export you can either go through Azure event Hub where you can of course if you're not familiar with can process events um with speed and precision service bus if you wanted to make sure they are in order you can export data to Azure service bus and then blob storage for unstructured data so this is for long term you can export uh data that you're receiving from iot Central to from device to iot Central and then to blob storage another one is through data Lake where you can process large amount of data the easiest way that I you know especially if you have API you can connect a web hook endpoint and then you can you know have rules against that or rules defined for that so here's a good example and how you would do this in this case I'm selecting webhook as part of destination so how I got there to this page is I would go to data data export in this case I'm going to go to destination I'm going to create a new destination and I'm going to specify web hook because that's the simplest way but you can actually experiment to try different ones and then you specify the Callback URL authentication and some of the headers and that's"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:50:43",
        "seconds": 3043,
        "text": "destination and I'm going to specify web hook because that's the simplest way but you can actually experiment to try different ones and then you specify the Callback URL authentication and some of the headers and that's what I'm doing here so in this case there's no authorization I'm just pushing it to that callback URL and then and then that's it and then on the data export side or the so once you have a destination a destination is a place where you can you can send the data the export is where you specify what data are you going to send to to that uh to that destination so in here I can have multiple destinations for the same data that I'm exporting from iot Central so in the screen where we specify okay the device that I'm going to do data export it has to have the word sample in it so I can filter you know because I think about thousands or hundreds of thousands of devices and I just want a certain location so you can have filter or certain type of devices you can do that and then of course if I want to add a metadata I can so in this case is sample I specify is true so anytime it exports data it will have that metadata information but we call enrichments and also you can export organization it belongs to and then on the destination side in this case um I'm specifying that it's going to go to um to my uh HTTP or my web hook there notice how there's data transformation here and the data transformation allows you to restructure the date and payload as you're exporting data out of I2 Central to uh to where it needs to be you can rename the fields filter out the fields this would be good if you have existing application out there that already have some you know process the data or sometimes you just want some calculations or conversions before you store it to your so this runs something in between your data transfer you know the data transformation so it looks something like this right typically uh you know on the data transformation you would create these and this is kind of this using a JQ which is kind of like a a language for manipulating a Json payload and and this one it you specify what the device template would look like and then the output would look something like this right so let me go back to that screen and maybe it'll make sense to to show you so typically the data that you would receive from from data export would look something like this right so Json payload did all the properties that is uh reported on that on all Organization for that and what it's the build transformation query would look at this Json payload and you know convert it or transform it to look something like this so it kind of flattens and it's it kind of simplify uh what what data would get stored so let's say if you're going to send this to blob storage it's better to parse this later on than than this all this massive ones so that's that's what it's for so it has that customization piece that you can do to to enrich or transform your data okay any questions so far I know I'm going through it fast and you know if you really want to delve deeper on this uh topic there's a lot of tutorials out there uh on especially on Microsoft learn to to understand more about this and there's also uh on GitHub there's uh there's some uh tutorials I got a small question I apologize because my laptop rebooted I just thought of the presentation so you might have already talked about this but all right I'm kind of curious so let's just assume you have that factory you got all those iot devices spread out all of your factory those devices are actually making a call into iot Central directly into azure you know that's one type of device right that's an iot device that is connected so if let's say your iot device has a Wi-Fi connection directly to Azure uh iot Central then it can start sending that if if it you know there's use cases where the device does not have uh direct internet connection but in order to send to IH Central you need Wi-Fi you need uh internet connection so you in that case that use case you need a a Gateway device that would that be like a scenario of like an Arduino or something where"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "00:55:48",
        "seconds": 3348,
        "text": "to IH Central you need Wi-Fi you need uh internet connection so you in that case that use case you need a a Gateway device that would that be like a scenario of like an Arduino or something where you might be just getting some sensor sense data like temperature data but it doesn't doesn't know enough about Wi-Fi that's the Gateway scenario right right right so Raspberry Pi can act as a Gateway right okay so like given those scenarios how do you let's go with the simple one if you have the Raspberry Pi how do you how do you authorize the request from the device into iot Central so just keep a simple case I mean what gives it the access to it to generate did you generate a a SAS key or yes yes so it's like a connection string and each device have their own connection string so that's what makes it more secure right so so since you each device have their own connection string you can just delete that device or block that device from connecting to to iot Central and then you know if let's say that device gets compromised uh you know none of your other systems are compromised because of that okay and you can revoke yes awesome thank you yeah no problem so rules uh rules is you know where you can notify operators in other systems right this is all more of the business process flows and and alerts on the custom dashboards so it would look something like this um let's go back to that screen where I was so this is on iot Central you can have rules and then on these rules I can create a rule okay and then I'll go back to the presentation so this rule in this case I want to say if the temperature hits a certain number of degrees in five minutes span let me know because it might be something important so in this case I'm looking at these devices that have this serial number that starts with Sr so a property of that device so if you go if I go back to this device right here each one of the device can reports its properties uh so if I click about see how it says serial number so these are properties we did talk about uh a little bit about properties um and then these ones also is another property where you can uh you know like a device twin so this is the one that we're talking about here if the serial number starts with Sr use that device uh as part of this rule you can also have multiple filters against that and then on the condition it says you do a Time aggregation every five minutes if the temperature of certain uh you know maximum in this case 35 degrees then you can call a web hook you can do Azure function logic apps however you need to or you can have other actions too you can send an email you can uh you know Azure monitor action groups you can send it to power power automate or a logic app to do this so you can have all these different rules that trigger something else in in Azure uh so that you can get alerted or on the workflow that needs to happen so you know you can send email maybe you can call you know as SMS or text message you can do voice or web hook so just different options that you can do to to uh to send and to to send messages okay moving to rest API uh rest API allows us to do App Management device modeling device onboarding I did talk about oh it's the difference between app management and device management and Data Insights App Management so you know if you want to uh you know there's you know we want to create rules or if you want to you know there's there's a rest API to create some of the uh options that is on here if you want to create a job you know that's you can there's an API to create the job without going through these screens uh device modeling you can upload a device template a device onboarding it's more uh you know provisioning a device creating the SAS key right or the the um you know the connection string and then the device management of course you know managing that device you know making sure that changing the properties on that device you know all that and then the data inside today I'm going to focus on device management and I'll show you how that flows so before you can call the API you know iot Central API you have to have a token uh you know and then you"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "01:00:51",
        "seconds": 3651,
        "text": "focus on device management and I'll show you how that flows so before you can call the API you know iot Central API you have to have a token uh you know and then you have to specify the role of that token like in this case I named it test token and it's an app operator role and it would generate the token for you it only generated once you have to store that uh key the API key to to be able to call and then in this case I I can send a patch request and dispatch request it tells you know connect to your iot central API you specify the name of that device or the device key and then I'm changing the property of that device and then of course there's different API versions so that you can identify which API API that you know which version that you're using and then in this case I'm changing the target temperature which is the target temperature if I go here I'm changing this I mean I can change it manually right I can change this uh this is the desired uh what what I want it to be and this is what the device is reporting right now so let's try to do that in an API and then of course once you run it it would give you a 202. so let's do that so I have the same one right here so this is a call a patch call to my API I have to send the authorization the shared access signature uh which is my API token and then call these and then I'm going to send that request foreign so once I send that request I would receive a callback right I'm calling that uh hatch request and it would give me if it was successful or not and it would give me display load and change it to the desired temperature to 20. so notice how this is my you know the the device that I provisioned a while ago and it received that message already since it's connected to the internet and on here notice how this one changed it was zero a while ago now the target temperature is 20 and then if I go to overview it start changing the temperature uh to to reach 20. now it was 22 and now it's it's going down so that's that's what it's doing right now so we changed the property and of course it did something to to change and this is the current temperature that it's reporting okay so there's rest API calls that you can to you know to think about it if you have a companion app not necessarily they don't have you know their users doesn't have to log into iot Central in order to do this the companion app can be responsible to managing some of these iot devices wait there's more of course if you're into uh industrial iot uh we did talk a little bit about gateways because especially on some of the OT devices out there you know if you have a PLC some existing Machinery that has controllers and you there's ways that you can connect it to a Gateway which connects that Gateway connects to iot Central and then you can do your processing after that okay in summary Internet of Things to um goals either you're remotely monitoring or controlling the device iut Central what is iot Central it simplifies the creation of iot solutions uh what are the benefits a lot of is low code environment there's a lot of flexibility on how you can customize it and uh and able to manage that iot Central application there's device template where we talked about what is a telemetic difference between telemetry properties and commands and then talk about iot plug-and-play which is a device catalog that device itself that you're using reports what how it how it can talk to uh from I just how IIT Central can talk to that device I did kind of did a quick demo on what the dashboards would look like some integration between the rules data export and API if you're interested in uh getting the demo that I um did today or that application you can um take a picture of this or you know get the GitHub link and I will I can paste that on the chat later on and I'm open"
    },
    {
        "speaker": "",
        "title": "Managing IoT Devices in Azure; the simpler way",
        "videoId": "oYBVaN_1jDI",
        "description": "This is a recording of the October 19, 2022 meeting.Collecting telemetry data from devices and sending commands from cloud to device are common requirements today for any IoT solution. Azure IoT Central reduces the burden and cost of developing, managing, and maintaining IoT application. Journey with us and we will walk through different features of IoT Central: connect devices, monitor, configure rules, integrate with other services. Learn how to customize IoT central to fit the needs.About the speaker:During the day, Ron Dagdag is a software artisan with 20+ years of experience working on a number of business applications using a diverse set of frameworks and languages. He currently support developers at Spacee with their IoT, Cloud and ML development. On the side, Ron Dagdag is active participant in the community as a Microsoft MVP, speaker, maker and blogger. He is passionate about Augmented Intelligence, studying the convergence of Augmented Reality, Artificial Intelligence and the Internet of Things.You can follow him on twitter at @rondagdag.",
        "start": "01:05:56",
        "seconds": 3956,
        "text": "demo that I um did today or that application you can um take a picture of this or you know get the GitHub link and I will I can paste that on the chat later on and I'm open to questions if you have I know there's a lot of things that I did and I went through really fast but my goal here is not you know not to you know overrun you my goal here is to kind of show you like hey these These are possibilities on how you would use iot Central and if in case there's a use case or not something that you you know that there's a need for you you're already familiar with with some of the things it can do if you want to learn more there's call to action you on Microsoft learn you can learn more about iot Central there's documentation for the rest API um also there's some resources on GitHub about IIT Central and how to manage applications using the rest API with that if you're interested in learning more about me I'm Ron dagdag director of software engineering at Spacey I'm a sixth year Microsoft MVP awardee uh the best way to contact me is through uh Twitter and Linkedin at Ron dagdag or in LinkedIn Ron dagdag um I appreciate any feedback I want to improve my skill for sending and also if you learn something new or at some point in time that's why I wanted us to connect through Linkedin at some point in time if there's anything that um one of the presentations I did or I did talk about something that you're able to use sometime in the future I appreciate hearing back from you because it you know it validates uh the stuff that I'm doing the reason why I'm doing this is because I know as a developer there's a lot of Technologies out there and sometimes a little bit of introduction or a little bit of something uh goes a long way in understanding all the different uh Technologies and so I appreciate your time uh feel free if you have any questions uh this would be the best time yeah I'll just Echo uh Ron's Point uh if you have questions feel free to come off from you and um pose the question I do have one question for you Ron uh if uh in your in your demo uh you you gave an example of using um would it be called a digital twin what was the property is that okay so we we used a basically a fake device right that didn't exist in the real world to you know to have a conversation with it and it sent you you know temperature updates and such I'm curious if you have any advice for somebody who wants to get started with a physical iot device I know you showed in the marketplace earlier the uh I guess um I know certified devices or something it was a it was a special list yeah what would you what would you start with um if you looking to just kick the tires on this didn't want to spend a ton of money but wanted to do something uh in the real world I mean the the easiest well not the easiest way I mean we're application developers you know if you have you you can run this you know.net runs on a Raspberry Pi and you can build this you know your device through Raspberry Pi there's also you know JavaScript you know you know there's a way you can connect node application and read sensor data that for me that's the simplest way uh since we're you know in our world we're already familiar with with uh you know some of these languages that are available out there and you know it's cheap enough if you wanted to introduce if there's already existing applications um or sensors out there that is available so like this one they have a tutorial on how you would do this um then step by step it got a little bit of complex I tell you why because there's different kinds of programmers right we there's there's developers that actually you know they're world is not in Azure in Azure we live in the world of gigabytes and megabytes right and there are some developers that live in the kilobyte world that the memory on you know the usage and so there's a different construct and how you would do programming on it and so you know for us the developers you know we can use Python JavaScript go you know and have these and that's that's what I one of the demos I have here is just a this is just a you know a c-sharp application that connects to the cloud and we can start from there and then you can go in and understand more of the microcontrollers and if you really want to really run it on a uh devices that are constrained right the memory constraint and low power so it just depends on how you know the battery life how you're going to run this where you're going to install it so that's that would entail uh how much processing power that you would need got it thank you yeah uh so so a pie a Raspberry Pi is a um is a pretty easy way to get started at something exposure to that yes because we have a lot of exposure on the languages that can run on the pie so of course of course if you're a seed developer or C plus developer it might make sense to uh have a microcontroller uh running uh an esp32 actually has a Wi-Fi connection already so you can program the Wi-Fi here and and I did try that I did try and I was looking at how does it connect to the Wi-Fi I'm surprised how many lines of code C code just to connect a device to a Wi-Fi and you know you appreciate is learn to appreciate that the the abstraction layer that came you know that that helped us just just simplify a lot of these things because uh you know it can get complex right on well thanks for that Ron uh and anybody else want to come off mute and ask a final question here um you can um interrupt me if you do um I'm gonna proceed I'm going to thank Ron dagdag for uh for joining us and giving the talk from uh Fort Worth Texas I um uh I I did capture some screenshots and various things so you can see them in the photos in Meetup and I did capture the demo QR code and the link so if people are trying to track that down you can find that in there uh awesome so again thanks very much uh Ron and uh for the rest of you all um Ron's presentation will show up in youtube.com Boston Azure usually within a day and um again you can find us on Twitter uh at Boston azure and we um we do not expect um any more uh attempts at in-person events in 2022 we'll get back to you for 2023. we have we're still planning but we have one more virtual event um that we're touring with uh or trying to get set up and that's for uh December I think it's sixth seventh or 8th but follow the usual spaces for updates on that and to the new uh the new members here who who joined us for the first time welcome and hope to see you see you back hope to see you all back everybody have a good uh safe uh safe uh evening and uh see you see another time awesome thanks again Ron thanks everyone "
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Jason Haley: A look at Azure Container Apps. This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/. so uh tonight i'm going to take a look at azure container apps it was announced uh in november at ignite i believe was the conference name um so it's new it's still in preview so it's not um it's not fully baked keep that in mind as we go through um some of the dim ups um so putting this talk together i've made some assumptions about who would attend this talk since this is it's a preview product so people can't use it in production yet so i just kind of putting together uh targeting this audience i'm i'm assuming you already know what a container is because i'm definitely not going to have a chance to get into it with this talk and i'm assuming you're looking to work with whether you have yourself or clients or what have you the type of workloads of a web application a web api microservices or you have some sort of a background process to get kick that gets kicked off um from a cron job or event driven logic of some sort or maybe it's just always running in the background which you know after i put this list together i realize that actually covers most logic that you you could write as a developer but nonetheless these types of items are the types that i have experience with and that i deal with clients and customers with so this list that i've got together here is pretty much me except for the very last one i'm also kind of assuming that you're familiar with web apps azure functions possibly not necessary azure container instances and kubernetes services you may or may not belong to any of these except for at least one or two hopefully if you don't fit on this list or maybe you're just the last one here you're just really good at staying up to date so you're spending your evening attending meetups and learning the new stuff if so i definitely commend you because i'm lousy at that i i wish i could do that so hopefully um you're still here we still have uh actually we've got a few extra people so that's that's who this presentation is geared towards someone who said yes or or falls into one of those categories now as i go through this talk i i want you to keep in mind a few questions because we're evaluating the preview product here and trying to get understanding what it does and whether or not it's worth you to continue to look at and and all of that stuff so you know things to think about is container apps going to be a good fit for the type of workloads that you have um if you're not running things in containers currently maybe it will fit some future growth going down the road so keep that in mind it does have to run in a container so that is one big gotcha uh something that would keep you from using it and right now as it is with um preview is it's got to be a linux container so that is definitely a roadblock if you're doing windows containers currently i wouldn't expect that would always be the case but that's a current limitation given the current features that we'll look at in the preview service should you think about should you start looking at it now and continue as it can as it grows into a fully baked product or should you just wait a little bit and come back so hopefully you'll get an answer to these questions uh in this presentation one of the things that i've picked up as i was learning this um was you know can you think of a poc project where this would actually fit in your scenarios and that's that's something that i've come up with and i've started diving into okay well how can i do that now what pieces do i need so if you can think of a poc project that might be a good thing to keep in mind as well and what are some of the pieces that you might need to learn a bit more to get the most out of it and i've definitely got a few areas that i'm looking into and as i go through this you might actually find some red flags that's going to keep you from using it anytime shortly so these are some good questions to keep in mind and you know given time i'll revisit my answers to these questions at the end of the talk and as i go through the presentation please feel free to interrupt i will put the chat on this window so i can check and see um if there are any questions you can feel free to drop them in the chat or just get off the mic and talk to me or i should say get on the mic and talk to me so this is uh the agenda so full disclosure i have been paying attention to container apps for a while since it was announced actually um i thought it was a pretty interesting announcement i had heard about the project before it was public and i thought it was interesting but i didn't pay much attention to it and then once they announced it and really fully described where they were going with it i started"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:05:04",
        "seconds": 304,
        "text": "announcement i had heard about the project before it was public and i thought it was interesting but i didn't pay much attention to it and then once they announced it and really fully described where they were going with it i started paying attention to it but i have only been playing with it for the last couple weeks so i've only got a couple hands-on weeks under my belt so i'm not totally experiencing this and i'm new and evaluating this as well so i've got your typical intro level presentation agenda here so if anyone has questions as we go through this and get into the demos the code the clr or another crc so i let me know and we can totally take this off track but i will try to cover these items this evening before we get out here uh we'll talk about what it is we'll compare it to some other azure services um the examples that they've introduced as it being suitable for some of the concepts that are specific to container apps its features as as it currently stands what cada and dapper is and how you would interact with those that's not really how you would interact them how they would be used or useful in container apps and deployment options i mean how how you get it out there actually it's not that complicated since it's containers but something also to pay attention to is the pricing preview well the preview quotas i should say since it's in preview there are they have uh limited some of the extents that you can use it which is um interesting i guess they don't want to do too many too much bitcoin mining i guess but i've i'll go over that at the end and then we can kind of discuss the pros and cons to serverless models uh so what is it what is azure container apps or i've heard it called aca i've heard it called akka i will most likely be referring it to it as container apps it just rolls off my tongue a little easier so the marketing page has this statement fully managed serverless container service for building and deploying modern apps at scale so that's pretty full of um keywords i guess but to me my simple definition because i'm a simple guy is it is an easy place to run your containerized apps full stop plus it makes using a couple of the cloud native extensions easy which are dapper and cada and we'll get more into that by the way it runs on kubernetes and it uses envoy for a proxy or it could you don't have to choose an external egress but those are both um things you're probably familiar with if you're familiar with the cloud native landscape everyone i'm sure has heard of kubernetes envoy you may or may not have heard but the reality is you don't need to know what it's using under the cover it's like you do with web apps you don't need to know how it's all stitched together under the covers it could be running on service fabric it could be running on iis it doesn't really matter you use web apps to run web apps so that's sort of the way that i'm thinking of at container apps is it runs containers the keda and dapa dapper are really good with kubernetes but it shouldn't be relevant that it's running on kubernetes because you can't control what version it's using or any of that stuff at the moment so just got a comparison to a few of the other services in azure that you can run containers with uh are on i should say azure app services um which is great for websites i mean it was actually originally websites i think uh it's something that you could i believe i'm not sure about functions but you can run multiple containers in each of these but the thing is though they're gonna have the same life cycle so if you have a web app that's running multiple containers and you roll out a new web app well you've got to roll out the new container it's not same time of course you wouldn't have to put a brand new tag on the container but the container life cycle is kind of singular in this this first column um apps app services functions container instances they're they're geared toward towards doing one thing so a function is geared towards to do specific things um app services geared to run a web app and the container instances is the container as a service idea so run a container or run these containers like a container with a side car might be a container group but it's geared towards running a container something you might do in docker you don't need an orchestrator for so the level goes up whenever you want different life cycles so say you have microservices and you have a website an order service and a customer service a login service report service so you have all of these services that may not necessarily want to be the same life cycle you want to add a new report you only need to update the report service you don't need to re update the login service because the login scenario hasn't changed so that's that's the beauty of"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:10:08",
        "seconds": 608,
        "text": "necessarily want to be the same life cycle you want to add a new report you only need to update the report service you don't need to re update the login service because the login scenario hasn't changed so that's that's the beauty of microservices and the ability to uh rev just that thing that you're changing versus changing every layer in the application for the monolith scenario and then rolling the whole pushing the whole thing out and having to make sure that you do your regression testings on the whole application so azure kubernetes service really shines in that light because it can handle tons of services really well and i'm putting azure container apps in the same scenario so it's it's going to handle your uh microservices or groups of logic i mean if they're a background process or whatever um you know they can all run separately they don't have to be versioned at the same time so that's kind of my comparison of the azure services to container apps for running containers it's it's going to be different so if you look at kubernetes service or aks you wouldn't want to go down the road aks if you really only had like five containers that you wanted to run but if you had say 20 containers well then now you're talking that makes a bit more sense uh granted you have the kubernetes skill set and the ability to get it running but you wouldn't want there's a certain bar there where you wouldn't want to bite off more than you could chew when it comes to a service container apps seems to be the sweet spot where you know you could start off with app services but now that you've got a few micro services well now let's go to container apps and then you might be able to grow very large before you need to go to the kubernetes route and maybe you would get to the point where you don't even need to go to the kubernetes service there are some questions along the line of cost and and how all that shakes out since its preview that stuff still um you know hasn't settled yet dust is still pretty cloudy there are a few other services i i mentioned one down here the red hat open shift on azure it will also do the same thing with as aks but um i don't know hardly anything about i do know it exists and i have a general sense of what it does but i i did mention it because i can't really speak to it so any questions yet uh does that really set the landscape of where it fits in for a product for running containers at the moment for you guys all right i will take silence as a good thing good so far all right cool so example scenarios there are a few mentioned in the docs or there are four mentioned the docs and i've added one where i really see the sweet spot for me um for some customer projects that i have and i'll speak more to that and i'll actually show you uh some demos along this scenario that i'm looking at so microservices of course um anything built on kubernetes going to throw that bucket in there microservice is great for anything run on kubernetes as long as it can fit in a container event so the next two are kind of the same thing same fruit i guess event driven processing or background processing basically the difference is background processing could just be a worker that's running 24 7 where event driven or schedule driven like a cron job or something along those lines would run well in here except for the cron job part right now they don't have the ability to do a cron job if you had an external service that would call your service on a schedule then it would work fine but it needs an event right now to do the processing and it wouldn't surprise me if they did work in run processing in the future especially they're using kubernetes under the covers why not it's available on the native side there public api endpoints they've kind of broken this out the public api endpoints well it's a mouthful could actually fit in microservices but they've called it out because they have since they're using envoy um as the proxy to get in and out of the the cluster if you will they can do traffic splitting relatively easy so that's why they've called out the public api endpoints since you can do traffic splitting well then you can do you know 80 to this one 20 to that one i myself have only found that scenario useful in one scenario which is where we push something out we don't want any traffic going to it but we need to hit it for testing and we need a specific url so that we can test it before any traffic's going to it and then we're ready switch it over to 100 versus um 80 20. i've never gotten to the point to where i i would do 80 20 or any um testing like that but that's that's you know everybody's got their own um environments and reasons to do what they do but the plus one that i want to mention is the monolith web application that's in the process"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:15:10",
        "seconds": 910,
        "text": "um testing like that but that's that's you know everybody's got their own um environments and reasons to do what they do but the plus one that i want to mention is the monolith web application that's in the process of being refactored to micro services so the example i have is an old nvc web application it's not net core the idea of course is we'll get it to net core but you know it's a layered application the way we used to write things before microservices you know it's got a data layer it's got a business object layer it's got the ui layer you know it's factored pretty well for the time that it was designed but it's not written in microservices so if we need to change one thing or add one report well then we've got to change the code and push the whole thing out which is you know just the way it's it was back in the day so um the idea is we want to start especially new features writing those in dot net core of course and breaking them out into micro services so we can version them uh separately and slowly move the existing um code into microservices and then you know swap the old one out for the new one eventually but it's going to take some time to get there it's like changing tires on a moving car right so that's that's the the fourth scenario that they don't point out is the kind of the scenario before you would even get to these uh yeah so and i mentioned uh what my example is there so let's let's take a look at it uh to begin with and uh we'll just get uh portal over here so the easiest way to find it is to go to the portal and say container apps container comes up is this nice little purple logo i don't have any in this subscription i had to create container app let's choose this guy i have a resource group to stick them in let's call it j haley akka one there's this concept that we'll get a little more into next of an environment so i want to create an app but to have an app running i need an environment so let's say i will put in east us2 so this level actually has a location monitoring now monitoring is log analytics so i want to know log analytics workspace so let's say j l a w one so we'll create that guy or we'll have it created networking this is so now working i'm just doing a quick demo here but i'll show you you could choose an existing network and with this subscription i don't have any v-net set up if you choose a network you have to choose two subnets one for the control plane thank um the aks cluster underneath apps would be your container apps running so it would be your apps so ones like the management control plane and the others where your apps are going to run so you need two subnets and then you can choose internal or external so the internal would allow you to do v-net only communication where the external will allow you to expose it externally but i'm just doing a demo right now so let's hit create on this so this is back to the app that was all about creating the environment and then now we're back to the app so let's choose some other settings i'm going to go with this demo but if i didn't so they have this specifically for us who are playing around with it get one up and running quick they've gotten smart and started adding that stuff make it easy on us you can choose a another container from uh acr or uh docker hub or some other registry and then choose the image it does have to be a linux image linux based image and you can choose your cpu memory you get a few different flavors here um we can talk about that but ingress do you want it to be available on https endpoint right away or not we'll we'll do this quick start and it will do a ingress port 80. now this port number is for what the container is listening on or exposing i should say and the container that they've provided for the quick start is an 80 so it's it's going to be exposed on 443 but containers on 80 so let's just go to the next let's just do review and create as this is creating let me go back to the slides because it takes it takes about three minutes i think that's how long it's been taken today so that's while that's baking cooking show here now let me go over some of the concepts that we just saw so uh the concepts for how and this image shows it a lot more than the setup"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "how long it's been taken today so that's while that's baking cooking show here now let me go over some of the concepts that we just saw so uh the concepts for how and this image shows it a lot more than the setup that i just did so you've got the environment that everything's being contained and the way i even envisioned this on the back end is like a kubernetes cluster don't know if that's really how it's implemented but this is how i envision it and then everything that you're going to create all these container apps are going to be running inside of the environment the unique thing they do expose is this thing called revisions so you have your container app say say order service so this is an order service and you have version one of your order service going out so you have revision one here and it's got they they call it a pod it's it's it maps to what you would think of as a pod in kubernetes but um really for uh connect container apps you don't need to know anything about that you've got this revision that is your containers that's running so you've got your order service and you make it change your order service now you get revision too and these they keep a certain number of revisions around they don't have to be active you can have multiples active and split traffic if you choose to do so or you can just have one active or or any flavor in between but they do keep around a history which allows you to roll back quickly after you've rolled one out or you can do your traffic split and all that stuff so they have this idea of keeping around multiple revisions um and and that's that's pretty much it it's not all that complicated you got your your containers that you've grouped together the best scenario or best comparison is a microservice we've got an order service maybe it has some side containers um to do logging or monitoring and then you want to re you want to version that as a unit and that's that's sort of how the um concepts and container apps work so let's go back to the i can find it all right so it's ready let's go to the resource okay so we get this url so we are now at the container app level this isn't the container environment this is container app i can go to the container environment by clicking on the link here navigating to it we only have one app so if we had multiple services there would be one app per service there's not much else here one thing that you as you play around with container apps and get really diving into it you'll probably find this interesting as you go the export template and then you can see how this environment that you're looking at is set up for the arm template this is this is useful when you're troubleshooting so especially when you get into the vna integration to see the settings that are that have been uh set up because you might be able to get running in the portal but not via the command line or a bicep template so you know being able to get to how it's actually running is is pretty useful when you're just learning the stuff or i find it useful all right so hopefully this comes back so let's go back to the app um you can see here's the application url and so if i click on this all right so it pops up this is our a container app it is [Music] jason before you move forward too far um how how do you save your quick start image i'm not sure if i missed it or i don't know how did i save it or how did i pick it how did you save it okay so it was just a check box they defaulted all of that for me they they decided what container registry it's come from what the name of the container was it was just a check box and i click i click save on the um create container app so it's not your custom quick start image it was pre-built yep yep then they've they've put it in the portal so it's really quick and easy for you to get up and running actually if you go to so if you go to this is the documentation or the doc site and i've got this link at the end of the presentation sorry i've got an animation i'm going to hide here um so if you go to the cli so let me show you where i was so i'm at the overview this is the landing page of the documentation um under quick starts if you go to the portal this is pretty much what i just walked through and if you go to the cli it's the same thing they've got a the they actually have the container spelled out for you in the portal or in that script here so this is a script that it defaulted to it defaults all this stuff but they've done a really good job on the quick starts and the how-to guides where you can just copy and paste these pretty easily um there are a couple that i ran into i had some errors but um they actually ended up being"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:25:16",
        "seconds": 1516,
        "text": "they've done a really good job on the quick starts and the how-to guides where you can just copy and paste these pretty easily um there are a couple that i ran into i had some errors but um they actually ended up being a bash issue not not their script issue um i can mention that later but the these scripts are really useful to get it up and going and learning the different parts of container apps but yeah it was it was just a checkbox i chose i didn't i didn't have to really do anything so yeah any other questions cool sorry i didn't see the question come on um yeah so that's this url so that's the url for the container app but like we learned there can be multiple revisions of that same container app so you could have you know version of one of order service and version two of order service and and you manage those through the revision management i'll get to the other stuff actually another demo i'll be able to actually show you more detail the secrets ingress and continuous employ deployment i won't get to because it's um github actions i'm going to show azure devops instead so this is um a list of where all the revisions would be i only have one we could create a new one so let's create a new one so i'm not going to give it a suffix um it's based on this one okay let's go and create it so i'm going to create a another revision of the same container app really containing the same thing same container same everything should be up and running soon um as this comes up let me show you a little bit of the ui if there were any inactive revisions by checking this box they would just show since i don't have any inactive and now if i refresh this they'll be two so we have two and this is where you can do the traffic splitting so you could say 50 50 and click save and it would do a 50 50 across the two revisions that i have but the cool thing is if see there zero traffic's going to this revision now because i just put it out there actually this is the older one by default the review the revision mode so revision mode you have two options multiple and single if you do single there's only ever going to be one active at a time if there are multiples then there's going to be two active but the latest one gets 100 of the traffic unless you tell it specifically how much traffic to get or that's my experience i i could be wrong that that happens all the time but that's my experience so this is the old one if i still want to do some testing on this one even though if someone's hitting my url that we saw here they would be getting the brand new one but say i want to still do some stuff on the old one i go into this revision and here's the url specifically for that revision so if i click on this that's only that revision that is not the new revision so it won't do any load balancing if it's zero on the or yeah the traffic won't be going to see zero percent of the traffic's going to it but i can still navigate to it and there's still one replica running so if you have um some scaling rules set and you end up multiple replicas running you'd be able to see what number of replicas you have running on this screen and this is the revision you can kind of get buried in these screens because there's so many levels it's nice that they've hidden the environment or at least kind of put it off to the side because you've got you've got the app level you've got the revision level and then you've got the individual levels of each revision so a little navigation here you can get information about this specific revision running uh what uh see there's there's really not a lot of information i mean that's also some of the great things about containers is there's not a lot that you can customize what's running where is it running how much resources it has that's pretty much it for this i don't have any environments variable set no secrets or anything like that scaling um we'll get more into this later but if you wanted to set any scaling rules um there's another blade that would or another blade that would show you where it's at and if you have dapper turned on this is where you would see your dapper components configuring all that stuff so that's a quick overview of the portal um actually there's one other things we missed was logs so logs goes to log analytics as you saw when i was setting it up so let's see what was output for this environment as we were doing it okay so this is a question i asked earlier on discord so i'm querying all logs on this and there's nothing coming back yet so we'll have to check a little later there they they said that they ship logs within seconds but um log analytics could take a few minutes before you actually get it so we'll check back on it later and"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "we'll have to check a little later there they they said that they ship logs within seconds but um log analytics could take a few minutes before you actually get it so we'll check back on it later and see if they show up can you set custom dns name and tls certificate oh that's what i was going to show so [Music] the short answer currently is no um not in container apps so the question i don't know if i repeat the question the question is can you set custom dns name and tls certificate um and let me show you i opened up firefox for this here so this is the container app in firefox and i wanted firefox because it's the dev firefox and i can show you the certificate info so it wires up https for you which is nice however it's going to be a see how do i get to the more information okay here we go another screen security view certificate so here's a certificate that is wiring up so it's going to be a wild card certificate just like if you it compares to web apps for me i mean i may be missing something technical on this but it compares to you know you have a web apps off of the the.net um url that web apps gives you it's https but it's it's a wild card um and that url is coming out once you i do believe they are working on solving our networking problems but they're not the highest priority so i have a good confidence that they know what we need network to do especially if you can do it with web apps you're most likely going to need to do it with anything running in container apps but they're not there yet not with the uh not with the preview functionality does that answer your question jim yes thanks all right cool so where are environment variables set up so environment variables can be added to you can do that with the command line or you can do that let's go back to here okay let's try to do another one i don't know if you can i've not tried to do environment variables in the ui but let's try it in the edit mode so one thing i didn't show when i was uh diving down in the divisions here so if you go to a revision you can edit here uh there is a json view alright so we can't do um the environment variables here so let's go back i've not okay here we go json view here we go so here's the json view but it doesn't give you the chance to edit it if there were any environment variables they would be in this section under the template so i'm not sure if you can do it in the ui currently you might have to do it via a script either with the the command the cli may not even expose it yet but we can look at the help a little later you can definitely do it with the the bicep template in the arm template but i'm not sure about portal yet explore that a little later uh okay so that's the concepts so the features that are there currently you can run multiple containers um obviously and and multiple versions of your apps so you've got the multiple container versions which you also have the splitting traffic which is useful if you want to do that 80 20 rule you can auto scale so they do have two scalars stuck in the box http so you can say whenever you get so many concurrent http requests scale it or you can do it with an azure queue or you can go out to cada and do the 30-some odd scalars that cata uses um i can touch on this but for those of you familiar with kubernetes you've most likely done something with a horizontal pod scaler and you may or may not have done anything with the vertical pod scaler but there's no idea of a vertical scaler in container apps so if and those are useful in the scenario where you've got a service that you didn't quite know how much memory it needed and it keeps hitting the memory and and killing itself that's where the vertical the pot vertical pod auto scaler comes into play because it can restart it with more resources whenever after it gets killed but there's no such thing in the container apps yet so you kind of have to know how much how many resources you're going to need to have an idea to set those resources the auto scaling it does right now is completely horizontal it'll stamp out multiple replicas given specific rules that you give it the enable"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:35:23",
        "seconds": 2123,
        "text": "how many resources you're going to need to have an idea to set those resources the auto scaling it does right now is completely horizontal it'll stamp out multiple replicas given specific rules that you give it the enable http ingress that's cool but they definitely as jim pointed out still have some features they need to add on before it's going to be useful in prod internal ingress and they have the service discovery which i've got a link in here which is similar to uh uh kubernetes type thing where you can discover your services off of the uh url that are fqdn um really the way that you're going to want to do it is use dapper but that's that's topic comes a little later you can build microservices with dapper super easy you don't have to worry about installing it you just check a box and it takes care of it for you so you have to know how to use it and that's where i'm at um run containers from any registry um which makes sense uh you could do it from github and acr out of the box or you've got your ability to put the cred credentials in there for another one i use azure cli extension or arm and bicep templates provide an existing ex existing v-net that one's got some glitches in it today they're working on getting those fixed but um you can surround it in your own v-net which is super super useful especially if you're going to do micro services you don't want those available in some other v-net though they do get wrapped in a v-net and you can control the ingress so it's not total but you are most likely going to want to put it in your v-net not some other network manage application secrets i changed the wording on here from what they had on their site uh because it they're not it said they said something like secure apple secure something secrets and they're not securing it it's just base64 encoded like with kubernetes which it's just an application secret um they're most likely going to really build that feature set out i couldn't see them going to production or at least much past version one without fixing something so that you can get it out of the key vault but um right now it's it's like a kubernetes secret it's base64 encoded which i'll show you an example soon um and you can view application logs which we saw on the analytics logs uh any questions out there before i dive into a more detailed demo oh cool okay jeff did you have a question i was gonna ask is uh manage identity supported not yet but it is on a short list so it will be coming soon you that's the other thing is there's so many things they know they need to add it just aren't there yet so the team's working hard on um so this next demo this next demo is me diving into what i find relevant for the service as it is even just the minimum features that they have currently i can really see this especially when it goes ga i can really see this using this on my client projects so i have like i mentioned earlier some client projects that are old nvc applications um and we want to start moving things to microservices and net core and all this stuff but our hands are tied because the car is moving we can't change the tire so easy without stopping it so this is the avenue that i'm looking so what i have is i have a web application that let me just go to the resources here so this is the resources so the majority of these items besides the website stuff or the web application stuff the v-net the container app the log analytics the private dns these were all created from the scripts on the quick start site or the documentation site just followed those i did have some problems with wiring up the v-net to my to an existing v-net they gave you they gave me the scripts to create the v-net the only thing i had to do is i added a an additional subnet for the web app to be integrated with because the the web app likes to have its own subnet too so i had to add a subnet for that but other than that it allows me to connect my web app to the container app via the v-net integration so that it doesn't go outside in a public virtual net network so this is a web app not too exciting for this talk i can show you what it looks like it's right here well the home page is here template right"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:40:27",
        "seconds": 2427,
        "text": "doesn't go outside in a public virtual net network so this is a web app not too exciting for this talk i can show you what it looks like it's right here well the home page is here template right out of the box but what i have is i have this orders controller that calls the container app over http clients going over the v-net to container apps and then it returns this list and if i keep hitting it you can see the guides change and the times change so not all that exciting but it kind of proves the point so let me show you the integration part so if you go to the networking which i can never find that work so networking i've got the v-net integration turned on uh it's pretty much just configured you you well it's configured now due to some issues that they were having earlier today i didn't want to do this from scratch because it wasn't working the integrated v-net stuff wasn't working with container apps um so if you've ever done v-net integration with a web app it's pretty much i should have brought one up to show you it's pretty much you choose the v-net and you choose the subnet if you don't have a subnet then you create a subnet to have your web application connect to your virtual network to via that subnet and that's all this is doing this is just mapping this v-net which i'll show you the the container apps is also in and it's just the web app is using its own sub-domain so if i go to the v-net i can actually show you the v-net so this is the v-net resource which ignore the man behind the curtain here uh subnets so the control plane that's one of the items that's in a script on the documentation page applications that's also scripted on the application or on the documentation page i was playing around with the subnet gateway the v-net gateway and i i haven't got that one all working yet um and then i added the the web app to um map to my um web so that's that's the integration part of the web app any questions at that point okay cool all right so that's that's all that's really interested on the the web app side so now if i go to the environment so this is the container and apps environment again i jumped into the environment level not the app level just because i was in the resource group listing but i wanted to show you this the static ip address for this environment app is an internal ip address which is kind of important if you want to make sure that you're going over the internet or the v-net so let me see if i can pull this guy back up uh yep nope let's try that one this one so if i go back to the environment on this one environment we'll see it's a public ip address so this is a public ip address so that's one key difference you know i've got the private ip address on the one that's here and the other one is a public ip address and it tells me the two different subnets that it's configured to use and i could go to them so now i look at my apps and it's just an app that i call the or api and this is where you could see more of the the features here so this is all the same um you know we've got our url uh nothing exciting there because you can't hit it publicly so if i go to this one it's not going to do anything if i hit try to hit it with fiddler same thing you know get an airbag because it's not it's not publicly exposed so now if i go to i don't think it is let's try this if it is well then you know i've been wrong before yeah the api is not publicly available which is good that's that's kind of the point of this demo so secrets so this does have a secret and it's the secret to my um my acr and my container registry where my orders api application code is the ingress is configured slightly different um i do have ingress enabled because i want to expose the http endpoint to my virtual network but i want to limit traffic to my virtual network and my container exposes 80 as well i didn't do continuous integration through this if we look at revision management i have this one set up slightly different i have it set up for the single active revision and if you look at this you'll see there's a several other revisions that i have been playing with so there's just one active item that's pretty much all it's interesting on this side so any questions on that so that's that's the web app calling the container app um over a virtual"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:45:29",
        "seconds": 2729,
        "text": "have been playing with so there's just one active item that's pretty much all it's interesting on this side so any questions on that so that's that's the web app calling the container app um over a virtual network which is um something i was really aiming to get that that will help me solve some customer problems okay so now questions cool and i will show you the devops portion of this soon so demo is good caden dapper so this one i really did want to do a demo of this but i couldn't do it justice cada i do have experience with i've used it quite a bit in aks um it gives you the ability to scale the the ways that i've used it mainly is q scaling so um when work goes into a queue and it reaches the queue reaches a certain point then workers spin up and scale out and then once the work's done it scales back in works out really well dapper oh actually let me go let me go to the size here so i can show you teach you to fish here um so this is the the cada site uh it has the concept of scalars um it's basically an abstraction of scaling providers how do you want your scaling of your individual container app to be controlled and the experience that i have is with the azure queue storage queue so i've used this one quite a bit so whenever something hits a cue that's when i want a pod to spin up and do some work or whenever it hits you know more than five then spin up another one actually when it hits ten spin up another one so that's that's how i've used cada it's it's abstracted away how your your application or your application code can be horizontally scaled there are two types of scaling in cada one's a scaling object and one's a scalar or scaling job i believe that's it scaling or scalar scaling job i could have it wrong no scale job so they're skilled job and then they're scaled object so that that's the different versions they don't have scale to object implemented yet it's a just skilled object so skilled job isn't there scale the differences are a scaled object is like a service so when when say my order service receives 500 um requests i wanted to to scale out a lot of order services so they can process that and then once the number gets down i want it to go back to maybe only one version but a scaled job would be you want something scale to start up and then when it completes it goes away so though that's two different flavors are sort of the same thing but they are different the scaled object which is more service oriented is the one that's currently there um we have a question the microsoft advocate team i mentioned earlier their team runs an itops team so we've got some links all right cool thanks andrew all right so the presentation the dapper one okay so first off before i jump off of keta keda has their help on a slack channel which is over here uh off of kubernetes so if you go to kubernetes um cada this is their slack channel so if you're banging your head against one you cannot get kata figured out um you can ask questions on the slack channel it's you have to go to the kubernetes slack and then add the uh keda channel they also have a and i'll mention this one later um an azure container apps has a discord server and then they also have a channel specifically for cada so if you're doing azure container apps and have a specific question towards cada you might want to ask it here first but that's two ways to get help on cada besides of course the documentation and there's some samples linked off of the documentation so dapper dapper and michael could help me on this um it is i believe it started i'm sorry michael mark could probably help me on this i believe it started out as service fabric mesh and then was refactored to dapper um so they actually started from scratch okay oh they did okay okay yeah service fabric mesh was was a whole massive service fabric thing designed to run containers okay okay i'm wrong on that so this has a lot of features that you can use to integrate a microservice especially microservices um like service invocation so you could call an endpoint on one of the other services uh pub sub that's uh often a need"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:50:34",
        "seconds": 3034,
        "text": "a lot of features that you can use to integrate a microservice especially microservices um like service invocation so you could call an endpoint on one of the other services uh pub sub that's uh often a need whenever you're doing microservices because there's just always a synchronous connection there uh secret management i don't know what input output binding is so i can't really talk to that state management is the abstraction of a state store makes it easy for you to save stuff in your application and then you can swap out state stores relatively easy if you need to do so for different environments and virtual actors i don't know much about either so dapper is one of those things i've been looking to dive into i just haven't been able to find a reason to do so so container apps is going to give me the ability to do that for dapper help as i shown here they have adapter channel and container apps but there is also server they have a discord server as well instead of slack so that's two ways to get help on on dapper related questions so uh we're doing on time 710 so let me yeah let me go back to the i just want to show you the dapper actually i'm not going to be able to do that given that show you this so this you can probably you can do a whole other session on dapper oh yeah definitely um i just don't think i know if you want to collaborate on that oh absolutely i've got i've got so much to learn on dapper anyways this is it's not available when you go to edit a revision to change it yeah so i can show you some code soon um but i don't have i don't have a demo of dapper upright because you just don't know enough about it so deployment options currently to get container apps out and running for you portal you saw that relatively easy to do i don't know that you can do environment variables like irene asked for um the cli that the cli demo code on the documentation for container apps is really good it really shows you pretty much everything you would need but let me show you since it's still in preview the command isn't on or i haven't been able to find it on the documentation site so it's a z container app not container space app is container app all one word so if you type that oh yeah hold on let me show you this first you can start navigating the help but you'll have to install something first so if we go to the overview so this is the documentation site and again this is going to be at the end of the presentation you'll need to install the extension so this is the extension for the cli if you do powershell if you're into that sort of thing you can try the powershell flavor i haven't tried powershell honestly and then you uh have to add the provider a registered provider i guess you do these two things then you get the container app uh available to to do these the things that i'm getting ready to show you so the container app help that's the high level stuff if you want to do anything with creating an environment or updating environment you would need to look at the env so you can just navigate the help documentation they have already built in pretty much by just doing the dash h and um reading it they've they've got pretty much the documentation here it's just not on the website i haven't been able to find it on the website uh the other app is this one so like if i say i have any available ipad so i do have one all right okay so this is my my sample one and i've got the table uh output by default or otherwise you'd see a bunch of json um but you could do a lot of other things to you know create delete list scale so let's let's take a look at scale scale so this is what you could do to set the scaling of a container app because that was this is at the container app level not the ian not the environment level so you can basically navigate around what you need to create so let me show you create so if i go here create and the like i mentioned the um the docs sites really good see they give you quite a few demos here as examples of what to do so they're definitely building this out it's not too difficult to figure out so this that's the"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "00:55:38",
        "seconds": 3338,
        "text": "the docs sites really good see they give you quite a few demos here as examples of what to do so they're definitely building this out it's not too difficult to figure out so this that's the cli um arm and biceps so let me show you some code and then i will mention where this came from towards the end uh let me find this not bore you with my directory scratch structure back uh up back up others okay so here so i have two directories um that's a code videos that i found and i have a watch list of 25 different videos of azure container apps that i will show you the link at the end so you can see those two of them one of them was in the ms reactor and that was just a week or two ago this is the sample code um from their talk uh see the they didn't i don't believe he did the bicep let's see i'm looking for is some bicep code i believe it's think texture that did the bicep code so if i look at the multiple container this is this is an example that actually uses um the dapper so if i look at the bicep this is pretty useful so this is going to be the devops this is where i pretty much learned how to do the bicep code for the devops demo that i will show you in a second um so see here's the dapper tie-in um it's just metadata pretty much it he's got some really good factored bicep templates he's done a really good job on this but nonetheless uh i will give you some more information on this so that you can watch the video to to see this sample code he did he does three good demos and it's really good bicep code which is pretty useful for container apps these days or pretty much anything so let me show you the devops so the web app and i i recognize that devops is kind of old school these days which is okay because you know as i mentioned the this my example or my poc is an old mvc application it does do deployment via devops so the question is how can i work this into the same pipelines that we already have so what i want to do is i want to bring up the code i don't think it's open it isn't all right so i can find it all right so here's visual studio uh so i will talk to this later this is the controller so this is the web controller all it's doing is it's grabbing a url out of the config and then it's going to make an http client call across to the web api which is via the v-net integration come back with a list and then display it on the ui the a web api is just this dumb list that shows you the machine name and just an order with some timestamps get added whenever i create the order so let me change it it's currently doing 15 so let's change it to two so it's very obvious that we've got new code here so i'm just going to check this in and push so this takes about three minutes to work through the pipeline so let me show you the pipelines okay so pipelines and i do have it broken apart um it is a yaml pipeline on this end but so this is the order api so it's got the um continuous integration turned on so it will kick off whenever i check something in because i've got it watching the order api path of the source code this is the um so all it's doing is it's building the docker image publishing the docker image and then i'm i'm moving over the bicep files that i have in this project so that the other side the release side can take that bicep file and push it out it can be done differently but i need that bicep file and the release so that i can push it out because they don't have a task yet okay so the build's done and wait hold on that's not wrong that's the web the build is done now the build's gone sorry i was looking to release this so the release is different um the release is the old school ui it's not a yaml so all i'm doing is i'm running an azure cli command you could also do instead of doing a bicep you could do the az container app update and then do the"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:00:41",
        "seconds": 3641,
        "text": "it's not a yaml so all i'm doing is i'm running an azure cli command you could also do instead of doing a bicep you could do the az container app update and then do the command args that direction too so that's another option i chose to go with a bicep just so i could play around and bang my head against the wall with azure container yeah with azure deadlocks for a while so i'm passing in the registry secrets they go into the um bicep template and then have the whole thing just push out the new version so the the new tag is going to be the build id so there's a number on the end of my builds and then that id is going to be the tag on the new image so that's the release so now the release is kicking off because i've got it turned on to do the continuous deployment whenever um the build gets done so again this is you know kind of the automated flow that i'm used to with regular old applications but this is pushing it out to a container app versus the um website itself all going on at once now the the interesting point and this is nice due to it being containers and i'm not sure how this is going to work going down the road but since i've got it running in my virtual network um i'm able to push from devops to container apps in my virtual network and i'm not quite sure what's open there and and whether or not that's going to get closed in the future to tidy things up but typically if i've got something wrapped in a virtual network i can't push it out to it but this will come out in a second whenever i hit this it will go up it's there so now we have our two going out versus the the 15 that was going out so that's the new version of the api if we go to a revisions revisions management this was pushed out at 2115 right that's when it was created it was refresh all right so now we're at 0 20 15. so the other one the oops sorry just made it inactive uh this one right here so that was the previous one so that pushed out our our new image just by checking in the code and pushing stuff up there can you just do a roll back here if there was a problem i could do a rollback by just turning the active back to the other hit save so let's try that because it doesn't take too long to save look at that we got a nice little air 403 the web app is stopped the back is back it's back it's not back okay so this was the provision okay so now it's there huh well that's not very seamless i had to play with that one so this is oh hey this is weird so now i have zero percent traffic going there i'm not sure how to do that try oh we'll go back to this one this is something i haven't done that's a good question okay so now let's change a hundred percent these numbers do have to add up to 100 so let's say let's see if this does it it's definitely not seamless wouldn't be an ideal scenario but i guess rolling back never is okay let's see cross our fingers i had to figure that one out let's get back to you on that one there's got to be a way to do it there's got to be a way to do it roll back it's a good question okay i'll give it one more try here and then that's it any any other questions while we're playing with this failure all right so see this isn't that's weird 403 the web app is stopped interesting is that my web app that's got the problem i don't know i won't spend more time on this there is a way to do it i'll have to practice that one and i'll let you know but yeah i mean there's no reason you can't roll back the the previous revision was there just need to uh figure out how to do it it should be something that you could easily do on the command line as well since that's all doable on the command line okay so back"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:05:43",
        "seconds": 3943,
        "text": "revision was there just need to uh figure out how to do it it should be something that you could easily do on the command line as well since that's all doable on the command line okay so back to the slides here okay so pricing now this is an interesting one and i don't know if you can read this give me a little bit so this is my problem with serverless um is this small number to me is just it just makes no sense it's so small that it makes no sense to me so i calcul i did some calculations just off of the ballpark um what if i had one cpu and i forget maybe one gig running 24 7 for a month what would that calculate out to just to give me an idea what these numbers mean it would be nice if they would give you a monthly but i i get that i get the idea that that's not what they're charging by here but um let me show you the calculations i came up with so this is the calculations i came up with and taking into account some bandwidth so it's roughly the amount that would be an s1 for a web app running 24 7. granted there's there's no storage coming involved but roughly the same as an s1 but the cool thing well i mean and i've also highlighted log analytics is another question if you're sending a bunch of stuff to log analytics it can get expensive so that's another cost that is also a big black magic trying to figure out what that would cost but predictive estimates for this is going to be practically impossible you're going to have to try it out and see how it is because you get a charge per request i mean granted you get 2 million free but there's a charge for request per million i mean that may or may not apply to you the million wise but um you know with these numbers being crazy small it's difficult to predict so that's just kind of a difficulty with per or serverless i guess they call it pricing structure okay so quotas for the current preview um for subscription you can have two environments running that's why i've been jumping between two subscriptions i don't know if you noticed one browser is one subscription and one's another so you get two environments per subscription you get 20 container apps per environment you get 25 replicas per app and then you can do two cores per replica and then you can do 50 cores per environment so this is kind of the big cap right there but those those are kind of um enough for you to totally play around with it and and try it out see how it's working but uh just keep that in mind um you need if you have one subscription you can really only do two environments but if you have multiples then you just have to worry about dealing with determining which subscription you're in um so some resources i have and i'll make the slide deck available um these are the blog posts this one basically is the introduction of cloud apps it was around the ignite period pretty descriptive where what they want it to be the connected microsoft it's a little more information than what the previous one was if you're interested in the whole v-net wrapping of container apps this last one's going to be very interesting to you and i see jim's typing a question some additional resources this is just the docs link that i found it's a little shorter than the big one github issues are being tr issues for it are being tracked in github there the code's not there but you can see the issues that they're tracking um the discord so that was this one they have a discord uh server so that you can ask and also learn so if you go to general you can kind of like here i mentioned there was an issue earlier today so we're investigating an issue with the environmental creation v-net enabled and we'll update soon i mean it's kind of cool to have some visibility into what's going on and a place to ask some questions uh so jim asked what's the future of aci there is some overlap and functionality they run containers that's it you know i don't know i haven't asked any one about that so aci is kind of a building block because there's there's stuff on the machine learning side there's functions may actually use aci to run its containers i don't know i'm probably wrong on that there's definitely other things that use aci so i don't see it going away but i can see its usefulness not being as useful if you have more than one container to run it seems like jeff"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:10:49",
        "seconds": 4249,
        "text": "wrong on that there's definitely other things that use aci so i don't see it going away but i can see its usefulness not being as useful if you have more than one container to run it seems like jeff holland just answered this question for someone i i'll see if i can find it and post it let me write that down um but there there there's definitely pros and cons to each if you're doing multiple containers i wouldn't want to use aci but if you're just doing one container for like a visual studio agent to do building and you just need that one container you don't need a container environment with just one container app running then i could totally see just using aci so i see a usefulness for it the drawback to aci is you need something on top of it to manage anything that requires multiple um right yeah it's like docker before kubernetes yeah it's totally useful and it's stuff that can be built on but yeah i mean i i see your point jim if you're if you're doing more than one i don't i don't i don't know why you would use aci i don't think there's really actually i don't think there's overlap here because it's kind of like aci is as bare bones as you can get from a container solution and this is trying to get closer to a dev friendly deployment platform true yeah and if this is really deploying some sort of a cluster behind the scenes it's definitely overkill for running something small and simple yeah but well so let me give you the microsoft perspective on that we're here to make money we are we are a profit-making organization so tiny workload we're not going to support a platform for tiny workloads there has to be real consumption behind it for it to matter long-term that makes sense now this is the resource that i would recommend you take a look at it's the list it's the 25 videos on azure container instances or con instances container apps that i've found on youtube the sample code that i was showing you is this red one right here the all things azure containers it was presented by thank texture just last month this microsoft reactor one was the other code that i jumped out of it's also a very good one it was just presented a couple weeks ago the 16th or last week so they're all very current i mean it had to be current since it was just announced in november these three are good because they dive into pieces of the stuff this one goes into a good dapper um demo and this one actually uses dapper too bicep cada and dapper you just include included in the title so these three are really good highly recommend those um good content some good diagrams to help you understand it um yeah this is a good intro as well it's the blaze i forget what blaze's last name is from when went to locked he did a good overview it was in november so it was early after it was announced um but he did a good overview so it might actually be a good one to like move underneath um jeff's whoops by the way for um for dapper in general there was some dapper there was a dapper con at the end of october i think those sessions are worth watching and there was a very good session the donovan brown and um drawn abrupt blank on her name right now presented at kubecon in early november very good sessions for it yeah was it um anyways i've started collecting um dapper videos but i i don't really have much there yet so i haven't really posted that link but um that's this last link is the one i'm i'm still i'm still working my way through those videos but they're definitely informative some of them are more than intro especially the ones that have sample code and if you hunt out their githubs oh i'm working on some blog postings for all the stuff that i've learned in the last two weeks digging into this stuff and i'll and i'll include all of the github repos and all the sample code that i've found useful from these presentations that i've found you can do a little investigative investigative research and find them yourself but it's all out there not everything's tagging azure container apps in uh github there are a few available um or easy to discover but not not everyone's using that yet but seriously the value of container and container apps differentiates when you consider the dapper plus kita plus encore parts of the of the of the service without that it's another container hosting option and it's not as compelling so i would definitely encourage everyone to focus on the application perspective on this this service rather than the kubernetes aspect of it yeah i totally agree i i think the"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:15:51",
        "seconds": 4551,
        "text": "without that it's another container hosting option and it's not as compelling so i would definitely encourage everyone to focus on the application perspective on this this service rather than the kubernetes aspect of it yeah i totally agree i i think the fact that they tell you it's running on kubernetes and they tell you uses envoy really just doesn't matter it's almost like when i worked for a startup in 2000 and we were using the oracle database because that's what the venture capitalists wanted us to use oh we use oracle it's like well okay that's great it's database and we gotta get the app working before it matters what the heck it's running on so the fact that they tell you it's cada and envoy almost sounds like they're just trying to get more buzzwords because you're not using it to utilize their product so a little insight so aks is considered extremely complex to deal with even though it's less complex than doing bare metal kubernetes it's still complicated and the idea behind container app service is to make kubernetes much more approachable largely by hiding it right so you can get the power of it the benefits of it without having to deal with it which you know going back over some of the you know the original cloud services story was amazing because as a developer because you could just build your asp.net code and deploy it to a web world web role without dealing with the vagaries of maintaining and deploying a web role you know a web server so yeah it's the same idea that so often when we you look at why we do things you need to flip it around and look at it from the perspective of our enterprise customers and what they've been complaining about and that's what this this is the first steps on solving that problem after we squash service fabric for no particular good reason yeah and i i i'm not before i can totally see where this is gonna really turn into a powerful service because i mean take take what was websites before they turned into web apps and then functions came off of that i mean everything that they've added that app service over the years and how useful web apps is now just to do something simple with the web app you have all kinds of choices now and i think they really are onto something here because i mean everyone's trying to abstract away kubernetes every everybody wants to push kubernetes to the bottom and build on top of it and you know just win because you've got this open source framework that you're working on instead of having to roll everything yourself i mean like like the original web apps um infrastructure i was trying to find the diagram that i'd seen in a presentation what you're doing let me ask andrew a question andrew you're an ops guy right is he is he here yep he's here but he's muted did you forget to unmute he fell asleep sometimes i have that sort of um yeah because the really tricky thing of the way we build stuff is we are still very operations focused and yet on the other hand we're trying to win the hearts and minds of developers so if you look at that part of the story and you look at kubernetes those two things don't go together so this is an attempt to do that unfortunately what we're doing in this case is not really painting a clear picture and we're leaving it up to all of you to figure out the value of it well so some so sorry were you gonna say something andrew before i jump in he's trying yeah um i i don't tend to touch this kind of tech myself i tend to look after um like this the the app support and the dev development teams i don't tend to do but directly but my job is sometimes like a middleman so i might have to go to the app support or speak to the infrastructure team but i work on different projects so i'm more here to find out a little bit more about it and then i can go ask and then understand it better that's that's my main um i guess position at the moment but more to pick up what jason can maybe share i've asked a few questions already but some of the developer guys they were saying well what is this they don't understand it so i think what jason was saying like kubernetes may be sort of similar but different but where do you apply it no yeah now you really want to devote it really is a place to deploy deploy container-based microservice applications which is why dapper is in there which is the distributed application programming runtime something like that application runtime so you know distributed computing predates containers and all of these kind of things all this science computer science goes back to the 70s and this is trying to make it real but it's being built by a company that only knows how to talk to ops people which is why i called you out here thank you um and you know the concerns that operations people have is very different but to the point that you're trying to if your people are"
    },
    {
        "speaker": "",
        "title": "Jason Haley: A look at Azure Container Apps",
        "videoId": "PBXGNiiwQv0",
        "description": "This is a recording of the February 24, 2022 virtual meeting.A look at Azure Container AppsAzure Container Apps is a \"fully managed serverless container service for building and deploying modern apps at scale\" currently in Preview.In this session I'll introduce the service, show you how to use it, discuss some of the scenarios it is targeting and dig into some demos to highlight its current feature set.PowerPoint: https://jhaleyfiles2016.blob.core.windows.net/public/A%20look%20at%20Azure%20Container%20Apps.pptxTime line0:00 Introduction0:25 My Assumptions About You2:20 Questions to keep in mind tonight4:53 Agenda6:50 What is Azure Container Apps?8:36 Compare ACA to Other Azure Services12:55 Example Scenarios Mentioned in Docs + 116:47 Demo: Quick Look at the Portal20:13 Concepts22:21 Demo Results of Creating Container App30:49 Question: Can you set custom DNS?32:34 Question: where are environment variables?34:00 Features38:42 Demo: Web App Calling API in Container App Over VNET46:05 KEDA and Dapr51:49 Deployment Options57:54 Demo: A Look at Azure Dev Ops1:06:00 Pricing1:07:53 Preview Quotas1:08:49 Resources1:09:29 Additional Resources1:10:23 Question: what is the future of ACI?1:12:41 Azure Container Apps Playlist1:15:42 Did you answer the questions?1:26:39 Questions?## SPEAKER BIOJason Haley is an independent consultant who focuses on Azure, Kubernetes and Angular. He has 20+ years experience architecting, designing, developing and delivering software solutions using (mostly) Microsoft technologies. He is also a Microsoft Azure MVP and leads the North Boston Azure User Group.Twitter: @haleyjasonLinkedIn: https://www.linkedin.com/in/jason-a-haley/",
        "start": "01:20:53",
        "seconds": 4853,
        "text": "only knows how to talk to ops people which is why i called you out here thank you um and you know the concerns that operations people have is very different but to the point that you're trying to if your people are coming to you and say what is this tell them it's a really easy place for you to build a microservice application or a distributed application and deploy it here so that's the that's the one sentence answer for you to go power the elevator pitch as we like to call it the rest is details okay all right nice one thank you there's like maybe some examples or you can do this with it you can do that with it and this is where you might use it on how you might go about it well find out if they know what a micro distributed application or microservices application actually is have they read building microservices by sam newman and then if they have it'll probably be really obvious what you should do with it and if they haven't they'll have the same misperceptions about microservices that everybody does in which case call me how do you spell sam newman sorry uh n-e-w-m-a-n cool sam being his first name yes yeah he's from your side of the pond he's from your side of the pond they're probably know of so some of them do you like microsoft some like um [Music] like distributed computing and bits and pieces around that it's just i'm trying to move more into azure more microsoft stack but it's where i fit in i don't know yeah this is more generic than that right cool if you think about the beauty of container well microservices in general the technology that you use to build the microservice should be irrelevant all right and except it's gonna run on linux right now um actually so here i i can do my usual controversial thing i am actually pretty actively recommending that my clients don't use windows server for the back end if somebody tells me they're running windows containers my standard question is why okay because windows containers are not actually containers and um but no i do not consider the fact that it only runs linux containers at this point to be a shortcoming only old-school microsoft technology people do i can't run my mvc apps on it man i've gotta i've gotta run those outside not your dot-net they can't right so flip them over to net six and move on i can't dude i can't what i can't not everything's supported just the way it is yeah i know i hear you still stuff right on cobalt so you know it's not a new problem yeah no i hear you and then maybe you can't maybe this isn't the platform for those apps no but it's a great so for me it's a great place to start picking that old one apart and throwing it into core and put it into and it gives me a perfect place to run these containers as opposed to you know they're they would never pick up kubernetes i mean so you start off with two services well we're not gonna they're not going to pay for kubernetes running a customer customer customer of mine they won't you know you sound like you've been drinking like i have i haven't i haven't yet i just can't talk um not yet anyways the um last year i couldn't spell engineer now i are one yeah anyways it's just uh the situation we want to start refactoring the site and picking things off and putting it into microservices but it's not going to happen fast and we can easily start doing two we could break two off pretty easy and then new stuff we can add into microservices so before you know it we're going to have say you know three four easy but you know that doesn't we you can't justify kubernetes with three micro services you can with container app service yeah exactly but that's that's container app service not kubernetes but nonetheless so um back to the presentation uh did you guys keep in mind what the questions were and did you answer your questions for yourself so um here are my questions like i i do think it's relevant for my workloads and i think right now is a great time to start because what i need it for it already provides enough of to get a poc working so you know i've got a poc i've got the idea the the raw ideas down but i need to start actually going down the path implementing things i do want to dig more into dapper it's going to be a little while but you know i've got to get one micro service out there before digging an adapter is going to help me in that implementation but i want to get familiar with dapper how to wire stuff together where to use it why to use it kata i'm already familiar with so i'm pretty comfortable there red flags that i see right now just troubleshooting there's not a lot of tools for you to troubleshoot logs are slow so logs aren't there within a minute or two so that can be totally frustrating if you're trying to to troubleshoot something when it worked on your machine but you put it out there and it's not um so troubleshooting can definitely use quite a bit of love but anyone have uh any questions or answers to their questions or scenarios that they they thought of that they want to bring forward i have a comment what's your comment do your best to use it the way we built it to be used well how's that microservices um whatever things we've implemented we've tried to hit like the 80 20 rule which i think you mentioned yeah everything we do is 80 20 overall so you want to try to stay with that enterprise customers in particular are very get very much into the details the nitty-gritty of doing things in a particular way the give get of cloud computing is we we assume the burden for you and you lose a little bit of control when you do that um so that that's my my guidance on this service as it has been since the beginning for if any of you around here have been listening to me for the last 10 years so um jason's right it's still a work in progress um treat it as such but and also and our marketing is is rough on this we don't tout the value of having dapper and kita and envoy present that is the primary value proposition as a developer for you to use and leverage that sounds good and i totally see a lot of potential with it so i'm definitely going to dig into it and with that i will stop the recording because "
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:00:01",
        "seconds": 1,
        "text": "Vaibhav Gujral: Demystifying Azure Networking. This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV). let me know once already so the recording has been started so for anyone who's doesn't want their name or voice or questions to be answered and that might be a good time for you to leave and then catch it on YouTube when we get to posted but the recording has started all right thanks hey everyone good morning good afternoon good evening depending upon which of a time zone you are in thanks for joining us life to refer this session if you are watching it on YouTube I welcome you as well I would like to thank Jason Veronica and others who run this user group for giving me an opportunity to speak today I'm going to talk about as your networking this is going to be a level 100 session where I will touch upon different as your networking services that this will not be a deep dive session into any particular networking service but I can assure you that it will be helpful to you if you are planning to learn about as a networking it would also be helpful to people who are preparing for their as your role based certifications so just the disclaimer are not a networking expert I come from application development background but I do work extensively on as you're making it extremely important for me to know the networking aspects of the cloud if you have someone like me who use as your at your day-to-day job or if you are willing to learn as your I hope I'm going to make it easy for you today I'm not saying that you will become an expert in as your networking after my presentation but I can assure you that I will share enough information with you that will help you get started and keep going with that few guidelines if you have got a caution or doubt in between the presentation please post it on the chat window I will get back to those as and when I get an opportunity or at the end of the presentation please stay on the mute do you avoid any distractions and if you would like to talk to me I would be more than happy to hang out in this meeting after the presentation with that let me introduce myself my name is Babu Jerrod I have over 14 years of experience working on enterprise class applications I'm Microsoft certified as your solutions architect expert and I also hold few other certifications I am currently working for qubit as a cloud architect here in Omaha Nebraska I'm also an organizer at Omaha as your user group which has over 750 community members in meetup and as an organizer I to organize user group meetings and manage user groups website social media presence and the meetup pages feel free to join the community if you are interested as Jason was mentioning we have also gone virtual so everyone is welcome in our meetings I'm a regular speaker at user groups like this one speaking on Azure related topics and I also blog on battabox real calm recently my blog has been listed among top 50 Microsoft Azure blogs websites and influencers in 2020 I have also been recognized with Azure Heroes community hero and content hero Badgers based on my contributions in the Azure tech community you can follow me on my Twitter account or you can connect me with me over LinkedIn as well with further ado let's jump on to agenda and see what we are going to talk today we will be starting with basics I will talk about Azure regions and data centers then we will talk about virtual networks we pin gateways network security groups routing I will touch upon different load balancing options towards the end and I will conclude this session with network monitoring I intend to cover a couple of quick demos as well just a disclaimer most of the figures that I have used in this presentation are taken from Microsoft documentation with that let's get started so when I speak to many colleagues in friends of mine one of the observation that has been that I have seen is that they don't really understand what an azure region is and the confusion that I have seen is they often relate region and a data center as this same concept which is partially incorrect everything in Azure do starts with the data center which is analogous to your on-prem data center if you have one and in Azure as really a data center is nothing that our group of buildings which is used to host physical infrastructure including racks which is servers and so on where is we there is a region in Azure is a collection of those data centers which are deployed within proximity with a network latency and at 2 milliseconds another thing to note here is that Microsoft then groups these regions under geographies which is to comply with data"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:05:06",
        "seconds": 306,
        "text": "data centers which are deployed within proximity with a network latency and at 2 milliseconds another thing to note here is that Microsoft then groups these regions under geographies which is to comply with data residency and other laws other compliance laws geographies are fault tolerant to withstand complete region failure through their connection to Microsoft's bandwidth and moreover geographies are formed with a combination of multiple regions making them fault or rent my last thing that I want to touch upon is availability zones which are physically separate locations within an azure region an availability zone is made up of one or more data centers which are equipped with independent power cooling and networking what you see here is different geographies with their different regions under them there are six six geographies all together Americas Europe Asia Pacific Middle East and Africa as your government and China and under each of those geographies there are multiple regions which make them fault tolerant I as I was mentioning earlier if we will have a look in Americas we have in total 11 regions ranging from East us central us north central us and so on and Europe there are 15 and in asia-pacific there are 13 regions this gives a slightly better view of different regions in different geographies in Azure the blue circles that you are seeing there since a region in each of the geography that is available for consumption where you can deploy your azure services then the ones which are with dotted circle like the one it's in Spain or Mexico Central they are the ones which are announced and are not yet available they will be available in the recent future then there are few which have those diamonds embedded in those blue circles those indicates the regions which have availability zones available which you can select when configuring your resources in those regions now it's important to note here that when you choose a region to deploy your resources to there are few considerations to keep in mind certainly for data compliance and regulatory reads reasons you might have to choose a particular region for example GP dr we might have to put the data in Europe but you should also keep in mind that not all these services are available in all the regions so I have mentioned a link there which points to the global infrastructure page for azure I'll go and check it out it gives you the latest list of available regions and what products are available under each of those regions or rather let me see if I have that open so this is the beta that I was mentioning about which details all the different regions you can go here and look for different as your geographies and see which regions fall under each of those geographies you can explore each region you can find out which products are available in which region let's say if I want to find out the stuff which is running in United States let's say if I want to see what your machines it gives a clear view of which product is available in which region and which is going to be available in future moving on on my presentation here's a snapshot of how many services as your office today on the lower bottom is the azure data center infrastructure which is the physical infrastructure owned and managed by Microsoft on top of that you have infrastructure services categorized primarily into three categories compute storage and networking on top of that you have all the different platform services which are customized to suit different needs like web services IOT ai data services and so on on the left side you see the suit of management services which you can use to manage your as your environments and to your right you can see the Asch services like as your monitor as your blueprints as your policy which you can use for governance you can also see as your cost management which is a service used to manage your Azure costs I'm sorry that's on the left side to the right side is your security services and today we are going to focus on the networking services we'll look into some of the services like virtual network VPN gateway Express route load balancer and so on so let's let's start with the very basic building block in an"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:10:10",
        "seconds": 610,
        "text": "on the networking services we'll look into some of the services like virtual network VPN gateway Express route load balancer and so on so let's let's start with the very basic building block in an azure network it is called as a virtual network which is a fundamental building block for a private network in has your environment being a private network it brings isolation on top of other Azure features like scalability availability and so on you can place your Azure resources inside a virtual network to securely communicate with each other or with internet or with your on-prem resources it's analogous to a traditional network that you would have managed and operated in your own Prem data centers so when you create a virtual network you'd need to define a RFC 1918 IP address space if you are not aware of RFC 1918 specification I would strongly encourage you to read about it what it does is basically defines your the best practices for your private network it states that the different IP addresses within your enterprise can be defined it can be categorized into three different categories starting with the hosts that do not require access to the hosts outside their enterprise in such environments the IP ranges are not ambiguous within the enterprise or in other words they are unique within the enterprise but they might overlap outside the enterprise the second category that RFC 1980 classifies is the hosts which need limited access to the services outside your environment right like email FTP RDP and so on in like the first category here the IP address ranges are also non ambiguous or unique within the enterprise but they might overlap with the entities outside the enterprise and lastly the third category that RFC 1918 defines is the category of hosts which have network layer access to the resources outside the enterprise meaning they just don't need to have IP address is unique within their enterprise but they also need to have IP addresses unique globally so the RFC 1918 standard allows three different IP ranges that can be used within any private network I have listed them on my slides they are 10 dot o dot o dot o 210 or 255 255 255 172 dot 16 dot o dot o through 172 or 31 dot 255 255 and the last one is one ninety two dot one sixty eight dot o dot o to 192 six 168 255 255 when creating a virtual network you have to define the IP address ranges inside and notation which is basically based on the idea of subnet masks it requires you to provide the IP rain in two parts Network identifying prefix followed by a host identifier within that network the highest prefix that you can use is last 32 and the number of IP addresses double with every reducing prefix now the example that I have taken here is one ninety two dot one sixty eight dot one hundred dot fourteen slash twenty four which has twenty four as a prefix it denotes my IP address range can have 256 IP addresses ranging from one hundred ninety two dot one sixty eight dot hundred or two hundred dot 255 now note that at max and a virtual network in Azure can only have up to 65,536 private IP range addresses which translates into slash sixteen prefix so you cannot have a prefix lower than slash sixteen for IP address ranges for your virtual network in Azure you can further segment your virtual networks into something known as subnets if you have a networking background you will understand what subnet is you can have up to 3000 subnets within a virtual network the traffic is enabled by default between the different subnets within a single virtual network it is important to understand that a virtual network is scoped to a single region in subscription what you are seeing in the figure here is how it is laid out when you create a subscription within an azure region or in the subscription you can have a virtual network with one or more subnets in it and you can also have resources assigned to each of these subnets then while scope is important here is because of two things first of all you cannot have a virtual network with the same name in this same scope so and secondly it is important to plan your virtual networks across different regions"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:15:14",
        "seconds": 914,
        "text": "here is because of two things first of all you cannot have a virtual network with the same name in this same scope so and secondly it is important to plan your virtual networks across different regions and subscriptions because if you intend to connect to different virtual networks they cannot have overlapping IP address ranges in other words you cannot connect to virtual networks with overlapping IP a this range is due to the conflicts that might happen between the IP addresses all resources in a virtual network can communicate outbound to the internet by default so and you can use something like network security group to restrict the network traffic at a subnet level we are going to touch upon network security groups in the later slides if you need to enable inbound communication to your resources from internet you can do so by assigning a public IP address or a public load balancer you can also use a public IP or public load balancer to manage your outbound connections as well a few best practices when you are creating your virtual networks to start with as I was saying avoid non overlapping address spaces when you are creating your multiple virtual networks so that if you are doing if you are peering those two virtual networks with each other in the future then you need to have non overlapping address spaces ensure that your subnets don't cover the entire address space of the virtual network meaning for the example that I have taken in my last slide I have taken slash 24 prefix for my virtual network so if I am defining subnets I should probably take slash 26 or slash 27 for as the address range for my subnets and avoid reserving the complete address space for the virtual network within a single subnet and that being said I don't really mean that we should have many few many small subnets it it depends upon the individual organizations requirements and it's better to have fewer large virtual networks at enterprise level then having multiple small virtual networks because if you have multiple small virtual networks it gets really tricky to manage the underlying subnets if you really have to break down your IP address ranges you can create few large virtual networks and have smaller subnets within them lastly and do ensure to secure virtual networks with network security groups I have aleppo stood a link down there where you can head out to to check out the guidance on how to better plan your virtual networks when you are designing them let's quickly go to the azure portal and see what we can do in so let me show you first how we can create a virtual network in azure portal so I'm already in my azure portal where I have logged in into with my live ID to which I already have a subscription assigned I'm going to click on create a resource and gonna search about virtual network click create it's going to ask the subscription in the resource group which defines the scope where your virtual network is gonna exist I'm going to use an existing resource group which I have created that you can create a new one if that's a requirement I'm going to read name it as v-net forward because for the purpose of demo I have already created three more virtual networks I'm gonna keep that in the same read in the central us region I can define one or multiple IP address ranges here I will keep I will go with the default one it comes with slash sixteen prefix meaning my virtual network will have 65,000 536 IP addresses that I can use within my virtual network and distribute across the different resources I can likewise add ipv6 address spaces and this is where we can add four more subnets so you can see here my virtual network address space range is slash sixteen whereas my subnet has prefix of slash 24 I can go ahead and add one more subnet like that and pray keep on breaking my IP address range within a virtual network into multiple subnets I'll just go with the default one for now we'll talk about all these features in the later slides and I'll go ahead and click on create so it's gonna take a minute or so I already have you watch your networks created so this is how once they watch your network is created and the other one which I have set it up is also created so as you see this is that a space"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:20:20",
        "seconds": 1220,
        "text": "your networks created so this is how once they watch your network is created and the other one which I have set it up is also created so as you see this is that a space that I has specified this is my subscription this is my resource group where it sets and this is the address space I can go ahead and add additional at the space if I am running out of IP address ranges in future here are my subnets if I want to add more subnets I can go ahead and add a subnet here moving on we have just seen what on a virtual network is how we can create it let's talk about our VPN gateway VPN gateway is a specific type of virtual network gateway that is used to send encrypted traffic between and as your virtual network and then on Prem location over the public Internet you can also use a VPN gateway to send encrypted traffic between virtual networks within Azure each virtual network can have only one VPN gateway so hence you can though you can create multiple connections to the same VPN gateway so when you create multiple connections to the same VPN gateway all VPN tunnels share this same Gateway bandwidth please take a note of that there are two types of VPN gateways that you can use VPN and Express route note that even though a v-net can have just one VPN gateway of type VPN it can still have an additional VPN gateway of type Express route when you create a VPN gateway in attach and attach it to a virtual network it does creates an exclusive subnet called as a gateway subnet in the virtual network that is used to host the resources that are required by the Gateway that is what you see here once you create a v-net VPN gateway and attach it to the virtual network 4 it will create a gateway subnet here automatically or you can go ahead and create it explicitly on your own a VPN gateway supports different connectivity scenarios starting with as I was mentioning in my last slide we can use it to connect a virtual connect multiple virtual networks within your Azure environment those virtual networks can be in same or different regions same or different subscriptions or they could have used either arm or the classic deployment model if you are not aware of the different deployment model as I said there are two classic and arm arm stands for as a resource manager which is the current state and all the old resources before arm were called classic earlier it used to call as es same or as your service management you can create classic you cannot create those classic resources anymore as far as I am aware but if you have any existing classic virtual networks you can still connect them with each other or with the ARM based virtual networks using a VPN gateway now when we create a virtual network to virtual network gateway it creates an IPSec i ke VPN tunnel between two different Bennett's as depicted in that figure VPN gateway sits in front of each V net and VPN gateway talks to each other to enable communication between those two V Nets it's pretty straightforward and as I was saying since there is only a single tunnel the complete bandwidth is dedicated to that particular tunnel the other option that that's available under a VPN gateway is for site-to-site connectivity it provides a connection over IPSec i ke VPN tunnel site-to-site connections can be used for cross premises and hybrid configurations where you have you want to connect your sites with our agile environment it requires a VPN device to be located on Prem that has a public IP address assigned to it you can also extend site to site into multi-site connection where you can connect your multiple sites like your branch offices or department offices with the azure virtual networks you need to note here that you need to have a VPN device located at each of these branch offices or department offices and each location and each of the tunnels that you establish for with each of these offices each one of them will share the available bandwidth at the gateway similar to a site-to-site VPN gateway we can also have point to site connectivity between as your virtual network and remote time computers and similar to site to site the bandwidth at the VPN gateway is shared"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:25:24",
        "seconds": 1524,
        "text": "similar to a site-to-site VPN gateway we can also have point to site connectivity between as your virtual network and remote time computers and similar to site to site the bandwidth at the VPN gateway is shared across all the tunnels that are created as I was mentioning earlier that one way to connect virtual network is certainly VPN gateway but they are not the best way to do it because their primary use case is to connect to have cross connectivity between on-prem to Azure resources the recommended way to connect multiple virtual networks with each other is through virtual network theory where you can pair one virtual network with another the outcome is that the IP address ranges of the virtual network peers appear as a single virtual network IP address range and the resources between both the virtual networks can communicate with each other with minimal latency as they would have done with the other resources within the same virtual network depending upon the location of the virtual network or the region in which the virtual network peers are in the peering falls under one or the two categories if both of your virtual networks are in same region it is counted as virtual network peering or as I say as I call it as into our region peering if the virtual networks are in different regions it is counted as global network peering you need to be aware of the cost implications for both the type or types of pairings for virtual network peering you pay for inbound and outbound data transfer at both the virtual networks and comparatively the cost for global peering is more than the virtual network peering since it enthrall it crosses different regions another thing to note here is that v-net pairings are not transitive what you see in the diagram here is how you can connect your different virtual networks with each other here watching Network a is paired with virtual network B which is in turn is pure with virtual networks see here virtual network be cannot company can't communicate with both virtual networks a and C but a virtual network a and C can communicate only with B and not between each other now both the pairings do support gateway transit meaning if one of the period virtual networks have a VPN gateway configured the peer gate win appeared virtual network don't need to have a gateway on their own and they can use the remote gateway what you are seeing here is a network topology which is very commonly implemented across enterprises you can refer to the link listed below for more details on this it is known as happens spoke topology in a nutshell you can create a hub virtual network in peer multiple spoke virtual networks to the hub the hub can be either connected to a VPN gateway or something known as Express route for on-prem connectivity will talk about Express route in the next slide generally hub virtual network is the central hub central point of connectivity between your as your environment and your on-prem resources it is used for deploying management resources and sheerly resources like firewalls which can be shared with the different resources sitting in your spa virtual networks in turn these posts have the resources that that are intended for isolated workloads which can be managed separately using hub-and-spoke offers some benefits like it does improves management it might result in cost savings if implemented correctly correctly it helps getting over subscription limits that exist for virtual network as the hub-and-spoke virtual networks can sit in different subscriptions and most importantly what you can achieve here is the separation of concerns so your central IT team can manage the hub virtual network which has all these shared resources and your development teams can have their own spoke virtual networks where they can run their own isolated workloads so before we jump on to express routes let's do a demo on virtual networks so I have already created a resource group as I was mentioning in before where I have created three different virtual networks watching Network 1 2 & 3 under each one each of those virtual networks I have created a virtual machines virtual machine once it's in virtual network one washer machine 2 sets in virtual network 2 and virtual machine 3 sits in virtual network 3 and I have already configured pairing between virtual network 1 2 & 3 if you will go here and look at the bearings you can see I have peering established between beam at 1 to v-net 2"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:30:30",
        "seconds": 1830,
        "text": "pairing between virtual network 1 2 & 3 if you will go here and look at the bearings you can see I have peering established between beam at 1 to v-net 2 which is enabled and I have not enabled gateway transit since I don't have a VPN gateway configured likewise if I will go and see for beam at 3 I have a peering between being a 2 & 3 I'll go back to the virtual network to which has P rings with both 1 & 3 now let's switch to the virtual machines this is my virtual machine 1 which has an IP address 10 dot dot or dot 4 let's go to the watcher Network sheet 1 and see where is that what a machine you can see it's it's the IP address that I've shown sits within that IP address space here is my device that is attached to that virtual network which is the network interface card for my virtual machine and it has the same IP address that I was showing you here likewise if I go to my other machine it has stand on 1 dot 0 dot 4 it sits in virtual network - I can show it to you quickly here this is the 10 dot one dot or dot 4 and this is my watchin machine three bits it's intended to dot order for which is my watcher Network three here you have ten door-to-door for so now I'm what I'm going to do is as I was saying green it peering is not transitive meaning I since virtual network to is connected to one and three it the machine which runs in that virtual network can be able to reach out to machines in both the other networks but the machines in virtual network one or virtual network three can only talk to machine sitting in watching the network - meaning v-net my virtual machine - can talk to both virtual machine 1 and 3 but what's on machine 1 and 3 can only speak to watch and pushing - so let's go ahead and think that's a 10.1 dot 0 dot for this is my virtual machine - and I'm pinging it from my VM 1 so I can reach to watch your machine - from virtual machine 1 let me go ahead and ping what's your machine 3 and as expected since being appearing ZAR not transitive I cannot reach out to likewise I can try that out then my virtual machine 3 oh this is my virtual machine 1 it cannot reach out to it because it's not paired with that virtual network I will go ahead and ping and since my virtual network - is period with virtual network 3 I my virtual machine 3 can reach out to virtual machine - now can let's come to the virtual machine - which can actually hit to the other 2 machines let's try pinging tango 10.04 I can get a response back let's hit the I can get the response back from both the virtual machines moving on let's talk about express routes express routes provides layer 3 connectivity between your on-prem network and the Microsoft cloud over a private connection which is facilitated by a connectivity provider with Express route you can establish connections to Microsoft cloud services as well like office 365 connectivity can be any to any or a point-to-point either network or a virtual cross connection through a connectivity provider the point to be noted here is that Express route connections provide private connectivity and that traffic does not go where the public Internet this allows Express route connections to offer more reliability faster speeds and consistent latencies Microsoft uses border gateway protocol or PGP to exchange routes between on-prem networks to your Azure services each Express route circuit consists of two connections to the Microsoft Enterprise it's routers as you can see in the figure here they have one primary connection and a secondary connection Microsoft requires that two for redundancy purposes each of these circuits"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:35:33",
        "seconds": 2133,
        "text": "Microsoft Enterprise it's routers as you can see in the figure here they have one primary connection and a secondary connection Microsoft requires that two for redundancy purposes each of these circuits each circuit can have a fixed bandwidth ranging from 50 Mbps up to 10 gigabytes per second the bandwidth is shared across all circuit pairings we are going to talk about circuit pairings in the next slide couple of couple of points to be noted here the Express route provides cue pricing models metered and unmetered as the name suggests metered is where the data outbound transfer is metered whereas in unmetered there is a fixed cost for fixed cost for your Express route circuit and the outbound data transfer is not needed also check out a couple of other options available in express routes you can have something known as Express route direct where you don't need to have a service provider or a partner in between and you can connect directly to the micro source global network another option is Express route global reach where you can link your different Express route circuits in different regions to make a private network between your on-prem networks now Express our circuits include two independent pairings private and Microsoft peering as the name suggests private peering is used to connect your on-prem resources with the azure services the private peering domain is considered to be a trusted extension of your own network into Microsoft Azure and it lets you connect your own primary sources with your cloud resources directly on their private IP addresses likewise for under Microsoft peering you can connect to Microsoft online services like office 365 if you have been an expresstoll customer and if you have been using Express route in the past and the chances are you might have an old Express route circuit which might have three different clearings as your public as a private and Microsoft earlier they were categorized to represent different IP addressing schemes which Microsoft has now represented in private and Microsoft peering now to understand what appearing is it is a pair of independent bgp sessions each of them is configured redundantly for high availability there is a one is to end mapping between an Express route circuit and routing domains and express out circuit can have one or two or both I mean it can either have private or Microsoft or it can have both private and Microsoft pairings enabled for this circuit now you can you can have a you can create a connection between your on-prem network and Microsoft Azure in using Express route in three different ways starting with you can use a colocation cloud exchange colocation where you can order virtual cross connections to the Microsoft Azure through providers Ethernet exchange a the provider provides in layer two or layer three cross connection between your infrastructure to the Microsoft Azure resources likewise you can also use a point-to-point Ethernet link for layer two earlier three connections with over Express route lastly you can also integrate your van with the Microsoft cloud overexpress cloud now Microsoft has a global network with Express route connectivity providers and system integrators to get the location wise list I will suggest you to check out the link that I have listed there what you see here is a failure to burst scenario for an Express route which is used to connect your on-prem resources with Azure resources in case of an outage site-to-site VPN gateways used as a failover connection if the Express route is up and running traffic flows between the on-prem network and the azure virtual network through the Express route connection through this way just in case if there is an outage or there is a loss of connectivity and the express out circuit goes down it traffic starts getting routed over the IPSec VPN tunnel through VPN gateway so please refer the link that I have listed there for the reference architecture on the express out with VPN failover there is another networking service called as as a virtual van which brings many networking"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:40:40",
        "seconds": 2440,
        "text": "refer the link that I have listed there for the reference architecture on the express out with VPN failover there is another networking service called as as a virtual van which brings many networking security and routing functionalities together to provide a single operational interface these functionalities include site-to-site VPN connectivity point to site connectivity Express route connectivity you can do it you can connect in multiple clouds through this and you did and the important point is you don't really need to use each one of those connectivity features together you can use a subset of those features depending upon your use case now the virtual van architecture is a hub-and-spoke implementation which is built-in for scaling and performance for your branches users Express route start kits and virtual networks as you can see in the figure as your regions here routes as the hubs that you can choose to connect to and all the hubs are connected in full map mesh to a standard virtual van making it easier for the end users to use the Microsoft backbone for any to any connectivity you can see different virtual networks behaving a spoke networks here and you have different kinds of connectivity like Express route side to site VPN or point to site VPN moving on I would also like to touch upon few features which are part of virtual networks which come in very handy to connect your azure services privately and securely to start with there is a feature called a service endpoint which allows your resources within your virtual network to reach to other Azure services over a private IP address you just need to enable this service endpoint on a subnet for the particular Azure service that you would like to connect from your virtual network and there is no additional cost for using an a service endpoint with your virtual network another service I would like to mention here is private links or private endpoint which enables access to as your past services over a private endpoint in your virtual network the traffic flows on the Microsoft backbone network and there is no need to expose your services over the public Internet Microsoft has already announced support for private endpoints with most of these services like sequel databases Azure storage for some of the past services like app services it is still in public preview and I believe it's going to go GA pretty soon the feature is very powerful and I expect that list to keep growing over the time it does provide truly private connectivity to your resources lastly I also want to mention about a feature known as virtual network net or network address translation many times there is a requirement to expose a single static IP address on an outbound communication from all the resources running inside a virtual network for such scenarios you can use virtual network net which once enabled forces all the UDP and TCP traffic to flow from the resources under the subnet to Usenet and show the static public IP address that is assigned at the net now you can opt for a single static public IP or you can opt for a public IP prefix when you are configuring your virtual network net gateway you need to setup an eight net gateway as I said with a public IP address or public IP prefix and assign it at the subnet level as depicted in the figure any questions so far I don't see any you know and so far we just put another comment out they remind people to post questions when they have them okay I'll keep moving let's talk about network security groups you can use network security gross to filter network traffic to and from azure resources in your virtual networks it contains security rules through which you can allow or deny inbound or outbound traffic for each rule you can specify the source and destination the port and the protocol when you create an network security group there are some default security rules which gets created automatically and you can overwrite them with your own security rules with higher priority you can also have augmented security rules which allow you to define larger and complex network security rules for example you can use something like service"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:45:45",
        "seconds": 2745,
        "text": "overwrite them with your own security rules with higher priority you can also have augmented security rules which allow you to define larger and complex network security rules for example you can use something like service tags that represent a group of IP addresses prefix from a given as your service like as your app service or as your storage as your sequel and so on network security group security rules are evaluated by priority using five tuple information source source port destination destination port and protocol to allow or deny the traffic as you can see in the figure NSG can be applied at either network interface level or at a subnet level so this particular energy is applied at the network interface level this energy is applied at this subnet level and to the left as I said there is an SG at NIC level all the security roles in both DNS G's are executed and given preference depending upon the direction of the communication for inbound it first evaluates the rules at the subnet level and then it evaluates the sub rules at the NSG which is at the neck level for outbound communication it first evaluates the rule at the NS g2 which is the energy yet Nick level and then it evaluates the rule at the energy one bitch's energy at the subnet level if the traffic is allowed at subnet level but not at the NIC level for inbound traffic the traffic is denied likewise for outbound communication if the rules ethnic lever are evaluated first and then the rules at the subnet level are evaluated and if either one of them has denied rule it will be denied likewise what you see here is for virtual machine - there is no sub know what energy sitting at Nick level so the only rules that gets evaluated for this virtual machine is NSG one likewise for virtual machine 3 there is a energy that sits at Nick level but there is no energy at subnet level and for vm 4 there is no energy either at and Nick level or at the subnet level so there are no security rules that apply the challenges with energy is that you have to base your network security policies on IP address ranges which is I believe okay in most of the cases but sometimes it gets tricky to set up the network security policies that align with the application structure meaning if I have to grope virtual machines and define network security policies based on those groups it is not possible or at least not very straightforward in energies the problem is resolved using something known as the application security groups which allows to configure the network security policies as an extension of an application structure so in this figure what you are seeing is Nick 1 and Nick - Nick 1 is here Nick 2 is here are members of this application security group called as ASG web and Nick 3 is a member of application security group called ASG logic Nick 4 is a member of application security group called ASG TB and now none of the network interfaces have an associated network security group and sg-1 is created on both these subnets here and here and contain certain rules with the application security group and within this NSG we have we can define rules specific for each of these application security groups either as the source and destination the advantage that we get out of these applications specification security group specific rules is that all the nicks that are assigned to the application security group follow those rules for example if there is a rule which is assigned to ASG Webb only applies to VM B&B m2 and it does not applies to v m3 whereas if we would have directly applied that rule at energy one without an application security group it would have applied on all the three different virtual machines I hope it makes sense moving on you can also use an azure firewall to secure your Azure virtual network resources which is a fully managed cloud based networking security service it is a fully stateful sur firewall as a service that comes with built-in high availability and unrestricted cloud scalability like any other firewall you can define application rules to allow network traffic through your firewall it comes with some out-of-the-box features like it supports availability zones it it supports for stun laying out bound snatch support inbound D"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:50:49",
        "seconds": 3049,
        "text": "traffic through your firewall it comes with some out-of-the-box features like it supports availability zones it it supports for stun laying out bound snatch support inbound D net support it supports fqdn tag service tags and so on now our denial of service attack is a cyber attack in which malicious party seeks to make a machine or a network resource unavailable to its intended users by temporarily or indefinitely disrupting services of a host connected to the Internet by flooding the target in machine with superfluous requests in an attempt to overload systems and prevent some or all legitimate requests from being fulfilled using Azure DDoS protection you can protect your Azure resources from distributed denial-of-service attacks it comes in two different flavors basic and standard basic DDoS protection is free of cost and is already enabled as part of the azure platform you can alternatively also opt for standard tier which comes with additional support options and mitigation capabilities for most of the use cases basic DDoS protection is surface in my opinion in the standard tier policies are applied to public IP addresses associated to resources deployed in virtual networks you can use as your monitor for real-time monitoring for standard DDoS protection and both the tiers does support ipv4 and ipv6 public IP addresses I see a quotient which says can be specified fqt ends on an energy when defining source no we need to specify IP address ranges we cannot specify fq d ends let me quickly go to Azure portal and show a couple of concepts there so when we are creating a virtual network we can enable the firewall at the time of creation or we can go ahead and create a firewall at a later stage as well here is the DDoS protection that I was talking about we can by default basic is enabled I can go at an off for standard and choose the appropriate protection plan here's the peering that I was talking about earlier here is the service endpoints I can go ahead and add a service endpoint specific for these services that I want to use like sequel or service verse keyboard active directory and Microsoft web is for app services likewise I can also add para whenever I enable a private endpoint on a particular app service in a particular service instance and attach it to a virtual network the private endpoint is visible under private endpoints played now let's go to NSG so what I did was I did allowed energy rule on my virtual machine 1 to allow the traffic for ICMP which is a protocol which is being used for pinging IP addresses so that's why it was I was able to ping different virtual machines what I am for the purpose of this demo I'm going to change this rule to deny and save it what this translates it is any much any inbound ping from any other machine will not work for the virtual machine one so right now it's it's it's still able to reach because it takes a minute or so before it can propagate the network security rule your brother network security rule is applied and the request starts getting timing out I'll go ahead and enable a louder rule and I will see sooner or later the machine response will start coming up because the energy rule is allowed now there you go the machine has come back now you can"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "00:56:03",
        "seconds": 3363,
        "text": "and I will see sooner or later the machine response will start coming up because the energy rule is allowed now there you go the machine has come back now you can also see the effect that the rules which are effective together in a combination of inbound and outbound security rules and their effective rules I think someone has asked this in the chat as well so here you go these are the rules which are effective now if you will see here I really don't need this particular rule here because all my virtual network traffic is allowed with these three rules and that you see here sixty-five thousand six eighty five thousand one and sixty five thousand five hundred the tree default inbound rules which are added whenever you create an energy and assign it to a virtual network and you can as a best practice whenever you are creating our rule you shall create a rule with a higher priority so that that rule can be applied and become effective the challenge is the last rule that you see here is denied so it always an energy always executes these rules based on the priority so the highest priority one the lowest priority one will be executed first meaning the number 300 with the priority 300 is evaluated first and then so on and this one is the this rule is the last one evaluated let's talk about routing when a subnet is created within a virtual network default route table is automatically created by Azure with the system default routes already added to the table as your system default routes can be overridden with custom routes you can add additional custom routes as well all the outbound traffic from a subnet is routed based on the routes in the subnets route table when you see what you see here is the list of the default routes that are added in the route table for a subnet as you can see each route contains an address prefix and next hop type when traffic leaving a subnet is sent to an IP address within the address prefix of a route the route that contains the prefix is the route as your uses now there are three types of hop types here ranging from virtual network internet and none for virtual network the traffic is routed between the IP address ranges within the address spaces of a virtual network for each address range in the virtual network there is a separate route created for each address range we don't need to specify these specific subnet ranges here because the subnet IP address ranges are already covered within the virtual network for the Internet next hop type the traffic is routed to the Internet the system default route as as seen on this slide is 0.0.0.0 / 0 that address prefix is can be overridden by adding a custom route all the outbound traffic to Internet is routed to the Internet through this particular route except in one scenario when the traffic has bound towards Azure services as your routes the traffic to an azure service directly on the azure backbone network rather than sending it over Internet regardless of the region or the virtual network these services in lastly the traffic routed to none next top as expected is dropped the traffic is not sent to any other location as you're automatically creates the fault routes for RFC 1918 IP address prefixes meaning if you send traffic on private IP address outside your virtual network range it is automatically dropped when you extend your virtual network address range to include additional IP addresses the traffic on these IP address is automatically routed to the virtual network next hog-tied now as your also offers additional default rules to support different azure capabilities like virtual network peering and VPN gateways when you create a virtual network peering between two virtual networks route is added for in each address range within the address space of each virtual network appearing is created for with the next hop"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "01:01:06",
        "seconds": 3666,
        "text": "gateways when you create a virtual network peering between two virtual networks route is added for in each address range within the address space of each virtual network appearing is created for with the next hop type as being v net peering one or more routes with virtual network gateway is also added as the next hop type here where which is added when we add a virtual network gateway to a virtual network likewise whenever we add a virtual network service endpoint route with virtual network service endpoint as the next hop type is added now there are situations where you need to either override as your system routes or you might have to add additional routes you can do so by adding custom user-defined routes to the route table you can create up to 400 user-defined routes inside a route table you can specify your variety of next hop types in your user-defined routes like virtual appliance virtual network gateway none virtual network and Internet as the name suggests for virtual appliance next hop type the traffic is routed to the IP add private IP address of a virtual machine hosting a network virtual appliance or the private IP address of an internal load balancer which load balances between multiple virtual appliances for virtual network gateway as I was mentioned earlier then traffic is this time for specific address prefixes routed to a virtual network gateway you shall note here that when we say virtual network gateway hop type here it only applies for the virtual network gateways which are of the type VPN and not for the virtual network gateways of the type Express route because in Express route you must use BGP for your custom routes none as I suggested earlier it's used when the traffic needs to be dropped what your network is specified when you want to overwrite the default routing within your virtual network and internet is specified when you want to explicitly route traffic this time 2n address prefix to the Internet now note that you don't CV net peering and virtual network service endpoint as the next hop type in the user-defined routes the reason being the routes with the virtual network peering and virtual network service endpoint hop types are only created by Azure when you configure corresponding resources in Azure also you can exchange BGP routes between your on-prem network gateway and as your virtual network gateway it is used with VPN gateways of Express route type you must use BGP to advertise your on-prem routes to the Microsoft edge router important to note here is that you cannot create user-defined routes to force traffic to the Express route virtual network gateway if you deploy a virtual network gateway deployed as type Express route you can use user-defined routes or forcing traffic's from the Express route though to a network virtual appliance when you exchange routes with the azure using BGP a separate route is added to the route table of all subnets in a virtual network for each advertised prefix the route is added with virtual network gateway as the next table type remember the good old days when we were required to have a jam box virtual machine to connect to a virtual machines in the virtual network well those days are gone you don't need to have a jump-off machine anymore if you have not not heard of there is a new service called as Azure Bastion service which is a fully platform managed platform as a service that provides secure and seamless RDP or SSH connective 'ti to your virtual machines directly in the azure portal over TLS when you connect wire as your Bastion your virtual machines do not need to have a public IP address and whenever you are provisioning as your passion' under virtual network you have to create a subnet for as your bash Bastion to work moving on as up does provides many other options to load-balanced your workloads starting with load balancer which works at layer 4 it distributes the inbound network traffic across a back-end pool which could have plain instances of virtual machines or it could be made out of a virtual machine scale set now there are two types of load balancers public and internal as the name suggests public load balancer is used for load balancing internet traffic to your virtual machines and you need to configure a public IP address for front-end so that internet traffic can reach to your load balancer likewise internal load balancer is used for"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "01:06:08",
        "seconds": 3968,
        "text": "internet traffic to your virtual machines and you need to configure a public IP address for front-end so that internet traffic can reach to your load balancer likewise internal load balancer is used for load balancing within a virtual network and it needs a private IP address for load balancing the network traffic among the different instances in the backend pool a load balancer uses a 5 double hash comprised of source IP address source port destination IP address destination port an IP protocol number the hash is used to map traffic to the available servers the algorithm does provide stickiness only within a transport session meaning packets that are in this same session are directed to the same server when the client starts a new session from the same source IP the source port changes and causes that traffic to go to a different server to handle that we can also use something known as source IP affinity distribution mode which is another way to distribute load from a load balancer under which we can send all the connections from the same client computer to the same server it uses a two or a three tuple hash if it's to topple it uses a source IP and destination IP to create a hash if it's a three tuple has it uses source IP destination IP in the protocol type for both types of the load balancer as utah's offers basic SKU and standard SKU that have different functional performance security and health tracking capabilities the point to notice that SK use are not mutable meaning once you create a load balancer with a specific SKU you cannot change the SKU you need to literally create a new load balancer with the right SKU and migrate the configuration from the old load balancer to the new one another service you can use is known as Azure Traffic Manager which uses DNS to direct client requests to the most appropriate service endpoint based on a traffic routing method and the health of the endpoints and endpoint is any internet facing service and it doesn't necessarily be need to be hosted within Azure it could be anywhere on internet the most important point to understand is that traffic manager works at DNS level it uses DNS to direct clients to specific service endpoints based on the rules of the traffic routing method technically clients just connect to the selected endpoint directly and not through the traffic manager and traffic manager is not a proxy or gateway traffic manager does not see the traffic passing between the client and the service it it just does the DNS routing and it does uses a few different routing methods that you can opt from like priority waited performance geographic multi-value and so on under priority as the name suggests you can route based on the priority that you set for different endpoints for underrated you can distribute either evenly or according to the weights that you define for each of the endpoints under performance you can route your request to the closest endpoints to your users in terms of the lowest Network latency if you use JA graphic you can redirect your request to these specific endpoints based on the geographic locations their DNS query operate originates from let me move to the next slide to give our understanding in this figure on the left side you see a system with priority routing where we have defined priorities one two and three four are three different end points when primary app goes down traffic manager picks up the next failover endpoint based on the priority we have defined here and which is in this particular case is failover a so the client is then automatically sent to the selected endpoint but not through the traffic and manager on the right side you see our you see where we are using weighted routing where we have defined weights for different endpoints once our primary endpoint goes down it identified traffic manager identifies the next endpoint with the highest weight edge which is our region B so that traffic is routed to the region B directly without going through the traffic manager recently there is a service which has been launched I guess in 2019"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "01:11:13",
        "seconds": 4273,
        "text": "which is our region B so that traffic is routed to the region B directly without going through the traffic manager recently there is a service which has been launched I guess in 2019 it was which is known as as your friend or it offers layer 7 load balancing capabilities for your application with instant failover you can think of as your friend or as application delivery network as a service it comes with some of the features like DSA or dynamic sight acceleration it does suppose TLS or SSL offloading it comes with Web Application Firewall and DDoS protection it does supports cookie based F in a session affinity it does supports URI path based routing and it does offer free certificates and multiple domain management similar to as your front door there is another offering in Microsoft Azure which is a layer 7 load balancer which is known as application gateway it enables you to manage traffic to your web applications some of the features it includes SSL offload and SSL policy similar to front door it also comes with an integrated Web Application Firewall which is a service that provides centralized protection of your web application from common vulnerabilities like SSL I'm sorry like sequel injections and so on ref is based on rules from Oh West 3.1 3.1 to 2.9 versions now I did touched upon both front door and application gateway and I mentioned both of them are layer 7 load balancers but there is a difference the primary difference is that front door is a global service whereas the application gateway is a regional service while front door can load balance between your different scale units or clusters across regions application gateway allows you to load balance between your hwachun machines or containers that is within a single scale unit as I was saying application gateway is levels is layer seven load balancer it does supports URL based routing as well application gateway can make routing decisions based on additional attributes of an ST TP request for example the URI path or host headers the Daiya the figure that you are seeing here in that you can see the traffic is routed based on the incoming URL if the URL includes images it routes it to the image server pool if URL includes video it routes it to the appropriate video servers now this is just a snapshot of as your web application firewall which I was mentioning in one of the last slides that it provides a centralized protection of web applications from common vulnerabilities like sequel injection and cross-site scripting preventing such attack in application code is technically very challenging and it might require rigorous effort from development teams using centralized Web Application Firewall does help security management a lot so this is just a quick snapshot of when should be use each of these services basically some of the coefficients we should ask is whether it's a global or regional service whether do we need to support HTTP traffic or non-http traffic that way we can choose a service otherwise you can head out to the link that I have posted there down below on that slide which gives where we have micro beer Microsoft has detailed all the different load balancing options and how we can choose from in a nutshell some of the factors that you should consider is the traffic type as I was saying in the last slide as well is it a that application is it a public-facing or a private application do we need to load balance between is it a global service or it's a regional service what is the service SLA what is the cost and so on let's talk about as a content delivery network pretty quick it's a distributed network of servers that can efficiently deliver web content to users Syrians are stored gasps assie reinstalled cached content on its servers in point of presence locations that are close to the end users to minimize latency what you see here in this figure is that let's say a user known as Elly's requests a resource from special CDN domain ending with a George dotnet which runs on a it's over in the point of presence the the DNS routes to the best performing peop location which"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "01:16:21",
        "seconds": 4581,
        "text": "resource from special CDN domain ending with a George dotnet which runs on a it's over in the point of presence the the DNS routes to the best performing peop location which is nearest geographically to the user if once it reaches the edge server the xor weather looks for the resource on the server if it doesn't finds it goes and looks at the it sends a request to the origin which might be a storage account or it could be a hab service the once the origin returns the requested resource the ad server returns it back to the requested user and it stores a copy of that on the ad server with a TTL like advice when any other user goes and requests the same resource if it is still available on the SS our it returns it back to the user if not it goes to the origin and gets it back let's talk about network monitoring pretty quickly and there are a couple of services that you can use the one which I like is network water which enables you to monitor and diagnose your health and performance of your network using network waters diagnostic and visualization tools you it can it helps you to for things like capturing packets on your virtual machines validating if IP flow is allowed or denied you can also identify where packets will be routed from a virtual machine and gain insights through all your op network topology as shown on this slide the other service that you can utilize is known as network performance monitor which is a cloud-based hybrid network monitoring solution that helps you monitor network performance between various points in your network infrastructure it does detect network issues like traffic black holing routing errors and so on it comes with three broad cap abilities performance monitor service connectivity monitor and Express route monitor as the as each of the those suggest a performance monitor is monitors network connectivity across cloud resources and on primary sources service connectivity monitor monitors the connectivity from your users to these services that you care about and Express route monitor monitors end-to-end connectivity and performance between your branch offices and Azure over as your Express route with that here are some of the resources that I can refer you to for further reading and for your certification preparation to start with as your architecture Center is a great resource where there are many reference architectures including couple of them that that are shown you in this presentation utilize Microsoft Azure documentation as the source of authority as it always has the up-to-date documentation do follow as your best practices for network security as listed on that link and if I am not seen in the past do check out Microsoft LAN which is a great resource for free learning and then Microsoft has also partnered with Pluralsight to offer 200 frees 200 plus for ye courses do check it out there are some good networking based courses as well in there then do check out a Friday and which is a show on Channel 9 and as your role-based certifications if you intend to give or appear for a certification with that I conclude my presentation and I would open the floor for any questions that you might have if not I would like to thank Jason and Veronica once again for giving me opportunity to speak at this user group meeting thank you I think there are some questions if we look in the chat is the chat on the slack or on the Dean Smith I see someone teams for example you mentioned network security groups RNs G's for managing a loud traffic curious if in the real world that takes the place of firewalls built into VMs or is it still common to also used the vm firewalls i have primarily used network security groups for majorly the projects that I have done but I have seen customers using VM using firewall as well but network security Grubbs does fall and does provide good tool available we can apply it"
    },
    {
        "speaker": "",
        "title": "Vaibhav Gujral: Demystifying Azure Networking",
        "videoId": "SXJoiDpDsSw",
        "description": "This is a recording of the June 30, 2020 virtual meetingDemystifying Azure NetworkingDifferent Azure Networking services can be used to connect cloud and on-premises infrastructure and services. In this hour-long session, Vaibhav will cover the basics of Azure Networking services including Virtual Networks, VPN gateways, and different load balancing options in Azure. He will talk about what each of the networking services does and when should it be used? He will also show a couple of demos and share some useful resources for further reading. It will be a level-100 session which will help the audience to get a clear understanding of Azure Networking. It would also be useful to administrators, developers, and solution architects who are preparing for Azure role-based certifications.Slides for the presentation are posted here: https://bit.ly/2C2YxpaSPEAKER BIOVaibhav GujralLinkedIn Profile: https://www.linkedin.com/in/vaibhavgujral/Twitter: @vabgujralVaibhav is a seasoned cloud architect with extensive experience in designing, developing, and delivering enterprise-class applications. He is currently working as a cloud architect at Kiewit Corporation. He is a Microsoft Certified Azure Solutions Architect Expert and he holds numerous other Azure Certifications including Microsoft certified Azure DevOps Engineer Expert, Azure Security Engineer Associate, Azure Administrator Associate, and Azure Developer Associate. He has been putting in his time and effort in building and growing the Azure community. Apart from being a regular speaker at different user groups and events, he also runs the Omaha Azure user group (https://omahaaug.com/) where he organizes bi-weekly meetings. He regularly blogs at https://vaibhavgujral.com/. His blog is listed as one of the “Top 50 Microsoft Azure Blogs, Websites & Influencers in 2020” (https://bit.ly/3dhbYyV)",
        "start": "01:21:32",
        "seconds": 4892,
        "text": "security groups for majorly the projects that I have done but I have seen customers using VM using firewall as well but network security Grubbs does fall and does provide good tool available we can apply it at the NIC level or at the subnet level which is the primary benefit we get out of using energies thank you for that I'll continue here to read off a couple others this is Bill okay are there you have any thoughts you want to share on Azure cost control as a cost control for networking services I guess so I could give an example to set the stage I know in my experience we've when we look at say DDoS protection standard you could if you're not paying attention they could be quite some sticker shock there so they don't know if there are other factors in the networking realm that you want to caution people I guess we do check out the V net peering cost if you are implementing virtual network parent because how pricing works for as your networking is by default any data transfer going with in Azure is free of cost and any outbound traffic from any Azure region is chargeable on top of it if you are utilizing virtual network peering it does charges you on the inbound and outbound that are transferred from each of those virtual networks I guess for intra region a virtual network peering it cost a cent or two cents per gig or to have to transfer I don't remember on top of my head the exact number but what happens is if when the data leaves watch on network one and goes to watch a network to eventually you end up paying both at what your network one in virtual network to on what so network one it is billed as outbound data transfer and whereas on virtual network - it is billed as virtual network as the inbound data transfer and that price goes high if you are using global peering as well so that is another thing that you should be you should consider when you are implementing Azure virtual networks thank you for that and another question is I'm not sure if you got this one already can we specify fq d ends on an NS g when defining source i don't think so i think it's completely based on IP addresses and we cannot define fqdn but if I can show you we can use something known as service tax so if I go here and go to inbound security rules there are different options any opens up as the as it indicates it opens anything over Internet we can specify IP address in an individual IP address or an IP address range we can specify something known as a service tag where we can choose from different service tags like internet or as a monitor or load balancer or virtual network so that it this is what I was saying it we can these are the aggregated rules that we can define rather than defining the individual IP address ranges and lastly I was also mentioning about application security groups this is how we can specify rules for application security close but there is no way we can define fqt in certain easy level thank you I actually have a question on this is can you how do you take an application security group and move it to a new subscription the last time I have used applications security groups was there was no way to create them in total I had to manually create it through PowerShell and once we create that the they are visible in here and we can choose the appropriate applications security group here and assign it to the rule since I don't have an application security group right now it doesn't shows me any any security group here great thank you and I think we may have gotten all of them except for the ultimate question that comes up at every talk is other slides available yeah I would go ahead and share that with Jason and we can share it and I just remember recall that in the I think recently they have allowed creating an application security group in the portal as well which I'm just not showing so I didn't I didn't give it a try before so probably we don't need to create it through PowerShell anymore oh yeah check that out thank you so you said you had suicides of Jason that's fantastic so I'm gonna flip over to Veronica here too unless unless anybody has any final questions you come off mute and fire away is there a good source of repository for powershell scripts and managing our resources I I can send a couple of github repositories that Microsoft provides go ahead and check out QuickStart templates where they have I believe they have it it's based on arm but I have to go and check it out if they have PowerShell scripts as well I can send it to Jason and probably situation you will be able to update it or I can add it in my slide taking the resources column the sources page fantastic thank you up looks like that that was the last question that I see posted so I'm gonna flip over to Veronica for closes out alright Diana share stop sharing my screen thank you so much it was a great talk and thanks everyone for attending I think it was a great event and if you have any more questions later you can ask on slack and we'll pass them to our presenter and he'll be able to respond the ORN will somehow find him and definitely will pass his quick your questions to him I'm sure he'll be happy to answer them later or provide any kind of help and I have two announcements a one is more global I just heard that Khan is gonna do a special event on July 30th so pretty soon and they're gonna do an event focusing on micro services so that might be interesting we have I think they are planning to do some as a related top cover some other related topics and to some sessions so it should be fun and virtual Boston adjourn event next one month is gonna on the 16th so July 16th tile we'll be talking about bots and share his real-life experience working with Azure bot framework and creating BOTS related to college and all the pros cons and everything that he learned I think we'll we'll do it again as a team meeting so same like we had today so you'll be able to ask questions and being yourself we can turn into Q&A session after so again really I just announced the need up on or a meet-up pages so definitely RSVP and join us next time and if Bill and Jason don't have anything else I think we are all set for the day thanks everyone thank you thank you thanks everybody "
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Udaiappa Ramachandran: Azure Governance. This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.. jason and the build for quite a long time back uh they are my good friends uh are you seeing my screen okay uh my powerpoint before i continue yes yes okay that's good um i'll turn up my streaming now and i'll continue on the top right over here okay wait so okay got it so i'm would i work for a company called akiminas um cto um um so i primarily focused on the uh microsoft azure amazon and google since we are a product based company we sell the software as a service platform accessories and the perpetual license so we have to work across multiple clouds so that's our our platform to make it work across multiple cloud also called called as cloud agnostic or cloud neutral um as bill said i also run the user group in new hampshire and nashville uh we meet once a month so here is the made up nashville ug if you've never been there please visit and then sign up and here is my little personal site if you want to know more about me you can visit their hooded io in today's agenda we're going to talk about the azure governance um so mainly in the part of management groups and road based access policies and blueprints those are the four four major area that we're going to cover and i hope by end of this presentation you should be able to take the knowledge and play it right away in your in your work so when you know when it comes to azure management if you take um on-prem it's a central i.t right control it controls the governance so don't need to worry about you always go to it admin he controls everything centralized but it when it comes to a cloud user have a direct access so anybody can get access to anywhere so so that's that's the nature of the cloud in order to control the management comes into six different categories right so first thing is a configure it can be an initial deployment or ongoing maintenance um you know are the automation to reduce the errors and then if you want to repeat the same work you do the automation kind of things for the monitoring you need to monitor all the health healthiness of your system um you know product is you know you want to make sure the service is always running um you know even it goes outage there is network or power error so you know that comes know microsoft provides couple of tools as you backup are the iso site recovery so it they have you know the production is very important and then the security you know any thread against your application or resource hosted in the azure and of course migrate so you want to migrate your on-premises workload to a cloud and then last but not least is a go on it's very important so governance mainly comes under the category of the people process action on the resources we need to well control that so so that you know you define that who controls what because in the cloud everybody has the direct access so we need to define that governance that comes under the policy management cost management and we're going to apply who has the access to that by using the role role-based access control we will explore that so now comes the management group if you want to get into azure the first thing what you do is you know you sign up for a subscription right so you get a subscription subscription is the logical group logical boundaries of your workload between uh you know your resource and and then the workload it's a logical separation from one one one subscription to the other subscriptions so management group so subscription let you create a resource group and then the resource groups can have one or more resources you define on it but it is a logical boundaries between your account and workload but when it comes to the management group so it's a logical boundary on top of the subscriptions if you're going to work with one subscription you may not need a management group but at any point of time you think it's going to have more than one subscriptions then the management group makes your life easy in my work scenario i have like 100 different subscriptions you know we need to set the policies we need to set the role based access we need to define what what resource we're going to deploy who has the axis who has the reader access who has the right access right so for that you applying every single subscription is going to be painful that's how the management groups comes into a picture right so subscription is the logical workload between accountant work account and in the resources then the management groups can comes on top of that it's a logical group of subscriptions to maintain all those subscriptions and then you can create the 10 000 management groups on a single active directory so it works in an individual active directory so in sales active directory um you can have a number of subscription in this case you can have 10 000 management groups a management tree can support up to six levels so sometimes you you may not see the one layer so you know for example you have you have an internal subscription my demo you have internal subscription in the internal i want to call it"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "management groups a management tree can support up to six levels so sometimes you you may not see the one layer so you know for example you have you have an internal subscription my demo you have internal subscription in the internal i want to call it as engineering sales and marketing i have external subscription i want to call it as you know different use case scenario maybe a usb east us west and so on right so we can and in that level you can create a six level down not more than that um this limits the root level so what according to the definitions the root level is not excluded you can go five levels down so the root level is the one and then the sixth level sorry and then the six levels all together it comes to seven levels so that's how the definition works so you can define six sub levels uh to categorize your subscriptions like taxonomize the descriptions once you have the management group defined then your subscription can only belongs to one management crew so if you have to move to another management group you have to remove it and reassign it a subscription at any given time can be part of one management group and then the management group can have many children that means that a management group have one or more subscriptions but a subscription any given time can belongs to one management group right so that's that's what it says all subscription management groups under a single hierarchy in each directory means that you know that's the definition of how the subscription management group works they have to be part of the same active directory it cannot nest across the active directory so here is some example so simple enterprise governance so you have the management group over here it's a corporate id and then you have a next hierarchy called production and non-productions in the productions you have some subscriptions under the non-production you have some subscriptions in each subscription you have a resource groups and the easy resource groups you have resources right that's a simple cover so the management group wise you have two layers the top layer is called the corporate i.t management group and then if you have a two more management group production and non-production then you know every management group then you have one or more subscriptions and here is a little bit complex enterprise governments so you have a business unit that's a top-level management group and then you have a management group called geography maybe u.s east u.s west or maybe asia you know or europe um and then you have the environment production and non-productions in every region you may have a production of non-productions and every management group can have one or more subscriptions and every subscriptions can have a resource groups under the resource group we have resources and so on so that's the two example of how the management group and subscription the resources are assigned together and they all have to be part of the same active directory you cannot you cannot manage them across active duty so next as set in the definition so we're going to have management group and then we're going to see the role-based access control the road based access control is what defines who has access to what right so there is two categories one is the airbag security principles assign access to whom who is going to get the access the access is going to be given given to a user users can have access and the groups you know you want to you don't want to send individual users then you define a security group and give them the access this group can have a you know main layer of access and then the service principle the service principle you go to azure active directory you define application in that application you define a scope in that scope you're going to say it's a application scope or dedicated scope you may need a some application may need application scopes some might need a dedicated scope in that scope you're going to set the permissions so that's called the service principle you go to active directory you define the principle and then you give the access the one good example is the management api so you go to azure active directory you define application you define a scope and then you give them a permission uh two management endpoints then in your code you can start using them okay um and then the main aged identity is something that controlled by microsoft for example you know you you want to build a system to store some sensitive data for example you know current sales are any sensitive data or keys to encrypt it you show them the keyword and you want your application to see the keyword you don't want to put any service principle in between so once you start ascending the service principle you know the client id and client secret which is nothing but username and user password right instead of you doing that the microsoft enables that managed identity so that your server or your application can directly query the keyword without you defining the client id and client secret so that's the managed identities so created and managed are made managed by the microsoft those are the those are the four um four different categories that you can assign to assign access to now when it comes to the scope so who where you can ascend that axis that access can be assigned to the management group levels once you ascend that access to the management group level all the subscription under the group under the management group gets the same access so if you maintain 100 different subscription"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:10:07",
        "seconds": 607,
        "text": "where you can ascend that axis that access can be assigned to the management group levels once you ascend that access to the management group level all the subscription under the group under the management group gets the same access so if you maintain 100 different subscription you have to remove some access you don't have to work on all the 100 different subscriptions just to go to the management group remove it it's good to go all the 100 subscriptions inheriting that that access control is going to apply instantly or you can apply to the subscription level sometimes you want to override it little bit so you can do that in a subscription level or if you are not using the management groups you can go to the subscription and ascend that access control you can also ascend to the resource groups level um so management group subscription or sometimes you can ascend to the resource groups level and then the resources so you can directly assign that access control to the resources right i'm sure any question feel free to stop me uh you know or keep posting it when it comes to the role definitions there are there are two categories built in drawers and custom roles there are hundreds of built-in roles but you can you know that's not going to solve your problem you can define the custom words tonight we're going to see how we can define the custom rows so one example of built-in tools is the owners contributors and genius mostly used um roles owner says he gets a full access to all the all the resources contributor um you know he close to full access but you know some some limit with some limitations and the reader he only gets a read access he cannot delete anything he cannot see you know or create any resources and so on right but contributor role is good but it has a little bit of negativeness for example the the user you are sent to a contributor role by default built-in draws he can also create resources in my cases if i give a contributed role to anybody they keep creating the resources they are not deleting it i need to control them you can create a role but you want to do everything else that's where i'm going to defend the custom or back to control the directions microsoft cannot provide every possible combination or combination of those permissions so they give you all the all the custom roles available in the system you compose based on your requirement then you create a new custom roles and then you assign that roles to either management group or subscription or resource groups or resources now here is the syntax how you can do a custom roles when no you just it's json file it has a four category one is the actions what you can do if you say star you can do anything and then no actions you define what what is not allowed right so actions what is allowed no actions what is not allowed in the actions i say you can do everything but no not actions i say you cannot write it means that you cannot create it you cannot delete you cannot delete it but what you can do you can read are um they call it as other scope you know whatever the possible non-scopes that not belongs to write and delete you can perform that and then the data actions what is the data actions mean you want to control it in a data data level for example the containers right so you can give access to um actions to a create a storage account or maybe not auctions but in the data level you want to restrict that he can delete the container or he can read the container that goes into a data action and no data actions that's a data level the good example is storage containers but the storage itself get into accents or mat actions the containers level get into data actions are not data actions and then when it comes to the assignable scopes you define this r back or custom role how you want to assign it you can ascend to the management groups and then you tell what management group you're going to assign to or you can assign to subscriptions right so if you want us into management groups you can only have one management group defined over here but if you want us into a subscriptions you can define one or more subscription just a comma keep adding it that's r a so you can keep add the subscription subscription one two three four and so on but if you want us into a management group you can only us in one management group but if you want us into another management group you just have to duplicate it rename it and then deploy it again that's how it works today with the microsoft and let's see what it went back here's a bunch of power cell command you can perform all these in the portal or you can also perform these on the powershell commands the very basic commands the new as role definition you create a json file when you use the new a0 definition and and that that creates that role in the scope given scope if you want to update this definition you use the set function and then you read what is going to be the definition and then you remove the definition very simple four command operations you can do that all right let's see some demo here so look at here so i different management groups for management groups and every management group i have a lot of data so if you look at 10 a large number of tenants um you know in this demo i'm going to use only internals"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:15:17",
        "seconds": 917,
        "text": "so look at here so i different management groups for management groups and every management group i have a lot of data so if you look at 10 a large number of tenants um you know in this demo i'm going to use only internals because there is a less density data so i have something called acumen internals in the internals i have two subs uh two management groups one management school called engineering and another management group called sales the engineering management groups i have two different subscriptions one called iqbal engineering another one called enterprise tag test so every time you create a subscription if you are a ea customer they they allow you to create a test subscription which gives you a some discount on the computing resource not all the resource on the license side of the computing resource they give you some some discount so for this demo i'm going to use this um i don't know i create a accumula internals as the management group underneath i have the engineering and engineering i have two things okay so how to create a management group you just click on the management group and then you define the name keep going on it so let me go back to the tenant root hand management group i'm going to say test management and then i'm going to say test so here is the two things the management group display name can be changed at any given time but management group id cannot be changed so you have to give a right name that you want to right so this display name can be changed at any given time just create save and it's going to create a new management group and good to go uh it should be in a few more seconds but he got it so that's how it's going to create it now when it comes to the role best road based tax uh our back road based access control um there is a two way you can do it as i said you can no this demo you're going to see the power cell but i will show you how you can create in the portal to create in the portal you can create the rollback on the management uh management group level so in order to navigate the management group you go to the management group click on the details and it shows it shows over here you click on the access control that's where you're going to apply the roles right so if you click on the ad it's not going to give you that so if you want to really create the access controller you want to learn it it has to be on the on the script level on the subscription log so i go back to the go back over here and then i click on up the subscriptions here and then i click on the access control and then i click i see the custom role right this option wasn't there when you go to the management groups so i click on the custom role and then the permissions you know i go through this wizard and then it gives you all the permissions that i want to and for example i want to do a virtual machine right so i type the virtual it displays me um microsoft compute let's pick anything we want here so microsoft let's take away perhaps right and then it displays me uh it should come no permission is found okay so and then you you can select what permissions you want right so as i said i'm not going to completing this screen so i can select maybe this read this so one problem that i found here they don't give you multiple options they give you four category one is the read other one is the right means that you can do anything you want minus delete right and then third one is a delete the fourth one is the other the other tied to a lot of little things like how you set the ipad address restriction and so on but there's not a lot of control over here there is only a read write delete another they only give you those four controls so you're going to combine those four controls and create the role-based access and assign to a subscription our resource the resource resource groups are the management group levels right so i'm just speaking randomly something i say add right and then i go next it goes json file and then i i see this and then i can copy it i can drag it okay so now if i continue finish this wizard it's going to create a permissions for me so instead of doing here so this is one way you can learn it how you know how to find these actions because we don't know what is the name of this action so you come over here click on the permissions and then see all the available actions the pick the one that you want it and then either you can finish creating here but if you finish creating here it's going to create another subscription not on the management group so you can copy the script and put them in a file and then run from the command line so it can assign directly to the management groups so now i'm going back to my power subscript i have this script already published in the git portal um the link here i'll show you the thing at the end"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:20:21",
        "seconds": 1221,
        "text": "management groups so now i'm going back to my power subscript i have this script already published in the git portal um the link here i'll show you the thing at the end of the end of the talk you can download the samples so now i'm going to use our back demo and then i have something called contributor read write but this guy cannot delete it right so i have this over here and then i set assigning scope to this one so i'm going to say some name demo contributor right so i save it i go back to my script and then i say demo contributor and then this is my test group i already created it so i define i upload this definition so if you go back to my management group here i'm going to go here sorry um internals engineering details access control role assignments i don't see any roles here right so these are the default rows that i have right now so let me create some rows here so demo i have this group that can be assigned and then i just run the definition and then that's optional line number six is option so let me go and create this definition over here okay so i got the demo contributor so if we go back i refresh it role assignments i don't i mean i didn't ascend the role all i did was i created the custom role so i go back to my roles and then i look at the custom roles and i just created it right so now i'm going to assign so there is two way i can assign it i can go ahead and add here and then add the roller segment and then i know i can pick my role demo contributor right and then i can pick the user that i want to give you to i can do that way but instead of doing that there's a lot more user it will display but let me go ahead and do it in the powershell so i hear role assignment she said i put some group id over here we go back um so let me run from here through here right so i now assign to some user so if i go back and reload the screen now i ascend this user okay so now this user has the read-only access right if i log in as a him and then try to delete anything i won't be able to do it okay so that's the purpose any questions so far so now since i assigned to an engineering subscription i go back to the engineering management group i go back to the any subscription that belongs or belongs to this management group in this case go back reverse so if i go here and then look for my access control role assignments and then oh i sent to uh engineering right yeah role assignments refresh you see here over here okay if you don't see it don't panic just reload it few times will display so this is by default assigned and it tells you it's inherited from the management group click on remove it it's going to remove it over here so all i did was i ascend on the management group the management crew had two subscriptions they're both now inheriting so if you go back to my another subscription i'm going to see the same thing so i go back over here and then look at my access control role assignment so this one over here so send it to a management group okay any question before move on to next topic and if you want to delete it of course i want to delete it so i go here and then the uh remove this assignment oh i didn't get that definition here okay map to the role assignment remove ac role assignment okay so it's got that uh okay it removed it i don't know why it wasn't running before i had no idea so if i go back to my my engineering over here and look at the access control roll assignments it's gone right and i can remove the definition"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:25:37",
        "seconds": 1537,
        "text": "uh okay it removed it i don't know why it wasn't running before i had no idea so if i go back to my my engineering over here and look at the access control roll assignments it's gone right and i can remove the definition for to remove the definition i have to use this idea roll definition id i put it over here my definition still will be here if you go back to the roles look at the custom it's still there i go back and run this cup and it says yes good to go so if we go back and refresh these that's gone okay any questions so far all right i'll go on to uh you guys are there right i'm not checking what's going on the next one is the policies so policies is how you control the compliances um on your on your resources right sometimes you want to put some sort of naming convention or some sort of pci tss compliance or any complaints that you want it that compliance is in the the policies can come from the built-in just like a roles or you can build your own custom policies right so microsoft cannot provide every single possible combination so they give you this is what is available you can bring them mix and match you can bring them okay so it is stickler right you don't have to write any code just like how we did a road based access in our back it's just a json file one file called rule other file called parameter so you you define the policy with the rule and parameter you apply the policy again to the subscription or to the management crew okay and then the policies can be triggered so it's composed mainly of the policy definition assignment and parameters the definition comes as a rule and then the your assignment the assignment can be initiative which is nothing but one or more policies uh just like compliance so you define your own compliances for example um any resource that created you know vm needs to start with the vm dash um you know web app needs to start with the web app dash application insight should start with the appi so microsoft recommended naming conventions then you can group them together as an initiative so anybody going to create a resource of all those things to validate and prompt you okay this is not meeting the meeting the policy requirement then they're going to fix it and you know to move forward so those are the three components policy definition assignment parameters um you can use the built-in policy or the custom policies um it always evaluates in a real time it's not you know so if you you know for example if you put a naming naming convention it's going to evaluate it when you create the resource or if you have something else policy then it's going to evaluate it constantly it always on it's it it runs it evaluates every time but there may be some latency but it is always constantly running and checking against all the resources and you can also trigger on-demand policy evaluations um that policy can be assigned to a management group subscription or the resource level and you can also exclusion scope for example i don't want to apply this policy to a vm or i don't want to apply this policy to this particular resource group you know so in one use case in my scenario you have a resource group for the test you know version uh and then that version has the dev test qa for the dev we don't want to apply any policy because the developers they're going to play with it so we can define exclude this particular resource so it's not going to validate anything against the particular resource group or resources and policy initiative as i said in the beginning instead of running a one policy at a time you can create a group of policies and apply to a management group or a subscription or the resources so every time you run it it's going to evaluate all the policies defined in the initiative and then prompt you it's biased or failed okay the remediation some of the input policy have the remediation for example if you if you if you turn on if you if you turn on the port 80 it will tell you that you know hey it's recommended to turn off port 80. so you use a web app you turn on port 80 then it will recommend you you know it's not a good idea um the tls one point it will tell you that you know some of the services is not compliant with the dealer you know if you're not if you're not turning on the tls 1.2 will tell you tls 1.2 and it will also give you an option that you can click on it and then go to the screen and fix it it will fix it some of the built-in policy will fix it some of the built-in policy they will provide you with documentation because they can fix everything few things are easy to fix such as turning off the port or turning on the some of the radio you know some of the predefined options is easy to do it but if there's anything beyond that level they'll provide you a documentation follow this guide and fix it so they will provide you a remediation step of you know most built-in policies that you can follow you"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:30:40",
        "seconds": 1840,
        "text": "easy to do it but if there's anything beyond that level they'll provide you a documentation follow this guide and fix it so they will provide you a remediation step of you know most built-in policies that you can follow you fixing that that eventually leads to your security score or compliance score in this case or not security compliance scores um yeah uh there was uh john had a question uh do uh do policies have more flexibility than on-prem policies what is the definition of on-prem policies john you cannot unmute and uh and uh just talk directly so basically when you have your standard uh on-premises machines with active directory and things like that when you set up a policy it seems like when you have a cloud policy you have more flexibility than on-prem yeah exactly um absolutely but you know cloud policies are way beyond an on-prem policies as you said active directory right and again on from you have to go through the centrality to define those policies maybe a password uh resetting policy or password-length policy in this case um those things are there they are controlled by azure active directory and what i'm talking here is the the policies is some of those policies are inbuilt policies yes all the policies in terms of active directory that you applied is available in the cloud it's a plus plus you have more on the resource side it is more flexible when compared with on-premises answer to your question is there answer question so basically it's like cloud policies or cl cloud policies plus plus like you said yeah on from policies plus plus so you can pretty much to every policies that you execute in the on-prem on the active directory level or if you have some custom policy that tells that you know the user computer needs a certain virus software installed so those are the policies that you're defining on premises right and you can do a similar things in the cloud but the cloud has more policies more flexibilities in terms of those resources because in the cloud there's a lot of resources than on-premises okay so basically when you move on to the cloud your whole ability can to control things goes up way beyond anything you could do with your basic on-premises stuff and you have so much more control exactly cool yeah and they're they're they're mainly defined for the compliances so you can bring any compliances that you want you write a policy you turn on the compliances it is it is more flexible uh you know let's move on to next one policy affection evaluation um so the policies have you know effect right well you know what effect the policies has once you defined it it's a it's a append effect what does that mean you know you have a policy defined on certain area but you know you want to turn on one good example in the documentation is you want to turn on some ip or remove some ip restrictions so for example your cosmos tv or you have acid storage you want allo or deny certain ips let's append right so r you can even define a tag for a existing resource if the certain resource is missing some tag you can define it but as for the documentation it's not a recommended append effect to uh to do a tagging but append effect to do some actions such as restricting ip address or granting the ip address use modify to do those kind of operations such as an updating the tag or something like that and audit it's not going to throw any error but it just added so if you go to the security center you can see what is been audited sorry so you're trying to do something um you know for example i'm just use a very simple example vm name should start with the vm dash so you can define a policy if the vm name is not going to start with the vm dash you deny it so it's going to tell you no you can't create a virtual machine because the policy is not met instead of deny it you can say audit so it's going to say a vm creator which is violating this policy so somebody can go and check check at it okay so the vm creator because then the crunch time they need to test something they created it but they violated a policy that's okay so you just let them audit so you can see it over there still and you can set up the notification or monitoring alert okay somebody created a vm which is violating the certain policy and you know this has been audited so you will receive an email or any other notification the notification you enabled you can see it audit if not exist for example you know uh um sometimes you know you you depending on the uh some some in the virtual mission world you're looking for something to be installed on the vm for example some agent uh for example"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:35:44",
        "seconds": 2144,
        "text": "it audit if not exist for example you know uh um sometimes you know you you depending on the uh some some in the virtual mission world you're looking for something to be installed on the vm for example some agent uh for example the anti-software agent or something like that and if it's not exist that's okay don't throw don't break it but just add it if not exist right so it's going to continue on but still not still going to audit it so your monitoring system from the security center triggers him sends you a notification this is what happens and denies of course you know you deny it you can proceed any further it fails so there's a stop um deploy if not exist um it comes to uh you know some sort of you know you know one good example in the documentation they say i did not use it the documentation they say if you have a sql server you want to apply the transport certificate encryption you know certificate for the encryption then you can do that part of your policy and that's going to deploy deploy if not exist condition then you can execute those steps to do um you know encryption encrypt transport encryption to install a transport engine certificate on the sql server level and then modify disabled means that you don't want all you want to run the policy for a certain period of time so you're running the policy if somebody is in a testimony you don't want that you don't want to really cast trouble to that or some policy is gone out of out of state so you won't run certain kind of rules from you know first through a 15th and then you want to turn it off then that's where the disable comes in then you can disable it until next marketing time comes in or some other event happens you can then go back and enable it um as we discussed modify multiple is main for example of modify is to create um add or modify the tag and so on because those are the summary effect uh not some all the effect they support it and how you know now you have like a seven effect and how this has been executed in order right the first things one the policy triggered in it checks is enabled or not if it's disabled no it's not gonna do anything that policy the second effect is going to look at it the second priority is going to look at it opened or modified right because the deny can write something that's why they check the append or modify and that's the policy executed second and then all the denied action executed and then the audit actually exist okay so those are the order first to disable to make sure whether we need to run or not then they append or modify and then the deny and then the audit so now how do you define the policy it's very simple yeah uh me again um uh john had a another uh question and the question is um can you set a policy where the the policy's effect is to not allow costs to go above a certain level exactly you can set the policy yes the answer is yes you can turn off some of the resources yeah okay does that answer your question john the cost is part of the policies and cost is also part of the part of the governances right in all governments is all about policies now policy is required in order to control the cost you don't want to lose money on it yep can i step in for a second sure so i've heard of so many places where they start using azure and cost just runs rampant because clearly they don't understand reserve time policies and different cost models and things like that and it gets too expensive so i feel like if there's a policy where you can just go you can run this until you run this this amount of money and then shut it down and then you're not allowed that would be a big help but i didn't know that existed yeah i don't have a sample to show you but it is existing it is i mean i can i can do a follow-up with you um we can get you some samples but it is possible to control that cost using the policy i think one of the the biggest thing i've noticed about azure there should be a specialty about finance management in azure so but great thank you yeah i mean if they put you know if they give us a first-class tool then everybody's going to control the cost and how come microsoft makes the profit so they want us to spend more money uh yeah that that's a good question so let me move on to how you define the policies um the define the policy comes into two files one is the rule other one is the parameter so you define the rule the right hand side um in the wrong order okay policies you know you define there is a conditions if all of the conditions met in this case field type is going to be a virtual machine then the name pattern if that does not match not in this pattern then you deny it so this is where your effect"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:40:48",
        "seconds": 2448,
        "text": "conditions met in this case field type is going to be a virtual machine then the name pattern if that does not match not in this pattern then you deny it so this is where your effect going to come in deny audit you know append or modify or disable it right that's what comes in another parameter file you define the parameters so if you use more than one parameter you're going to keep defining the parameter on the parameter file and how we execute it as a very simple powershell command new as a policy definition you can also do this in the portal right or you can do it over here so new policy definition and then the uh and then the assigned policy deposition good to go your policy in place so for this demo i'm going to use a very simple two policies let me go back to the portal again so i go back to my management groups so i'm right now in the management group called engineering i go to the details right i have the policies okay so here i can define a policy but to define a policy i'm going to duplicate this tab when it loads so i go i look for the policies over here policy over here and then i can definitions okay so which is not here oh here it is i didn't see it sorry definitions and then policy definition and then you keep adding it so definition location so which is going to be in this case because i'm browsing on the management group so it tells me all the management group that i have it so i can select the management group for example engineering in this case i say that's where this policy is going to be applied and then i can define some name and then some description and then the policy rules again it's a json file once i type the policy rule and then click save the policy is saved and then you assign it and then you you once you are signed it's in effect right so instead of doing the portal i'm going to do it in the powershell command so i go back to my demo called policies i have the command over here and then i have two policies the one policy is called a virtual machine okay so this is the policy vm name and then i have another policy called a web app right so this is this is important so for web app microsoft dot web slash sites and virtual machine i call it as come on here it is rules and rules okay so we call it as microsoft compute slash virtual machine for web app microsoft.web dot sites right and then the corresponding parameter file so same parameter name pattern and then and and here i call it as a name pattern and i have powershell command that runs all the policies here right so for demo reason i'm going to put demo here okay so i defined the management group called engineering that's what i'm going to apply it and then there's a full scope how it's going to be sometimes microsoft needs a scope sometimes not and then policy definition we're going to we need some name and then the display name as we seen on the ui and some description and then the policy file which is the rule and then the uh and then the parameter file which is the parameter and then the management group that i'm going to apply it if you want to apply the policies to a subscription it's going to say dash subscription but in this stock we're always going to use the management group so i define the management group a motorcycle dollar and i run this script it creates a policy and then here again i create another policy which is the web app so let me fix the rules of the web app if i have anything hardcoded here parameter so nothing hardcoder so it could be good to run save all um so i go back to my computer policies and then write the match pattern.ps1 before i run that if i go back to my engineering and then the policies right when i look for the uh when i look for the policy policy definitions when i look for the custom type i don't have anything okay so i'm going to add a custom type let's run this command okay so if i go back and then it was there yeah okay so i had some more hot coder makes sense uh let's say get policy that's not a problem but and then i run the"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:45:55",
        "seconds": 2755,
        "text": "let's run this command okay so if i go back and then it was there yeah okay so i had some more hot coder makes sense uh let's say get policy that's not a problem but and then i run the what is the command that failed okay created it and just go around this command not so drunk yeah and then i just go look at it over here i refresh it okay i got my vm naming policy right where it is assigned i can look at the assignments um no it's not assigned when i look at it over here and the policy it's not assigned yet so i'm going to assign it right now okay so that's a statement you can assign but i'm going to hold the assignment statement for now to demo other other functionality so let me create another policy here surround these two okay so we go back to the definitions and then look for the custom type refresh few times is there you come for text sometimes it takes bit longer okay did everything correct yeah it is there okay so i have two policies now how i can assign it i go back here it's going to display me um come on load it okay so i go back here i select the custom i can do that right click and then assign so you can view definition edit definition duplicate anything that you want to do it now if you want to assign it i say right click and then assign it and then it tells me what scope you want to apply it right in this case we want to change the scope um i can define it but right now the policy under this management group so it can be assigned that management group or underneath okay um and then exclusion scope um as i said you know if you look at it um you know optionally choose you know i don't want you know it displays me based on the subscription i'm you know that scope is the managing group called engineering underneath i only have a two subscription tells you i don't want to apply to this subscription really because you know this is something going to break so i can exclude it or as you select i can exclude the resource group say for example if i say this one and then it will tell you which resource group you want to filtrate or not filter it and so on right and then you give some assignment a name to it um and then enabled it or disabled it to run the policy and then you just review and create you know once you click on this and then go to next step and it gives you the name pattern because did you you know if you remember correctly here in the policy we had a one parameter so if we look at it um rules here so we have one parameter that parameter we have this parameter file that's the parameter file is prompted over here now you define the pattern this is not supporting a regular expression right now it supports the three characters question mark asterisk or cash for numbers okay those are the three things um so i i heard that from microsoft they're working on the regular expressions but it is not there yet so you can use one combination of those patterns okay so if i want to say everything started with the vm and i don't care after that what it comes in so i say start so vm test r means you know i i'm expecting one or more character after the dash but it doesn't matter what it is so i want some numbers to be there then i put this way so i'm expecting vm dash in some characters one or more characters then dash and i'm expecting the number that's how i put the patterns okay so i can complete and create this but i'm going to cancel it for now so that's once i assign a policy so if i did not assign it but that's how you assign individual policies you click on it assign it and then click on it assign it so where it's going to effectively work also in a second so that's the way that you ascend individual policy but there is something called initiated definition what does that mean you want to create a compliance standard right so you have a naming standard so right now in my naming standard if any resource that creates a vm this has to be vm dash web app this has to be app dash so i can create initiative definition instead of assigning one at a time i can create an initial definition and come back here it's going to load all my custom policies these are custom says the customer i'm going to select that policy i'm going to select that policy and then i'm going to say my my naming compliance naming compliances i say that and then i click save right so what i'm doing is"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:50:58",
        "seconds": 3058,
        "text": "customer i'm going to select that policy i'm going to select that policy and then i'm going to say my my naming compliance naming compliances i say that and then i click save right so what i'm doing is the initiative is nothing but grouping one or more policies instead of ascending the single you know individual policy you group them together this also let you pick all the built-in policies so you can mix and match there's a crazy number of written policies you can go through it and then choose the one you want to if they're not going to meet your requirement obviously you can define one like this so i'm going to save this one okay so now it prompted me so if you looked at it before when i click right click assign there is a parameter tab that comes with the same text box you're going to define it but in this case it's the initiative now when you build the we have to send the parameter so i'm going to say for the uh the password is the virtual machine i'm going to say vm dash star and then the second one is the web app i'm going to say app desktop okay and then i click save now i created the initiatives so if we go back to my initiated definitions sorry um assignments and then assign initiative right initiate the definitions and i have my initial definition so before when you have seen a policy you right click on the policy click assign but here how does in a initiative you go over to the aston institute now i'm assuming to the management group engineering i select my compliances which is custom um customer initiative that we created we're going to assign the scope of engineering and we are not going to exclude anything okay so that's the name we gave it and then you know it's created by and then uh um the code next step there is nothing to define the parameter and then the next step if you have a remediation that this is what it gives you you don't have if you don't give up um you know you can provide a remediation steps either it's a self-cleaning or if you use the built-in policy such as you know checking for the transport standard or the encryption it will give you automatically the remediation steps over here but in this case we don't have any of the mediations i go to the final step and then i there is no error all right and then go on create so i created an initiative that contains two policies now what is next now we need to we need to see how it's working right so we applied this policy to a management group called engineering so what does that mean if i go back to the subscription underneath i'm trying to create a resource then this policy should be in effect so i'm going to go back to this uh engineering subscriptions go back um i think i can go here i try to create a create a vm for example let us do that let's do a create a resource um say alright that's why we applied it and then uh it does not matter what i'm going to give it here or i just say something like that so i can delete it later uh virtual machine name so i'm going to violate it i'm going to say demo boston something like that i'm not going to worry about any of these but and i always use windows so let me use windows here i just say some user password all right and then when i go review on create surrounding the final validation and it said it failed when i looked at it it failed on the naming convention right so now if you look at it what it failed to tell you so okay you know this this definitely failed on that one so if i look at it open a new tab um it provided me okay this is the convention you want to you want to change it yeah you can now review and click and provide save and change it if that's this is not expected behavior yeah here is here you come and change it but now how do i fix it i go back to my previous screen which is a basic screen i go and say vm dash you know hello boston right and then now i go review and create it's running the policy rules now earning the validation still failed but i've seen this sometimes it will take a time when you apply the apply the policies um keep trying on it trust me it'll work i'm going to go"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "00:55:59",
        "seconds": 3359,
        "text": "earning the validation still failed but i've seen this sometimes it will take a time when you apply the apply the policies um keep trying on it trust me it'll work i'm going to go back to my screen previous basic close all right so what we did was just put remove the dash vm dance review and create okay it may be the initiative sometimes it's not understanding but um it will work it sometimes it does that weirdness but it will work the logic will work if i go back and unless in the unless in the initiative let me go back here let me delete assignment yes i delete the segment then i come back to the definition and then i look for the custom um and then that's the initiative i'm going to i did not send it so i didn't worry about it let me assign this one virtual machine okay assignment value that's fine review and create parameters i'm going to say vm dash star review on create create supply to engineering now okay it's assigned we go to the assignments you look for policies that's awesome okay let me create go back to custom and send it right yeah unless i need policy that's what i did yeah it is odd it just takes the time um it's over there let me go ahead and do a same operation over here just in case this passed to basic review and created it still failed vmware's holocaust okay um i did a request disallowed by the policy okay i it brought the right policy but you know trust me this is supposed to work and that's how my other policies are working on my other subscription but at times it has a problem or if you if you come back in few minutes later it may work too you will try it end of the demo right so that's how you you run the policy uh yeah that's how you run the policy any questions so far can i jump in so i've noticed with azure a lot of times if things don't work you just need to stop give a little bit of time let things catch up and then they work that is true till today yeah i mean we have that problem every day it's funny because normally with on-premise you can go so fast but in the cloud you have to stop you have to wait let let things think and catch up you just have to be patient um it's it's not all the time but sometimes this is the problem when you try to reuse the same identity uh in in in my in the work that i perform we rapidly clean up because we don't want to pay for it right and then we rapidly rebuild it when that happens it failed you know this is the case for example in the index services like searching as you search our gognity subs they call it this now we want to create the index delete the index more often and then dribble to the index when we when we're trying to reuse that investment so we don't want to create another index service yep when we use the same name we have this problem so like one out of three times it brings the stale data from the last time i created the none of the indexer will run and then bring the data and so on and i had the same problem the cosmos tv when it was trying to um when you so trying to send all the changes to my back and function app it will not do it if i go and delete and recreate that and even though i enumerate the data but it depends what you're doing it it you know in in the in my experience i've seen this is more more often it's happening when you try to reuse the same same operation over the existing service same name identifier or the existing service it happens but i think the bigger thing i'm getting at is when you have all your resources on-prem and everything like that you can control the resources and you know what the workloads and everything like that is and when it's in the cloud on one day you there can be low utilization across the cloud so"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:01:02",
        "seconds": 3662,
        "text": "all your resources on-prem and everything like that you can control the resources and you know what the workloads and everything like that is and when it's in the cloud on one day you there can be low utilization across the cloud so everything happens right now and other days there's high utilization so you have to give it a little bit and then it works yeah true um i you know i mean i i think bill you can answer better this question but i will try my take you know it's something called auto scaling uh microsoft has auto scaling on every single component they build you know it can be a serverless it can be a compute or it can be a database in the for the database they provide auto screening request unit now compute they're providing auto scaling from you know like um um scale out not the scale up or down you should be able to scale out you know one two two to three mission or back to one machine or web app one instant to any instance or back to one instance right uh when it comes to the database there is a problems but i i you know i worked a lot in the on-premises in the past but when compared with on-premises uh the cloud is seems to be much better i know there is a problem but that problems is not always happening but it is happening here and there right it is there it's inconvenient sometimes but i believe you know face the upfront investment on on premises working with the stale hardware but these problems face the problems once a while is okay seems to me you know in even another example if you take a database they provide you artists curling up these request units you know you can provision for 100 000 unit but there is a base unit you want the city for example 4000 records to unit and it's going to scale automatically but doing that in the on-premise is almost impossible um so um bill you want to add something that'll be great but i will move on i'll make one minor comment uh that azure is i i gotta think it's one of the most complex sophisticated uh high scale systems you know ever created there are other you know aws is big complex system azure that uh and there are you know some others but it's got to be in you know the top one percent of boy this is a big large complex distributed system right and it happens to run our workloads but also the uh the azure workloads in uh and it has uh an eventual consistency model where when you apply a policy or you create a new policy and make an assignment there's you know it captures the request to do that and then it's got some tidying up to do in the background and that can take milliseconds or seconds or maybe sometimes minutes in the outside i i think that's just a natural consequence of building complex systems is that you let them settle sometimes i don't know do you have the same so that's my uh you know thumb to the wind idea of what what i would imagine would be a hard problem to make that um uh not be uh just to solve that in a way that everything was instant and worked all the time a lot more expensive and there'd be more risk paths right if you're if you have to wait for everything to settle before the you know ui gave control back for example dude you experience that you work across the three clouds today uh is this phenomenon i i i don't think you want to hear this answer but um the the cleaning of the resource you know the reusability mode um there is a little blackness in the microsoft compared to the aws but it's not something that you cannot accept it i accept it all the time i understand okay i understand things are going on you know one out i told you in a good example when we when we reuse the same index we had this problem one out of three times right so we go back you see the index is deleted yeah index deleted index is deleted data source deleted but where is that you know you few seconds later you run the new new index few seconds later you have a stale data over there where it's coming from i know it's crazy it's coming from if i would have waited 10 more minutes it's cleaned because they work in a partitions across multiple hundreds and thousands of missions and sometimes randomly you see this problem if you don't give enough time to cool down um when compared to the other provider it is but there may be a problem the other provider too based on the area that i consumed a little chatty here but it's not bothering me to be honest it's bother somebody in my lab but it's not bothering me and you did can i ask something sure uh a couple days ago i had a meet up and the person was more immersed with aws and google cloud and he was talking about i could get this wrong because i'm still working"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:06:08",
        "seconds": 3968,
        "text": "and you did can i ask something sure uh a couple days ago i had a meet up and the person was more immersed with aws and google cloud and he was talking about i could get this wrong because i'm still working on my cloud the uh cdi pipeline and he's talking about all the different steps and components and all this to get it to work on azure you know i mean uh aws i'm just going it seems like all this is just built into azure and it's easier am i wrong yeah it is easier yeah i mean microsoft is a software company it is easier yeah so it it's like azure you put the parts together but with azure it's all there yeah oh i thought i was just crazy but thank you yeah it is it is easy compared with uh um it also depends what type of resource you're consuming it right you know if you if you go back and just jason might be the right person to talk about it if you go back you know year back you know if you want to manage you know containers as it might not be uh might not be providing the right tools but you know but if you go back now microsoft provides awesome tools to manage those things right it's always evolving but microsoft goal is to i'm not a microsoft person but i believe microsoft always brings the awesome tool sets to make a developer's life easy but you know it just takes the time but you know the end game you will see awesome tools yeah just to add it to one more thing there actually the microsoft right so if you have any on-prem licenses or something like that microsoft let you use those on-prem licenses for the resources which you are provisioning in cloud let's say you have windows server licenses or anything which you already which the company might have already bought and they're using for on-prem and now they decided to move it to move to cloud uh they might think like oh what happens to my my licenses which i purchased up front no they can they can use it they can that's what they called as a hub so you can you can you can use those licenses and that saves like some good cost for you yeah that's a good point again there are you know enterprise style test which gives you uh some discount on the resource consumptions can i add in so if you have a on-site sql license you bring that up to azure and then you you use uh the reserved instances your cost drops astronomically it becomes almost yeah but those license only applies to the enterprise subscriptions not the tab test subscriptions so there is there is a so there but but that's still that's really good amount of money uh to save actually that's that's a good savings okay so i i think i i start i okay good uh thank you may know your name sorry i'm not seeing the indian dashboard sorry this is vampc my name is okay nice to meet you okay good point thank you so now i know i had a two policy right so um so i got one policy for vmware policy for web app i'm not sure how i configured but now i start applying the web app policy so if i don't have a app star then it's going to fail so i say something like this and then i say it says yes yeah looks a valid name and then review and create what it was failing few seconds ago now it says passing that's one thing to understand uh it's training few seconds ago or i don't know all right it was it was just spring it failed the validation sunday like put a app dash but anyway we got it let's move on um let's move on to the blueprints um there was great questions thank you let's move on to the blueprints so now you have the management group how to create the control the subscriptions right now you have the policies how do you want to defend the complaints you know to control the subscription you have the role based access control you define who belongs to what group and how you want to give them access to on the resource level then you have a policy the who you know the the people have access to the resource how they can meet the compliances that's why you have the policy so you heard the management group you put a subscription then you defined who has what i access using the role-based access control you know to what resource and then you define the policies how do you want to defend the compliances when they're going to access the resources right now how they can deploy all the resources together how they can integrate all the policies you just learned how they can integrate all the in the role best they learn how they can deploy the resources so what you defined it makes sense right that's something called blueprints the blueprints is composed of resource groups on template policy assignments and then the role assignments once you have the blueprint defined and assigned to a subscription are to a management"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:11:12",
        "seconds": 4272,
        "text": "deploy the resources so what you defined it makes sense right that's something called blueprints the blueprints is composed of resource groups on template policy assignments and then the role assignments once you have the blueprint defined and assigned to a subscription are to a management group then all the subscription under the management groups you can deploy all the subscription under the management groups so this is very important so if you have if you repeat certain type of deployment for all the customers i'll give one example in my scenario so we run uh we run a managed managed customers who want to have their own subscriptions we run a software as a service where we onboard our own our subscription they take a software service model so when we run the management uh managed subs customers we would provision a new subscription we'll manage it but they are going to be deployed the same exact pattern right so for example we create a web app we create a radius instance we create a cosmos tv we get a search index keyword storage you know everything we created so now that's a repeated steps the one way we have the power cell published on the online you can before the blueprint you can go ahead and download the powershell script and run it it's good to go with the blueprint you don't have to run it you can make all those predefined templates available in the portal right so blueprint is composed of mostly the arm template if you already know how to use arm template blueprint is nothing new zero learning it's exactly just copy everything in the arm template put them in the blueprint you know create a json file put on everything in uh there is a few tag before and after you defend those few tags and just copy the arm template content and put it over here that's all it is all right and it's a declarative um it follows some patterns like a convention patterns called artifact and then you you put all the artifact inside we will see in a second right and that applied to a management group or subscriptions uh you know you can pass a parameter so you define all the parameters in the blueprint template and pass it across all the arm templates in other words artifact it can have a policy or initiatives um you can you know you know one difference between arm template and the blueprint is on template you can store it somewhere as a storage but they are not giving you a workflow on it meaning that you can um version you cannot apply version authorization for example you create one today and you want to modify and convert that as a v2 you can do it to the blueprint but not with arm template but you will have to maintain it somewhere else but the blueprint versioning is natively maintained within the cloud it can be a static parameter or it can be a dynamic parameter meaning that a template is executed that output can be passed to a template b you know then that output can be passed down to a template c right so that's how that's how the dynamic parameter works you can define the sequencing by default scope from top to bottom but you can you can make you can change the sequencing by putting the depends on so you have three templates you know storage keyword and web app you want to create a web app right after the storage and you're going to say the web app template depend on the storage so it's going to wait until the storage is created right and then the resource logging resource locking is you deploy using the blueprint and you don't want somebody else to delete it they want to keep running it that's the most dangerous things then you know when we run the manage managed customer instances we don't want anybody to delete it accidentally um so to do that you know there is option called locking so nobody can delete it until the resource owner goes and unlocks it and delete okay now how to create a blueprints it it comes with the two files one is the blueprint.json there you define all the parameters right the second artifact um the artifact the template is nothing but copy of currently whatever arm template that you are using you have on template to create a web app just copy and paste to here you have on template for keyword just copy and paste over there right so any arm template you use today just copy and paste over there and then you just decorate with these tags resource group parameters and so on so if you look at it over here here is the resource group demo that demo should match with the resource group demo over here you dynamically replace the parameters it will give you option to replace it but that's how it works and then the parameter website right that parameter is coming from this parameter so whatever parameter you defined over here you can read the parameter over here and if if you want to read output of this file parameter into some other file you just going to say whatever the template name of parameters are the parameter name we will see an example okay and then the type is important so just a two files one is the blueprint.json to define your parameter second one is the artifact which is nothing but the arm template with some more parameters on it and it takes a convention based pattern and this is how it convention so blueprint.json then you create a folder"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:16:15",
        "seconds": 4575,
        "text": "blueprint.json to define your parameter second one is the artifact which is nothing but the arm template with some more parameters on it and it takes a convention based pattern and this is how it convention so blueprint.json then you create a folder called artifacts and then you define the artifact one maybe the keyword artifact two maybe the storage artifact three maybe the web app and so on um i'm not sure what's the time now bill do you have to are we okay we still have time um so blueprints yeah i think we have the the room for uh another half hour or 45 minutes again thank you so okay that's a virtual meeting joke come on uh so so if you look at the blueprint power cell uh there is mainly uh two blueprint commands right one is import you can import it and then the path and then you give the scope and then other one is published so if if you import it creates a draft until you publish it right so if you define the template you you you import it it creates a draft and you do again it makes changes and it's going to overwrite it so you import it you publish it but again you're going to import the same template it will ask you okay you want to overwrite it and that will become a second draft and you can publish that as a different version okay so you can have multiple versions um so this is a more you know if you compare the amp template amp template you need to version it somewhere else amp template is not going to tell you how the resources are provisioned okay um but here it will tell you how the results are provisioned which version is coming from all those cool things you can do it also in the demo um so let's go back to the demo close this one i come back here if i look at it looping.json i have um i'm creating a three resource here one is the keyword other one is such service and then the third one is the storage and fourth one is the web app right so i'm creating a four services and they are um this you know if you have arm template this is what it looked like on template and now i just added the queue tag um not i that's microsoft record you to add those two tags before and after okay so let's take improvement.json first it has a parameter the parameter is going to be a website name and storage account name storage account type and you can define if you want the load values you can define it over here and then the key vault name and then some object id who has access to that keyword and this is again some user id who has access to the keyword and permissions make i hardcode it to all but you know it up to the whole defining that blueprint.json right so just a key take here you can define the parameters you can define the allowed values you can set the default values in this case i set the default values i said download values right so that's all you do blueprint.json and then one thing to note on in the bottom resource group that's very important and we have to refer this name into all the artifact that we defined so let's take a keyword.json and we have the parameter you know um you know it's multiple parameters here let's go scroll up keyword right keyword name object user id where it's coming from it's all coming from the blueprint.json where we set that value if you look at in the bottom we say the resource group demo so he said that should match what is in the blueprint.json once you have it you see that you know it goes to the blueprint.json it reads that template and set the value here okay and then it keeps setting all the values from there and if you look at it over here secret value it's setting from the output so how you read the output it sets the output from the storage which is the story just uses the name here is the story okay go back to the artifact stories read the outputs and then read that value so that's going to be secret value for this template so it's now it's reading the value from the storage artifact but it cannot run fast so what we do here we say that depends on the okay so we create the storage connection string that depends on the keyword so we need to create the keywords so that we set the value secrets okay i'm sorry storage here so this go back depends on so there is no dependency on the storage so this is going to create first okay so now when you go back to the keyword depends on the secret depends on the storage connection string it depends on this keyword name so and then if you look at it over here the secret value comes from the storage so it's going to execute that storage first and then take the value ascend back to this storage connection string over here and there are the other parameters okay"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:21:19",
        "seconds": 4879,
        "text": "the secret value comes from the storage so it's going to execute that storage first and then take the value ascend back to this storage connection string over here and there are the other parameters okay so now go back to the web app if you look at the depends on over here it should have some different sound it depends on the website and then the resource id absolute app service plan name so you first need to create a plan let's see i mean again this depends on apply to arm template if you have arm template if i already used a different term that's the same thing same thing used to here but it knows when you use the output parameter like that or over here it knows this is not the first thing to run because this has the dependency parameter on storage so it will go and look at the storage okay and then it execute the storage first and it takes this one that does some analysis you know microsoft runs some rules to see what to run first if you don't you know um you know if you don't know any dependency it's going to go in the order of top to bottom all right so now how to deploy this so i go back to my blueprint file i you know so there is one thing to note you need to have the blueprint registration happening so you go to the you know that registration should happen on the subscription level you go to the subscription um so if you look at it over here home subscription and then look at the resource providers and you need to enable it okay if not done already you need to come back you know there may be a lot of things you click on it and then register it so you have to find the blueprint one i already did it but you find the blueprint one and then enable it do that and then you just um have the file and some name and i'm going to run from the root of the folder okay and then run this command so you can i'm running it under the management group called engineering i run this one go back to my um go back to my management troops near ring right details okay no it's not part of that let's follow the blueprints okay blueprints okay blueprint definition i don't have anything i don't understand i don't have any assigned blueprints here right so let me go ahead and look at it so i'm going to run this one oh god i broke it then name i broke it let me delete it it's a problem okay i've been done it go back and the my blueprint you know so if i look at it if you refresh this time now i see it and then i can publish from here or i can publish this command if i you know it doesn't matter where i do it but let me do it from here and then i call it as the uh and read okay so i published it now so if you want to create another version i can go back and run the same command assuming that i edited something right i click on it it's going to ask me i'm going to write it as a trapped version yeah do it okay um right now i'm going to read the blueprint again i got it and then now i'm going to publish it and this time i'm going to call it i want 2.0 i'll show you where it appears okay so i i did a two version one is the 1.0 second one is 2.0 i didn't make change but you assume that you changed something okay so now i have the blueprint um so when i refresh it it's the same blueprint but it has a multiple versions if you want to see you can look at it view blueprint um you know the latest is 2.0 but when you deploy you can go back and then see the 1.0 so this is this is the artifact this is the things now let's assign this blueprint so we can assign it okay so when you assign it asking me the subscription again i assigned to the management group called engineering under engineering there is only two subscriptions so it is prompt where you want to apply it so if you want to apply the same deployment across all the subscription you"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:26:22",
        "seconds": 5182,
        "text": "subscription again i assigned to the management group called engineering under engineering there is only two subscriptions so it is prompt where you want to apply it so if you want to apply the same deployment across all the subscription you will select everything so when you do a deployment it's going to do it for all the subscriptions in this case i'm going to go only enterprise stove test okay and the location you can choose anything i want and here it displays which version you want to display if i want to go back to one point what deployment i can select 1.0 and here is the option you want to lock it or not um and then the here is the system assigned or user ascent identity but you know user ascent identity you have to go and pick up hazard direct app id system has identity microsoft will do it for you by using the inbuilt um inbuilt service principles so now our template had these kind of patterns again if you don't you know you have the resource group name so i'm going to say for easy purpose would i boston demo copy that value all the time i'm going to pick the location over here set the value i set wrong value here and show you why it's going to break down the road i said that one click on type and again we said this is a predefined value so you can define it and then website name and then assign okay now okay so service name and then assign right so it's going to assign it meaning that it's now deployment in progress so you have the you have the blueprint you know deploying to one subscription you just you just assigning it so if you go back over there you can see the status what is going on over here so it may tell you it's you know deploying it in a few seconds later it will say deploying it and it's going to fail because one of the parameter i punched in wrong that's the key thing of this when you go ahead and resume there it will skip all the successful steps that it run already right so you have a 10 artifact in your blueprint five artifacts succeeded the sixth artifact somehow broken now you go on to fix the parameter you rerun it it's not going to run the first five successful artifact it will check it but it's going to skip it go you know for us it's keeping it for the system i'm not sure what it's doing it but it's not going to run those files uh it goes to the sixth step where it's failed it's going to continue from there and you can see all those things when you're trying but this will take some times to trigger in um over here but you can see all the activity lungs um that's how the blueprint works any question it's coming up yeah it's deploying now but soon if you go back to my subscription here enterprise tab test um sorry and represent this resource group i'll come just just not happy today um any question [Music] so you're running some um scripts and you know using some various resources along the way you're running from the command line is are those posted to github or anything like that for example for access by uh the public yes uh i'll get you the url so uh yes the answer is yes i'll get in a second so now look at it it failed what it does is it created the resource group it created the storage then it failed i go back and look at why it's failed okay something failed key vault i had a bad parameter over there okay what is it bad parameter when i want to set a access policy i give a some blob of text but access policy cannot set to a blob of text it has to be a guide that existing existed in the active directory so i don't want to browse my active directory in you know in front of everybody so i already copied some values for the demo purpose so if i go back to my rbac command i have this over here okay so now i go back to my um so you did two resource creators successfully the third one it failed i go update assignment right and then i go and fix the parameter so this is the parameter i purposely did wrong okay and then i assign it um it takes time and now it will resume and complete everything so if you see like a few few minutes later you create all those things and we can we can refresh this over here and see it'll display so the storage is created um we'll come back some time okay so now answer the bills question yeah i do have um samples over here the all the code that i ran you can download from here he said he said thank you very much everyday we'll we'll"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:31:25",
        "seconds": 5485,
        "text": "answer the bills question yeah i do have um samples over here the all the code that i ran you can download from here he said he said thank you very much everyday we'll we'll capture that url and uh post it into the the uh chat for folks to have easy access to yeah um so we go to the last slide yeah that's the references link that i learned from hopefully it can help you too any question at this point so if i go back to my assignment it's still waiting yeah it's deploying but it'll succeed this time and the resource is ready um if you look for back the resources they are locked so if you go back to uh so for example here oh look over here if you look at the locks it is locked i don't know whether i set a lock or not but if you look at the resources it should be locked by default and see it may be doppler under end of thing but yeah it will be locked you cannot delete it i am the super user but somebody else comes in they're gonna delete it yes i think that completes my talk tonight um if any questions i will take it yeah uday um i i was wondering if um let's see how to phrase this so if uh if i'm just getting started and maybe i have maybe i have some older azure production workloads and i want to say start using management groups or policies or or blueprints uh even but more focused on the first two say uh should i just go in and and um make up policies from the ground up or are there example policies you know i can reference and learn from and maybe you know copy copy as a starting point yeah there is uh example policies uh when you so if you go to uh subscriptions um so go back to the home uh click on the policies here and then you go to the definitions there's a lot of examples of policy definition so import sample from the github there's a lot over here um you can that's that's helps you to define a customer first you're going to define what policy you want from there you're going to check it's a built-in policy solves the problem so if you know there is a built-in policy that can solve your problem you can import all the built-in policies into your management group or a subscription if not then you define custom policies and does it happen to be an equivalent pre-existing set of resources for like how one might model a management group or a higher management group hierarchy like guidance on this the management group you know you know you know if you look at this you you know if you want to define management group on your arc you will there's no guide on it but you will have to define your own hierarchy based on that in my hierarchy it's very simple i have the tenants where my customers i have the internals you know where i have the engineering and sales um uh engineering and something else and i have the another one called sales you know i only have a three three three management group on the top level and one of the management group has the two two sub levels but here is the example this link tells you how you can defend the governance on the management group is it okay if i if i pitch in there is it fine yeah go ahead please yeah so i just i just want to say like how we did for our organization so in this way it will give some idea for other people that's the reason why i want to talk so what what we did is like in our organization there is like sub departments like you take like a sales department like uh some manufacturing department and then some other other departments right so we assign like subscriptions to those subscribes to those departments and then we we went to the management group and we defined those departments and inside that department again we created like non-broad broad and load uh subscriptions and then we assigned those in this way what happened what eventually happened for us is like"
    },
    {
        "speaker": "",
        "title": "Udaiappa Ramachandran: Azure Governance",
        "videoId": "SZo7TnM0LXc",
        "description": "This is a recording of the August 27, 2020 virtual meeting.Azure GovernanceMicrosoft Azure offers enterprise grade security, but are you aware of all the features available to help you configure your Azure Subscription securely - and keep it that way? In this online-only meeting, we will deep dive into Azure Governance including RBAC, Management Groups, Policies, and Blueprints.SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.",
        "start": "01:36:28",
        "seconds": 5788,
        "text": "to the management group and we defined those departments and inside that department again we created like non-broad broad and load uh subscriptions and then we assigned those in this way what happened what eventually happened for us is like we know how much subscriptions are how much it is getting cost for each subscription and we know under which it is falling it is falling under finance or it is falling under sales or something that helps us to say like hey sales is consuming uh 50k per annum i think next year okay let's increase it to 10 so for budgeting purposes and everything it really helped so it's it's it's uh that that hierarchy like how he is how we are seeing here that geography i think instead of geography i think we changed it to uh departments there so yeah uh you know just add some more note in uh in my case um you know we started six years ago there was no building per resource group at that point in time right so we were adopting the year building we were depending on the year building now you can build a pretty much resource group to a resource you can see it so you can you know instead of creating like every sub sub subscription per customer you can have one subscription and then you have multiple resource code one resource script per customer and so on as pumps he said um you know since we started six years ago we have to learn the ea model so we manage the buildings per subscriptions per customers but that's alternative way but if you would have started today i may be using your own subscription the resource group um are maybe some subscriptions not a one but maybe a few subscriptions but not today we are like uh 85 subscriptions that's not something we wanted to have that was a good example thank you yeah thank you uh and i have one more question uday but i'll i'm going to pause and see if anybody else in the audience uh has a question and they're welcome to certainly go ahead of me what are your questions folks on uh blueprints management groups policies governance can i just ask i guess it might be a follow-up follow-up question because back in the day i.t was seen as a black hole because it was money in and nothing out and then a few places started chargeback models and once that started happening it was profitable and now i thought if you could tie a subscription to each department then you could recall recoup and send the cost where it needs to be but can you do that kind of recouping under a single subscription yeah you can do that i did not know that yeah right now the building is you know you can you can bring down all the way to a resource so you can see the building cost for a resource and then it's grouped by resource group which is your department yeah you are your department may have more resource group than you can combined it go ahead but can you do the billing on the sub-level right right we can do that there is a concept called tagging is available in in the in the microsoft microsoft introduced a tagging so what we can do is like let's assume right now you you have only one subscription and you and every department provision all the resources inside that subscription without following any naming convention okay let's assume that is your worst case scenario okay so what you can do is we can we can you can one of your engineering team can write a simple code and take each resource before doing that maybe they have to they have to identify like which resource belongs to whom like let's say a resource one belongs to team one and resource two belongs to team two department to whatever it is so there is a tagging concept involved so they can write a small script and then get that information and then tag it to that resource so right oh and then use the power ba or anything and then group the resources by tag so then you know like which which guy goes to whom and who is accountable for oh yeah good thank you yeah the tagging is a very powerful system uh when it comes to anything in this case um as he said you know you can group all the cost fit tag and you can define a policy to make sure everybody defending the tag for the resource yeah yeah you can do that too all right are there uh further questions come again sorry i i was asking the audience if there were further questions if there aren't now i'll uh i'll throw in my my last question uh when you're starting with um uh management groups and policies they're they're they're pretty powerful is um do you have a recommendation on on um you know how fast to jump in like would you recommend jumping in in audit mode or you know or turn on um you know more aggressive policies right away what's what's your experience on the right way to kind of ease into it um it depends how the existing you know you know how many resources you have in the existing system uh it turns out that it's not a bad idea to go aggressive you know people get if people are up to it very fast um you know audit mode is not going to solve anything until unless you pay attention to that right you have to go to a security center and then watch all those things if you really want to know uh there's going to be a problem i think that i think you have a little aggression tonight more um i mean few few policies it's okay to have audit mode for example disk encryption if you do a lot of vm it's okay to have audit mode that's input policy does too but uh you know i would say not for everything audit then it doesn't make sense for you to roll in the policy but you will have some in uh in a required mode you have to force writing certain things yeah sure thing right you're not going to make any progress unless you yeah if you do it if you do audit you know nobody's going to follow the standard just like you know the voice of experience there well it's it's uh it sounds like um like that's a wrap uh uday uh huge thank you uh enlightening talk as always and really uh want to thank the really engaged audience as well it really brings a lot more to the conversation when uh we have a lot of back and forth like we did tonight so appreciate everybody's willingness to uh speak up and uh it was great to have the the little bit of a round table going here thank you for having me bill tonight yeah you welcome uday and uh i love to look forward to having you back again uh many times i i'll share with the audience that on uh tuesday that's uh september 1st uh is our is the next uh scheduled talk which uh interestingly i i believe is 100 focused on blueprints so it'll be a you know a more uh i would i'm guessing a a slightly more in-depth version of a subset of uh uday's talk so if you want to drill into that and get uh the you know a different perspective uh tune in on tuesday this session will be posted usually within a day or two to the uh youtube channel uh that on if you go to youtube and you just google or search for boston azure uh you'll find the youtube channel there are i think eight videos there now this will be uh number nine and if uh folks have uh suggestions for us uh we'd like to hear them uh you can tweet at us you can post in this message before you leave and you can um uh post to our uh ba slack you know bitly slash ba slack slack channel join that and and have a chat where we'd love to hear the feedback you could also post on meetup but we love to hear the feedback and we were always interested in your ideas for for talks it was some chatter about uh talk ideas tonight through that was productive so bill and everyone else thank you for a great presentation thank you thank you all day thank you guys talk to you soon bye bye okay good night everybody thank you guys thank you "
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:00:04",
        "seconds": 4,
        "text": "Choosing from the many ways to Docker in Azure. This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.. awesome we're good oh you're on mute rob or i don't hear yeah zoom are you there oh no can you hear me now i can hear you now yes much awesome sweet one win for technology okay welcome everyone to boston azure i'm really excited to present today choosing from the many ways to docker in azure we're going to look through a lot of different compute mechanisms inside of azure and see how we can host containers there here's the part where i tell you i am definitely going to post the slides of my site tonight have you ever heard that from a speaker and you're just like but but are you going to post them which is why i've already tweeted the link to the slides and let's head over to robrich.org right now we'll go to robrich.org and here's uh click on presentations here at the top here's choosing from the many ways to docker and azure and the slides are online right now achievement unlocked so while we're here on robrich.org let's go click on about me and we'll see some of the things that i do i've done recently i'm a microsoft mvp and mct that was a lot of fun i'm also a docker captain a friend of redgate azgive camp is really fun azgive camp brings volunteer developers together with charities to build free software we start building software friday after work sunday afternoon we deliver completed software to charities sleep is optional caffeine provided if you're in phoenix come join us for the next a-z gift camp or if you'd like a gift camp here in boston or wherever you're watching this video from hit me up on email or twitter or find me here at the meetup and let's get a gift camp in your neighborhood too some of the other things that i've done pro microservices and dot net six that was a lot of fun i got to work with sean and matt on that book and one of the things i'm particularly proud of i replied to a dot net rocks podcast episode they read my comments on the air and they sent me a mug and if you'd like to no i'm just kidding so that's some of the things about me let's dig into some of the things about azure so there's lots of different ways that you can run containers in azure azure kubernetes service azure container service azure container instance azure service fabric azure web apps azure container apps azure container registry and it's like which one should i choose i'm going to frame that a little bit differently and talk about when should i choose each one let's take a look at each one and see how that works and when we might choose each one and what makes that one superior in that use case taking a step back what is docker well docker is container virtualization what are containers they're lightweight kernel virtualization unlike typical virtualization with like hyper-v or zen or parallels we're not virtualizing the hardware we're virtualizing the operating system and so then docker is this suite of command line tools for building and running these container images now that's kind of cool we're virtualizing the operating system instead of the hardware which means here on the left is traditional virtualization on the right is containers we can see that we're already using the content much more efficiently on the left we only get three virtual machines and on the right we got seven containers now this is definitely not to scale but we can see we're already using our hardware more efficiently because we don't need these duplicate copies of the operating system in each container each container is only the difference between the host and what we need to run our application so this is how we do containers the cool but annoying part is that because we're virtualizing the kernel the operating system our kernel needs to match the kernel in the host needs to match the kernel in the guest so if we have a linux container we need a linux host and if we have a windows container we need a windows server host well what's missing well how about gnome and kde how about windows desktop how about mac os hey i'm running docker on my windows desktop or on my mac laptop you telling me that's a lie well yeah kind of in production we want to do it here on the right where we're using our hardware as efficiently as we can but on the left is how we'll do it in development so i'm going to take my windows laptop or my mac laptop i'm going to install my host os so you know windows desktop or mac os i'll install"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:05:08",
        "seconds": 308,
        "text": "but on the left is how we'll do it in development so i'm going to take my windows laptop or my mac laptop i'm going to install my host os so you know windows desktop or mac os i'll install my hypervisor in the case of windows it's a hyper-v in the case of mac it's hyperkit and then i'll install a guest operating system now this is a linux operating system a linux virtual machine and inside that linux virtual machine we'll install docker desktop so yes i have two hypervisors now but now i'm able to run my linux containers in my linux virtual machine on my mac or windows desktop in production we definitely want to do it this way we want to do it as efficiently as possible but in development we can do it like this now what's really cool with windows is that this guess os can be wsl so if i have wsl2 installed and i install docker desktop docker desktop will notice and just say hey can i hook into wsl2 we click yes everything's fun now the cool part there is that we can pretend that this hypervisor is actually hooked to our host os so we can do things like localhost and the port of the container and it will just map us in automatically that's really cool if we're using something like minicube or mac os or some other operating systems we don't have that wsl integration then that auto magic proxying between the things is a little bit harder so that's containers let's talk about what is an orchestrator now when we're building these container images we're getting all of our content into place but then we need to be able to run them at scale now if i just said docker run i've got it running but i'm only running one of them what happens if it crashes what happens if it's not working what happens if i need to scale up because i'm getting more traffic that's where we get an orchestrator an orchestrator is a cluster of machines we'll take a collection of machines we'll connect them together and we'll install the orchestrator on that set of machines and then we'll give the orchestrator some instructions now um we can give it our desired state i want three copies of my application running i want them across availability zones i want to be able to scale traffic up and down i want to have the storage move over here these are things that we can give to our orchestrator that desired state now in windows we have desired state configuration this is not that rather we're telling the orchestrator our end goal and however the orchestrator needs to do it it can do that so do i put the container here or do i put it over there if this hardware is having difficulties i'll just shuffle them all over onto this one these are things that our orchestrators do automatically and we can sleep through it that's really cool we hand the desired state to our orchestrator and our orchestrator makes the decisions about which machine should be doing what and we don't need to worry about it so for example we might hand our orchestrator instructions like i would like you to start this group of containers i would like them to be across availability zones i would like them to cap out at this much memory this much cpu if they go over that consider them unhealthy if they don't respond to a ping in this way consider them unhealthy or maybe if they don't respond to this web url consider them unhealthy if they're unhealthy automatically kick them off and create a new one and so you know i don't need to worry about did that container go awry um the orchestrator is just gonna fling it off and and pick up a new one with an orchestration engine often we often will also have load balancing and a management ui and so that allows us to visualize what the cluster is doing so as we pick an orchestration engine oh so the tldr there an orchestration engine is both scheduling the stuff but also keeping the containers healthy not necessarily that it's going to make our containers work better but rather it's going to monitor them and if they are unhealthy it will start up a new one so we have lots of different orchestrators that we can choose from kubernetes mesos docker swarm azure service fabric amazon fargate each of these are orchestrators where we can give them those instructions i'd like you to run my image i'd like this many copies i would like you to keep them running across availability zones i'd like you to scale up and down using these rules and each of these can do that the cool part is that that orchestrator is kind of what we're picking as we pick the various compute pieces inside of azure but taking a step back let's take"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:10:14",
        "seconds": 614,
        "text": "rules and each of these can do that the cool part is that that orchestrator is kind of what we're picking as we pick the various compute pieces inside of azure but taking a step back let's take a look at the docker ecosystem they all run containers now so far i've been using the term container to mean both container and image i'm going to stop doing that let's talk about the docker ecosystem we start with a docker file and this docker file is the configuration is code that gives us the instructions of how we build an image that image is the binary blob that tells us how we might run this but it's not running yet then when we instantiate it when we start it then we get a container so we could think of this like a class file a dll and running the dll on the server or a class file an object definition and an instance of the object here when we get to a container we run it on a hypervisor in this case i chose docker machine but we could also choose kubernetes or aws fargate we just plug in ethernet and power and that image spins up as a container it gets a unique hostname and ip address and is nicely sandboxed from other things what's interesting is we can choose to share images or download images from docker hub now unlike github where we share our source code with docker hub we share our binary blobs so if i download something from docker hub i don't need to recompile it i only need to start it that's brilliant simultaneously we could use a docker compose file or kubernetes yaml files to specify many docker files or many images from docker hub or another registry we now can collect those images and then start them together on a docker hypervisor like kubernetes or in this case i chose docker swarm plug in ethernet plug in power identify how these things connect and i can now run a fleet of services all together on a kubernetes hypervisor or docker hypervisor so that's really cool this configuration as code is really tiny it gets us to an image that we can start as a container and then we can start to run our app really really easily if our app has problems we can start up another container this image is isomorphic it doesn't change so let's go build a container now i have here an empty directory now we could definitely go into visual studio and create an application that would be fun but i'm going to say dot net new and that will allow us to scaffold out a website as well so we can choose various types of apps and so i'm going to say net new mvc i'll give it a name of site and an output of dot now i could have given i could have both name and output are optional if i didn't specify a name it would use my folder name so in this case demo and if i didn't specify output it would create a new folder inside this folder so then i would have a demo folder and inside that a demo folder and my content would be there so here's our website if we say net run then our website will start up if we say net build then our website will end up in the bin folder and we can say net site.dll inside that bin folder and launch our app that way but let's open this up in vs code and start to containerize it ooh i've got a lot of stuff open let's close these because none of those files exist okay so i have my regular website here's my home controller and my home controller has various actions in this case here's index i can come over to my home view and it says home page welcome that's cool it's a regular website now our first step in containerizing our application is actually to create a dot git ignore file file dot git ignore now our git ignore file is everything that we don't want to commit to source control so we don't want to commit built files we don't want to commit downloaded files we don't want to commit user specific files we don't want to commit temp files and we don't want to commit secrets so let's do that with built files we don't want to commit our obj folder and our bin folder downloaded files if we were in a.net framework app we wouldn't want to commit our packages folder here in net core or in this case.net 6 then we um oh actually i was"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:15:17",
        "seconds": 917,
        "text": "downloaded files if we were in a.net framework app we wouldn't want to commit our packages folder here in net core or in this case.net 6 then we um oh actually i was supposed to click yes there it would create a dot vs code folder there in net six we don't have a packages folder so there aren't any downloaded files if we wanted to get really particular we could go after these libraries here and switch them over to cdn resources and then exclude those but in this case i'm going to leave that blank user specific files star.user the vs folder maybe the vs code folder if we have unique things there or that's generally you know just static stuff that we've created that allows us to debug so i'll check that in we also don't want to commit the star.suo and those are the user-specific files temp files so we might have star.orige that's created by git when we do a merge conflict we might have star.tmp or star.log any other temp things and then towards secrets right now in our app settings we don't have any content but if we chose to put secrets in our app.development.json we might want to exclude this or what i like to do is i come into my app settings and i will say let's create a connection strings section my db and i will say use user secrets and now this is the only reference to that and so inside visual studio i can right click on the solution i can say use user secrets which of course doesn't work in vs code and so then that secret would not end up in source control and not in development or maybe i might put a default here that specifies your local machine but i'm definitely not going to put any passwords there so thus far we've gotten secrets outside of our build just by you know using user secrets the cool thing about user secrets is it actually puts the file in my um user directory uh inside app data and so that's definitely far away from my source control source control so i won't end up accidentally committing it so those are the things that i want to exclude from my git repository any questions so far on these on this git ignore file no questions out there cool so our next step in containerizing this application is to create a dot docker ignore file and so let's call this dot docker ignore and inside this docker ignore file is everything that we don't want in our production container and it actually has the exact same syntax as our git ignore file so let's just go grab that and put it here now there's one more section that we want to add and it is non-production stuff we still want to exclude built files downloaded files user specific files temp files and secrets but then we also want to exclude non-production stuff so app settings dot development dot json and here in properties launch settings.json now the interesting thing about launchsettings.json this is all of the stuff that we need to be able to debug our app here's our development environment variables the urls that we'll use both with kestrel and with is express is express settings yeah we definitely don't want that in our production container so let's exclude that and now we've got a docker ignore file this is everything we don't want to get copied into our container next we want to create a docker file now the interesting thing is this is dockerfile not dockerfile.txt so if you accidentally created this and the interesting thing is if you create a file in visual studio it'll add the txt easy enough pull the txt off and just call it dockerfile here in this docker file is our configuration as code our instructions of how to build up this image so we have a bunch of keywords here we'll have from copy run and cmd now all of these commands will run as we build up our image this command is the command that it will start when it launches our container so we'll only have one cmd command but we may have"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:20:23",
        "seconds": 1223,
        "text": "run and cmd now all of these commands will run as we build up our image this command is the command that it will start when it launches our container so we'll only have one cmd command but we may have lots of these other lines to be able to define what we're building on top of what we want to copy from and the commands that we want to run as if they were shell commands run as we build up this image so we want to start on the shoulders of giant so let's head over to docker hub and we'll search for net and we'll get in this list the um dot net repository oh really wants me to log in and here's all of the repositories associated with net net samples is fun it shows us lots of different kinds of docker files monitor is a great way to be able to view asp.net apps runtime depths is what we would need installed inside of linux to install.net but it does not have.net installed on it yet built on top of that is runtime which allows us to use console applications but not web servers builds on top of that is asp.net which allows us to launch web servers but it doesn't allow us to compile built on top of that is the sdk which does allow us to compile so let's pop open this repo and take a look at what we need to do here pardon me here on the right this is the base image that we want to pull so let's come back in our docker file and we'll do that we don't need the docker pull part though and now let's pick a version by default we probably want to use 6.0 but scrolling down a little bit we can see the other versions available the other labels here's 6.0 if we didn't specify one we would get latest which is the same thing and this is built on top of debian there's also alpine and alpine is known for being a really really small linux distribution so let's use the version 6.0 dash alpine instead of just latest or 6.0 now i've matched this 6.0 to the site.cs proj 6.0 so i know i'm building in the correct version of net and now i've got the build tools so now let's copy everything from our directory where we'll run the docker build command to the directory that we've specified in our image what is that directory let's set it workdir src now i could definitely say var lib fu bar and would automatically create and then cd into that directory but src works it's going to copy everything from here except for everything that we chose to ignore built files downloaded files user specific files temp files secrets and non-production files so even if we specifically tried to copy one so if i said copy app settings dot development dot json into the current directory this would do nothing because it's specified here in the docker ignore and i just realized i'd typo that so let's fix that so now that we've got all our files copied into place how might we run it if we're on the command line we would need to do a net restore to restore all of our new get packages then we would do a net build let's build in release mode then let's do net test run all of our unit tests we'll also do this in release mode so we don't end up with one release mode and one debug mode debug is the default here and then dot net publish we'll publish in release mode and we'll publish to the dist folder dotnet publish is like the right click publish inside of visual studio but we're doing it here inside of a devops pipeline inside of a docker image so this will be pretty predictable every time it's going to grab the dlls it'll grab the javascript and css files and it's that stuff that we would want to send to our web server so each of these are the cli commands that we want to run to be able to do this how would we do this inside of a docker image well let's run them let's run this one and this one and this one and this one and now they run as docker commands now we do need to set some environment variables and i'll just copy them into place because that's a little easier than watching me type we want to set that environment variable to say we're in production and we're going to set the url to start on 80 and this plus says on all ip addresses so don't just listen on localhost but listen on all the ip addresses so that we'll get inbound traffic from our orchestrator then we'll add some metadata that says we're started on port 80 and what is the command that we'll start we'll say net site dot dll and that is in the disk folder so let's work dir dist and now we have a docker"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:25:27",
        "seconds": 1527,
        "text": "we're started on port 80 and what is the command that we'll start we'll say net site dot dll and that is in the disk folder so let's work dir dist and now we have a docker file that could work in production now we could choose to deploy this today it would work just fine but we've broken some of the rules of docker and so let's see if we can fix stuff up one of the rules of docker images is that we don't want build tools in our image if someone was able to pop our running container they now have a compiler where they could put in some extra code and start to compile that code and then run it so let's remove that compiler heading back to docker hub we can see the asp.net repository so let's pop that one open and we have this base image right here here's the one that only includes the runtime for asp.net but not the build tools scrolling down we can see that there is also an alpine version so 6.0 dash alpine so back in our docker file let's split this in half let's say from this now from here down is a different image than here so we can say this is our production runtime server image and i put server in air quotes because you know it's not a server it's an image but we can kind of think of it like a server and here is our build server image cool now we've separated this into two different stages so that we can avoid getting our build tools and our source code into this production image and make that production image just ever so much smaller we do need to fix up this let's set this to the app directory and let's copy this um the dist folder into the current folder except for now it's gonna go look for a dist folder out here and it's not gonna find it so let's say from equals build now this specifies the build stage so let's name this one as build and now it this command will go copy the dist folder from here from the build stage from this stage so we'll get only those built content we won't even get our c sharp files into this new image this new image is going to be really tiny that's excellent we just made our production runtime image much smaller we removed that potential vulnerability by not having compile tools inside of our image and so that'll work a lot better another thing that we can do here with this docker file is that each of these commands will create a new docker layer and cache it so if we were to come in here into our javascript files and we were just to modify this one javascript file that would invalidate this layer and then rebuilding it we would re-install our nuget packages now that probably takes some time and if we haven't changed any dependencies then reinstalling that on every build might be unofficial inefficient so really what we want to do is restore our new get packages then copy all the files then build now we can take advantage of docker caching if i just change a javascript file or even a c-sharp file it will only invalidate this layer and it won't need to reinstall my nuget packages now we do need to tell it where the nuget packages are so let's copy in our manifest site.cs proj into the current directory and that gives us the list of nuget packages in this case we don't have any and so now when we restore our new get packages we know which which packages to restore cool so there's our docker file there's our configuration as code that tells us how to be able to build and then finally run our image inside of an orchestrator we haven't told it anything about which orchestrator we're going to run in we've just told it how to build this image any questions so far here on the docker file nope questions cool okay so now that we've got that docker file we've got that configuration as code let's build it so i'm going to say docker build and i'll tag it as docker in azure and give it a dot that dot says i want to build in the current directory so you know as i come in here and i say copy everything from that current directory it now knows what directory that is okay so let's build now it's going to do all of those steps"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:30:31",
        "seconds": 1831,
        "text": "know as i come in here and i say copy everything from that current directory it now knows what directory that is okay so let's build now it's going to do all of those steps inside that docker file if i need to it'll download the base image in this case it already had it and then it'll start to do those steps to be able to build up my image so now it's doing a net restore yep this is the slowest step but it's pulling in all of those nuget packages in a very deterministic way so that if i do need to rebuild my image i'll know which i'll know that i've got the latest packages determining projects to restore here's the console output i'm not sure why blue and black is the thing but i'm glad the current command is white and then gray so it looks like we restored our nuget packages now we're going to build i don't know did we make any c sharp typos let's see i think our build might succeed go go go go oh there is a flag that we can pass we can say no uh dash dash no dash restore and it won't re-restore our new get packages but it was it's pretty fast for it to notice that it already has them it is taking a little bit longer than typical because i do have teams running on my machine and so it's a smidge more loaded than usual but usually this kicks off in you know a few minutes uh or rather a few seconds like under a minute all projects are up to date so now we'll kick off the build go go go go part of the hard part about doing this demo is that sometimes i don't have internet access because i'm streaming i definitely do but this would definitely fail if i didn't have internet access build build succeeded so let's run all of our tests in this case we don't have any unit tests so we don't have any failing unit tests excellent so it'll just take it a second to notice that there's a way you can say no dash rebuild here but it's really easy to for it to notice that it's already built and just move on except of course my machine is overloaded so it's going to take it 27 seconds that's so silly all projects are up to date does it need to build no it doesn't oh now we're at dotnet publish so now it's going to take those built resources all the dlls the javascript files the c-sharp files any images that i have and package them up into that dist folder i could then copy that dist folder into iis or into another web server and that would host my asp.net application so again i could pass in dash dash no dash rebuild or dash dash no dash restore and then it wouldn't try to re-restore the things but it's all good the cool part is if any of these commands failed the docker build would fail and i wouldn't get a resulting image so if i have a failing build or if i have a failing unit test i won't end up with a final image and therefore i can't break production if i have failing tests that's cool so now we're going to flip over to the other stage and so we'll copy that content into place and now we have that image that we can start to run so yeah i could definitely do a docker scan to use sneak but let's say docker run and we'll map port 80 to port 80 in the container and we'll run docker in azure but maybe part 80 on my local machine is occupied so i'm going to say port 8080 now that i've got that image running well it'll take it a second to spin up now that i've got that image running as a container i can come over here to localhost 8080 and i can view that website there we go welcome we just built an asp.net web app and we containerized it that's cool so now i'm going to stop this app docker container list docker container rm ab8e i just need to specify a uniqueness to this and so four letters ought to be unique"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:35:36",
        "seconds": 2136,
        "text": "that's cool so now i'm going to stop this app docker container list docker container rm ab8e i just need to specify a uniqueness to this and so four letters ought to be unique and now my container is no longer running and so if i were to refresh this now we get the site not found page similarly if i wanted to start it multiple times i could just run multiple docker run commands and now i have two copies of my web server running now that's cool we're able to build and run our application as a container but we don't have that orchestrator piece we don't have that piece that is able to host it in a cloud hosting environment monitor its health automatically restart it if our container crashed we would need to rerun that docker run command so next uh any questions thus far about the docker file and docker run processes everybody's quiet man you must be doing a good job either that or i muted no no no i can hear you cool so our first stop inside of azure is a docker registry now we can definitely use docker hub what we saw here was that it actually doesn't use docker hub for the microsoft based images it's actually using mcr.microsoft.com so they're using a private registry as well and so we could use docker hub or we could use a private registry now docker hub is awesome you can get free hosting for public images you can also get paid plans that allow you to do private images or we could use azure container registry and the cool part about azure container registry is that now the content is already in my subscription so when i start up something i don't need to pull it out of the cloud into this into the subscription i'm not paying ingress or egress data charges it is private only there are tricks to be able to get it to host publicly but it's kind of involved so let's go spin up an azure registry i'm here inside of azure and i can create a new resource and i can say container registry now it's called azure container registry or acr but if you put azure in the front or you search for acr it doesn't find it yeah search is hard but i want to go create myself a container registry so i come through and i'll pick a resource group let me create a new one boston azure and i'll enter a name rob rich i'll give it a spot where i want to put it west us works i can choose the standard or premium or basic and it looks like robrich is already used because of course it is i already have one so going into my azure container registry we can see that i've got this registry and if i go into access keys it will give me the keys that i need to log into this registry so my registry happens to be robrich.azurecr.io so i'd come here to the command line and i would say docker login robrich.azure.com cr dot io and i've already done that so now i can say docker build dash t rob rich dot azure cr dot io slash docker in azure v0.1 and the cool part is oh i have to give it my folder dot the cool part is because this is cached i haven't changed my docker file i haven't changed any of the build commands then we can see that i just used the cached content and it was able to rebuild really quickly that's cool now i have this robrich.azurecr dot io docker in azure so i can say docker push that to azure and i've already done that so popping open this i can come here to my repositories and i can see that we've got docker in azure and we've already got the v0.1 pushed up now i did it a little bit ago but that's exactly what i did was i just did a docker build and a docker push and that got it up to my azure registry cool so now that we have that image in our container registry for all the rest of the demos we'll just launch that image and"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:40:39",
        "seconds": 2439,
        "text": "and a docker push and that got it up to my azure registry cool so now that we have that image in our container registry for all the rest of the demos we'll just launch that image and then because it's already in azure it's already in azure this is a private thing so we may for some of these we do need to log in from the azure service into our registry to be able to get that connection but in this case we've already got it so azure container registry that was easy we'll probably use azure container registry no matter what other docker azure compute resource we use because we really do want to keep those images private and we want to be able to pull them straight into our content so next up let's talk about how we choose cloud compute resources you've probably seen this diagram you've probably seen it so many times that you're annoyed we're choosing what we're choosing to outsource if we have an on-premise thing we own all of it if we choose infrastructure as a service we can give up the servers the virtualization the storage the networking if we move over to platform as a service we can give away more things and if we choose software as a service maybe like salesforce.com or um azure cognitive services we don't need to install anything we just go to a website so we have a machine on our system and azure vm azure web apps and azure cognitive services where do containers fit well they kind of fit in between these two because we're owning a little bit of the os those shims that we need to be able to do that we're owning our run time but we're not owning all of the os so it kind of fits in between these two but there's lots of different places inside of azure where we can choose to own more or less of our compute and so that's usually what we'll be picking as we pick from the many places where we can host our containers inside of azure now there's lots of different ways to run these apps azure kubernetes service azure container instance azure app service azure container apps we could even just install docker on a bunch of vms and what we're choosing here is what we want to outsource we're also choosing our orchestrator so as we do these all of these are real docker they're hosting real docker images or you know oci compliant images we're not creating microsoft brand docker resources we're actually using upstream content so for example when we run kubernetes in azure we're running real live kubernetes not microsoft brand kubernetes that's pretty cool so for each item we're going to take a look at what we're choosing to own what we're choosing to outsource some of the pros and cons of making those traces and ultimately what scenarios might lead us to choose this scenario now ultimately we're going to ask which one is best and the answer is well what scenario do you have let's find that scenario and find the docker hosting platform that gets you there ultimately what's best for your organization is probably different than what's best for my organization because we might have different needs or different concerns or our app may be designed differently first up azure container service and this one is definitely legacy in fact it's been deprecated for quite some time so if you're on it i'll be impressed azure container service was doc was azure's first mechanism into hosting containers basically it was just arm templates that would automatically provision virtual machines you could choose which template you chose you wanted to run dcos docker swarm or kubernetes and it would provision those resources and allow you to then manage those resources going forward so i didn't need to set up kubernetes but i needed to own kubernetes going forward and if i wanted to horizontally scale to more nodes i would need to pull in those virtual machines and hook them up to kubernetes so in time we wanted a higher level of abstraction and so azure container service was deprecated with azure container service we choose to outsource the provisioning and initial configuration but that's all product updates vm upgrades windows updates node scaling all of that is on us it was retired some time ago and so if you haven't moved off already then here's where you might go with dc os you can use mesosphere's open source mechanism with docker swarm you can move to docker enterprise which is now owned by uh oh i've forgotten the name um and if you're using kubernetes then azure kubernetes service is perfect oh"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:45:42",
        "seconds": 2742,
        "text": "mechanism with docker swarm you can move to docker enterprise which is now owned by uh oh i've forgotten the name um and if you're using kubernetes then azure kubernetes service is perfect oh docker enterprise was bought by mantis so if you're on azure container service here's where you would move to next let's talk about service fabric now i put this air quotes legacy because the majority of azure actually uses service fabric under the hood a lot of it is moving towards kubernetes but service fabric is not going anywhere anytime soon it's a little bit awkward to deal with but azure runs on service fabric so if you run on service fabric you are completely fine but service fabric is kind of a wacky orchestrator in this case you don't create a cluster of machines azure automatically provisions a multi-tenant cluster for you and so you just say here's the content that i want to host and azure just hosts it inside that multi-tenant cluster so the way to do it is i create a new service fabric project in visual studio which just seems so weird and then given that content i can go into the service fabric explorer and i can start to upload those services now the cool part is i don't i'm not limited to containers i can upload platform as a service content much like azure web apps or containers or i think you can actually host virtual machines inside of service fabric as well so service fabric is really good all of the content of provisioning pieces is washed away i just say here's my app and run it if you've ever used fargate it's not that different so as far as service fabric i've chosen to outsource the cluster management the virtual machine updates node scaling container restarts all of that is handed to someone else and i choose to only own the container process that's great it's kind of the easy button and so if you're after that easy button then azure service fabric can be perfect i have a service i just want to put it up in azure and it's great somehow went on mute again i think one last year a little bit thank you for calling me out for that sounds like my mic disconnect i think you're back sweet awesome where did i get lost was i on this slide yep perfect so service fabric is great if you don't want to take on the complexity of kubernetes but you do have multiple microservices that you want to host it was originally designed for windows but you can do both windows and linux on service fabric now so when would you choose that if you want to hit that easy button if you don't want to have to worry about kubernetes management and if you just want to say hey azure just run this if you have windows containers you'll probably find an easier path on service fabric than on kubernetes but it's not impossible to run windows containers on kubernetes so that was a service fabric and azure container instance next we'll talk about azure kubernetes service any questions thus far a bunch no no comments no questions cool so azure kubernetes service is the big dog it is the big service it's the way to run kubernetes inside of azure and the cool part is we're actually running real live kubernetes we're running upstream kubernetes this is not a microsoft fork this is actual kubernetes the cool part is that the control plane is completely managed for us we don't need to pay for it at all google cloned that process and so now the control plane is free on google as well you still pay for the control plane on aws but yeah azure started it so because the control plane is a multi-tenant and completely managed process we can't run anything there but at the same time we're now only responsible for the virtual machines that are our aks nodes so if we want to horizontally scale our nodes down to one then our cluster is pretty inexpensive or if we want to horizontally scale to more nodes then we can take care of that and we don't need to worry about the control plane at all"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:50:46",
        "seconds": 3046,
        "text": "pretty inexpensive or if we want to horizontally scale to more nodes then we can take care of that and we don't need to worry about the control plane at all we just drag the slider to get more nodes so let's go create an azure kubernetes service ah teams brought up the thing and now i can't reach the other tabs in my thing okay so let's go here portal.azure.com so i'm here and i'm going to create a new resource and i would like kubernetes um kubernetes service perfect yes i would like to create one of these i'll create a new resource group boston azure and now i can choose the scale of my cluster so i'll choose devtest for now what's my cluster name rob rich i can choose where i want my cluster to be um i can choose availability zones in devtest there aren't any i can choose my kubernetes version 238 123.8 sounds good i could get up to 124 if i wanted to and i can also optimize for availability or optimize for cost and in the dev test one yeah i'll definitely optimize for cost i can choose the size of my node and the cool part is you can choose node sizes later but that's only to change one node so this is kind of the last time you have to choose the size of your cluster so in this case i'll choose a d2sv3 [Music] select i could swap particular nodes up and down but i can't swap the node that it will automatically provision later and so that's kind of a bummer i can choose to manually scale or auto scale and i can choose how many nodes i want to pick up to you know very ludicrous in this case i'll just choose one next i can take a look at my pools virtual nodes is actually really elegant it will automatically scale into azure container instances that is amazing we'll talk about that as we dig in some more i can set up authentication networking i can tell it to create a new network and specify the network details uh a lot of traffic routing rules uh you can see why azure service fabric is kind of the easy button kubernetes is a bit involved similarly the integrations i can hook it to my azure container registry i can hook up container monitoring and azure policy [Music] advanced will give me nothing and then finally i can create it but in this case it's telling me that there's an error running final validation i shouldn't have clicked that button because i wanted to go back to here and note that it's going to be an error on the name because this name is already taken because i happen to already have a kubernetes cluster started here so here's my kubernetes service and if you've ever tried to upgrade kubernetes you will really appreciate this i can come in here to configuration no not this configuration this configuration and i can upgrade versions so i'm definitely not going to do it in the middle of this demo but you can just click here and have it automatically upgrade or i've chosen to have it auto upgrade whenever a version is available inside my maintenance window and so it'll always always keep me on the current version and that's really cool so now that i've got a cluster created let's start to run some stuff there so um i will do an az aks get credentials then i specify the namespace and or the name of the resource and the group of the resource and then it will stuff things inside of my cube config so if i say cube ctl get cube ttl config get contexts we can see that i have my docker desktop context but i also have my cluster inside of azure so"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "00:55:52",
        "seconds": 3352,
        "text": "cube config so if i say cube ctl get cube ttl config get contexts we can see that i have my docker desktop context but i also have my cluster inside of azure so i'll cube ctl config use context rob rich and now when i run cube ctl commands i'm actually running them on azure instead of on docker desktop so i'm going to reach into my stash of interesting things and go grab this kds folder save us a bit of typing of kubernetes yaml kubernetes yml can definitely get away from us here i have a service that will load balance across all of my resources i have a deployment that specifies the details of how to start this pod notice here's my docker in azure v1 oh it's not v1 though it's v 0.1 so let me fix up that oh here it is v 0.1 specifying that image name and the container port it's a little bit mad because i'm not specifying a resources limits so i'll just give it an empty thing there but here i've chosen to specifically launch only one but i could choose to launch three or ten or even have that automatically scale so i've got my deployment now i've got my service that will load balance across all of those pods and then i have my ingress that will be able to map a specific hostname so here's that hostname that i've chosen to point to that service so the ingress maps http hostnames into kubernetes services the service load balances across all the pods and the deployment ensures those pods are running so let's apply them cube ctl apply dash f k s slash service now i could do this one at a time or i can just say cube ctl apply dash f the entire folder and it'll just loop through all of the yaml files in that folder and just push them up into azure cubectl getall and we can see all of those resources that got created now the unfortunate part about cubectlgetall is it doesn't include ingress so let's do all and ingress and it will take a while for this ingress dns to propagate because not only does it need to propagate in azure it also needs to propagate up to the azure to the control servers and then down to my isp so if we were to visit this url right now it probably wouldn't work but we can see the pods running so let's do this cubectl port forward and we could port forward into a pod or into a deployment in this case let's port forward into the service docker in azure and we could forward port 80 on my local machine to port 80 in the container but or in the service in this case i'm going to do port 8080 on my local machine so now that i've got that proxy set up i can come in here and i can say localhost 8080 and this website is running in azure inside of azure container service now that's awesome i was able to start my website inside of azure kubernetes service and if i need to i can come in here to my yaml and i can specify how many copies i want to run so right now i'm running one let's run two so apply dash f k s and apply is both an insert and an update so it noticed that the ingress didn't change the service didn't change but the deployment did so if i say cube ctl get all i now have two pods running instead of just one one started nine seconds ago one started two minutes ago and just as easily as we created them we can say cube ctl delete dash f k s and all of those things will get deleted from azure it's really easy to accidentally forget that you've got content hosted in azure and let it go so i'm going to specifically kill it as quickly as we can so that was cool we did azure kubernetes service any questions so far on aks well so when what i've chosen to outsource with aks well i get to use full kubernetes so anything that will run in kubernetes will"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "01:00:56",
        "seconds": 3656,
        "text": "so that was cool we did azure kubernetes service any questions so far on aks well so when what i've chosen to outsource with aks well i get to use full kubernetes so anything that will run in kubernetes will work just fine inside of aks i can choose to own the kubernetes version or in my case i chose to outsource that as well i can choose to do node scaling or i can outsource that as well all of the container restarts all of the node patching all of the control plane is outsourced to azure and i don't need to worry about that at all azure kubernetes service it is real live kubernetes service uh windows is no longer in preview now so you can use both windows and linux containers inside of aks push button scaling i love that just being able to drag that slider and get more vms inside of my cluster that is so cool on the downside kubernetes and yaml now the kubernetes yemel isn't always the easiest but it is you know regular normal kubernetes so that's just the way kubernetes works when would i choose this if i have many microservices then aks is the perfect solution because i get to run all of them here in one place i don't need to create a new netlify account for each service or a new github actions github pages account for each service or another azure web app subscription i have all of my microservices in one place i can use upstream open source kubernetes and it works out really well next up let's take a look at azure container instance the cool thing about azure container instance is it is a rest api for containers now if i was to build a cloud architecture i might have common nodes i'd have a virtual machine mechanism i'd have a storage mechanism like azure blobs and i would have a mechanism for spinning up containers and that is azure container instance now it's an api for spinning up containers and so you can just say hey spin up this thing but there isn't that orchestrator behind the scenes that will watch it and automatically restart it and scale it and i actually learned that they did do automatic restarts now but there's no concept of scaling if i want to run two copies of it i call the api twice the cool part is it is completely utility billing so if you've ever used aws fargate this might feel right at home it is per cpu memory second build so however many seconds it's running that's how long you'll get billed so it's perfect to be able to build an architecture on top of it you know it's a great way to be able to run dev test utilities but it's also great for let's say you have a platform where you want each client to have a separate container then you could use this api inside your service to be able to build up your platform so let's do some azure container instance magic now i'm here inside the azure cli and this command is wonderfully gnarly ac container create i'm going to give it the name of the container that i want to create i'm going to give it the resource group my resource group just happens to be named kubernetes this has nothing to do with kubernetes but that's the name of my resource group what's the image i'm going to pull there's the docker in azure v0.1 i'll give it my username and password i have those stored as environment variables i'll specify the ports that i need and the dns label so that's the dns label that i've got and then once it's done starting up i want to go get the ip address well the fully qualified domain name the url that i will use to be able to browse to this now it does take a second to be able to spin this up in azure but what's really cool is that api is perfect for just being able to spin up containers really quickly so let's go here let's go to http that and we've got our container up in azure that fast now dns propagating may be a thing so maybe we won't get it to load right away but that's really cool that is azure container instance just a really quick api for spinning these things up so let's take a look at the containers that we've got az can container list and we'll output as a table in this case i only have one so we'll only see that one but we can see um it's uh running in this resource group the kubernetes resource group it succeeded here's the image the ipn ports that it's running it's a public thing here's the cpu and memory that i chose it's a linux container and it's running in east us because that's where my that's where i created this okay so azcontainer"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "01:06:00",
        "seconds": 3960,
        "text": "that it's running it's a public thing here's the cpu and memory that i chose it's a linux container and it's running in east us because that's where my that's where i created this okay so azcontainer logs let's take a look at rob rich docker in azure resource group kubernetes and now that i'm taking a look at the logs for this this is much like docker logs or cube ctl logs here's that console output that came out of that container and just as easily as i created it i can see it can say az container delete i'll give it my name of rob rich my resource group and i'm going to say yes so that it won't prompt me to confirm it and just as quickly as it spun up it will spin down and so there's it no longer existing again let's go take a look at our containers running and we will see that there aren't any now that's really cool we can also choose to spin up an azure container instance here in the portal we can say new azure container instance or what's particularly awesome is if we go into our container registry and we go into the repositories and we pick a particular repository and then we pick a particular version we can hit the three dots over here and we can say run instance and it will automatically spin up that azure container instance so that we can start to play with it and see how that works which is really cool so that was azure container instance azure container instance is this really elegant api for building up containers now i've chosen to own spinning up those containers so i choose to take on scaling and the container process they do now have automatic restarts on unhealthy containers but we used to need to own that as well we've only chosen to outsource our host our vm patching our host infrastructure those are all outsourced now we choose to own our orchestration process effectively so when might i use this utility billing is amazing if i just want to spin up this container real fast and see how it works and i need a little bit more horsepower than on my local machine then i can just push up a dev test thing or i may choose to be able to build up a platform on this where i might have one client per container so on the upside it's utility billing no infrastructure to manage on the downside there's no auto scale so i would need to kick it off multiple times i would need to keep track of my traffic and manually scale that one con that used to be here that is no longer i used to only get one port forwarded in you can now forward in multiple ports into your azure container instance containers so when i choose this when i just quickly want to spin up a test or when i build want to build a production platform on top of it now let me talk about virtual cubelet we saw that checkbox about automatically scale into aci virtual cubelet is that piece for aks it is another node in the cluster for and the way it implements that node is by by starting things inside of aci so this is a great way to be able to get infinite scale inside of our aks and utility billing without needing to define our nodes it's like one big giant node inside of aci it is so cool on the upside it's great to be able to scale into this infinite thing where i get utility billing on the downside i need to run the virtual cubelet somewhere and i can't run it in the control plane so i do need one node in my cluster but i only need one and i can push everything else to aci so that was azure container instance our api into containers and we also talked about azure kubernetes service next let's talk about azure web app service or azure web apps now the cool thing about azure web apps is it's kind of platform as a service it's a really great analog to iis if you squint real hard it's like well it's exactly iis and so it's exactly iis but it also runs containers now it only runs a single container so this is great for a monolith if you have mini containers then you would end up with many azure app services and maybe that's less effective you might want"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "01:11:02",
        "seconds": 4262,
        "text": "now it only runs a single container so this is great for a monolith if you have mini containers then you would end up with many azure app services and maybe that's less effective you might want to choose kubernetes but it works with both windows and linux containers and like iis it automatically restarts so i can come in here and i can say i would like to create a new azure web app and app service ah i think app service domain is the right one i may need to say web app yes oh this is an app service domain let's try again i have some app services so inside here let me say i would like to create a new one and after i give it an app name i can tell it that i'm running code which is probably what we've done before or i can make it a static web app in which case it'll run on azure storage or i can say it's a docker container once i say docker container now i can choose my container os and i can pick my registry now it's a little bit mad because i haven't given it a resource group or an app name yet but once i get to the docker settings now here it's saying a single container oh we've got docker compose now and i can point it at my container registry and then i can pick a particular image and the tag and the cool part is if i choose latest it will actually create a web hook that automatically will update my web app anytime i update my container another way to create these app services if i come into my container registry i can actually go into repositories and i can choose a particular repository and version and i can also say oh i went a little bit too far right clicking on this version i can say deploy to web app and it will automatically create that web hook in case i update latest to automatically rebuild redeploy that app and so what we saw here when we were looking at app services is that there is a site called robrich and uh until decently recently my website ran as an image inside of azure web apps it now runs in azure storage which is quite a bit easier to update and um and refresh because it's pretty big but yeah it just had a web hook that anytime i pushed an image up to azure web apps or azure container registry it would automatically update my application running here in azure so that was azure app service what's really cool is i've chosen to own the container process but everything else we've chosen appsource container health and restarts container scaling host infrastructure vm patching we could even do auto scale much like we would with any other azure web app on the upside azure manages everything and it just runs our container we don't need to worry about how do i hook up the kubernetes things how do i you know do all the things on the downside it only runs a single container and only a single port so if i need multiple ports going into my container then i may need to flip over to azure container instance or probably azure kubernetes service so when would i use this if i have a monolith that i'm just trying to lift and shift and i want to get it into a container running in the cloud then azure app service is perfect because i don't need to fuzz with a lot of stuff and i get that interface that is probably really similar to iis that i'm already familiar with now there are less options available inside azure container apps or azure app service when i choose um a container because some things are managed by the service so i can still inject in environment variables but i can't for example pick the platform as a service architecture that's baked into the container so next up we could choose to install docker in virtual machines and this is definitely the ninja move but if you want complete control over everything then you can install whatever you want in a virtual machine so we might choose to install docker kubernetes now in this case we would provision some virtual machines we would install our orchestrator of choice at this point we manage everything now this might be perfect if you're doing a process that needs to run across clouds and you want to have an identical version of kubernetes in every cloud so now you're not dependent on"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "01:16:06",
        "seconds": 4566,
        "text": "at this point we manage everything now this might be perfect if you're doing a process that needs to run across clouds and you want to have an identical version of kubernetes in every cloud so now you're not dependent on when the cloud chooses to upgrade to the next version of kubernetes you can take control of that so we've chosen to outsource well buying hardware that's pretty much it the majority of the content is now on us we've installed kubernetes we choose to manage and patch it whenever we need to or not we need to worry about container health and cluster patching and scaling we own everything now if you choose this path that's probably exactly what you want but well that's what you get on the upside you can control everything on the downside you must control everything so when might you use this if you're building a software as a service platform and you need to go across clouds and you need all of them to be exactly identical then you managing everything might be the perfect solution so we looked at lots of places where you can run docker in azure and so kind of scaling them from most managed to least managed on the least managed side we have vms and then aks aci service fabric and finally app service is the most managed so whatever our comfort level on the management scale might lead us to choose a solution similarly how many containers can we run if we only have a few containers like one or two azure app service can be perfect azure container instance and dev and test can be great because i can just scale them up when i need it and then kill them off really quickly service fabric and aks can run lots of images and vms can run as many images as we want but we're paying for the vms so the scaling steps are pretty intense by comparison if we want to build our own orchestrator on top of azure container instance then we get utility billing and we can scale to the scale of azure which is phenomenally big a similar scale oh so this kind of combines all of the different details of all the different azure compute resources that we've got you can grab these slides from robrich.org or here's the money shot where we take a look at each of those services they all run windows and linux we can take a look at their pricing models auto scale models all the restart models and whether we choose to own the virtual machines that they run on any questions so far about docker and azure no questions awesome hopefully that gave you a minute to snap a picture if you wanted to as well so what's really cool here is that we've seen lots of places that containers will run inside of azure we didn't mention azure container apps which is brand new it's kind of half kubernetes but kind of a little bit simpler it includes dapper which is really cool but ultimately what we saw is that there's lots of options here now the question isn't so much which one should i choose but rather which one best fits my use case and what's really cool is that docker will meet you where you are so wherever you are whatever things you need you can plug in in exactly that way do you want to own everything then azure vms would be perfect do you want to own nothing then azure web apps might be perfect do you really like open source then aks to be able to get built-in kubernetes might be perfect or do you have a few things that you want to just spin up really quickly and then discard azure container instance might be perfect ultimately azure will meet you where you need to be this is a lot of fun getting to show you choosing from the many ways to docker and azure the slides are up online right now at robrich.org and you can hit me up on twitter if you're watching this on demand at rob underscore rich for those of us here live at the event what are your thoughts what are your questions what other things should we mention next time we do this talk so we actually have one question right now um it is from james and he is asking are you familiar with aca like serverless kubernetes it was jade in may yes azure container apps the cool part about azure container apps is it is a simpler yaml than kubernetes yaml but it really tries to reach that kubernetes-like audience the people who are just kind of overwhelmed by kubernetes gamble it is kind of the gateway drug because pretty soon you may hit those limits where they've made opinions that you may not agree with or they've blocked in the name of simplicity they've locked you out"
    },
    {
        "speaker": "",
        "title": "Choosing from the many ways to Docker in Azure",
        "videoId": "v9eqOV-35g4",
        "description": "This is a recording of the September 13, 2022 meeting.You're ready to go cloud native with containers. Now where do you begin on Azure? There's a dizzying amount of container options available in Azure. How do they compare? Which is best for your organization? Come with us through a tour of each Azure Container hosting technology, the pros and cons of each, and decide for yourself how best to host your containers on Azure.About the speakerRob Richardson is a software craftsman building web properties in ASP.NET and Node, React and Vue. He’s a Microsoft MVP, published author, a frequent speaker at conferences, user groups, and community events, and a diligent teacher and student of high-quality software development.You can find this and other talks at https://robrich.org/presentations and follow him on twitter at @rob_rich.",
        "start": "01:21:08",
        "seconds": 4868,
        "text": "where they've made opinions that you may not agree with or they've blocked in the name of simplicity they've locked you out of some of the kubernetes things it does run on top of kubernetes which is really awesome but it it doesn't quite feel like kubernetes so it is a fun thing to play with but every time i get into it because i'm familiar with kubernetes i'm like no i'm just going to upgrade to the real thing what's your experience with aca i think james doesn't have a mic so he's gonna type his answer that works okay so he's saying he is using it for a couple of projects oh excellent i'm glad you found success fortune real kubernetes to azure aca okay that's good ah how interesting i usually go the other way sounds like we may need to find ourselves around a beverage where you can tell me more this is cool yeah you guys should connect i don't see any other questions whoever has a question or a couple of questions feel free to unmute yourself okay i guess that's it for more questions um awesome well this was a lot of fun getting to present today thanks for having me here at boston azure thank you so much rob thanks everyone for coming today what's up for next month oh we're still figuring it out that will notify people once we finalize the schedule and everyone please um keep following us on twitter and checking meetup group um yeah we'll be posting there sounds great see everyone next month see you thanks rob are you still there rob are you still there rob when you had the website up i tried to go to that site and it looked like i couldn't get to it is that because you it wasn't available to all he is gone which site are you referring to when he created that site out on azure i actually tried to go to that site and it didn't hit it which which demo was that uh it was one about three fourths away it was the uh docker in azure east u.s azure container io um yeah i'm not sure he may have pulled the plug on it quickly quick enough or it was one of the demos that wouldn't have had a public endpoint unless you added something additionally to it yeah all right well that's all i have to have to watch the demo again and see if i can find it all right well i know he took it down so it's not there now all right all right thanks bye duty and "
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Udai Ramachandran: Azure Front Door. This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.. if you guys don't mind i'm going to turn off the camera all right great um yeah you can record if you want to i already think you already started it okay so today's topic is going to be as a front door um it's i use as a front door for ghost and a year now we have built a platform which is a multi-tenancy platform that completely route through the as a front row okay my name is ramachandran uh call me it's easy i work for a company called akumina as a cto um i've been um playing with the cloud for a long time um not only microsoft azure i also uh worked a lot with the aws and google i do have a user group in nashville um please visit and become a member uh meetup.comg i have great topics aligned and i put all my presentations over there and my personal blog is would i dot io today we're going to talk about the load balancing solutions you know front door is not the only one there are you know three three other solutions we will look at it um and why we need a front door um then how we use the front door different concept like domains and back ends or origins routings and how we can do a firewall and then there is a front door b2 is coming which is the preview right now and what's the difference between v1 and v2 and run the same demo using the vita as well so load balancing solution so microsoft provides these four types of load balancing solutions right so load balancer is technically a network layer load balancing um and then there is application gateway which is the regional load balancer with the vaf enabled another application firewall can inbuilt and then there is a traffic manager which is again the load balancer but you know it's not ssl you know tls based it can you can't do a ssl offload like terminating the dls and all those things you cannot do it it's just a incoming request and forwarding it but the one benefit of a traffic manager is the dns based routing so you can do a dns based routing where you cannot perform that type of dns based routing in a front door but the front door is the global load balancer just like a traffic manager but it probably it brings the you know tls product called tls termination and it also gives it runs on the edge and it gives you without you throwing any files into um cdn you can map that everything to go through a cdn so you get a better performance um you know are the cool benefits that load balancer plus the tls plus the edge caching all those things so as a front door um as i said it's a uh edge network to create a fast secure and very scalable web applications it depends on the layer 7 just like um app gateway this is a layer seven applicator is regional this is a global um it's composed of a three concept domains and domains can work with a web application firewall so even before you get into a in you know where your instances are running now you have full control over there um back-ends or origins is your website where you're hosting it or a static web app or even an external endpoint that you're running it um they provide a multiple programming model that you can work with it you know the easiest model is the acid portal that's what we're going to see it today but you can do everything that we're going to do in azure portal by using the power power shell or cli or arm template or even using the management endpoints so in my case now i used a lot of azure portal power cell on template plus for programmatic of multi-tenancy you know we have a multi-tenancy application to do a lot of onboarding things dynamically i'll walk you through we use a lot of management endpoints by using the shisha and we pass payload as arm template so if you look at the diagram over here it's a very simple and i will dive into that later as we go through so you know the incoming request is coming in and you have a region's region one region two region three for in this case and you can do a path-based routing or you know latency based routing um all those cool things but i will walk you through how this works over there but the key concept take away in this diagram you can route one or more regions based on the configurations but you know from the edge if you take the features of the front door itself the first topmost feature is the tcp uh split what does that mean um you know instead of long request right for example you are browsing from uk but your server is in um us for example right so you know instead of coming all the way to the uk's us server it runs on the edge right so front door runs on the edge so first your route is requested to"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "uk but your server is in um us for example right so you know instead of coming all the way to the uk's us server it runs on the edge right so front door runs on the edge so first your route is requested to the edge location from the edge it will constantly ping the server where the server is if you have a server located in the uk eu and eus it knows that which server is the optimal route okay split your one long request into a multiple short request so your first request is always goes to a front door it terminates there and then it creates the you know pre-request in making sure which connection is optimal for this request it it has um you know type of uh prepared uh like http 2 kind of things like um caching the next user comes in it will it will use the same connection again from the front door to your application wherever your application is right so it's always split the request one request from edge your your user to edge where the front door is running the another request from front door to a application where the application is running if you have multiple application it knows constantly scan and get the optimal route possible um it's it provides the health you know constantly scans um you can't figure how often how when to take that from the load balancer and then when to bring it back into a load balancer um and it has the routing you a path-based routing so you have multiple endpoints running in a multiple different regions um it may be a application that you won't run it or it may be a static resource that you want to provide from the multiple different regions so you can route through a path for example slash image go to one servers last video goes to other server and so on um so it you know again it's a multiple websites you can bring it in um if it supports affinity some application may be a stateful um the stateful applications always need affinity so they're constantly connected to the same server until they terminate the system so it supports that and then it says offloading you can take https through a front door and you can terminate and then you can go http from front door to your applications if required um you can define your own custom domain it can be a wild card um you know star.yourdomain.com or you can go you know x dot your domain.com y.o.domain.com and you can set a different origins and then so on um and then the you know integration um which is always you know your request is always come to the front door then you can configure the app to to ideas or ips um uh the intuition detection or intuition prevention techniques um redirect http to http yes now you can get http request and then you can redirect to https request if that's a requirement um custom forwarding with the url right there is a rewrite options you can do that or the forward options um it also supports the ipv6 and http 2.con and your user to a front door is http 2 protocol but front door to backend is http 1.1 is not flushed yet with http 2 product cards um it has the basic td os productions now we said that second the few concept to here is um like domains packets and routings those are the three concepts right so now when you look at the domains you know you can bring any number of domains there's some limitations but you know you can technically customize your domains you don't have to use the um use the front door domains right so for example if you create a web app it comes with you know app name.azurewebsites.net you know similarly front door comes with whatever name dot you know uh fronto.net right so you don't have to use that you can map to a custom domain and then you can route route to the domains um if you use a wildcard domain once it's used you can only have one front door you cannot have additional front doors for example you you know you have a domain called yourdomain.com but you want to split them into multiple different sites right in my case i have hundreds and hundreds and thousands of sites running um i don't mind sub domains but if i use a wild wild record map it's a star.eodomain.com i cannot create another front door and configure it for that i have to say group of domains in a domain of you know 1 through 10 runs in this front door domain of 11 through 20 runs in the other front row um you can do everything in one go but that's not the right way to do it sometimes you get a problem also in a demo why it's not advisable um wildcard is not always available but you can do that with card if you want to you know once you have the front door you can only go up to 100 domains so that's where the wildcard limitation will come in so if you do a wild card you don't have limitations right so all your domains is going to come you know x dot y dot z dot it's all going to go look at the wild card okay here is my um you know end point and it's going to go to the end"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:10:11",
        "seconds": 611,
        "text": "you don't have limitations right so all your domains is going to come you know x dot y dot z dot it's all going to go look at the wild card okay here is my um you know end point and it's going to go to the end point good to go but if you don't use a wild card you can only can't view 100 dominance and then you get to create another front door and then reconfigure it and then you create another front door and then reconfigure it no but the management ui is pretty pretty not not very clean but you can you can do that or you can pay a little bit more for domains to configure the same same front door configuration that you created if you don't want to create a multiple front door you want to use the one front door to manage everything then you can do that but it's going to be extra additional cost five per domain looks better with the azure dns i use azure dns all the time uh it's very transparent fast high you know it looks better in my opinion um test certificate are not allowed so if you want to try with http yes they provide um they will provide you a trend or defined certificate but some reason you want to enforce that with your own certificate you will have to bring an enterprise certificate paid a certificate you can use the you know testers that you created using the make set that's only works other services but not for this service um you can't use the subject alternative sand like for example um you know you can define asan um x.y.o.domain.com right so you know some people will cheat dot star.y.e.o.domain.com and you might have noticed even as a web app won't take that certificate if you try to cheat with the sam name you cannot do it you will have to find the fully qualified one sub domain in this case you will have to buy star.y.e domain.com and then the star can be any any second level sub domain so you cannot go star dot star even that concept won't even work with any of those services in the cloud it has to be always one sub domain or one sub sub domain so it is only one star is allowed next to the concept is the backend backend is also called the origin or origin servers right so it can be azure resource such as the uh you know the old platform cloud services or the web apps um or the virtual machine or the container any any services web endpoint that running or it can be the external endpoint you know somewhere you're running some site which is exposed to the public internet you can use that why i set the public internet the front door cannot connect to the private internet that's why the printer the next version of the front door comes in the the current go was a live version of the front door you can only connect to the public endpoint um it has a host header you can map to the host together to take a valid request you know sometimes when you you know if you leave it in a public internet anybody can pass anything to secure if you want to pass additional host header from the trusted resource you can do that it also has the priority you know how the backend is defined so you have a back end you know you have a two uh two missions running on it are two load balancers behind us attack and you know then you can set the priority um you know how to route the traffic it's again the same concept as traffic manager how you would perform and then it's also gas that has the concept of weight you can set the weight how do you want to write it you know um like a you know maximum request to go here or there the default um routing is the uh the latency sensitive route meaning that it will route the fastest uh node or the low latency node for example i am uk connecting to eu node may be closest but it may have some latency some traffic just like you know point a to point b we take a highway we assume that's the fastest and that is true most of the time but sometimes you know something happened on the highway taking the local road is the most optimal route right likewise you know you know if you like the user connecting from uk there is no no node in the uk there is a node in eu that may be the closest but them is still connected to a node in line or west coast because the traffic goes free it's easy to go low latency then they will always connect to a um you know to a best node so that's that's the logic built into it but you can override all those things by using the priority weight and then there is a last one called the latency sensitivity but you can enforce some no don't go to a us and you still work on you know you are closest to no and you can set some value that value can be 500 milliseconds connecting to the us best maybe a hundred milliseconds but now you can change that latency to you know until 500 milliseconds you know if my local node is going to find a millisecond still stay here i'm fine with it don't go to us west you can set that that's called latency sensitivity you can set that and then the health probe has a lot of things you know you can help the probe using the path protocol method there's you know they support two method head ht head request which will not download any data just send the request"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:15:12",
        "seconds": 912,
        "text": "you can set that and then the health probe has a lot of things you know you can help the probe using the path protocol method there's you know they support two method head ht head request which will not download any data just send the request or then see get all the header details and come with it the get request is going to download the data it based on how your health endpoint is designed one can use the head request or get request in most cases i would recommend you have another endpoint or add another router type head which just sends message and then sees it okay i'm good and come back the get will bring the message why it is important um the front door is going to do a crazy number of pink to your end point right so you have a three endpoint three region running there is a 200 plus edges running that is going to pink coming from all the edges to your application right so if you know you you know even your get is going to return at 10 bytes now assuming that 200 requests coming in a second you know you multiply that right so 10 bytes of 200 will become 1000 bytes which is equal to close to a you know one kb and and if you leave it for one hour it's going to be like a large number of requests if you leave it one hour it will be about 12 000 request that then you multiply by 10 you're setting a large of data you're paying for no reasons to avoid that you know they recommend the head request so which will not download the data but still tells them that the service is healthy or not can take can can forward the request to the edge or not um in the load balancing concept they are sample size you know how many iterations that you want to consider as the pass or fail you know you can say successful sample in the total number of samples and then the successful sample those are the property to keep the service in the routing table or not but it will constantly scan you know there is a health issue detector it will remove it and as the health you know it will still constantly ping but once the service is up and running they will add it back to routing next one is the rules engine um the rules engine is help will help lot in this case uh for example uh that's the one i was telling like edge level caching so if you have a static files you know you want to cache it you know you don't want to cast the dynamic files right for example um you know um so anything that the dynamic data the login route or user profile and so on you don't want to cancel those urls but you still want to cast all the static routes right you know anything that comes slash image slash css no slash j is you know and so on then you can define a rule now how do you want to define that how long you want to cash it the cash comes with the multiple options you know you can go up to three days uh 24 hours to three days or you can set a hard limit you know how long you want to you want to set it by the default option anywhere from one day to three days um that's because the one day is the gdpr requirement so you have the gdpr right that you know you hosting in the uk uh eq regions but you're browsing from the us they kind of keep the data more than 24 hours um so that's why that limit comes in um so it's also help you to do a geo filtering so you can set the user come from so and so region either a load deny or you know log and some options and then ip filtering sometimes you know you have you see that the some ip address constantly you know pinging your server or doing some bad things you can block that you can also set the security header so for example you want to allow somebody to post data without being in your own domain then you can set the content security policy who can post the data to you you define that you know then those customers can post the data of course caching so now the routing um when the the routing comes in the routing and the rules are you know hand to hand but you know it has the pattern match how do you want to route it you know slash images or slash images star x and so on it can either forward to the service or it can redirect to somewhere else and then roots engine decoration that's what we see in the previous slide um previous slide that does the road syncing and then the vap um so front door that's that's a good thing you know even before you you know you don't infuse application gateway you will have it's a region right so you have to run it on every region um if you run your application in uh three regions now you need to define a three application gateways and configure it but the front door you don't have to do it because it's a global and then the map is also global you know it runs there it runs on the edge and it sees it okay policy violated either you know based on the configuration either you did ideas or ips i know it's a province it's going to stop it if it's a detection it's going to log it and then let you browse to the"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "okay policy violated either you know based on the configuration either you did ideas or ips i know it's a province it's going to stop it if it's a detection it's going to log it and then let you browse to the site um it has the ru it it has the top 10 ow asp it has the crs drs meaning that common rule set drs meaning their default rules rule set they are they have some versions coming in some they have some vulnerability packed into every person in the front door old uh the current front front door which uses the 1.0 common rule set 1.21 default rule set they have a vulnerability defined and then the new front door the version is lifted 3.0 which has the you know little bit more added rule sets for the vulnerabilities again the key point for the app is for conventional detections you know how you want to predict all your you know malicious request versus the valid request you can also set some access access restrictions by using the custom custom rule just like a root table uh of um of a front door you can also different rule on the web you know if you have a detection mode and on our prevention mode anymore um you can add some more rules you know how do you want to you know restrict certain type of jio or ip or you know based on the conditions you can do a rate limiting um and then you can also do a redirect for example the user comes from xyz location or the or the body contains so and so message or the header is missing so and so message then redirect to a different site right so you can do that as well uh rest api so this is what we use uh we just go here play with it uh and then see how the payload look like and then we put the payload in our system and then we create it right so they have a rest api playground you just log into the portal and then you browse to a rest api you see all the methods they support click on it and then you can play right there simulate the payload and then see whether it's working or not if it's not going to work there it's not going to work in your code so that's the right way to test it um we do we just we use this rest ap there online more often to validate our request or if you see something is not working this is the first place for us to go all right so this is standard premium i'll hold these and let's go some demo and then i will come back and then we will have the preview and then i will show how everything mapped you are not going to see a lot of difference uh between the v1 and v2 i call it sp1 and v2 the other one is the front door this one is called front door standard premium um we'll come back and check that one any questions so far you guys are there yeah i've got a question about some some of the differences in relationships between domains uh domains routes rules and pools correct i'm really confused about like how all those relate to each other yeah um so can i give you a quick scenario and then maybe you can explain based off that yeah so if i have two domains uh two completely different domains and in two different regions i have two pairs of app azure web apps so they're completely different sites right and i want them mirrored between east and west coast do i need two well i mean before we continue let me do a whiteboard i'm going to share a different screen now okay continue on i got your point keep going yeah so i i what i want to do is i don't want to have to have two different front doors for two websites i'd like to use the same as your front door yeah for both websites both my applications um does that mean i need to have two what i think are called routes um yes let me explain to you uh so so let me go back over here you see me whiteboard or no not yet i'm looking at a google google home page or a new tab rather it's a different window yeah let me know when you see my whiteboard now i see a whiteboard okay so first thing you said don't mind right i'm going to say you know one dot your domain dot com okay two dot yeah you are domain.com uh now let's say the next one is uh two.mydomain.com all right completely okay great mydomain.com right so those are the two domains now you have the front door over here you're going to add one.yourdomain.com and the two dot my domain.com right you also said you have multiple services which called the back end pools are origins okay so in the east region you have some app running is that right you said sorry say that again east the east you have an app running right"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:25:20",
        "seconds": 1520,
        "text": "you also said you have multiple services which called the back end pools are origins okay so in the east region you have some app running is that right you said sorry say that again east the east you have an app running right yeah so i have an i have an application running mirrored in both the east and the west coast okay so i have the best for both applications so really there's four azure same application it's the same application no they're different applications okay different applications so a1 and b1 let's call it as a1 and the b1 okay yeah all right so now routing right so route comes in over here so you know they're they're both running in both locations so east has has a copy of a and a copy a copy of your domain and a copy of my domain is it like that you want yeah just like that okay so you have the both side running over here yeah for redundancy and also you know if someone's on the west coast i want to send them to the west server server pool right okay so those are the packets right you know it's completely disconnected back end is a packet that is all it's going to do is the packet is healthy or not and i know i'm a healthy to take a request that's all it does the route table is what tells you where you're going to route it so now you need to define a router for one dot your domain.com right that's that you're going to define a route in this route you're going to tell so before i do that so here the pack and you can consider this as a pool one this is a pool two r you can change you know um you know like all together one pool okay so i was thinking like mydomain.com would have one pool where one service is in the east and another service is in the west and yourdomain.com would be a different pool for one services in the east and in other services in the west you can do that um you can do that so uh so let me take this one so so you you're going to have a pool one consists of a1 and b1 right sure pull 2 consists of these two like you know p1 and uh changes slightly different color here this one and this one right so this is two this is is that right that's how you configure you there oh sorry muted my goal here is to have for yourdomain.com to have geo redundancy okay so let me keep the high level so what you can do here so you can define mix and match right so you have the your domain.com in the route table you're going to say i'm going to say one.eodomine.com is going to go to the pool p1 you can only say one pool right r2.mydomain.com is going to p2 okay so what happen at this time so there is a constant ping is going to go and all the places here to here one and then p1 and and so on a one year one this constant being we know based on how you configure the default is 30 seconds if you leave that way there is going to be 12 000 things per node it's going to happen you know in an hour okay anyway so now it's it's going to you can do it what do you just explain there is no restriction you can just do it so one dot our domain.com comes in it's going to go to a yeast you know and then if the user browse from the west it's going to go to a west and then similarly 2.mydomain.com it's going to go to east if the user draws from the east and west the only thing you can do because you putting the node a1 b1 into both back and pools you cannot restrict by the front door headers because it's going to say nope that header is already configured so you cannot do that so other than that you should be able to do what you exactly explained you can mix and match and the same same um pack and can be a part of another pool to do the two dot my domain.com that's fine yeah so like i know i know that i can do this but i'm i'm kind of unclear on what primitives are involved in doing this so would this require two different routes to say that your domain.com goes to all one as soon as you have the domain here so this is the front door you know like the the first configuration you have to say here like i'm going to have this domain this moment right as soon as you do mine it's invalid until you define the route right so you define your domains which is the domain is the first configuration and then you will have to complete the route how are you going to route to the domain so the you use the url kits one dot your domain.com this is the route is where you're telling either a path or the you know and the the pack and port where you want to rotate right and the host header so now which header you want to send you want to send to one.yourdomain.com or you want to send"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:30:23",
        "seconds": 1823,
        "text": "telling either a path or the you know and the the pack and port where you want to rotate right and the host header so now which header you want to send you want to send to one.yourdomain.com or you want to send you know some sort of static headers x dot y dot com you know those three parameters you can only set it over here plus the caching how do you want to cache it it's going to be a dynamic cache or the static cache and all those things you set it on the route not here so each application should probably get its own route exactly every domain needs to have its own router so that's a massive massive difference between azure front door and as your front door standard and premium no in my opinion yeah no because money no the front door premium is just brings additional functionality like you know you know right now this is a public endpoint right so you are you are these things most likely to be in a virtual network but it's still exposed to a public right but you can prevent that by setting the header but these endpoints are can be virtual network but still port 443 r80 is open to a public somebody can hit it right but that you can prevent that you can put this this package completely private that's where the premium brings into it for you know added value so you can now those are routed within the microsoft network layers maybe i'm confused then because all right so i don't whenever i go to the pricing page for the old azure front door you have to pay per routing rule beyond whereas on the new standard premium model i don't see any pricing based on it's still a preview it's still a preview so you don't they don't talk about them it's still so nice so they might still charge yeah yes yeah it's still a preview so and you know a few things you know when i started look at like six months ago um for the same demo talk that i'm giving i gave six months ago it wasn't working um they said you know certain things we are working on it i looked at it today this is one functionality still not working which is the caching still not working um you know there is there is no better way to configure caching the front door provides some much better option than the front door preview that we are talking about anyway um thanks for the question i will change gear here sorry guys thank you for the explanation oh let's go here so what are you going to do um so i have um some samples i already created because you know creating on the fly it will work but it's time consuming process so for the interest of audience just to go quick uh know how we can create things uh and i look for the front door right so either front door or front door standard premium the way the configuration work is entirely different the terminology they used is entirely different but once you configured no they all work i will show you the the key difference between a front door and front door premium but once you once you get into it and you understand okay that it that's what it is so i'm going to select the front door and just click create go for it and then you know you just say here you know um whatever the host name i usually say ft just copy that word for now um azure ft.net right so like creating it and then i can say i need assess an affinity or not which is mainly for the stateful applications who needs to be routed to the same node if you have a stateless application you don't need to bother about it the other one is the application firewall so you can you need to create the firework first and then you can add it over here right so um if you enable it it will ask you to select what firewall you want to pick so you can pick it i'm not going to complete so i will take whatever i i can do right now okay and then just add it now you need to come back to the packet port so which is also called origins um you know you come here you give some name and then you add the packet right so i'm going to select something here app services and i have that subscription i'm going to select maybe um east to us so here is the key if i have to pass in the incoming header right the url to all the way to the um the application then i have to keep this as empty okay if i leave the value over there you know when the request opens it's going to pass whatever value was there so that value will be passed but you don't want that value to be going some application you may need to but you know you know most likely you want to pass in the incoming cost header all the way back so in my my case when i build a sas application we have you know 500 plus customers url hosted in one front door and not one multiple front doors but when we come in it's"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:35:25",
        "seconds": 2125,
        "text": "most likely you want to pass in the incoming cost header all the way back so in my my case when i build a sas application we have you know 500 plus customers url hosted in one front door and not one multiple front doors but when we come in it's the same compute it has the domains but we want to pass in the incoming uh header right so it comes like you know um would i dot my company dot com i want to pass in all the way to the back end woody.mycompany.com so i can do some partitioning based on the top level domain name i can look up the particular data customers data and then you know let them work with it so if you put that value any domain come in it's going to pass to our endpoint that domain so you have to keep that as empty and then you can enable those port and then add it and then you can keep add to the packets right so um you know you can say again i have your app service and i'm going to say this is going to be um used to use this to us you know just speaking randomly and then you keep adding it so you keep add as many as many backends as you want um then your path you know if you want to differentiate the path you know you keep creating it you know one for images one for things but in this simple demo we're going to keep everything dynamic and static mixed so i'm not going to set any path um there is no requirement for us to isolate it but if you want to isolate it you put a path and then you come back create another another attack and pull right and so on uh probe method is a head our get uh as i said head is just connect and gets it get download the data so even if the 10 bytes is a lot you're going to pay a lot of money so you have to be very careful using the head request this sample size you know it checks for four and then to mark it as a healthy you know this money is needs to be passed um latency sensitivity zero is the default meaning that it will always know the closest route in the example i told you you know highway is the best route to go from point a to point b but sometimes there's something happening on the highway it takes a longer so we start tend to take the shortcuts right so like that mechanism built into it sometimes it's also called dynamic site acceleration tsa so it's constantly sends the ping and then make sure what is my best route possible okay so i say add and then routing rules okay in the routing rules you get to say some you know whatever name it is and then you accept the protocol and then you say the frontal domain so this is where it's going to be as you add a domain here so right now we said azure eft.net but you know when we have the custom domain we're going to add custom domain one custom domain to custom domain three and it would be here and then you select which term and you want to map and then the match path again and then you either forward or redirect within the back and forth you select right now there is only one you select it and then either you redirect rewrite um our caching i would if you say enable over here it's a dynamic route caching say you you're expecting the dynamic data for example your endpoint returns the current date and time right but that will never return for 24 hours the one time it's returned that value is cached so you don't want to cache it here but i will show you where you can cache it so this is the one for routing when i set it here that is not this is only for the path for the healthy check i i miss spoken here this is only for health check if you want to route image versus image versus you know other thing then you you come back and create a multiple routes routes table one for image one for video and so on but this is back end of that path was for health check where your end point is you know in my case is you know i might say api slash health right you know wherever your health is um endpoint is health and finance but if you leave a route and that's not a good idea because most of the time the route side tend to have more data than the uh other sub routes dedicated for the intersection anyway you got the concept so that's it and then you know one other thing that we have to note down here is the interval seconds right if you leave it 30 seconds based on how many regions you run you're going to hit that number pretty high pretty high in an hour so if you increase the value you can go up to 255 if you said 256 it's going to throw error 255. now you are in you are increasing the value to run you know close to 4 minutes 15 seconds right but the problem of that as i said in the highway example you know you see like there was now there is an accident two minutes later everything is clear the road is clear it can go high right but that that optimal route it's not recorded for next to four minutes so it's going to check every four minutes instead of every 30 seconds right so the lower the value is better to detect your latency but the higher is higher the value it saves a lot of data on money side of it so you you're going to play with some you know based on your requirement you know what value might work for you there um you know the optimal value may be 120 that's what i do it but you know but you can play with that value but you have to have some value more than the the front of preview they make that as"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:40:27",
        "seconds": 2427,
        "text": "work for you there um you know the optimal value may be 120 that's what i do it but you know but you can play with that value but you have to have some value more than the the front of preview they make that as a deep order 60. okay so that's it that's all and then you know next section is tag and then review and create you're good to go you created the fronto right so let's go back to the one we already created any question all right so i'll take this one so so once you create this is what you're going to see it right so this is how it looked like um you know friend print ends i have a domain here so how do i add a domain so i can add one domain here but now it's going to say boston demo 3 because i already used two boston demo 3. my wr right it says okay you don't have the name defined um in the latest they will have a lot of way to fix it from the portal itself but in the current printer you will have to add those values so i'm going to go back to my um goodness just stop me guys if you're any question so come come back to cost you brought up the health probes costing is that at the the inbound data transfer to origin rate exactly yeah so it's it's from your application to a front door it's uh you know how much state i took from so the front door knows where the your application right your application and then the front door right so that's where the request is originated those data you need to pay for it um if you your health endpoint is going to written say you have a generic health endpoint that gives a much more details than the health check of 200 okay you know says i have like a health endpoint gives me um you know 50 bytes but when you run that that number of requests it's going to be a pretty pain you know a lot more consumption over there so if it's just like a 200 okay with no body no real body it's no different from a head from a cost point of view yes exactly so you know i mean you are not going to see it right away there is a you know money saved but you just look at it you run it you see it then you will realize how this tiny bit of data increases your billings um so i'm going to have this boston demo 3 here i'm adding it i'm going to route to my cname record here so the one that i created ft b1 dot azure ft.net right so i'm say ft view on azure ft.net go to that one so i create it okay so i go back to here so it found it that's the cool thing about you know using the azure dns you know one thing is a performance other thing is very easy to work together you know they are on the same service blade and then status enabled this one is the https you want to do it if i do enable i have option to select the front door managed or use my own certificate okay um so if i say front door managed then they're going to renew it they're going to maintain it it's pretty much free you don't have to pay for it but you know you will also have to use your own then you know it's good idea to use the key vault and then use the latest option so that way um that way you know as you renew the certificate it trades the latest and then apply to it okay and then you give the latest instead of the selected versions um here is the one place that you can use the test certificate you have to have the industry certificate or you have to use the front door managed certificates but again front door managed certificate is not applicable when you use a wildcard domain if you map the star.active.here then then render many certificate is not updated and then i have some app already created i selected it will get into it later and it says an affinity in this demo we don't need it you know it's a very simple website you're running it and then say now we have the domain added right so now in the routing table so i go back to my routing i say boston demo three i accept these two protocols you know and then here i'm not going to route there i'm going to route over here okay and then my path is going to be default i'm not going to change it and then i have a rules i have a ruled one i'll tell you why i need that rule you can keep it empty in that rule i'm you know i i disabled the caching here because i don't want the dynamic caching but i do need the static caching any static file that is used in the system i want to be served from the edge i don't want to go to the server so that rule i depend on the rule one i will show it to you so i'm going to select that's my role in gene and then whatever the packet port that i can't figure over here right and then if forward you know either http or https comes in you forward to https only but you know our http are the match requests so whatever the income is db then match request will power to http"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:45:31",
        "seconds": 2731,
        "text": "here right and then if forward you know either http or https comes in you forward to https only but you know our http are the match requests so whatever the income is db then match request will power to http is to be yes then power https we are not going to rewrite any url here we are not going to enable caching's ad okay and that's it now that the other settings that you need to worry about is this one the timeout this also the preview they made it at 60 seconds um you know most cases 30 seconds is optimal but you know your application does a lot of processing it needs more than 30 seconds then you can do so i believe the max is a 240 yeah 240. so you can go up to a four minutes um so it will not time out your front door will not time out otherwise it'll timeout terminate the request so you can set any value you want i'll save it it's going to take a time because we put https over here so that's going to take a uh oh we didn't do it okay i've saved it okay it's still not done yet okay we'll save it um any change you perform you will have to you know once everything is done you will have to put if you make any changes you will have to post that post might take anywhere from five minutes to 30 minutes um if you don't see it right out of five minutes i know the first time it will be frustrating but you know you will get used to it but it takes at least 15 to 30 minutes to get the value over there all right let me go back and then uh show you so now we add a domain right so how do you route to the domain to your app services so i go back to my app service you know i pick these are the two app service in the pool i go back and then do a custom domain and then i add the custom domain constant demo three we know and then i say validate okay so it says invalid right but after they mapped the boston demo three i came out item.ft so you know if you run your application in multiple regions you still need those those domains to be added you will have that text record as it explained over here so you copy this value and then you create a asuid you know text together that's what b do when you create a app uh when we onboard a customer say you are a customer you know your url is going to be x dot you know mydomain.com then we ask the onboard process we will create this recorder first is uid dot the x right and that will let us mount that to our add the custom domain to all the regions that we are running so we run pretty much 12 regions across the world so it will automatically close and runs all the dns records and then we will add a you know mapping to a front door just like how we did you know the real domain boston domain three i couldn't do as a c name to a front row but in this case it won't let me add because i need either a permanent record or a asuid record it's a temporary account so i'm going to create a temporary record here copy this value oh god there has to be a text record because cname required already mapped to a friendly value you say okay right now i go back to these and then okay so now it's valid because it sees the temporary card and then it won't it will let me add it so now i can go and add that record now i just you know since i enabled the https only so it takes few minutes to refresh that i select from the theme you know you either you import it in my case in my demo i have everything keyword so i'm browsing it and adding it in your case whatever where you want to work now you are you can also create a temporary certificate from here if you want to just valid for six months so you can create using here if you want to create one in my case i have imported using this one anyway so i got it now i got to the same thing for the you know uh the you know other regions but due to the time constraint i'm not going to do it but i will but you got the concept how you enable from you know from the adding the domain your dns records to a front door to a routing table to your application so we gone through the data flow for the demo purpose i'm going to use the one i already have it which is the boston right so that's the that's how the front door any question here so the next one is the web application firewall so i you know"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:50:33",
        "seconds": 3033,
        "text": "through the data flow for the demo purpose i'm going to use the one i already have it which is the boston right so that's the that's how the front door any question here so the next one is the web application firewall so i you know the creator application firewall so here we we mapped demo map one so once you click on it you see what it is and um you can do the managed rules so if you look at it this is what i was telling you the default route set to 1.0 and that's a that's in the preview the latest one i believe 1.1 and then common rules at 3.0 they will keep add these vulnerabilities the more vulnerabilities they will add it is running right now in a detection mode we are not stopping it uh you know it's more reset to direction so we enabled all the rules but it's not even black somebody's going to give this you know um sql injection you know um you know vulnerability it's going to pass in it's going to go to the server but it because we said to a direction if you do a prevention mode it's going to provide it top error you can also add a custom rule so if you want to add a custom rules over here you can define a custom rule rule one whatever you want to call it as rule 1 you know and then put the policy uh priority just a number they you know you might have used as they everywhere there is a priority and then you can say geo or ip size or some sort of condition that you want to pass it in if you do a jio and it's not in the u.s and i don't want my my site is only for us customer then i would now say the user is not in us then you know you deny traffic or redirect traffic and so on you got the concept since we are running out of time all required to be passed you got the concept so you can write as many rules as you want they all execute okay now the next thing is the association how you associate the rules that is not allowed here no you can don't secrete the once you create the web now how you associate with them that's what that code over here now let's go back to the printer and then take about the rules in gene right so what is this rules in general so this is what i was telling i was turning off the caching when i was adding the routing table right because in the routing table i said no don't cache anything but i can override that by coming back to over here so if you look at my rule here i create a rule 1 and then i said static assets it contains that you know you can put a multiple js css link right and like you know if you think that one of your path also has a lib somewhere else not intend to have a live of what you're thinking then you can add multiple conditions you know have that and not have these then do that so what i'm saying what we are doing here we take the request url you say contains and one of those you know if you want to multiple you can do a you know underline delimiter so just enter one at a time on one line one one per line js css leap and then you do that condense after converting to lower case if the path contains one of that then i want to do a forward to this pack and pool you you know then you do a you know either you can say match request again you can do a match request into https only i am not rewriting it but i'm enabling the cache and the cache is going to be a time i also enable the dynamic compression for the better performance and then use the default cache duration yes that means it's going to cash from 24 to 36 uh 24 to 72 hours if it is gdpr compliance you know based on where you browse where the origin located they will do a 24 or the 72 hours okay so now we create these rules and the rules is already configured so for that reason only it will cache it and tell you okay i'm going to cast that request any any any request that goes to a css that contains the js css lib will never go to a server it will terminate the first request will go to the server the subsequent request will stopped at the edge um you know and then it serves the data properly all right so that's the rules engine um today yeah yeah can i ask a question about rules engine suicide yeah this is basically it's not really a question about rules engine but i'm curious about your experience with the rules engine in that i know you run some complex systems i'm curious in in in such a world is it common to have a few rules or come and have 50 rules like what's the what's the span of rules that you see in the real world um i i know so if okay good question it depends on the requirement uh you know you might think if it's a 50 rule it needs to run all the 50 rules right somebody might say oh how fast it's going to run but i believe there you know it's kind of 50 else condition they will optimize index they will optimize it the answer to that question is is it's it's absolutely it depends on the requirement but now i'll give another example here you can split this into"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "00:55:35",
        "seconds": 3335,
        "text": "going to run but i believe there you know it's kind of 50 else condition they will optimize index they will optimize it the answer to that question is is it's it's absolutely it depends on the requirement but now i'll give another example here you can split this into three rules right you know one rule just to say yes alone and then create another rule and then you tell them you know tell them request to url and then contains uh operator contains and just say a css right you can do that as well but now you technically running three rules this is the bad practice if you can compose all those parameters into the one rule then you do that but if you want to do it like you have a 20 different 20 different path just for 20 different paths you want to repeat that for 20 different path then maybe maybe not a best practice you know you may have some requirement that you know certain path want to be cast at a lower interval than the other path but that in that case okay but they are going to be duplicate of what is defined on the first rule then don't do it just do it in the value as this like that but again i answered your question i think it it case my case but you know i i had a maximum of three rules that's all i'm running today um but i don't know i'm answering correctly to your question but you know i i don't i did not see a requirement for 50 rules but i think if you have a system that gives you 50 rules yeah it needs the 50 rules but what i'm saying is don't worry about the performance of computing those 50 rules they have a pretty good indexing very very helpful i appreciate it today thank you yeah all right let's get back to this one over here then and the other and the final thing that you must configure is the diagnostic settings okay if you don't configure diagnostics i don't know why they call diagnostic settings if you don't configure you go to a lock it will say you didn't configure anything but i wouldn't say that as a diagnostic you know diagnostic my my opinion i maybe you know you guys can correct me like something problem is going to happen that's going to help me but it's in the you know but i need to have the complete logging then you have to come here and add it so just go here you know put some name on it and select the values what do you want to log i always select all three and then i i send it to a log analytics workspace okay but don't even try to send it to some storage account or somewhere because those things is never going to help you um log analytics workspace is the best tool that i ever seen you can run it but it also it's not a free tool it's pretty expensive as you know the more you curry the more data you store the more money also you're going to pay in my in my case is the the project that i'm working on the more money go to the log analytics and any other services that's because there's too much of logging going on too much of korean going on then that leads to a more money like no per day the 100 gig you put them in a log analytics workspace you keep it for three months and you think about it how much log you accumulated you have to pay for all those things when you want to query they have to go through index through all those data so that's that's pretty expensive so you know do some analysis but you know some people might store it to a storage account for the auditing purpose i probably gonna look at it if you put on a storage account you can read it friendly nobody's going to look at it maybe the financial data you know if you keep financial data i may add it for the auditing purpose you know for seven years otherwise there is no use but i always use a log analytics and our system is not a critical system it's a content management so we don't care all those loggings we just put them in a log analytics we never configure more than 90 days you don't need those data more than 90 days for pre-production 90 days you know production we have a two cloud pre-production production cloud uh production cloud we give for owner eight days anyway so you got the concept you need to have those value in order to run some analytics logging over here right um so i think we covered the basic concept we saw the front door designer firewall rules and then now how you query the data right so you go back over here and then you can you can you know for example uh so you see the locked request i don't know it's it's not populated thing is hanging there something coming i don't know all right well it's so that takes some time while it's working on it uh that is not working i will show some lock from the other system but you got the concept so that you know even though the lock says even though the log says in a blocked request which is a blocked request now in the demo case we made it as a detection only so it's plot but it detected and then we move forward because that's what we want but they come under the blocked request category um you know they've brought a lot of sample queries you know you can look at it you know request for queries for example you know they're pretty good this demo site has set up this afternoon so you know enough data for you to see it all right let's go back to our ftv one so we have the you know this is the main blade right here so if you look at it in the"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:00:38",
        "seconds": 3638,
        "text": "this demo site has set up this afternoon so you know enough data for you to see it all right let's go back to our ftv one so we have the you know this is the main blade right here so if you look at it in the request count you can see this is not not affect us because it's a demo site request to size nothing you know we haven't promised anything we've been talking for the last one hour we didn't browse anything so there is no data to show and if you look at the back and health percentage i see it tells you okay you have two endpoint one is talking to a dewc which is the germany west central other one is the eus which is the east u.s right so i have two end points they both seems to be healthy right if it's not healthy obviously the bar is going to go down as it becomes healthy the body is going to go up and then stay in that level okay so that's a very helpful uh blade over here the next thing is you know we go back to the front door and then we look at it not this one i don't know maybe ready or not so if you can look at it it will tell you the status it will take uh 15 to 30 minutes right now it's ready um but you know we can browse it but we did not configure all the end points right so this endpoint is configured same exact way that i was configuring the boston demo 3 so we will use this endpoint to see some data i'm browsing from the u.s east uh you know i look at it i see my sample code i put on my now okay what is the incoming domain coming okay which region it's coming from and the data so if you look at it the data changes if i put check that caching enabled yes then this will be the static right you know it's coming from the edge then i will not get this value increased at all so now since we set the static route to see do some static level caching so if you look at it i don't know anything over here i reload i look at the css if you look at tcp heat what does that mean you didn't go to the server at all okay so tcp hit means and this is another indicator that you are your data is coming through the front door okay and it tells you i'm coming from the front door but i had a caching i never go to a server so this file is never gone to a server i did a pressure lock disable cache so i'm forcing to go to server but it found the file on the on the edge and then it gave me the file okay so i got it you know if i had another another path uh yeah this also this path has to limb this path has the css and then this may be having the js yeah it's also tcp heat so you got the concept what will happen if it goes to the server you will see the tcp miss meaning that it will find the content on the edge and it has to go to the server and then download it back and then give you back but once you refresh all the other users coming from the same region they will they will be sold from the yes they will get a tcp hit the key advantage here is now i don't have to worry about not say i'm a application that i've been building for several years i never throw all my static into you know this was a design issue i never and i won't be able to throw everything into a cdn right me hosting a cdn throwing it over there and then calling from the city i don't have to do now the front door does it for me you know it's all running on the same system but front door does it for me uh you know for all the path that i configured okay so that completes that one so when i go back to a different region hopefully my dm works i will show you otherwise you'll skip what happened okay any question while i'm waiting for these things to load so this is another vm that i have it in a different region entirely different regions um you know if i go and browse the same url here so i'm going to go ahead over here now it's gonna give us to germany right so so it's gone to west germany and then i got everything um we look at the network stack it should be a tcp miss because i didn't get it i refresh it tcp hit right so i'm first time browsing to that when the first request over here it wasn't missed it didn't find on the on this on the edge because this this when i when i hit from somewhere in asia the the front door tells them okay are you the closest is the west germany i'm going to route you to west germany okay it's going to west germany and then that's the first request after clearing all the i know i i cleared before demo everything so tcp means but now the second time it goes it sees it easily if somebody else is browsing they are going to dissipate them okay so you got the concept all right on next what else i'm missing here i will come back um so let's go back to the slide here um a standard premium um so the standard premium is the same functionality plus it has the uh you know um inbuilt the cdn and and"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:05:45",
        "seconds": 3945,
        "text": "what else i'm missing here i will come back um so let's go back to the slide here um a standard premium um so the standard premium is the same functionality plus it has the uh you know um inbuilt the cdn and and then the uh it has the uh and i have another tech that explains how you can do it it has the functionality called a private linking uh which is a cool concept and i use it in in my hosting deployment remove everything behind the door we only expose the back and nothing else is exposed to the web app outside to the public internet you know so you can connect to the connect to um on-premises which uses the internet you know they use the express the private private linking you need to download and install it you can do that so that way you know your front door can talk to on premises in a secure way but again the same concept is available um they have two skus uh one is the uh standard skew uh which is same as the uh what we have today plus the uh traffic analytics and some most um security capabilities the premium sku has the part protection i mean the bot production still available as a preview to a current front door uh but you know there you know it's it's optional bot protection is optional on the current different door and also a preview but in the new front door they are not optional i think you can buy it um as a private link support that's a key and the thread intelligence and secure analytics i know some more money more price the second point over here is the global load balancing that's the same dynamic site acceleration that's the same you know that's how it tells you what is the closest node by sending hundreds and thousands of ping to your servers i'll skip this one and i'll go this one so front door what we have today is a cdn static file website caching dynamic site api acceleration all those things that we signed the standard they call it as a delivery optimized because they have a inbuilt cd cdn that's what they say but i don't care as long as i get a senior functionality they also have a small little bit more smart way of doing the dynamic site acceleration and how we want to connect you to a closest to their back uh traffic analytics and a health report and then the premium sku the main thing is the private link support uh then they have that the common rules of three point two drs loads so don't find one and then some more okay now things to know there are five zones in india australia are those things um you know ensure json is properly promoted udf8 encoding you know sometimes you know you download from the git this may be a utf-64 encoding to underwork it has to be edified encoding if you use json file uh minimum builder response is 2 kb even it's less than 2 even if okay so this is where i was telling it right so if you you you send the data which has the data data in the body then you multiply by 2 kb you know it's it's you're going to pay a lot of money so right so and then 100 domains um per front door uh that's not going to include the wildcard domain um or i don't mind more five dollar more per domain afterwards um so data transfer from back into a front door is the bandwidth building how much data was moved in the wire um it's a hoverly building all right now let me go and walk you through uh front door uh v2 okay so it's the same exact uh but the the you know the the the play the ui the the naming is slightly different this is the v2 if you look at the v1 this is you know defined over here like this but if you have more than say 25 this will overflow in a pretty bad way so i go back um how do you create a front door v2 so i select weapon door premium i create i would select this option because this option is i'm comfortable using this option but you can select any option but anyway you will have to complete it uh you know then continue on um you put some name on it as he said it doesn't matter what option you select but you will have to select before you you you complete the creating the service but once you created it you have to date and change it um again you know it's a private link everything is a cool console but you're going to pay for the money after their private network data flowing um and then and so on add a certificate uh you know add an endpoint endpoint is nothing but uh you know when we create a front door we give the name right that itself become an endpoint and here they're forcing you to they call that ascend point okay but there are different naming conversions and then uh go tagging and then review create but we are not going to complete it but let's go over look at it uh how we did as a existing one so i have to v2 uh again in find manager so when we when we do the endpoint this"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:10:48",
        "seconds": 4248,
        "text": "and then review create but we are not going to complete it but let's go over look at it uh how we did as a existing one so i have to v2 uh again in find manager so when we when we do the endpoint this is the endpoint manager right so ftv to z0 on azure ft.net if you look at the you know f1 uh open a new tab uh if you go back to the front door design you can look at the overview now you see there are some request coming in so let's go back to the designer so this is the end point right so we're going to use that end point to route all the dnses so that is over there and then you add the domains right here they call it as the origins and front door is called back pack and poll so if you look at it it's nothing but you know how many servers the same servers that i added over here okay and the settings also remain same right sample size and then successful sample latency sensitivity and all those things stays there um and then the route tables again same routing we had a routing there too right so you click on the routings and then you tell them um so you want to edit just to say edit endpoint and then look at it here's more data so you say that you know it's a routing table for um this time and what i'm going to do for you okay this case doesn't matter so i was selected accidentally but it doesn't matter for me because i'm not going to browse through that i'm only going to browse through this because i don't have access to add that domain into my application because my application needs the incoming valid domain not that domain but i will never be able to add that to my activity okay so um and then you know origin group which is the pack and the routing table just like before right so you you create a route you select the pack and port here it's origin right so it's like the origin and then how do you want to route it and then again the road table this rule is what is not working um i discovered around two o'clock i create a case but they never able to answer me we have a direct support we're never able to answer me um it's not working the caching is not working same as a rule that we created on the front door but this particular rule is not casting the static price but it will work caching if i check that but but the problem is that is it's going to do a dynamic caching all the routes that i have um that's bad right so you don't you want when you browse this data you want to get this data to be dynamic this to be dynamic uh but that's that's what i call it as a dynamic um okay so that's what it's all same there is no difference if you look at it and then the security is again a firewall so we saw it over there in ah you go through here domain so if you want to add a new domain just click on add a new domain and then and here there's a little bit of integration so if you want to add a new i just put a name since i have everything in the the same uh as you turn and then they will do all the work you know you don't have to go back remember when we did it when we had a domain boston demo 3 we went in we added all those things but here they will do it for you if you want if you if you use their blade but if you use it programmatically you have to do all those things um origin groups again that's the same as the back end you know this is the other way to add if you had a more origin group we can add it here then rule set same as the rule set security is the same as um optimizations um the complaining here you enable it but i don't want to enable it my site is a dynamic site i have no idea why they said you know things um it's kind of funny to me again diagnostic logs you have to enable it once you enable you should be able to query the diagnostic logs right so he got we haven't browsed anything that configured this url but if you browse the url then it would say the url that configured over there um boss demo 2 surprising boss number two here oh god oh god mismatch one word it goes to somewhere else all right so that's easier the incoming domain i think right now it's dynamic but if you look at it my caching wasn't working i don't know it's working now so if i look at it over here it's supposed to say cache miss or hit but it's still not saying anything but if you look at my configuration here we already configured all those things so look at the rule one we have this rule but here they provided uh it's a different way to edit uh you know there there was a text box you put one line at a time so here you have a little lady but i don't understand this concept they completely the rule ui is slightly different even the microsoft engine is"
    },
    {
        "speaker": "",
        "title": "Udai Ramachandran: Azure Front Door",
        "videoId": "vTLZ3GoZZvI",
        "description": "This is a recording of the September 14, 2021 virtual meeting.Azure Front Door is a global, scalable entry-point that uses the Microsoft global edge network to create fast, secure, and widely scalable web applications.Azure Front Door -Standard/Premium (Preview) feature combines capabilities from traditional CDN, global load balancing, dynamic site acceleration, security including Azure Web Application Firewall(WAF), DDoS and adds new features such as delivery optimization, enhanced traffic analytics,  extensive security capabilities across WAF, BOT protection, Azure Private Link support, integration with Microsoft Threat Intelligence, and security analytics.This session will include a deep discussion and demo of the following items:• Introduction to Azure Load Balancing solutions (Front Door, Traffic Manager, Application Gateway, and Load Balancer)• Key benefits of Front Door• Custom Domains• Application Backends• HTTP(S) Routings• Rules Engine• Web Application Firewall• Programatically creating and managing the Front door• Monitoring and Alerts• Approach to Single and Multi-tenant global load balancing## SPEAKER BIOUdaiappa Ramachandran (Udai) is the CTO at Akumina, is a Cloud Expert, Azure insider, Organizer of New Hampshire Cloud .NET User Group (@nhcloud) and is often engaged as a speaker for the New England Area User Group, Boot Camp, and Code Camp.He is also the founder of UVONS TECHNOLOGIES PRIVATE LTD.(https://uvons.com), a software development company specialized in Cloud Computing (Azure, AWS, and Google), and Artificial Intelligence.",
        "start": "01:15:52",
        "seconds": 4552,
        "text": "one line at a time so here you have a little lady but i don't understand this concept they completely the rule ui is slightly different even the microsoft engine is not able to answer but they'll get the answer today or tomorrow all right so that ah okay one last thing so so here you know if you if you write a more programming like i do um you can go back here right so you check you know i'm just picking this name for example and then try it you log into check and then put the values and then you take that payload and then attach to your request you know so whatever the payload you generate over there attached to the record so i pick this one say but the type is little problematic for me to find out on sorry bill you are saying something yes i am copying this i need to tell you okay 200 name is available right so tell all the methods here you just browse through it you know find out which one you want and look at it then you copy the payload you have all the end points here and then just send it good to go it will create so it's easy coding all right any question guys okay i'm done if you um so if i if folks have questions for uday feel free to unmute yourself and just ask him verbally great thank you for staying till the end it was great i always enjoyed talking to this user group and thanks you thank you team for having me here tonight it's always a pleasure to have you and i love your your demos you always give interesting demos that uh reveal what's going on at a deeper level uh you know looking at http headers and such i always have i always enjoy uh watching that um uh so folks have questions for uday you can you can chime in in the meantime i'm just going to wrap up with i'm going to ask in a second if there are any announcements but in the meantime i'm going to hop to the um to the list of upcoming events we have three events planned only two of them have made it to the um uh oh i'm sorry we have two more events planned including including uday tonight it was three but we have our next event is uh tuesday november 2nd same time same bat channel and it's on application insights and telemetry in azure of course uh and it's uh the speaker is uh isaac levin and that that promises to be a good um a good session with uh telemetry that's already posted and you can rcp repeat that on either the north boston azure or boston azure meetup site to uh you know to register your interest and get access to the link and then we have another one that i think is two weeks after but we'll get it posted and that's um from doug vanderwaad who'll be calling in from presenting from texas taking advantage of our ability to support remote speakers and uh the topic of his uh talk is escaping me at the moment veronica jason do you remember sorry bill i was looking at the the meetup we have two in october um they i put them out there as drafts maybe i didn't post them um so we have uh bicep by um alex frankl october 19th and then kubernetes for data scientists is october 5th so there oh we haven't cloned those over to the boston azure side then they must be on the okay so a little out of sync between north and boston azure let me publish them yeah they're still in draft mode so we're going to publish them soon that's fine i was just um saying that they are in draft mode so we're gonna publish them soon and we'll have two events in october october 5th and october 19th um and then one in november for now sorry for the confusion i see a silo moment everybody's here yeah oops i was talking to myself too um so okay so veronica just posted uh we have two in october that will be posted soon two in november that will be posted soon only the first one in november is posted so we have little uh clerical work to do but stay tuned um any final questions for uday and any other announcements from anybody i have a user group meeting coming up i'm you know we have a couple of topics um please visit meetup.com [Music] you are over here awesome so you get um more of uday and azure stuff from nashua ug uh i've been to uh a number of those events in perth and in virtually uh good stuff any further announcement okay well uh uday um thank you again for speaking uh the the talk was recorded and it'll show up on uh youtube.com boston azure starting tomorrow usually and um and we'll post a link in the meetup site that points you into uday.io wherever in there the the slides and other material are that's on radar day yes i will send you the link tonight very very good thank you everybody uh good to see everybody from uh from all over the place thank you guys good night thank you "
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Near Real-time analytics with Azure Synapse. This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad. everyone for joining in uh good evening uh I'll start with a brief introduction about myself uh and then we can start with the session so uh myself I have total 10 plus size of IIT experience and currently I am working as a solution architect for one of the leading Dutch bank uh I live in Amsterdam Netherlands uh so today we are going to talk about uh how we can Implement near real-time analytics using Azure signups so during the session uh feel free to ask poster question in the chat or if you want to speak up unmute and raise your uh voice uh I'll be happy to answer all the questions and in case uh I I in case I won't then I can also get back to you later on after the session yeah so if we look at the agenda for today mainly it uh we'll be going to uh this uh like two points the first one is uh introduction of Cosmos database and synapse link uh and how we can use the Azure signups link feature of Cosmos TV to create an end-to-end near real-time analytics uh with Cosmos TV and sign ups and yeah we'll take up q a at the end if there are any yeah so let's start with uh the introduction of Cosmos DB and synapse link uh before we get into the more detail I think first we have to understand uh the challenges uh and and what kind of uh uh problems uh are being resolved by ISO synops links for Cosmos TV I will also get an overview of azure signups and then we'll Deep dive more into the end-to-end technical implementation so uh first of all there are a couple of challenges uh when we talk about traditional analytics workload with Cosmos TB which is one of the offering of Microsoft uh so first challenge is manipulating manipulating the amount of provision throughput so in Cosmos TB We have basically two uh kind of throughput we can choose we can manually provide a request unit for the processing or we can also enable auto scale uh but if it is not if it uh it is auto skill uh then cost of Cosmos TV is very high and if you manually manipulate the provision throughput at the beginning itself then there are possibilities that uh some in case of more workload we won't be able to process the data efficiently or let's say read or write data efficiently with Cosmos DB this is one of the bottleneck then the second challenges uh using the change field uh change data field to move data to Cosmos so uh you know in normal relational database we directly uh work with the Trans external record so we do not maintain the history but if there is a requirement where we want to maintain the history of data and then using the change data feature of uh to move the data to Cosmos TV is a challenge and then the third challenge is to develop the custom ETL mechanism to move the data to Cosmos DB so even if let's say you are using in in if you are implementing a one of the data platform solution where we have let's say ATL data Factory pipelines in which you are doing some material transformation and then if you want to move the data to Cosmos DB you have to write a custom logic as per your preference maybe in a python or Java or any other language uh but uh it this is all this is applicable for both batch and near real time in Json but if you want to uh let's say as soon as there is a data in a landing Zone uh we should be able to make the data available immediately in Cosmos DB without any delays uh then that is not possible or there are potential delays while uh doing the custom development so these are mainly the bottleneck when we used traditional analytics workload with Cosmos DB uh now let's see what is this Azure synapse link feature for Cosmos TP and how it overcome all the challenges so the first challenge it overcomes is enabling the analytics over the transaction later without impacting the transactional workload so it will enable uh so when we enables Cosmos T before synapse then we will be able to support both transduction as well as analytics data uh without any performance bottleneck then the second feature is uh Azure Cosmos DB analytics store it allows to sync the traditional data into a column in a store then the third major benefit is no need to develop and manage complex ETL jobs so because we are enabling with this Azure signups link feature for"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:05:04",
        "seconds": 304,
        "text": "allows to sync the traditional data into a column in a store then the third major benefit is no need to develop and manage complex ETL jobs so because we are enabling with this Azure signups link feature for Cosmos DB we can enable new real-time implementation and from as soon as there is a data in the landing Zone the sign up links only make the data available to Cosmos TV so we do not have to first of all develop any ETL code and also we do not need any operation Edition or maintenance of these CTL jobs and the biggest Advantage is uh we can make the data available in an aerial time manner so we'll be able to perform near real-time analytics with the data that we want to let's say use process and bring some value for the business um yeah so this is a brief introduction about Synapse link feature of Cosmos TV uh before we further Deep dive as I'm mentioned at the beginning let's also on go through the introduction of Cosmos TB and synapse offerings of Microsoft uh and then we can go through the end-to-end implementation so let's talk about uh what is cosmos DB uh what are the offerings and how we can uh use it basically or for which workload or which use cases we can use Cosmos DB so Cosmos tip is Microsoft Global distributed multi-model and nosql database uh it has a lot of flexibility and uh also from the performance point of view it it it mainly allows us to elastically and independently skill both in terms of throughput and storage and we can also enable jio application to make the data available in Cosmos DB uh in a multiple region in case of any region failures so it is Microsoft like it is a nosql database uh which we by which we can scale uh horizontally and vertically based on on the workload and the configuration and also uh there are other advantages like it offers multiple apis so when we let's say try to spin up the cosmos DB in the Microsoft in the Azure Resource Group uh you will know you will have an option to choose different apis so if you want to use a document database uh as a nose in a nosql database then there are two offerings uh no SQL API and the mongodb API if you want to work with the key value data pair uh then you can use the table API so if you want to work with the columnar database then you can use Cassandra API and if your application or a use case wants to use a graph database then you can use Kremlin API so these are different type of offerings uh when we want to use Cosmos TB with Microsoft Azure based on your workload and the need we can use different API and then there are also other benefits like we can enable near real-time implementation if we use signups link feature of Cosmos TB uh it has a complete integration with application insights and other services so if you want to let's say understand the performance if you you are facing any bottlenecks or if you want to see how the the processing happens uh or there are built inbuilt monitoring dashboard we can use to closely monitor the cosmos TP workload now Cosmos TB uh it it mainly allows us to build an application which is highly responsible and available applications worldwide uh highly responsive in the sense that uh uh we can make the data available very quickly in any real-time Manner and that can be used for the consumption purpose for various reasons and while configuring all creating Cosmos to be we can also enable jio Geographic replication so it is highly available application which can be used worldwide it also apart from this it also ensures that our in the end users data is as close as to them as possible with a guaranteed low latency for both read and write at the at the 99 percentile so uh if we enable jio replication and if your application is a worldwide application uh we can let's say configure jio application for Cosmos TB and we can try to consume the data from Cosmos DB from the nearest location and also it offers a lowest low latency now when we talk about Cosmos TP there are uh I mean it also provides us a more flexibility uh to make a choice on what kind of consistency model we want to choose uh so Cosmos TB as of now provides five different type of well-defined consistency uh strong bounded Stillness session consistent prefix and eventual so these are a different type of consistency being offered by Cosmos TB and based on our workload and the requirement"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:10:08",
        "seconds": 608,
        "text": "provides five different type of well-defined consistency uh strong bounded Stillness session consistent prefix and eventual so these are a different type of consistency being offered by Cosmos TB and based on our workload and the requirement we can choose one of the consistency model uh for read and writes from the cosmos database uh this is a brief introduction about Azure Cosmos TB now let's also Deep dive further into uh what is the synapse offering what are the features and how we can use the combination of Cosmos TB and synapse to make our neural near real-time implementation much easier simpler and a flexible so Azure signifs as we all know I think most of all us who are working with data analytics uh projects uh signups is an integrated analytics service which actually allows developers and end users to use SQL and Spark for their analytics and data warehousing workload so it is a unified platform in which we can do our development in SQL but if you have a need where you want to create a distributed application with more performance improvements or more performance optimizations then we can also use a spark on the top of it so it provides a SQL pool and a spark pool when we create a as a signup server uh once the synapse server is created you are you have a freedom to create those server pools and then do the development on the top of it now with signups uh we can build the pipelines for data integration a machine learning purpose ETL or elt workload now the major advantage of using synapses it has full integration with other services or a component so basically we can leverage all the Azure components to build our end-to-end uh let's say data analytics a project chain starting from collecting the data doing the ETL or elt on the top of it and once data is available in a golden layer we can it has connectivity with tools like power bi where we can create power bi visual reports or if you want to create a machine learning model or any advanced analytics activities it also offers an integration with Azure machine learning service power bi and Cosmos TV so we are now going to in this session we are going to explore the feature of integration with Cosmos TV for ISO synapse link now apart from this synapse also provides us with an unified management monitoring and security over the Enterprise data Lake uh it has complete integration with TD less Gen 2 or let's say blob storage so we can also securely access the data uh it is a unified platform as I mentioned earlier so we can collect the data process the data and also create a visual reports or a kPa reports and apart from this from the Ops point of view we can also do monitoring so uh with the help of synapse Studio mainly it enables data Engineers ba engineers and data scientists a unified experience to build a complete analytics Solutions so in a traditional uh even you know in a traditional or in a cloud data analytics workload uh most of the people are working in a silos so data engineer works on python application or a pi spark application to create an ETL logic uh then there are uh a data analyst will work on the data created by data engineer to create some insights so they are working with different tools and when we work with different tools and when we work in a silos there are multiple challenges like uh data prepared by data Engineers might not be relevant or compatible with the tool that uh a data analysts are using it but uh sign ups Azure sign ups uh our overcome these challenges by providing unified platforms so basically all different type of roles uh can work on the same platform so there is no data compatibility there are no challenges with let's say schema or data requirement uh so this is uh like we have now understood the basics of Cosmos DB and sine and Azure synapse offering now let's see uh what is this feature of synapse links for Azure Cosmos DB and how we can use it to create an in real time streaming application so the synapse link for Cosmos DB is a cloud native capability uh it is at step basically hybrid transactional and analytical processing so if you want to use if you want to work with a workload where we have a requirement to work with both transdictional and electrical housing processing then this is the feature that we can use with Cosmos DB now with this synapse link"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:15:12",
        "seconds": 912,
        "text": "use if you want to work with a workload where we have a requirement to work with both transdictional and electrical housing processing then this is the feature that we can use with Cosmos DB now with this synapse link for Cosmos TB uh we can actually uh create and run the new real-time analytics over the data in Cosmos 3B using the cosmos DB analytics store so once the Cosmos TV is created yeah first of all we have to enable the synapse link and with this Cosmos DB analytical store we can enable the real-time analytics or an implementation uh then with Azure signups links it provides a way to perform near real-time analytics on the data without having to any uh without having to create an edl pipeline so basically normally in a in a normal workload or even if we take an example of cloud workload if you want to create a new real-time application uh we need to do a lot of development and also we need to have a platform capability so let's take an example of Kafka Kafka is a Kafka Confluence is an aerial time streaming platform so let's say if you want to enable new real-time injection using Kafka platform then first of all we have to make the data available in ADLs into from media list and do we have to create a data Factory pipeline under which we can have a databricks notebook uh now this databricks notebook can publish the messages or new updates to the Kafka topic and then we have to subscribe to this Kafka topic and create a custom development maybe in python or any any other language to consume the data in any real time manner but uh if it synapse link for Cosmos TP basically we can avoid all this complexity uh without having any additional platform capability or without doing any addition development data sync at a sync connector end uh we can get the data in any real-time manner on the top of Cosmos database so uh this is the let's say the oral flow we have Cosmos database uh maybe with one of the APA SQL API or a Cassandra API or mongodb AP and there we have data stored with some features with some indexing now on the top of this Cosmos DB we can enable Cosmos DB analytical store which try to converts all the data from row base index test to the column based indexes and then we can use synapse analytics to directly let's consume the data in any real-time manner from Cosmos DB upper and along with this we can also leverage other features like reporting or integration with power bi or other tools so this is a signups link feature of Cosmos TB now they're also new term right this Cosmos DB analytical store so let's also understand in detail what this feature is about and how it will enable us to enable any real-time implementation so analytic Azure cost positive analytical stories and isolated columns to uh which mainly allows us to perform analytics against transductional data without impacting the transactional workload so let's say in a traditional database implementation uh what happens is uh there are like multiple applications who are dumping or writing the data to SQL dbn at the same time let's say if we are also reading this data for a tool like w or power bi then we see a lot of Performance challenges but uh with this Cosmos DB analytical store uh without impacting transaction workload or a transactional read or write we will be able to perform the analytics efficiently without any let's say list delays uh and and let's say we can create those visualizations very quickly or without any any performance delays So transactional Stories are all store which is optimized for transactional reads and rights so it will optimize the reads and rights which are happening to the trans transactional workload then one of the major advantage of this Cosmos DB analytical stories it is schema agnostics and it allows us to iterate over the application without having to manage the schema and indices so in a normal relational database before we make the data available we have to create a schema and in case of any schema drift or a schema evaluation or schema changes first we have to change the schema and then we have to uh let's say then only we can induce the data to the database but the cosmos DBS it is a nosql database it is a schema agnostics and it is also able to handle the schema drift and apart from these we do not have to additionally apply the indexes it is internally it will do all the optimization by itself then with this analytical store it also helps us to perform the super fast transactional reads and write on the top of Cosmos DB so as we look as we discussed at the beginning uh Cosmos to"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "optimization by itself then with this analytical store it also helps us to perform the super fast transactional reads and write on the top of Cosmos DB so as we look as we discussed at the beginning uh Cosmos to be offering has two two plants like we can uh provision the throughput or requested at the beginning itself or we can also enable score Auto scaling but if we want to do a trade-off to reduce the cost based on your application then I mean without impacting or without provosting more requests on it or Auto scaling uh with this feature we can also quickly read and write data to Cosmos TB now uh apart from this we can also extract the data out of Cosmos DB in a separate layer that is more suitable for to perform the analytical workload using the chain data feed so for example if you want to if we uh we can spin a better functions to listen to the containers of the cosmos DB for the insert so whenever there is an insert or a new insert into the Cosmos TV container then we can uh we can also let's say quickly uh using the change feed so it will automatically monitor the changes happening in the cosmos DB container and then we can maybe make the data available in data Lake store or blob storage or if our Target is to move the data to uh to a different let's say if you want to create a databricks Delta table then also it is possible so we can screen up with the combination of Hazel functions we can closely monitor all the changes which are happening to the Cosmos TV and based on the required scenario we can also enable uh the post processing action uh so these are the features of cosmosity analytical store uh is uh apart from this what analytical store does is it is a column store so it is mainly optimized to perform the analytical queries so uh this way we can reduce the latency of reading the data from Cosmos DB uh and then we can use it to work on uh different use case or a scenario for the downstream consumption with Cosmosphere analytical store it can also sync the operational data in the row store in a separate column store which can help us to perform the analytical queries without building any ETL pipeline so no custom development is needed uh so then when we enable this analytical store uh basically it it is an isolated column store which is created based on operational data inside a transactional store so they both will be persisted separately data is automatically listing between both operational and a transactional store and we do not have to use the change field or developer own ETL mechanism so let's say if there is a requirement where we want to maintain the history of data then we do not have to do any custom development uh it will all the singing will be done automatically and the latency of the syncing is around two minutes then auto sync will occur regardless of intensity of the traffic so there won't be any impact on the performance of your application the syncing will be will happen in the background uh independently so that way it provides more flexibility and we do not have to worry about any Performance challenges now uh in in analytical store basically there are two modes of schema representation so we have well defense schema and we can also choose food with Fidelity schema representation so what do we mean here by well defense schema is it is a tabular version of the data in a transaction store while the fulfilled schema handles the full breath of the schema that exists in return external data so these are the two offerings that we can select while creating the analytical store so that this is mainly briefly about this what is this Cosmos DB analytical store now coming back to the the main feature by which we can enable new real-time implementation is enabling the synapse link um so first of all the prerequisite before we start with this implementation is that the cosmos DB should be present in your resource Group Azure science link should Azure sign up server should also be present in your resource Group now uh once you create the cosmos DB uh we can go to the the Azure portal so on the left hand side you will be able to see the container and also the different components that you created inside a container and on the top pane you will be able to see this kind of pane so from this pane first of all uh so once the code must be is created we have to go to the data Explorer and once you click on a data Explorer you will get the screen along with the container details and the and the underlying files so we have to enable uh we have to click on a button enable as a"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:25:19",
        "seconds": 1519,
        "text": "the data Explorer and once you click on a data Explorer you will get the screen along with the container details and the and the underlying files so we have to enable uh we have to click on a button enable as a synapse link uh so once you click on it then it will take few minutes to take effect and once it is done we have to set up the analytical store for the container which we will look into the next slides so once we click on enabling the Azure signups link feature uh we have to set up the container to use the analytical store so yeah we again we have to go to the data Explorer click on a new container now uh once you set up a new container we have to provide the name partition key and throughput configuration as per our requirement now the essential thing here we have to notice the at the bottom there is a feature uh where you can turn off or turn on the analytical store so once you create a container this you have to provide a container name you have to provide the partition 3 the throughput whether you want to enable auto scale or a manual and even if it is auto skill then until uh which Maximum are used you want to provision let's say so here we can specify the maximum request units and there is a feature uh to enable analytical store so this is a must once you enable the signage link if you want to use that feature then you have to also enable the analytical store now once that is done it will create a container basically so once the content has been created uh you can see this kind of look where uh let's say we can configure different options so this is the cosmos DB container we created a cosmos DB with SQL APA under the dostp container we created this device readings and when you click on this device readings button because we have enable synapse link and analytical store you have option to and uh to set this feature so time to leave feature geospetel configuration and analytical storage time to leave So based on the requirement we can also enable these features and uh we will also deep dive further into what this feature is all about and how we should configure it to meet our project needs so first one is analytical time to leave so time to leave feature for analytics analytical store mainly describes how long we want to keep the data internal analytical store uh this setting is isolated from the time to leave setting that we have under transaction store so as we discussed we have two type of stores we have operational stores and we have a net we have transaction store and we have analytical store so we can only for analyticals store we can specify this feature to unders to make sure how long we want to retain the data no since both the settings are isolated data archiving becomes very simpler for us so analytical analytical stories optimized in terms of storage compared to the transactional store apart from this we can also retain the data for a longer period of time by setting this feature uh so if we have a need where let's say same data is being used by multiple consumers or a multiple Downstream application then we can and we can enable this feature for a longer period of time so every time whenever there is a read we do not have to go to Cosmos DB and then fetch the data so it is kind of a catching mechanism now once we enable these feature the next step is to connect the cosmos DB to sign ups link right so we have a container uh on which we have enabled analytical store now we want to connect the cosmos tip now we want to connect this container to assign its work workspace so if you do not have a synapse workspace then the first requirement is to create a synapse workspace you can follow the link to create a signups now from the uh now one if the synapse is created then we have to open the Azure synapse analytical workspace once you open it you will get this kind of UI or a screen and from this this screen we want to connect to an external data right so we have to select the data section and from the data section you have to connect to the external data so once you click on the XML data you will get a screen where you can choose different type of connectors let's say if you want to connect to block storage or a cosmos DB with API SQL API data Explorer these are various type of connected that we can use so at the time of preparing the uh this deck actually we can connect the cosmos TB account we can connect from Sinex to Cosmos to be account only via SQL DP or mongodb now if we have a globally distributed Cosmos DB account then an analytical store will be available for the container in all the regions and any changes in the transaction store it will be replicated to all the regions of the cosmos DB account so once uh based on"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:30:24",
        "seconds": 1824,
        "text": "distributed Cosmos DB account then an analytical store will be available for the container in all the regions and any changes in the transaction store it will be replicated to all the regions of the cosmos DB account so once uh based on let's say if we have spin up costs to be with mongodb APA then we can select this connector or supposed to be with mongodb APA and as soon as you click on a button you it will you will get an option to create a link service uh like in data Factory also we create link service for the point-to-point connection same way here we have to create a link service so you have to provide a link service name description integration runtime whether you want to connect to yourself integration runtime or Auto result integration or anything Auto original integration then time is a compute provided automatically by Microsoft so for most of the workload we can use this Auto visual integration runtime and in the connects so uh in order to set up a connectivity with Cosmos TV uh you can explicitly specify the connection string or you can if you have your connections thing stored in the keyword then also you can configure it with keyword as of now I'm directly specifying the connection string so from major subscription we can select the subscription name and the cosmos DB account name and then we can specify the connection string so once all the details are okay and validated uh the link service will be created and on the left hand side of the cosmos DB on the synapse server you will be able to see the the link service which we created now now uh as we discussed like we have different type of containers right when we enable silence link for Cosmos DB so we can differentiate between what this what these two containers are like analytical store and the transactional store uh so in oldp in on in on for transactional store we only have container for analytical store we need to create an Apache spark pool and to do this we have to create a manage pool so first of all we have to create a participal hole in the sign up server uh so this is the screen that you get so once you click on the analytical spool if you want to work with this week well workload then you can create a SQL pool if you want to create a spark pool then you have to work with a spark pool and this is the component where we created a link service if you want to enable any triggers then also yeah we can create a trigger now coming back to creating a spark pool so we have to uh on the left hand side click on Apache spark pull button and if you click on a new then you will be able to create a spark pool now once you click on a create button you will get a screen where we can we need to provide this information so we have to provide the spark pool name and the node size so if we are dealing with small data then the small is sufficient but if you have a more workload then we can choose based on a configuration Auto scaling feature should be enabled it is recommended to also save some cost and make your application highly available and once let's say all the informations are inputted and validated then yeah it will create a spark pool as you see uh the spark pool has been created and if you want to let's say con uh permanently save this change then you can click on a publish all then even when you log in for the next time or there are other developers in your team they will also be able to use this spark pool now uh now let's also Deep dive further into how to work with the analytical store in synapse uh so this will be I mean we are now starting with uh the the I mean first of all uh we are I'm just explaining you what kind of data is available in Cosmos TB as of now and then how we can use it to enable new real-time streaming so that is a sample device reading container it has 10 000 documents and each document contains uh uh this kind of structure in in a key value pair so we have ID we have temperature damage level age in days and location now let's try to query the data using Spark uh the spark pool that we created in synapse and when querying the data we can either load the data to spark using the data frame or we can also create a spark table uh sign up support enables us to query the data in Cosmos DB without embedding the transactional workload and we can also ingest the data to Cosmos TB using the spark pool in a streaming manner or in a via sequence pattern with both Cosmos DB as a sync and a connector so let's say once the data is available in Cosmos TB this is a simple command so we are at least for this demo we are going to load the data using the spark data feed by spark data frame so uh data"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:35:26",
        "seconds": 2126,
        "text": "so let's say once the data is available in Cosmos TB this is a simple command so we are at least for this demo we are going to load the data using the spark data feed by spark data frame so uh data frame uh using spark.read.formit uh the format is cosmos.olic because a data is stored in uh analytical store this is the option so uh option for the link service so the link service has a connection string to Cosmos DB using this link service it will try to set up a connectivity and uh here we can provide an option from which container we want to read the data so if once we let's run this data frame the data will be the data frame will be created and we can use this data frame further to meet for the real time streaming so once we learn the let's once we learn this command in the notebook the data frame will be created and this will be the content of the data frame uh so temperature damage level is in days and location now uh we want to perform some ATL on the top of it all or let's say for an example uh we can execute the query where we want to drop a few columns so we can just it is a simple let's say Pi spark command where we are dropping these three columns and as soon as we drop the column then we'll be able to directly see the changes in the cosmos database with her only relevant columns so now we have prepared the data frame so now we can use sitemaps to perform the Analytics now one thing we have to notice we can run the target analytical store meaning that the queries have no effect on the transaction workload so in our data frame we have a column for how old the device is in a d so there is a column called how would the device in a day now let's see uh which one are the oldest columns and what kind of damage they have sustained in the field so from that from the data from the da funderscore clean database clean data frame where we have removed certain columns uh we are using we are let's say uh first of all doing the order by based on Aging day so we in a descending order so it will let's say create a list of entries with in the device which is the oldest Center top and the newest at the end now uh we want to display only let's say 10 records or a limited record so we can display by using this command uh now the point to note here is uh here in this session uh I'm just demonstrating the capability of able to run the query on the top of analytical store using Cosmos DB spark in synapse without input without affecting the transactional workload and but this is not only limited to the using the query in the this is not only limited to query the data in spark we can also query the data in t SQL using the serverless SQL pull so there are two pools right we have server we have SQL pool and we have a spark pool so even if you are more comfortable with SQL and if you want to uh do the data processing or work with data using SQL queries then also it is possible so in SQ in synapse we can set up the SQL pool and then work with the SQL queries now if you are following this uh I mean when you want to do the Henson if you are working with your personal sandbox or a resource Group then the recommendation is to remove immediately uh let's say I mean we can quickly provision the serverless SQL pool or a spark pool based on our requirement but once the setup is turned maybe you can turn it off to reduce the cost now now we understood the advantage of using signage link for Cosmos TV but it also have I mean let's also understand from the cost point of view how costly it is or how the costing or pricing is being calculated so when using synapse link for Cosmos TV mainly we have to pay for both analytical store as well as the the processing or a compute that we use in synapse so it is not I mean the cost will be calculated based on your usage but it will be a pre the cost will be calculated for both Cosmos to be a feature as well as the processing power in signage no analytical store also follows a consumption-based pricing model so I we will be charged based on the storage written in the analytical store and the number of read and write operation that we do on the top of analytical store so since pricing is separate from transactional store we do not have to provision any additional requests you need so for if you let's say only when you want to do the processing with transactional store you do not have to worry about any performance or you know or you do not have"
    },
    {
        "speaker": "",
        "title": "Near Real-time analytics with Azure Synapse",
        "videoId": "w3EzsIsBZak",
        "description": "This is a recording of the January 25, 2023 meeting.The main goal of this session is to build a near real-time solution using Azure Synapse in combination with other services like key vault, cosmos db, data factory.About the Speaker:Sagar Lad is a Technical Architect with a leading organization and has deep expertise in designing and building Enterprise grade Intelligent Azure Data and Analytics Solution. He is an expert in Azure (PaaS, IaaS), Infrastructure as Code, Azure Machine Learning, Azure Bot Services and Cognitive Services,Python and powershell Automation. He has a rich 8+ years of experience working across top organizations in the industry. He loves blogging and is an active blogger on C# Corner. LinkedIn : https://www.linkedin.com/in/ladsagar/ Twitter : https://twitter.com/AzureSagar Certifications : https://www.credly.com/users/sagar-lad",
        "start": "00:40:28",
        "seconds": 2428,
        "text": "you want to do the processing with transactional store you do not have to worry about any performance or you know or you do not have to allocate any additional request to it so this is how the pricing works there are also some limitations of using this feature so some one of the limitation is uh currently synapse link for Cosmos DB is only available for SQL and mongodb APA we cannot use it for Cassandra API and Gremlin API if it's uh offerings of Cosmos PB for any containers with the analytical store enable automatic backup and restore of data is not currently supported so basically if you want if we if there is a need to restore the transactional store then the container will be restored without the analytical store enabled so that is the one of the limitations yeah so that's the end of the session that I want to present today uh if there are any queries or any points to discuss I am feel free to open and share do we have any questions in the chat a few thank yous like Patterson dragon here's a question did you see yeah I mean so there is a question from Michael uh so as of now Michael there is no support of Cosmos TB gramlin in apa for the sign ups link but uh it is on the roadmap of Microsoft but I do not have the timelines as of now uh yeah there is one more question from my chroma so yes so the question is does synapse allows pulling data from on-prem SQL database the answer is yes uh so in signifs uh you know we have gone through the process of creating link service so in link service creation we have two options we can use Auto result integration runtime or we can also create Self Service cell Auto result or self-service integrated runtime so if we use this feature then we can also get the data from on-prem SQL database by creating the self-hosted indication and tabling service um yeah I think I don't see any further questions so over to you Jason and William great uh Sega uh thank you very much um uh very informative talk uh look deep dived in a few topics that I'd only uh superficially learned about so so appreciate that uh the um the YouTube video will usually show up about a day later on um and I'll post in here the coordinates of that it's basically youtube.com slash um Boston azure and um I guess that that that's uh that's a wrap and uh keep an eye on the usual spaces for more events uh we have a couple more coming um actually Veronica did you want to say anything about the the next couple before we uh kick people out yeah I mentioned in the beginning that um we uh we are currently blind to events in February um I am creating them right now in Meetup so one is going to be on the 7th and another is going to be on the 28th um so definitely check on our Meetup Pages for both past Boston Azure and Norway Boston azure and then we'll also post all the information um in our tweeters okay thanks again uh and thanks again everybody for joining uh including um from Nigeria and a bunch of locals and uh thank you for the uh long distance call in uh have a good evening and a good day everybody bye "
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Hasan Savran: How does Azure Cosmos DB work under the hood?. This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog. rather than you know how i will try to explain the why question here for most of the topics that i'm gonna actually cover today so i'm gonna start with the history and we are gonna go from there like i'm gonna try to give you an example of a kind of like a fake company i created how to use the cosmos db and what they need to kind of pay attention to and if you have any questions please like you can ask me probably at the end of the session and i will answer any of the questions uh before i go in the presentation let me talk about myself uh i'm from cleveland ohio right now i'm working as a business intelligence manager at progressive insurance and currently i'm microsoft data platform mvp this is my second year and i'm very happy and honored i've been doing web development 15 years in almost eight years i'm doing the business intelligence on top of that uh so if you will have any questions you can ask me now or if you can you know if you come up with a question later you can follow me on the linkedin or twitter i'm pretty active out there and i can answer any of your questions from there too uh i have a blog i write about cosmos tv i'm not not there but rather than cosmos db i should still share like front-end c-sharp and sql server so whatever i know really i like to share in my blog check it out you might find something that you like so that's me and let's actually start the presentation as i say before i'm gonna start with the history like for most of the beginner levels so in 2010 microsoft came with this project named project florence the main reason they came up with this project because they needed as nosql database internally to share data uh for their products if you think about it in microsoft there's huge products for example there's xbox there's office uh there's all kind of like ltp applications and there are users in all over the world so they kind of need to share the data and unfortunately you know they cannot use the schema because depending on what they are sharing they needed a nosql database so sql server was not going to cut that in 2010 they started a new project and in five years actually they had a great product and in 2015 they were agree on say that you know okay this product is stable let's share with public and let's make money on it right so in 2015 they actually published this new uh server and they call it android document team this was the server for developers to store json documents on cloud and retrieve the data from this server they had to use a language very close to t sql so many people already know the tc cool so people like it and people start to use it a lot microsoft didn't stop in 2015 they continued developing this and cosmos cv you know became really the backbone of the azure most of the products are using the cosmos tv so in 2017 they came up with many new features and i guess the biggest change was the name they changed the name from documentdb to cosmos city also they introduced like global distribution multi-model and many features in 2017 but after 2017 every year they are actually you know [Music] giving us like more features every year so 2020 came corona came in the same time and slot cosmos db did not stop and in this year actual day last year uh they gave us the serverless and rsca options in 2021 let's see what they're going to come up with i'm curious the microsoft uh conferences are coming up so let's see hopefully you will see something exciting from the cosmos tv so the first question i get from many people is like who is using this product or in what situation i should pick cosmos tv rather than sql server so i kind of categorize those two three categories the first one is the entertainment like the game so in all days you know when i got a game right what used to come up in a cd you put in cd you install it you are done with it right you pay like 30 40 and you have you own the product and you will play until it ends but now the games are different you pay all the all this money 50 60 on top of that you start to play the game if it's a racing car for example uh they might try to sell you a car in the game or they might try to sell you parts so your car will go faster you know whatever so they still try to have those transactions going on they still try to get money from and you need some kind of system to do that in the games and now user can be in anywhere in the world so it's"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:05:06",
        "seconds": 306,
        "text": "you know whatever so they still try to have those transactions going on they still try to get money from and you need some kind of system to do that in the games and now user can be in anywhere in the world so it's like a global database cosmos tv fits for that perfect uh if they don't sell anything they might have those you know all of the games are right now you know online people place online and you kind of need to give like who's the top 10 players who are the players you're playing with so you kind of mean that data has to come from some kind of database so cosmos tb really fits for that perfectly the second one is the retail services so whenever you try to sell something well your database is very important because the usual database of the bottleneck and when the special days comes up like black friday you might be you know selling thousand items per day and black friday comes up you might need to sell ten thousand or hundred thousand items your uh application needs to be able to serve them and users your servers their database servers needs to be able to you know handle that so cosmos db is great with that because it's very easy to scale up and scale down because after the black friday you might need to go back where you were so uh if you're trying to do you know selling anything online cosmos it is great for them one is iot devices and iot devices are all over the world and they are probably responsible of the big data right because they are creating data every second they are sensing something and they're just sharing it so usually they don't have skimming because depending what kind sensor is coming from you know you're not gonna have one scheme for it so they need a no sql database in the meantime they can be really in remote locations and they just constantly sense the data so you need like a not just a database but you need a platform which you are going to actually get this data then you are going to save it somewhere and also you want to analyze this data so are you actually making surprise stands for iot solutions so cosmos db is used in iot devices they want to uh three questions i get about cosmos tv why do we need another database don't we have enough databases out there do we really need another database that's a valid question and i'll kind of give you an answer for that is we kind of need to figure out you know what is really happening in technology so in 2000 i believe 17 ibm came up with this kind of research and they find out that in two years before you know 2017 so 2015 2016 we managed to generate 90 of data on the earth in two years that's a crazy number of uh you know uh data so we need to store this data somewhere and for example the numbers you see in the right side here those are the numbers what happens on internet per day so look at for example the twitter so 500 million tweets how many of you actually think that twitter uses sql server for them that's that's not going to happen so we need another type of database here and microsoft did not have a nosql database before so they needed to come up with the you know a product like cosmos tv and everything's going to azure it's going to be a cloud friendly so that's the main reason we have cosmos tv here also our users change right so now in older days we don't have damage well our users are creating all kind of data so that's funny but actually that's the reality that that picture so uh we have a lot of data most of them might be useless but we still need to analyze this data and we still need to store this data somewhere so that's another reason that we need another kind of database system which can handle all these things also we have different device types so you might have one application but that application has to run in tablets it has to run on the cell phones it has around the desktops and depending what type of uh you know device that that is your application might kind of you know i guess change a little bit for example it is going to work in cell phone and a gps chip on it so you might need to actually start to generate more data because you know you have the gps and you might want to track what's really happening or drive the user's home and also customers are expecting more because you know in older days we used to have like an enterprise you go to your company you used to have like this great kind of grit it kind of tells you what to do it was kind of boring right but now if you think about all of the customers all of the users are used to all these shiny applications because everybody is faced with it and everybody has a twitter account and when they go to work they end up with this great kind of grit and it's kind of boring so people are actually expecting more now uh also the applications because of that applications are consuming more data and they are trying to do more stuff for users and they generate more data"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:10:08",
        "seconds": 608,
        "text": "this great kind of grit and it's kind of boring so people are actually expecting more now uh also the applications because of that applications are consuming more data and they are trying to do more stuff for users and they generate more data than before uh also the globalization is yep so if you're a developer and if you solve a common problem and you kind of go and you know share this application in one of the stores in amazon store microsoft store wherever next day when you wake up you might end up with users from all over the world right which is great but i'm you know hopefully you pick a right database for your data so you know that your application can handle all these users so globalization can happen in anybody so you need a database which can actually handle all those things so what i'm going to actually show you here is uh let's talk about like a i will give you like a business example and this page here actually this used to be from the azure i'm sure they have more data centers now each dots here you see is a data center and really if you think about that whenever you try to create another any kind of azure feature this is the first page you come up with right you want to kind of pick the location where is this application or feature is gonna actually stay so let's say uh we are in we work in a company and we build cars right and we are located let's say we are located in europe somewhere central europe so we are we have a great competition going on because all of the other companies you know they are creating all these smart cars they are creating all this the cars can drive themselves now and you can send messages and receive messages to cars so that's what stuff going on and we start to feel kind of uh i guess nervous we say okay let's jump in that ship and let's maybe pour one on our model let's make it you know a smart car all we want is we want to put some iot devices in it so we can receive and send messages to the car and give a user i guess our customer a better kind of environment but that's the idea so we hire the dev team and we talk about the dev team and they figure out very easily that we are going to need the nosql database here because we are dealing with kind of big data and our customers are all over the places so they say okay with no sql database for this and they say well you know what let's get cosmos dbhs so they go and actually create the account and when you actually create the account first time in cosmos db it's going to ask you one big question and that question is which api are you going to use are they going to use sql api api grammar api so when you're in that area you should already know what you are trying to create but in our case this is a whole new application for the whole new application microsoft and i will suggest you to pick cpypn the main reason for that is sql api's most advanced cosmos tv is apm because microsoft is in charge of it and then the one who is actually adding features into it so if you're going to need something in feature you might have chance to go to microsoft enhanced form if you're gonna pick something else uh microsoft might not be in charge for example mongodb right so if you're gonna ask for something you have to go to mongodb not the microsoft so i will suggest you to pick sql apn if this is a new project we are starting from scratch as soon as we create the database we are going to end up with 99.99 sla with only one location and with one database that's that's a great number uh so from that point our dev team start to kind of you know investigate and try to figure out okay where is our customers where are they selling this product first so they find out that most of the products we are selling is in the united states um in europe and some in asia so those are the three places that we are going to have a lot of customers they are going to try to read and write data now you might feel a little bit nervous in here because first of all we don't want users from the united states right uh towards data to europe it's just like there's a big you know kind of like that leg over there and same with the asia whenever you try to read and write that's that's not going to work uh we check the cosmos tb actually cosmos tv gives you a global distribution which means that i can actually pick other data centers close to my users and the users in united states if they are investigating west side my sdk will actually sense that i have a data center right here and i will use this one to write and read the data so the team decided to say okay we are going to have four uh database and we're going to put them into"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:15:14",
        "seconds": 914,
        "text": "i have a data center right here and i will use this one to write and read the data so the team decided to say okay we are going to have four uh database and we're going to put them into this uh east data east uh data center let's data center the united states we already have one in europe and we are going to put one in asia so depending where the users are they can actually access wherever it's closest to them so that's great and at the end what's going to happen here is uh whenever you write the data from united states in cosmos db is in charge to sync this data to each data center so each data center will have the same data as soon as we actually pick these items here pick the data centers and click update it really depends how much data you have in that case but usually if you have like less than one terabyte probably in 30 minutes all of the data centers will be online and it will be good to go and as when everything comes becomes online our sla is going to get better too so our sla is going to get 99.999 so almost hundred percent there so which is great so what has to be 11 uh cosmos cds cosmos db is not like sql server right in older days in sql server you get a dvd you put on the cd drive and you click the next five and gonna so many times and you you are you know you customize the sql server you know exactly when the files are you you can do everything that's that's not the in cognos what do we know in cosmos db first we know in whenever you actually try to save the data the data is getting saved local ssd drives so we know that it's fast also what else we know is the file is getting saved in physical partition so in each physical partition depending how many i guess how much data you have you're going to have x amount of physical partition the first thing you need to know about physical partition you have absolutely no rights to change any dividends so microsoft manages it under a person so if you try to go a little bit deeper in this physical partition each physical partition has a replica set in it and that kind of i guess the picture tells you why cosmos tv is very fast because in the application right and if you are trying to get the data from from one partition you have four locations you can hit and get your data depending on what consoles is the level you pick so that picture actually tells you like why cosmos it is pretty fast so this one there are two other things that you need to know about the physical partition before they move on and those two numbers that you need to know is first one is 50 gig which means this one physical partition can store up to 50 gig uh data if you have more than that you're going to end up with another physical partition so that controls the number of partitions and because the cosmos db will not wait until the 50 gig i will say probably 70 or 75 percent when it's get falled will get it will start to create the second partition and what's going to happen here is you're going to have one full physical partition the second one is going to be empty so cars must be in the back end is going to try to balance and move some uh you know data from the first one to the second one so everything will be balanced the other number you need to know is 10 000 request units request units is the currency of cosmos needy so that's how you actually pay and you actually set that up when you are setting up the cosmos tv database so 10 000 requests units is the limit of a physical partition so for any reason if you need more than 10 000 let's say you are going to need 12 000 requests for your application even you don't have 50 gig in this physical partition you will still end up with two physical partitions because one physical partition can handle up to 10 000 request units so those two numbers are important also other thing important as you can see in here it says without global distribution so this model actually fits if you don't have any kind of global distribution if you have in our case we have the model changes a little bit in here for example in our case we have europe united states and asia right so as you can see what change here is one of the followers in each uh replica set becomes a forwarder that's how actually cosmos db i guess syncs the data in the back end so the data actually comes in to the leader leader shares all the data to the followers then when forwarder actually gets the data it shares whatever is you"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:20:15",
        "seconds": 1215,
        "text": "that's how actually cosmos db i guess syncs the data in the back end so the data actually comes in to the leader leader shares all the data to the followers then when forwarder actually gets the data it shares whatever is you know change or insert it and with other leaders in other other data centers so that's how actually cosmos db syncs the data in the back end so this is usually the moment i get the question like what actually the conflict happens conflict happens in any sequel any uh databases so you might have an insert replace or delete conflicts so it may be the user from asia and united states is trying to write the same data in the same time right which one cosmos dbe is how cosmos city is going to handle that when that happens a referee comes up from nowhere and says that well we have a problem here if you don't change anything what's going to happen is the last right wins rule is going to go and get the latest data and whoever write the same data last time we'll win it and we'll just ignore the other one that really doesn't work for many businesses right many businesses has this complex logic and whenever you try to if you have the two data coming from the same place you want to be sure that you are picking the right one so if that is the case for you you can go to the custom option how custom option actually works is you write your own store procedure which you write put all your business logic in it so you can kind of check every kind of node of the json document and make a decision in some way and then you are going to actually register that stored procedure uh as a merge and so procedure so what's going to happen here is when a conflict happens that conflict is going to go in a queue and from that queue the surplus here is going to pick and run them each time and it's going to solve and figure out which one is going to be the which data we are going to trust which one we are going to draw so you're going to be in full control of that with the store procedure next one i'm going to cover here is the storage uh engines we used to have only one storage engine in cosmos tv which was the transactional storage so it doesn't matter which api you use whenever you you know throw some data to cosmos db that was going to go to the transactional uh storage and that was a raw store transaction storage when i say raw store as you can see in this picture here we are saving the data raw bible so this works great for web applications right usual web applications you don't try to analyze the data that much you have like an id you search by id you show only one page so you don't try to get like a huge amount of data and try to analyze it so that works for every application is good but when you try to analyze the data or you try to write a report depend using your cosmos db database then the things getting a little bit kind of i guess expensive let's say like that because databases in raw store everything is you know saved by row by row and this can get really kind of expensive if you are trying to analyze the data trying to you know write reports for the power bi to get the expense so cosmos db came up i think it was last year the new storage system name analytical storage and this is by default it's not in it so you have to enable that if you want to use that what happens here is all of the analytical storage is actually getting saved as a column store which means that as you can see we are actually saving column by column this makes the aggregation much faster because everything is you know save right in the same location it's much easier to figure out you get the average summer you know some or minimum maximum is much easier to find so it gets much faster also the getting data from analytical storage is cheaper than getting from raw store so it's much better if you're analyzing data it is coming from the analytical storage so if we try to kind of look at this analytical storage a little bit the best thing about analytical storage i don't know about you but i have a lot of sql servers right now in my environment and we have oltp and we have reporting right and we are in charge of moving data from ltp reporting and usually we do we use ssis for it ssis can be really in pain they can fail for no reason you know it really doesn't matter how good call how good your code is because of network it might fail because the database might not be there it failed you know it's just not stable and in this case cosmos db is responsible to move my data from transactional storage to analytical storage so i don't need to do any kind of etl here and cosmos tv really depends how much data you"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:25:18",
        "seconds": 1518,
        "text": "it's just not stable and in this case cosmos db is responsible to move my data from transactional storage to analytical storage so i don't need to do any kind of etl here and cosmos tv really depends how much data you have they kind of guarantee to the data will be analytical storage in two to five minutes i mean my experience if my day-to-day is small i would say in 30 seconds probably it's there i think they're just trying to be safe out there by just saying two and five minutes but uh that's just itself it's great i like to write an exercise packages my data is there it's almost like real time i can actually analyze my data and report my data easily uh just like the oltp uh analytical storage is globally distributed and that gives us a great you know isolate isolation between the oltp and all the gland and as you can see the prices here you can kind of i guess it really depends how much data you have and how much data you're going to analyze but it's much cheaper than try to analyze this data in oltp database for sure now if you compare this to in transactional storage we have logical partition we just cover the physical partition i'm going to cover the logical partition a little bit but for each logical partition there is a limits which is 20k in analytical storage you don't need to worry about that the apis is getting you know write their data still the transactional storage and if you want to read the data from the analytical storage you need to use the snips analytics default time to leave property is very useful in cosmos tv and it's more mostly for retention or caching the data so if your business is going to say that you know what i don't really care about this data after two years you can come here and say that default time to leave is two years and after two years calmness tv will be responsible to remove that data from your database for free that works with analytical storage you can't say that okay this data is going to go away two years for the analytical storage i want to keep this data five years and then you can do that but i just want you know passing the fun appears to column store turned into life so those are great functions for caching or retention portion now if you look at the cosmos db like on a paper so what do we have here is first speaker in the database of cosmos each database is going to have one api and those are going to be in containers so that's kind of the first question you need to answer and your options are sql api in mongodb cassandra and table api so each container it doesn't matter which one you're going to pick here and then we are going to have and store procedures user defined functions these two the first thing you need to know is those are in javascript so you have to know javascript to be able to uh create stored procedure or use your defined functions also the biggest difference between the stored procedures and user defined functions is stored procedures runs only on the leader in that graphic asset what that means is leader is always busy getting the new data updating data deleting data so and also it crosses surplus users that means that if you are trying to create your procedure to get data that is not really a good idea because leader is already busy and we have all those followers right followers you should try to get the data from there rather than leader so store procedures are good if you are inserting updating or deleting data well you cannot delete that one you cannot update the data and user defined functions actually can work in any way so if you are using like the uh if you are trying to get the data then i will go with the user different functions now the next one is triggers and then triggers um we have two type of triggers in cosmos tv one is a pre and then second one is post and if your campaign triggers a sql server the biggest difference is in sql server triggers getting fired automatically and in cosmos tv you have to do that manually from the sdk merge procedures and conflicts those are that i just covered whenever there's a problem with the conflicts you have the surplus video you register as a merge procedure and you kind of handle the conflicts like that also in the rather right side we have items so the items the wallet items here because it's not the name kind of depends on what api you pick so if you pick the for example sql api you're gonna call your data documents if you pick the gremlin it's going to be nodes and edges and table api has roles so those changes you could you will see mostly in the rest api if you are using it you the url is going to change and"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:30:22",
        "seconds": 1822,
        "text": "you pick the gremlin it's going to be nodes and edges and table api has roles so those changes you could you will see mostly in the rest api if you are using it you the url is going to change and the name is going to change like that all right so this slide actually shows you we have some system defined properties so those properties exist for every data in cosmos tv and the first one is underscore rid this is the unique record id uh the second one is etec i'm just going to pass that for now because the next slide is going to actually show you what that is mostly is optimistic concurrency control underscore ts this pretty important one just shows you the last time the data is updated for that item under self is addressable url if you're using especially the rest api if you just take that self you kind of have a pinpoint where this data is and you can get and update data by the rest api id is the only one you have kind of writes to i guess override it if you like and for example if you have a container named orders and you want to make the id order id you have the chance whenever you are trying the container you can say that id will be overwritten by order id so in the bottom here you can see the examples for example and the example i'm going to show you here for example let's say the self for example as you can see dbs here is containing it's telling what the database is this is the database id and this is the collections this is the collections record id this is the documents and this is the documents record id as you can see this number or this text matches record id perfectly so this almost pinpoints the status itself as i said before the i'm gonna cover the e-tec right now e-tec is mostly for optimistic uh concurrency so if i get uh let's put the optimistic concurrency definition here but if i try to explain that i guess in a little bit uh let's say for example in sql server right so we have the table and let's say we have two users and they are going to try to maybe update the same data and they have no idea that they are trying to update the same data let's say we have some maybe i can update the uh credit cards limit of a user right so two people open the same persons and they are looking at the same data so let's say user1 updates it first and user two has no idea because they open the same time user two doesn't know what has changed so user two clicks the updates and what's gonna happen in that situation so it really depends on the dev how they program the application because database has nothing to do with it in sql server usually what dance do in that cases like that is usual tables has like updated dates or updated by kind of columns so what devs does is they get the update date and they take it to a front end and they hide it under that form people see and when they click the submit they still have that date and they post it back to sql server and before they actually update the data they kind of compare update date if the updated matches perfectly then that means the data doesn't you know change and we can go safely change it if update is going to be larger than what we have then that means somebody else you know already updated we might need to go back to user and say that's well we have an issue here please get the data and check it out again so as i said before all that logic happens in kind of like in the middle where the devs are responsible for it sql server has nothing to do with it it actually can do all that logic itself and it's using the e-tag for that what does e-tank actually if i draw back here as you can see e-tech is kind of like a almost like a guid data right so what's really happening here is you it supports uh three operations and you are kind of giving a condition you are if you're going to use the for example if match then matt this works only if you need to update data or delete data and you're going to pass the e-tech if e-tec is actually matching perfectly cosmos leader will accept that data and you will you'll have a success message if the e-tag is not going to match then that means somebody else changes data and then cosmos db will be the one which is going to actually throw them to the user and i think that error code is 412 http code 412. and that's if match is the most common uh if not match and it modifies since they are still there and i don't i didn't see that many people use them that much and if i try to"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:35:24",
        "seconds": 2124,
        "text": "is 412 http code 412. and that's if match is the most common uh if not match and it modifies since they are still there and i don't i didn't see that many people use them that much and if i try to explain what that is if not match is usually for getting the data and this is mostly for especially browsers that a lot not for cosmos db but if the data doesn't change browser doesn't want to go to the server and get the same data again again right so in that case uh we are using if not match and if it's not matching we don't go to cosmos tv to get the data it's cached we can get it from there and if modify since is from the get and you actually pass the date here and if it's not you know modified since then you get a date and that works like that all right next one which i don't really have that much information here because it's just also itself many companies you know might be looking for compliance if you're in the united states we might be looking for hipaa pci as you can see there's a compliance list of cosmos tv here so this might this is just for the reference let's look at partitioning partitioning is pretty important in cosmos db and probably is the first curve you're going to take in this list hopefully you're going to take it nice because really your position might depend on how you how well you take this curve a lot of things can go wrong with partitioning and you can really need to understand and why it's important uh the most questions i get when i started talk partitioning they is one of them is oh does it like it works like primary plc also isn't it not really primary key in sql server you know it just makes the row unique so you won't have the same primary key again again and on the one of the adventures it has it puts a index on it so really cosmos db's partitioning doesn't work like that how about the table partitioning if you compare the sql server similar but still we have kind of i guess in table partitioning you know you take or wait your data to get really large then you start the partition cosmos db is not like that you have to write the partition id before you have any data so what can go wrong in this if you pick the wrong partition as i said before we are going to talk about the logical partitions and logical partitions has 20 gig limit if you pick the wrong primary in the if you don't pick the wrong partition id you might exceed 20 gig logical partition and that means you have to re-partition now bad news for you is you cannot repartition cosmos db containers you have to recreate the container and move your data with the you know knee partition id so that's gonna cost you uh you might have hot partitions you might you know like maybe one of your partition is has 500 items maybe other partition has i don't know 500 000 items so that's going to create a lot of traffic problems and it's going to be costly for your application if you try to explain the partitioning in cosmos db is organizing data better so you can find what you are looking for easy for example look at this cache here which migrates about like that and you don't have to really live in this house to know that if i'm gonna ask you can you go get me the screwdriver you know exactly where screwdriver is so it's gonna take you i'm not gonna think that much you're gonna you're not gonna waste that much money you know time to find what you're looking for here same with this cost if somebody's going to ask you go get me do i don't know red shoes or the giant white jacket you know exactly where they are and you don't even wave this here it's right front of you it's organized now and it's not going to take the question i guess that's one of the best examples i used to work in a customer service long long time ago in a computer service and i used to work in the third party shift and sometimes i used to get those calls from the technical services they are saying like oh can you find me this computer x in the data center and reset it i cannot log in my data center wasn't landed and you know resetting the bottom i can do that in five seconds if i can find that computer and it's gonna take a lot of you know i'm gonna waste my time type it sometimes it took five ten maybe 20 minutes to find the computer to actually press that button so i guess what i'm trying to explain here is we don't really think about this damage when it comes to data how about you know organizing the data in databases if you think about the sql server usually what happens is you know dev creates the table we are lucky if it has primary equipment and then you know they start to push data in it and from there you know maybe works"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:40:28",
        "seconds": 2428,
        "text": "if you think about the sql server usually what happens is you know dev creates the table we are lucky if it has primary equipment and then you know they start to push data in it and from there you know maybe works three four months every four months everything works fine then you know we might get a call the dba gets the call and say that you know what this application starts to kind of slow down what's happening vba goes and looks as it looks at the table and figures out that there's no indexes on it so he put some indexes on then you know maybe we are good for under two or three years then our devs comes back to the dba it says that you know what this thing is getting slow again what's happening vba looks at it it looks like we have a lot of data so he says okay you know it's time to actually create partitions then usually that is the workflow in sql server the cosmos db is the whole this other side so you have to actually create the partitions in the beginning not when you need it in the last second uh to do that you kind of need to know your data you need to know like your real classes how you can actually search with data so you can actually pick the rate partitioning also you kind of need to check out if your application is going to be a right heavy application or re-heavy application uh for example if you have an iot application right your devices really doesn't read any data it's always going to push data so it's much better for you if you actually create a really unique uh partition id maybe the id of the you know iot device or maybe you might need to actually go even unique than that because that's going to make the transactions much faster but it is read heavy then that means that partition id that you are going to create you kind of need to know partition id to actually read that data because if you have the partition id things are going to get much faster also things are going to get much cheaper so those two things are important and the other thing you know about the partition is partition id will be hashed and cognitive that makes the distributor requests that distributes the storage and is intelligently root the queries for efficiency so it's pretty important to pick the right partition now if you go back and look at our example this was our example here right so we were actually i was showing the physical partitions with lego blocks and here looks like via two in each data center now i want to change technology a little bit so rather than using the lego blocks we can actually say that each lego block is a physical partition and they are like a container ship this has really nothing to do with the container uh technology it's just i'm just talking literally a container ship when you create a database in cosmos tv cosmos db gives you one empty um container and that is your physical partition you it's your responsibility to actually organize your data and both in this ship so in you here you can see each container is gonna have the partition id so in our case we are really carrying cars so if it comes to the partition id probably what i'm gonna pick here for the car is gonna be the big id because that's gonna be the unique id for each car and that means that each container here is gonna have one car in them i can't store any kind of information about the car all the messages maybe all the alerts all the warnings as soon as i know which container it is and it should go open it and my data will be in it so if you are going to try to do maybe pick a rock partition in this case what might happen is you're going to say rather than you know picking a mean number maybe you're going to say that you know what i'm going to organize my data by bottle number then that means you know you are going to have one huge container here when you open that container there's going to be all the cars in it so that means that it's going to take much longer for cosmo cv to find what needs to get updated what needs to get retrieved and that means more cpu more memory more io and more money so that's why you kind of need to pick the right partition id so your solution will be first of all rather than you know fast and other stuff it's important to be you know cheaper affordable that's one of the you know main problem most of the people picking the wrong partition id and they said that cosmos db is expensive cosmos db will be expensive if you pick the wrong partition for sure so if we give you another example which i say that you know those uh e-commerce websites let's say we have a market marketing and we are selling all kinds so if you think about that model what do we"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:45:33",
        "seconds": 2733,
        "text": "the wrong partition for sure so if we give you another example which i say that you know those uh e-commerce websites let's say we have a market marketing and we are selling all kinds so if you think about that model what do we have here is we are going to have users each users are going to have their orders we are going to have tables about probably the reviews and of course we are going to have shopping carts so in here you are really seeing one two three four kind of data models we need to make this thing work and if you think about the partition id we are going to have a lot of candidates here right so for users you might have picked the user id or the location of the user as a computation orders you have some products we have some options so how do you pick them the best i guess idea i can give you here is this is don't think like sql so because if you think about the sql server probably you're going to have this three programs or three databases i mean the three tables and you're gonna kind of join them by product id user id but in cosmos it is not going to be like that so first of all in cosmos if you cannot join container to container if you think about for example amazon right so when you go to the amazon first time the page opens and in the main page is kind of useless it just shows what's really happening in the website you kind of need to pick the category first so if you are looking for for example books you might need to pick the books and it's going to show you more categories under that if your database is cosmos tv well that's going to be a challenge for you because for example if we have the products and you're going to pick the product id as your [Music] partition midi well by picking the category it's really not going to help you to you know show which products you should select in the next page in cases like that it makes sense to actually multiply your data rather than you know putting everything in one container so you might have actually two containers one name products and you actually get the partition id by product id and you might have another one and you can call that i don't know product categories and that one will be the partition id can be product category led and you can have all the products of that so many people won't like that because then you can have product information in two places if you need to change the product for example name or the price then you have to go this two places to change it so they will kind of match together that is kind of like a no normal in a relational database cosmos tv that's almost that's what you need to do if you want to keep this affordable because you there's nothing wrong with actually putting them in two places cosmos db has tools to actually sync them if you need to so you will have a product categories my user goes and picks a category uh it's category id is my partition id so it's very cheap for me to actually go and get all the products under that and also i don't need all the products the product information i need the product name maybe the price maybe the picture of the url that's all i need i don't need all the description of that anyway so then you know my user picks the category i list the products very easily and cheap then my user is going to pick the product now i have the product id then i can actually go and look at the main table with the products and i will search by product id and get all the information i need on for example in amazon you have the picture description reviews all kind of stuff so you can get and pull it from there so the way that you are going to actually organize data in cosmos cp is much different than relational database the next i'm going to cover here is with the partition id is iot so as i say for in iot we have sensors and they are the one which is pushing data so in many cases you might not have good candidates for partition id uh for example let's look at here we have the knight rider here and believe it or not iot devices people actually think about it in 70s and 80s the problem was technology wasn't out there to actually make it happen but anyway so in nitride actually we have some iot devices out there as you can see so the problem here is let's say one of those vlt devices is actually sensing the maybe temperature of the engine and it's just sending to you know the database well maybe it does every 20 seconds every 30 seconds and usually that's kind of kind of the same data and this iot device might not have that much information what is it going to have is probably you know the temperature as a number and maybe the device id that might be it you know there's not that much out there and in cases like that you might need to actually create synthetic keys and synthetic keys are this for example let's say my device id"
    },
    {
        "speaker": "",
        "title": "Hasan Savran: How does Azure Cosmos DB work under the hood?",
        "videoId": "WdX3pikoLsc",
        "description": "This is a recording of the February 23, 2021 virtual meeting.How does Azure Cosmos DB work under the hood?To master any technology, you need to understand the foundation of how it works on the back-end first. In this session; We will explore Azure Cosmos DB's infrastructure. I will explain to you how Azure Cosmos DB works and handles data in the back-end. We will cover the basics and some of the most misunderstood features of Azure Cosmos DB.Learning new technologies makes you a better leader and collaborator. Join me to learn more about this new Cloud Database technology.Hasan Savran is Microsoft Data Platform MVP and Microsoft Certified Solutions Developer. He works at Progressive Insurance as a Business Intelligence Manager. He spends his days architecting cutting edge business solutions by using the latest Web and Database technologies.Hasan has spoken at many SQL Saturdays, Code Camps and User groups. He is an active member of the HTML5 and WebAssembly W3C groups. He likes to write about SQL, CosmosDB, C#, and Front End development on his blog",
        "start": "00:50:37",
        "seconds": 3037,
        "text": "maybe the device id that might be it you know there's not that much out there and in cases like that you might need to actually create synthetic keys and synthetic keys are this for example let's say my device id is nitrogen and what else i know about this rather than the all the sensing you know sensor numbers is maybe the date so what i can do here is yeah i cannot just pick the for example you because that means all the cars from 1985 is gonna write to the same partition that's not gonna work and that's gonna create uh you know hot partitions in 1985 i might have 20 devices in 1986 i might end up with maybe thousands so it's like it's not going to work but what we can do is we can try to maybe combine what we have and make actually a synthetic key in our case what we can do is okay we had a night rider we had 1985 so you know then we can kind of combine them and create a synthetic key if we want to make it more unique if we have a lot of devices we can do that what we can do here is then okay we need to use the same thing we had the device id we had the year and our sdk maybe generates a random number from 0 to 200 each time it tries to write that will make this thing really fast because it's going to be really unique but the problem is if you are going to try to read this data you are going to have a lot of problem because there is no way you are going to be able to guess this number that's a random number but if you are worrying about only a right heavy application this might be to go another idea you can do here is you can just hash for example in here we have the win number if you hash this view number i should be able to create that hash if i try to read it again so that's another kind of option you can use all right i think that's all i have for you today and i hope everybody learned something new today and as i said before you know i can answer any of your questions now you can just uh let me know if you have any questions later from any of those uh platforms thank you i hope everybody enjoyed awesome thanks um there were a few questions that were asked along the way okay i think you covered most of them but uh i mean let me scroll back a little bit and uh we we have a few members of the group that um also managed to attempt to answer it so let's um have uh you at least address them here so um first one is is cosmos db storing only transactional data like in most sql server cases or can it store objects like documents and emails in there as well yeah you can you can do the documents uh but i mean depends on the size you can save them as uh so i'm not sure what you mean by the difference but for example i put the stack overflow in my cosmos db so each post is an html you know it can get really huge so i save it like that and it can't do that yeah so the follow-up to that was um i'm not saying made to that about the documents but also the original documents also what what is the index search platform behind it is it flavor of elasticsearch or or something else i think you got into the index in a bit so yeah you can check my blog about uh indexing more but uh there's like uh three type of indexes there so there's one for numbers there's one for shrink and there's one for the geospatial data but that kind of depends what api you're used to so mostly and family with the sql api but mongodb can have this kind of all things yeah actually i don't know what i'm thinking um uh the person that asked that robert if you're if you have a mic you can come off a mute and see if we got all your questions answered yes hi thank you very much um i think bob has answered some of them along the way and also um hassan you you said that the database itself can store those documents or emails one question maybe that i may have is what would be the maximum size or would there be a performance issue if the documents were larger what do you think the recommended or expected largest size would be to store in the cosmos db directly yeah i mean it's not really the top of my head plus the maximum but i think that kind of works the same way with the sql server you know for example if you are trying to save the image you don't want to put the image in the you know database you want to put the image somewhere else and put the url in the database so i think that kind of applies to cosmos db2 and i wouldn't recommend to put like very large objects in cosmos tv for sure thank you were there any uh anybody else have any questions feel free to come off you yeah i've got one this is uh jim o'neill um i noticed you started out with the you know the sql variant or the sql sort of interface on top of cosmos one of my major kind of questions is when do you make the decision point whether to just stick with a sql database or to use um cosmos if for instance it is really schematized data that you're working with would you ever use cosmos if you just had schematized data so i guess in that case i will say really your environment because most of the devs pick cosmos db because sometimes they don't want to deal with dbas unfortunately okay you know if you want like a you know very fast development if you pick the cosmos tv you don't need to worry about the dbas you know they try to figure out what you are doing in other stuff so if you want like you know fast development cut they pick cosmos tv even you should pick the sql server have you had any issues with with the sql server interface in terms of compatibility with you know what you might have with sql with sql server proper like certain constructs don't work or aggregates or things like that i mean it really depends the size of your data too so sql server can actually you know store nosql data you know it supports json documents so you can store the json in sql server right so if you have an on-prem sql server and if you don't have that much data you really can store the json document in sql server and you can actually retrieve that data from sql server too as long as you know you don't you are not trying to create an iot device you know it's a huge big data in it i have good experience with it but the problem is you know most of the dbas do not like json in sql server so you kind of need to deal with that and also you know your in memory tables you can kind of do all kind of stuff in sql server really fast close to what cosmos db is trying to do here so but as i said before you know then you really need to deal with you know dbas and give them good i guess reason why you want to do this okay thank you yeah anyone else awesome well thanks thanks very much for the presentation definitely so i i've been learning uh cosmos a bit because i'm studying for the um the developer exam the azure developer exam i haven't personally used it and it's it's such an interesting database so thanks again for presenting um just another reminder for anyone out there who is a presenter um please contact us if you want to present anytime and i will be sure to get you on the roster and thanks everyone for joining yeah thank you hassan if you could hold on for a second sure let me stop the recording here "
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions. This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.. and i just started the recording and uh definitely dan thank you very much for presenting tonight um with these two user groups um the boston one and north boston azure dan used to attend mine all the time and he would attend bills um often but he was usually mine he was one of the regulars back when we met in person and he was always uh uh helping with global azure boot camp and i just remember he did a couple of vm talks at the azure boot camp that uh it was just spilling over they were so so popular so dan's definitely one of the presenters that we've had at the group several times uh often with infrastructure related stuff like this evening but you know dan knows a lot more than just infrastructure talk so definitely uh thanks for speaking tonight dan i'll let you take it over from here my pleasure and so i'm going to try to stream this through um through the camera so uh you should be able to um i believe when i talk it should just automatically be center stage is that the is everybody able to see that i see the picture of the uh room in burlington i think yep all right so i'll give it a try we'll see what happens um so again welcome to the uh combined boston north boston is our user group it's always an honor and a pleasure to be here i can't wait till we can meet in person again i really enjoyed that uh my name is dan colon i also with uh udai i help him out at the new hampshire cloud user group and next week i'll be presenting on uh azure centennial and uh the name doesn't really reflect exactly what actual centennial is because i'm limited to 80 characters but basically it's a security information event management and security orchestration automated response solution basically you have security events that you can automatically respond to and that's basically azure centennial uh so phil welcome to uh join me you die next week april 20th we're going to cap it at 10 000 people so you know sign up quickly and today we're going to cover arc enabling management of hybrid and multi-cloud k8 s solutions so let's uh jump into the agenda and we'll first go over azure arc what is it um how does it allow us to manage uh infrastructure in a multi-cloud on-prem environment then we'll look at registering or onboarding a kubernetes cluster into his rr in fact that's the specific area we'll be focusing on today we'll move to get ops which is a framework for automating continuous deployment and uh decorative infrastructure using get as a single source of truth so basically you can submit a change to your get repository and then have it automatically deployed into kubernetes so really cool with policies you'll be able to enforce organizational standards and assess compliance such as uh one thing i've always used it for is i enforce every resource must have a tag with an owner applied to it so if i come to something like well who who's running this i don't want to delete anything on anybody so i find that very useful and last but not least we'll look at my monitoring where you can have alert and notifications um based on uh kubernetes uh telemetre metrics so is there arc well we command it's a management tool and allows you to uh do on-prem and multi-cloud it's a single pane of glass for managing all your infrastructure so if we see right here in the left i'll turn on my little pin we'll see how this works this right here see how well you draw a circle uh you can manage"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:05:06",
        "seconds": 306,
        "text": "right here in the left i'll turn on my little pin we'll see how this works this right here see how well you draw a circle uh you can manage servers in different cloud environments kubernetes clusters sql server azure stack hyper-convergent infrastructure specifically we're going to look at kubernetes clusters today and this is sort of an overview is our arc so we have a zero arc here and if i look at the slide before we'll see the symbol here is their ark and the reason why i'm showing that is this used to confuse me as i dive navigated between the blades like what's this what's this and it's um so i i hope to make that clear for you so azure arc you can manage many different types of infrastructure and uh specifically we're going to look at the kubernetes so you'll see this symbol here but using azure arc we can manage you know on-prem kubernetes we can manage like eks uh gke or any cncf compliant kubernetes cluster and some of the use cases for this is uh i like to really point out this last one it helps prevent didn't mean to draw on top of that helps you helps prevent vendor lockout or lock in basically i i'm sure a lot of us have heard of aws and power where poller was giving a day or two notice before they were not allowed to use the aws platform anymore and i believe i'm not sure if they ever recovered from that but i know they were immediately down because they were very well tied into aws so one this is why i'm specifically focusing on kubernetes with their art today because with a container you can very easily move that from one kubernetes cluster to another so if you have kubernetes clusters in different clouds you can very easily move that workload from one cloud to another um to help prevent this because i mean we used to be told you know the cloud high availability resiliency well what happens if they're not going to let you use their platform and give you zero to no notice so i think this is something organizations have to start to look at so i'm going to do just a very quick overview of kubernetes uh so basically kubernetes is a container orchestration which means you can it helps orchestrate scaling up scaling down deployments of containers containers will house your applications and um when we speak of like aw i mean um eks aks or gke uh of all the major vendors they're they're uh managed kubernetes platform basically they're they're managing the master node for you so you can just concentrate on the worker nodes and nodes are are similar to or are synonymous with vms so this cluster would have six vms assigned to it and the advantage of that is it gives you a higher density of resource utilization versus just a regular vm um it's also other advantages is you know auto scaling and loosely coupled infrastructure so that's why there's a big initiative out there to use kubernetes uh because now developers can just put it in a container hand it off to operations and then they deploy it so it runs as it was uh developed tested and then in production so it isolates all you bring all the dependencies with it within the container and we're not really going to dive deep into kubernetes but i'm going to show how easy it is to set up a cluster in a shirt because in order to provision a cluster in their arc you have to"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "in a shirt because in order to provision a cluster in their arc you have to have one that exists so we'll jump jump into that now and uh we'll see how the screen increases yep so i'm going to i'm already logged into the azure portal i'm going to create a resource i'm giving a second for my computer to respond i'll just try to oops i got impatient hit refresh so now we gotta wait a few more seconds and of course the azure portal is usually uh much faster i'm just running a lot of things on a very old uh laptop and i'll just give it a second because i will need the portal to show the rest of the demo so even if we don't bother creating a cluster we still want to see the portal and we're almost there so this should be you know maybe uh i'll do a lot of times i'll do screenshots ahead of time and uh so this is definitely a case where i wish i had done that all right we are almost there all right so i clicked on create a resource i'm going to type in kubernetes now i've hit enter and it'll give me some choices so so what i'm going to do is i'm going to continue with the presentation and when the screen comes available we'll jump right back to it all right so we're going on an assumption i've created a um kubernetes cluster in this case aks i've also well we'll see when the screen comes available for us but some of the prereqs are we must have the azure cli version 2.15. so let's take a look at that so i can just type version to see the version i have i'll give this a few more seconds if this doesn't work what i'll do is i'll turn off the fancy circle and just go to a powerpoint presentation i was hoping for a new computer for christmas but i got a lump of coal so just uh unfortunate think that i think that's what we all got this"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:15:14",
        "seconds": 914,
        "text": "christmas but i got a lump of coal so just uh unfortunate think that i think that's what we all got this year yes i was told to stay inside for a whole year they haven't let me out yet i don't know why all right the the marketplace has actually presented itself so while we're waiting for this demo to return we're going to go to the other demo all right so again i'm in the azure portal i've i'm looking for kubernetes and i see it here kubernetes service so i click on this and all right so what i'm going to do is i'm going to take just two minutes to turn off the um this video so uh my screen will go blank and then i'll be there in in two minutes so i'm gonna say oh well we think okay maybe things are speeding up so i'll say create all right um so just bear with me for two minutes let's stop the virtual camera and now i'm going to share my desktop um oh thanks for the feedback on the video quality so now that i'll be sharing the desktop i won't be streaming a video so i'm hoping that we'll uh improve things and screen two okay well i'm waiting for that to take control i have a backup plan too i can see it oh great okay all right let's see how this goes all right so i'm creating my kubernetes cluster and basically the minimalist required is i have a resource group so i'm going to just choose an existing resource group i'm going to choose aks-rg just me saying your community service resource group and then i have to give it a unique name so i'm going to call this my aks cluster and when you're doing tests and all you know sometimes every node is is related to a vm so instead of three you know obviously production you want like three at the minimum but if you're just doing testing or whatever maybe one you can also change the note size or vn size so it costs you less money i have tried micro micro vms but then i always run into problems of not having enough resources to run the application so it's sort of a double-edged sword you go too small and you're gonna end up using time anyway and so really that's all that's needed to to um to provide and then review and create and then once once we do that in this case i'm not going to create it because i already have we'll have a aks cluster so when as we continue i'll go back to that screen to show you the cluster that was created we're now going to uh continue with the prereqs and so version 2.1.5 2.15 is required"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:20:16",
        "seconds": 1216,
        "text": "that screen to show you the cluster that was created we're now going to uh continue with the prereqs and so version 2.1.5 2.15 is required i have 2.19 so i'm good however you know if you were below that or you just want to upgrade you can just type a z upgrade and uh basically it's in preview so you may not want to do it for production but um then it'll ask me if i want to upgrade i'm not going to upgrade because you know i ran this demo with 2.19 so why do i take a chance and those that's in you watching my machine getting updated so i had a i had the required azure cli the next thing we need to do is register our uh namespaces so i'm just typing az provider dash h or you can type dash dash eight help to get the uh help for this and there's only uh like four different commands for it like az provider register is one easy provider list is another uh show unregister so if you haven't done it before and there's actually no harm in running it twice you'll run az provider register dash dash name space microsoft dot carbon eddies then you can run the next line for microsoft dot kubernetes configuration but before you go to the next step you want to make sure it's actually registered because it does take a few minutes so for that you just type daisy provider show um namespace and then the one that we're interested in and uh i'm gonna change the output to table so it's easier to see versus json and this will show if this namespace has been registered if it is registering or if it's unregistered so after you run the register command and you run the show command it will say registering and so you just want to you know keep writing this until it says registered or just wait an hour and then you'll be fine anyway once it's registered then you're good to go to the next step so i've already registered these both namespaces but this is a very easy step that's required now when we have a we'll look at our kubernetes cluster and this is the one i created in aks ignore the other symbols you'll see that we will get to that so i had this aks cluster that already exists and what i would need to do now is to make sure i connect to it using cube ctl which is basically um allows you to talk to the cluster the you carbonated is utility allowing you to talk to the cluster so we're going to actually dive into a little bit about that because i think that's important being able to jump around from one cloud to the next so um let's see where i like to go here let's say and there's no harm in running this command more than once so the name it wants is the name of the cluster the name of the resource group which i call it apf and so what we'll see is this will come back and go it's merged i forget the exact message but we'll see that in a second and basically what it's doing is editing editing this file right"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:25:17",
        "seconds": 1517,
        "text": "back and go it's merged i forget the exact message but we'll see that in a second and basically what it's doing is editing editing this file right here this config file i'm going to go to the next screen and bring back my folder here so the file location that the cube ctl uses a config file location is your home directory dot cube and it's config so my home directory is c slash user slash daniel clone that's fine so i'm gonna open this up in notepad which i already have it open all right so i have a typo no big deal that pi also why it took longer but anyway it automatically fills this up in this file i could come here and just delete it let's say we're not sure what's there so i'm going to run this again with an extra e and we'll see it'll create the config file and then we'll see um have the information uh that needed my cube ctl to connect to the my aks cluster and let me know if the video i mean if the sound quality is bad or the video is bad i'll keep a lookout for that all right so here's the message merge my kes cluster is current context so this is important current context and we'll take a look at that my aks cluster so let's drag it back here so we'll get the right text and we'll see obviously you don't want to show this to people but there you go this will be deleted afterwards anyway here's my cluster my iks cluster and there is a current context my k cluster so i want to show you this for a specific reason so now we got the aks cluster um we can communicate with it i can just type uh cube ctl get nodes that's probably one of the most common tell me about the nodes and they'll go out there and that'll return that and so why is doing that what i'm going to do is i'm going to enter the information for aws so i also have an eks elastic kubernetes service cluster setup i'm going to open a second well actually that won't work so one thing that i've done is even if you open up a second command prompt it's still the same session and you can only use incube ctl this way i'm sure there might be another way um you aren't going to be able to talk to one cluster at a time because it's using one config file you can actually specify which config file to use and then you'll be able to talk to more than one but here we see aks so i know i'm talking to that now i'm going to get the information for the eks i just happen to call this my eks cluster another thing that's also important is sometimes you have to specify the region i don't have it here but i happen to know uh to type that in let me see if i have the information on the next slide nope maybe this slide before well so i have i have i mean basically so if it's your default region you're good to go if it's not then it's not going to find it unless you specify the region it's in and i forget the region name so i'll do a quick look up or we'll just take"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:30:29",
        "seconds": 1829,
        "text": "it unless you specify the region it's in and i forget the region name so i'll do a quick look up or we'll just take a guess i think it's u.s east one before i type that i'll i'll google it real quick i could log into it but i thought just googling it'll be faster okay so i got the format right that's really what i was worried about uh usc's one i'm pretty sure now so i'll hit enter and then we'll take a look at the config file and what i want you to notice is right now this is my ks cluster but i'm actually changing it it's going to add and change the current context at the same time to my eks cluster but aws uses a much longer name and you'll see that all right so i i typed something wrong no big deal um so what we'll do is we'll assume i added that and um i probably have a backup somewhere just so you don't have to see me uh labor through it so i'm gonna open up a backup of the config file maybe it's this one it doesn't really matter but um this obviously has a lot more information for different clusters and what we're looking for is the current context and uh oh this is an older file but yeah i've done it a lot of times so anyway you'll see that you know you can have one it could point to one current current context and i actually have the commands oh here they are so right now uh i only have uh one kubernetes cluster um registered in there but we'll get the idea so i can say uh so this is just going to the config file listing everything and the one that is current is going to have an asterisk to it and if i want to switch it i don't have to after i've run this command once i don't have to run it again i can just say uh cube ctl config use dash context the the context name so then you can switch it that way either way will work and then what you want to do is uh make sure you can talk to us so you can type cube ctl get nodes and the reason is uh so now that we know we communicate with it then we will actually register or on board um that cluster and we would do that with this command at the bottom connect kas to is our arc so it's going to be azconnect k8s connect the name of the cluster so if i was doing eks it'd be my eks cluster and then this resource group is going to be the resource group where is our arc is so in this case i called it arc dash rg and there was nothing special about that resource group i literally just created a blank resource group called r rg so that that was um there's no special setup there so we take a closer look at this az connect k8s you can um you can uh come connect you can delete them you can list them"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:35:34",
        "seconds": 2134,
        "text": "there so we take a closer look at this az connect k8s you can um you can uh come connect you can delete them you can list them let's go ahead and list them so because i've already registered everything and so this is going to give a list of uh three different clusters one in azure one in aws and one in google i can very easily delete it so i'm no longer managing it in azure i can add it back i could just i would type the command before that uh the connect command so that's easy enough to add and that's literally all you do to register it so just a real quick recap because i know it jumped around a little bit is make sure you have the current version or higher i mean you have the minimum version or higher you register your namespaces um you can talk to the cluster using cube ctl so we're gonna you know get the credentials basically in the cube config and then you're gonna run a command to make sure you can talk to it uh in this case i put cube ctl get knows but it could be anything and then we're going to connect and that is all there is to it sometimes it takes a minute or two but usually it's pretty quick so in that case we so we registered those so let's take a look at what that looks like this was from before we created in um a aks cluster one thing to note is i i'm not sure if i already said this to could practice it once or twice but you don't gain anything by registering the aks cluster versus your art because you already have everything available to you within azure but it's very easy to set up very easy to try out um so it helps so i'm going to azure arc and i'm just going this way to show you the navigation and so here's kubernetes clusters so i could have gone directly there i created shortcuts on the left and what we are about to see is a view that you would see after you register so literally after i run that connect command it's listed here and that's what you see and you can see these are at slightly different versions and i mean they can be completely different versions but they're fairly uh i try to get ones that are close together for no particular reason um and so now we've onboarded uh clusters from multiple clouds and the step is the same as on-prem the as long as the kubernetes cluster is a cncf compliant we're good to go all right so now we're going to look at uh getups and basically this will allow us to um deploy from get straight to kubernetes so i got a very simple demo i'm trying to keep things very simple um and you you'll see how easy it is actually so let's get it's going to be your signal source the truth for the entire system um so these are the get principles uh these are some practices ensure you test have at least two repos per app one app for source code and second forward the manifest files uh have a plan for secrets management you obviously don't want to store any secrets in a version control system this is just a list of all the different technologies with the uh definitions i i thought at least"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:40:36",
        "seconds": 2436,
        "text": "secrets in a version control system this is just a list of all the different technologies with the uh definitions i i thought at least this was helpful to me i'm not going to go through them but um it's amazing all the different technologies that are that are behind the scenes somewhere for something if you're wondering what this green circle is that would be where i would appear so yeah so i talked about helm a little bit but i'm gonna just sort of go through this quickly and we'll go to actually uh get itself i mean uh using get ops you don't even need to know anything about uh flux but don't confuse it with the flex capacitor yeah from uh um back to the future all right so we're gonna go directly to the demo and i'm gonna go to my ks cluster and so now you know is her arc kubernetes cluster now i'm looking at the specific cluster and i see get out here we'll see i already have something configured so i'm just gonna click here real quick and we'll actually set one up so i'm opening up the configuration uh we see this url right here so i'm just going to copy this so we're going to sort of go backwards oh cool so this is a repository that i forked so we'll go back even one more step once it appears and this is for slash arc dash k ks demo so this is a public repository and i'll point out a few things here you can actually deploy directly from here the problem is just you know like any repository you're not allowed to make changes here so you could deploy from it but then we wouldn't be able to do the next step and let's make a change so uh if you fork it which i've already done uh you'll get a copy of it in your own repository and then we can deploy from this url and then we can make a change and then see that it's automatically deployed so i would copy this url and i'm going to go to uh one of these other clusters where i probably don't have it set up oh great okay so now say add configuration and i'm going to scroll towards the bottom first i'm going to say public uh you can do private but then you have all the security stuff so we're just for the demo we're doing a public repository right i mean it's readily available i'm pasting the url in here i'm going to give it a name and just make sure i don't run into any unknown errors we're just going to use the same name so i'm going to one that i've already entered the information we're going to copy it over and i'll move this just off the screen so i can copy and paste or maybe it's probably better we see it right so this one was called rks dash demo say name as the um repo and the operator instance and namespace is called cluster dash config"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:45:51",
        "seconds": 2751,
        "text": "so this one was called rks dash demo say name as the um repo and the operator instance and namespace is called cluster dash config and the operator scope is called cluster so i just want to use all of the same stuff uh namespaces are a great way to logically separate resources in your cluster let's say it's using helm charts once again enable helm if i wanted any other uh parameters i would just enter them here in this case we don't need any so this is a very simple example so i gave it a name which really can be anything i believe the cluster config is is in the helm chart so we needed to use that and i made it a they didn't want to buy those setting up well it's a public repository anyway but if you're going from your own private repository you have to set up the keys and all i'm going to click add and now we'll see um that the operation is pending and could take a few minutes it can take 30 minutes who knows uh well once it's done we'll see what it looks like so it's saying uh pending so i'm gonna go to one where i've already uh configured this and this now says installed we'll give us a little more room here and so this would take in that it deployed from github this repository has been deployed into the cluster so uh just to make it a little faster we'll look that up real quick i'm already connected to the my aks cluster so i can just say get service i can also find this through the portal i just happen to know this might be a little faster and this is some of y'all may have seen the is there a vote before but this is basically this is that application so i got my external ip address proof in the pudding and there's our application so you can vote for cats dogs you can reset the count uh whatever you want so in this specific we're gonna dive into this a little bit more but what i wanted to show you also is let's say oh good didn't think my memory worked that well anyway uh here's some name spaces teen dash hey team dash be team-c so let's go back to repository and under here name spaces and here's team a team b team c so it looks fairly easy if i want to make a change to add a new name space shouldn't be too hard so we'll just open this up i'm gonna copy this uh go back to the folder i'm going to add a file create new file obviously i mean you can do this locally and then you commit it or you can do it right in github and make the commit so that's what i'm doing and this is going to be a d and then created i mean that's fine so i'm going to commit new file all right so now i've made another change so"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:50:57",
        "seconds": 3057,
        "text": "and then created i mean that's fine so i'm going to commit new file all right so now i've made another change so you would have checks and balances somebody would have to review this before it automatically got submitted uh but let's say all that got done and now i've just submitted now what would you have to do to get that out to your cluster well the answer is absolutely nothing um it will i apologize i forget the the polling frequency but it automatically pulls for changes and it will automatically deploy that new namespace sometimes it's quick sometimes it may take a while let's see if we get lucky oh yeah that was actually very quick so it's done it's been deployed so in theory i can have all these clusters in different clouds pointed to the same repository so when i make a change i've automatically deployed to all those all those clusters in different clouds i think that's pretty cool so um one thing to note is i believe if i was to remove team d it doesn't automatically remove it in the cluster because then it might destroy some applications that depend on that namespace so that's a nuance to to think of but if i was making a code change that would have been fine so that's that's basically getups get get ops oh here's the poll um so if you delete if you delete the configuration it'll happen within 10 minutes and then i hear as i talk about the name space gets deleted they are left and tapped in order to avoid breaking other workloads so you can use cubectl to delete the namespace if needed to all right so those are actually the nuances i was just alluding to oh last but not least monitoring so we got insights alerts metrics log workbooks let's take a look at that so uh configuring this is actually quite easy so let's go to my eka eks cluster and click on insights i'll give it a few seconds so basically configure azure monitor i'll just click on a button it's going to ask me for log analytics workspace so if you don't have one you'll have to create one but that's fairly easy just create a new resource go to log analytics create a unique name for it um i'm just going to use an existing one called art monitoring law for log analytics workspace i'll say configure and this could take a while so uh what i mean by a while is i guess like here it says five minutes five ten minutes so i already have it done for the myks cluster but you see it's literally just clicking on a button and say go for it i'm just going to close one or two tabs to increase the resources for the computer and here we see um node utilization so"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "00:56:01",
        "seconds": 3361,
        "text": "to increase the resources for the computer and here we see um node utilization so i guess it's around 11 percent uh the memory utilization you know 20 plus percent no count we have one on the i my aks cluster we can obviously change the time range we can look at reports and we can get this compact capacity we can find things of data usage we can look at the nodes and this is i know it's taking a little bit to come up it comes up much faster when you're not presenting we look at controllers containers and then if i go to alerts i can i won't go through the steps but basically i can create a new alert rule so you specify the metric and the value you wanted to to trigger off of and then what you want done maybe send an email we got metrics um total number cpus won't be too exciting it'll be one oh six oh okay um you look at uh into your pods containers let's do containers so you can choose different metrics here uh this one has not the little guy has anything exciting there we got logs um so what we could do for this as we look up kubernetes specific stuff let's see i can say load to editor these are uh predefined queries you can write your own but it's nice to start off with something and then you change around this is using a kql and then i'll just click run oh time generator greater than seven days i should have taken a closer look we may not get anything back i don't think i did this seven days ago oh i'm waiting for that we will change it we'll say give me the top i'm gonna hit cancel hit run again uh not probably limit five oh okay so we got our five records not sure why they just show"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "01:01:26",
        "seconds": 3686,
        "text": "uh not probably limit five oh okay so we got our five records not sure why they just show it uh so there they are so you know uh you got that you can look at the chart and there's a lot of um things you can do with kql and this is specifically against those logs let's take a look at the workbooks i don't want to save any changes so basically i can always paste that into the dashboard too or pin it to the dashboard and these workbooks will give us more information let's say oh you know um all right so we'll click on this you know i accidentally or maybe i have it after monitoring is policies all right so if i had something interesting to see we see it here but i i don't but so monitoring is fairly easy to enable and then it obviously takes a little investigation to find out what might be important in your specific case so what i want to do is uh go to policies and not sure why get that i don't even see slides for it all right fair enough um let's look at policies so one thing to note is um uh policies well we'll see we'll see with policies so right now we have these two policies that say i'm in 100 compliance but how do i apply a policy i can just go to our policy and the same for monitoring i could have gone to azure monitoring it's really the same thing as if i drill down into the is there arc and then kubernetes and then monitoring you can go the other way too so now i'm in a policy um let's go to definitions so you can define your own policies in this case we'll just find one and apply it uh so you have built-in or custom so you create your own or built-in all mine are basically built in right now so it doesn't matter if we filter it get the same result categories i don't want to see everything i just want to see maybe something related to kubernetes here we are i do have a test one interesting um so here kubernetes cluster pi security baseline standard for linux based workloads i don't really know what it is but let's click on it so one of the things you want to do is like anything specific you want to research it hey i want to look at"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "01:06:41",
        "seconds": 4001,
        "text": "so one of the things you want to do is like anything specific you want to research it hey i want to look at all the policies for kubernetes what are they trying to force where are they after um and so forth so we have this policy here i'm going to say assign so you basically find a policy you want or you create your own and then we're going to assign it we'll choose a scope a scope is going to be at what level it's going to be applied at and then everything below that so i'm clicking the ellipse on the right if you have more than one subscription you can obviously uh go there some say in my example's description i don't want to apply to everything in this description i only wanted to apply to the to the clusters that are managed by user arc in this case i have them all in the same resource group which makes it handy we call it r rg i'm gonna say select so this will apply apply to all all those clusters in there you can exclude so let's say in that resource group i have a cluster in there i don't want it to be applied to i could exclude it here and okay we're gonna enforce it so i'm gonna say review and create or i'm sorry let's go to next and so this is important so when you first apply a policy i mean i recommend always audit it first you you know so then you will see what effects it will have without it actually making any change without it enforcing anything because we're enforcing business rules here um so once you're happy with it and then you can update it to deny so we're going to say audit um say review and create and i'll say create so i'm just trying to keep it very simple how you can just very quickly not really know what the policy does and we can just apply it and and then have it audit so now if i was going to go back to the clusters that are under is there arc and then i'll go to my ks cluster i will go down to policies and so this is the policy i just applied it says not started yet so there is a polling for it and then it will run it may take some time and then they'll say either 100 in this case i have three different uh clusters so you know either 100 60 30 um it'll report on that and that's how you apply a policy so it's actually quite easy i really encourage you you can do that on i think almost any resource um try to go to policies look up tags and try to enforce a specific tag so in summary is our arc allows you to manage uh you can governance through policy you can apply uh security through policy you can manage different things kubernetes servers data services uh other things can consider the"
    },
    {
        "speaker": "",
        "title": "Daniel Colon: Azure Arc Enabling Management of Hybrid, and Multi Cloud k8s Solutions",
        "videoId": "XXy8uQ8tjBE",
        "description": "This is a recording of the April 14, 2021 virtual meeting.This session will cover what, why, and how of Azure Arc. We will then go into connecting to a local K8s, and an EKS to explore how we can control this like any other native Azure resource along with controlling an AKS instance.1. Concepts2. Getting Started3. Policies4. Monitoring5. Security6. Other Azure Enterprise Resources to ConsiderDaniel has expertise in infrastructure, internet technologies, and systems integration obtained through 20 plus years of working as a manager, architect, and developer on projects for mission-critical back-end systems that have included various cloud platforms such as SoftLayer, AWS, and Azure. He has taught various courses at Northeastern University including ASP.NET, C#, and XML Web Services. He has various certifications including A+, Security+, Azure Administrator Associate, and Azure Solutions Architect Expert.",
        "start": "01:11:42",
        "seconds": 4302,
        "text": "policy you can apply uh security through policy you can manage different things kubernetes servers data services uh other things can consider the zero centennial so that's also a multi-cloud on-prem management tool that allows you to uh basically you collect logs from all your different resources and you can mine those logs to see where a risk that might otherwise not be noticed because of noise let's say somebody's gone in and tried to log on to one of your servers and they were unsuccessful but let's say they went to all 30 of your servers and was unsuccessful well you would notice one log on an attack and like oh that's no big deal but the same ip address just hit all 30 of your servers doing that so then azure centennial will help you see that so you can mitigate it before it becomes a real problem and any questions oh what the azure art jumpstart this is a a great website i think it's by a microsoft guy um let's just go to real quick let's see so i have a little trouble clicking on it all right i'll just type it in so uh this is a bunch of uh quick starts for azure arc and there's also subsections specifically for is arc enabled kubernetes um and like i said any cnc nf compliant kubernetes uh cluster should work so you see he has you know rancher ks3 i don't see mini cube here yet but that will probably work i would think um we look at aks you know terraform if you're familiar with that you can use that to deploy it or arm i personally think for testing it might be easier to just go to a portal create it real quick and then you you're going to register the namespaces and use the azconnect k8s command and get really done from that point so any questions i don't see any questions quite a bunch tonight that's a quiet night um i i have a question uh dan yeah yeah i'm curious if the road map for this uh so obviously you talked about kubernetes and uh kubernetes is a popular framework across azure and competing clouds and in other circumstances like on-prem and such is arc the vision for arc to bring together all management experiences for all compute and other kinds of workloads everywhere is this like the grand uh one pane of glass uh so i believe for uh so it's sort of a little bit different so it's to bring the management of all resources outside of azure to a single pane of glass uh so you don't necessarily i know i showed aks here but you wouldn't really do that um procedure could be unnecessary the um uh but i i think their marching orders or initiative is to be able to manage everything outside so basically um i didn't actually talk about this but if you notice i didn't talk about having to configure firewall rules or anything how did i get into eks or gke basically it installs an agent and it goes out to the azure space so uh it eliminates that so if there's a you know inside your cluster you will see a namespace for azure arc with those agents running and that's that'd be the same thing for any servers or anything so if you think about how microsoft manages anyway it's going to be an agent on your vm and it's going to talk to azure and with that concept you can really manage a lot of stuff thanks for that um and a follow-up question i know you mentioned uh azure sentinel which is a security service uh were you mentioning that as a um you know you did mention it's another service that can help you keep an eye on not just azure but non-azure resources um um um did you mention or or can you clarify if if azure arc has a role with uh azure sentinel used in that manner uh so they're they're independent but they sort of work in the same way so you will you know instead of an agent talking on a vm remotely to azure you are shipping your logs or streaming your logs externally into a um analytic workspace and from there edger sentinel will mine the data thank you for the clarification sure all right well i think that is it for questions um it's been a pleasure i'm going to let's see i'll do the stop presenting yeah uh uh everybody um i'd like to you know join me in thanking uh mr daniel colon for this uh insightful walk through azure arc and how to uh get it to do your uh kubernetes biddings no matter where your kubernetes bits are and uh thank you dan uh excellent talk as always uh uh for um for anybody who it wants to uh revisit this uh we'll have the video posted up on the youtube channel within um usually uh within a day um and the youtube channel jason can you mention do is the is the youtube channel now available in a new url because we hit the 100 not yet but it will be okay so you can uh for now you can you can find uh this talk uh you know in a day or so at uh bitly slash azure youtube and stay tuned on the either the north boston azure or the boston azure meetup sites for uh further events that are being planned and i will just ask one time if are there any further announcements from anybody before we close down well thanks everybody for joining thanks dan for uh presenting and i'll see you all next time that's good thank you very much "
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Bring DevOps to the Swiss Alps. This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.. foreign I think you've already mentioned everything about me uh the only thing maybe I just recently moved to Australia so I'm based in Perth right now but I'm still working as a freelance software architect for uh Swiss companies so today I want to tell you something about a project I was working on last year the project is called uh optimal most ropey system um I I just want to give you an introduction of the project then what challenges we faced and how we used various Azure Services especially Azure Arc to solve these problems and then I want to give you a bit more in-depth um about the features of azure Arc um before we start a roofing system uh what is that here you can see a classical rope system in Switzerland there we have the literary area where in summer for hiking in Winter for skiing and what you can see here this this red box is also called a vehicle vehicle and it brings people uh up the mountain I usually you step in in the valley and just go up at the mountain and get out it's quite simple and my customer um had the idea to um automate this whole system so that yes um that they need almost no Personnel to operate it um one of these tasks would be for the vehicles to come out of the garage uh when they're needed right now the workflow is that the employees have to estimate how many people will come during the day and put the vehicles from the garage on the roadway in the morning and on the evening put them back in the garage um so it's quite a lot of work for them and it's also not flexible at all for example if it's a bad weather in the morning not many people will come but if the weather is fine in the afternoon more and more people will come in the afternoon and so they maybe don't have enough Vehicles people have to wait and um yeah it's not practical for the customers and since uh the vehicles are coming out of the garage they are only you uh used when they're needed this has many advantages cost wise for example that's less they enter less energy usage and overall cheaper to run another Advantage if it's autonomous uh you can run 24 7 and you don't need people overseeing it or at least less people another nice feature is that if you have a smart system you can Implement routing through a system of or through the network for example right now you just go from point A to point B but with this um smart system every vehicle can find its way through a network so for example um like a Subway you can say I I'm at Point a I want to go to point D and the system Roots me there um for our test project we had two mountains where we wanted to go to and the customers could choose uh in the valley if they want to go to Mountain aob and they got redirected there without having to do any switches of uh transportation the initial challenges we were facing um the first one was more challenged for me because I'm A Cloud architect I'm used to use cloud services just click through the Azure portal use whatever I need but in this project we had to use existing Hardware this means we had to install the software there find on-premise software and yeah just rely on on the software we manage ourselves and the second probably bigger problem was that our customers controlling the firewall and it didn't allow any inbound traffic so some problems we faced was we didn't know how to do the deployments for example from Azure devops you need a connection to your on-premise infrastructure to push the deployments this was not possible also we couldn't use any cloud service like Azure monitor to catalogs create dashboards create alerts and so my first idea was we could use a VPN connection to Azure or an express route connection express route is a private connection so your ISP has to create this and it's a direct connection from your on-premise data center or location to Azure it's not a connection over the internet but the customer immediately said no we don't know this we don't want it so we had to find a solution to back around this and here you can see"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:05:07",
        "seconds": 307,
        "text": "not a connection over the internet but the customer immediately said no we don't know this we don't want it so we had to find a solution to back around this and here you can see a simplified version of the network so what they had is a whole bunch of Ubuntu VMS and so until we were running kubernetes and the only thing that worked was from the VM go through the firewall to a container registry and download new container for kubernetes cluster but everything else was blocked for example I set the connected from Azure devops uh was blocked so we had to find a solution how to implement a modern uh process to have deployments monitoring and so on with all these limitations and here you can see our test station so the manufacturer of the Roku system uh built one of the stations in their manufacturing facility and that we could test our software uh with the real system for me this was quite cool because I used to work on online shops and they are not really exciting like you click on buttons you buy a couple clothes and that's it and with this system if you click on a button suddenly a door opens or we heat the starts moving so this was quite interesting to see how the whole system works and here you can see how the system works from a customer perspective so the customer interested area and they have here this this board and barely can select where they want to go uh you might notice from elevator in airports or shopping malls where select on which floor you want to go and then you get a message and go to elevator aob and then the elevator brings you there and that's the same way so you click where you want to go and then if here I bought and it tells you where this vehicle is going how long it's going to take to arrive there and how many people can fit in the vehicle so I can see it will take 50 minutes to get there and still 10 people can fit in there and due to all the limitations I discovered Azure Arc and I thought this might be something useful and so we built a proof of concept around Azure Arc uh so what is Hash Arc it's a way to project the infrastructure that's running outside of azure into Azure so outside of azure means it could be on premise or with a different cloud provider so it could be Amazon Google whatever and you can manage uh Linux and windows VMS and bare metal server uh could any kubernetes cluster as long as their cncf um it's Cloud native Computing Foundation certified and you can also manage SQL Server and here we have the Azure portal and here on the left side you can see what they can manage so it's a whole bunch of services some are still in preview because there are a lot of new features a lot of changes going on and it helps you to manage your own uh on-premise or outside of azure uh infrastructure the same way as you would do if it's running on azure so this means um let's say I have a couple uh on-premise VMS and a couple Azure VMS usually I have to run several um like tools to manage them like I have my cloud tools and I have my own premise tools and with Azure Arc you can match them all with your Cloud tools so I can use the Azure update management or configuration management or install the the Microsoft cloud Defender so as an administrator I don't have to learn several tools I use the cloud tool and manage everything with the same tools and for us since we had a kubernetes cluster there's something called Azure Arc enabled kubernetes and with this um you can manage uh kubernetes cluster the way you manage this is through extensions so once you have Azure Arc installed on your kubernetes cluster you can install extensions for example for Azure monitor or for Azure policy and then you can use Azure functionality on your on-premise kubernetes cluster and another big Advantage is um that you can connect to your kubernetes cluster through Azure Arc without opening any incoming ports so the way it works is the Azure Arc agent is running inside the kubernetes cluster and creates an outbound connection to azure"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:10:10",
        "seconds": 610,
        "text": "kubernetes cluster through Azure Arc without opening any incoming ports so the way it works is the Azure Arc agent is running inside the kubernetes cluster and creates an outbound connection to azure and I as a developer can connect to Azure and through this connection uh can access the kubernetes cluster as if it was in my network foreign the next problem we had was the deployment how to do the deployment without any access to the kubernetes cluster and for this Azure Arc as an extension agent on the kubernetes cluster for BDubs there are two big projects one is Argo City and the other one is flux um Azure used the flux agent and this agent runs inside the kubernetes cluster and you configure this agent to pull a git repository and if there are any changes in this git repository the agent downloads these changes and installs them and the guitar can contain yaml files or Helm charts so and it doesn't matter if it's a private kit repository or a private one so I'm gonna show you how we did it with a private repository and again you don't need an inbound connection inside your kubernetes cluster because the agent is running in the cluster and pulls the changes so all you need is a connection an outbound connection over Port 443 https and today we managed the deployment was we had two git repository the first one was the the normal application repository where we had um our pull requests we had build pipelines we built uh the docker image uh ran our tests and pushed the image to the registry and then we had a second repository where we had the configuration so this configuration more or less contains the helm chart um and the sound chart told the kubernetes cluster what a container to installer to run inside the cluster foreign about this um with flux you can also create dependencies or configure dependencies for example um if I have a new application I want to First create a new namespace inside my kubernetes cluster and then deploy my application there if I try to deploy the application first the application will say I can't find the namespace and it won't work and with flux I can configure the dependencies as you can see um what I just said so on the left side we have the normal application uh repository so here so the developer just implement the features create a pull request then we have a pull request pipeline uh running unit tests verifying everything is working then we have a CI pipeline PCI pipeline may run more tests and create the docker image and push it to an Azure container registry or any other container registry and the new FCD pipeline this can be automated or manually triggered um since our Roku system was transporting people um they are quite some law some strict laws about it in Switzerland so there's an official government that has to verify everything is running and certified so we couldn't deploy all our changes so we had to do it manually get certified and then just run it and what the CD pattern does is it makes changes in the configuration Repository so in our case we just change the tag so we updated the tag committed this change and since there were changes the github's agent inside the kubernetes cluster saw that there are changes downloaded them and applied them to the kubernetes cluster and with this approach we were able to do um automated deployments without having any access to the kubernetes cluster so since I was contracted to also do some work show something and not just talk I was tasked to make a proof of concept and the idea was to make it as realistic as possible but also as simple as possible and since I said I'm not used to run software on premise I didn't want to go with a full kubernetes version so I tried k3s because it's lightweight it's open source cnsf certified so it's everything you want and it's also developer"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:15:13",
        "seconds": 913,
        "text": "software on premise I didn't want to go with a full kubernetes version so I tried k3s because it's lightweight it's open source cnsf certified so it's everything you want and it's also developer Ranger or Ranger um so it's a big company behind it and also a big Community great documentation and the best thing about is you just need this one line command and you have kubernetes running on your Ubuntu VMS so it just took us a couple minutes to get started with um our kubernetes cluster and the next step was to install Azure Arc so the install Dash Arc you have to have the Azure CLI on your master mode installed and also the Azure Arc Sila extension um you can install these things extension again with your online command so it's quite easy to get started and then you have to register a couple Azure provider um for one of you who don't know Azure provider there are um a little bit like nougat packages in.net like they provide services and you can install them or activate them if you need them once you have installed them in your subscription um they're there for all your services and in actual you can register them with a single line command and um what we needed was just the the kubernetes and um once this was installed we could run Azure arc on our kubernetes cluster so as you can see here um we can check for example here for the provider microsoft.com you can see it's registered so it once you register it takes around 10 minutes and once you get the registration State uh suggested uh you're good to go to install Azure Arc and installing a shark is again just a online command so it's very easy to get going um all you need is the Azure C live command and you provide the name of your Azure Arc instance and in what Resource Group it's should be installed in your Azure subscription then depending on the internet connection it takes uh five to ten minutes and after this you can check with the CLI that it's installed or you can also check in the Azure portal and what this command does is it um uses Helm charts to um to deploy the Azure Arc applications inside the hasharc namespace and if you look into disaster Arc namespace there you can see it's I think it's 10 applications that are running there and if you look at the name you can already guess what this applications are doing um for example if here an extension manager taking care of your extensions when you have here a matrix agent um taking care of your metrics or like Gathering your metrics and then you have here an Azure active directory proxy um which allows you to connect through Azure active directory to the kubernetes cluster and I said before um you also have it in the Azure portal um that's a so-called single pane of class because you have one dashboard where you can see and match everything so you don't have to go to different tools different views um it's just in one place and you can match your outside infrastructure against means another cloud provider or on-premise the same way as you do um your Azure infrastructure and if you go back in the Azure portal to our Azure Arc instance um we can see everything we can match on the left side and if we click here on our kubernetes clusters we can see that currently we are managing two Azure Arc kubernetes cluster and on this overview you already get some very basic information um for example in what Resource Group it's running what the kubernetes version that's installed on the cluster and in what location it is and if you want more information you can click on it for example on the k3s arc and then you get the overview which looks very familiar as the Azure kubernetes service so if you use to eks it looks more or less the same so on the top you have a couple basic information like logging or access control and in the middle you can see what's going on in the"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:20:17",
        "seconds": 1217,
        "text": "it looks more or less the same so on the top you have a couple basic information like logging or access control and in the middle you can see what's going on in the kubernetes cluster the only difference to AKs is if you click for example here namespaces you don't see your name space right away you have to first log in with an access token that's just an additional layer of security and to get access you can use the kubernetes are back the rule-based access control system or I can use the azure rpback and as I said before for the proof of concept we wanted to make it as simple as possible and so we decided to go with the kubernetes rbex system because for Azure Outback you have to do some Azure active directory registration um you need an administrator doing this for you and it's more complicated and [Music] um yeah since we said we used kubernetes epic we could create a user inside the kubernetes cluster give this user um the permissions we needed and then generate an access token with this user and then we can use this access token to connect in the Azure portal to our kubernetes cluster but as a developer I can also create a proxy connection so I can use my windows development machine and I create this proxy connection through Azure Arc um to the kubernetes cluster discounts that downloads the kubernetes configuration and then I can access the cluster the same way as loot access a local cluster or an AKs cluster and the way you uh create this user and Company kubernetes CLI which always starts with Cube ctm then what we want to do in this case I create then on what object you want to do the work so that's a service account that's a user in kubernetes and then you give it a name in this case I just want to have you so that can do everything so I named it admin user then you have to give this user the desired rule in kubernetes you can use a cluster rule binding um when you say what cluster role so I used the cluster admin so my user can do everything on the cluster and lastly you say what user so it's the previously created admin user and once you have this in place you can create the access token um again if they kubernetes CLI and um so again you say create token and then you say for what user you want to do it so for the admin user and this paste uh the better token a principle token in the command line and then you can copy this token um and sign into the Azure portal so once you sign in you have access to your on-premise kubernetes cluster through the Azure portal and you can see uh what's going on there and can even uh Delete pods or like analyze what's going on I said before um Azure Arc allows you to manage um or bring Azure services to your kubernetes cluster through extensions and the most important one was the getups extension for us for the deployments but they're also more useful ones for example Azure monitor which allows you to use Azure Monitor and to create dashboards what's going on inside your cluster or create alerts and um another one is for example the Azure keyboard so it can use the Azure keyboard as your Secret store so what this extension does is um it redirects the the request for secret from the kubernetes cluster to Azure keyboard so you can safely or securely manage your secrets um but since this talk is called uh devops in in kubernetes let's focus on the the github's extension the github's extension as I said before is a flux operator and it can be installed via the Azure portal or via the Azure CLI uh I'm gonna show you later um yeah yeah sorry to uh catch off um would you mind spending a minute um uh elaborating on um get Ops what is get Ops yeah I'm gonna show it in two slides again and how it works we can wait thank"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "you mind spending a minute um uh elaborating on um get Ops what is get Ops yeah I'm gonna show it in two slides again and how it works we can wait thank you oh okay um just a second about flux and the github's extension um there are two versions so um our demo used version because last year there was only version one available and version two has more features for example you can configure dependencies but it lacks some functionality and it has a horrendous documentation like I've never seen such a bad documentation and um the functionality doesn't reflect the documentation at all so for now I'm going with Russian one and um to your question how githubs Works um the idea of githubs is is that you have a github's operator running inside your kubernetes cluster this is in our case here the flux operator but it could also be something else another popular one is Argo CD and what this flux operator does is it checks a git repository if there are any changes so it is configured to look um in this github's repository if there any changes and if there are changes committed the the flux and also applies them so for example if I have here in the github's repository a Helm chart that says um run version 1.0 of um my container image um the flux operator downloads it and runs the helm chart and so I have the version 1.0 running inside my kubernetes discuss stuff and now the developers create more features Implement them and then I decide it's time to update so I changed the configuration inside the github's repositor and say I want to tag 1.1 of my container image I commit this and then the flux operator seized as a new commit downloads it and sees um that I want to run the tag 1.1 and starts or downloads the container image with the tag 1.1 and starts it inside the kubernetes cluster and therefore I have the new version running inside the cluster without actually having to push any changes inside the cluster I hope this answers the question uh yeah Wolfgang um uh this I I guess is a good um description of exactly what it's doing uh I I was uh I I'm not sure the term is as common as um you know it flows off your off your tongue uh so maybe uh like a conceptual description like what are we trying to accomplish with get Ops might help the audience that was where my head was oh okay yeah usually um or in the past you have a CD pipeline for example in Azure devops and then you push your changes um this could be to an Azure service to kubernetes Cluster to your IIs on premise but it all was always a push and with githubs you have a pool so the githubs operator pulls changes or pulls new features so I think that's the biggest difference between these two approaches thank you okay if there are any more questions um just ask if not I'm gonna continue um I said before you can install um extensions through the Azure portal or the Azure CLI my preferred way is the sscli because it's very simple and you can easily repeat it and copy the code so if you look at the command even if you don't know Azure or the Azure CLI you will understand what's happening so again um with the as you see light it always starts with the AC and on what object you want to do something and then what um operation you will do so on the kubernetes configuration I wanna do a create and then you have parameter and the parameter are named so you already know what's going on so you provide a name uh the name of your cluster the resource Group and hear the Repository so what you can see is here I'm using a devops repository so that's a private repository so I'm going to show you in the next steps how to access the private Repository and then you can also configure the operator here for example"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:30:27",
        "seconds": 1827,
        "text": "devops repository so that's a private repository so I'm going to show you in the next steps how to access the private Repository and then you can also configure the operator here for example with here changes uh usually you have between 5 and 30 minutes in a production environment but for our demo I don't want to wait so I put it in one minute then you can also see on what branch so only check the master Branch this means the developers could work on their development Branch or feature Branch it doesn't affect deployment only if I commit to the master Branch it gets deployed and lastly I um also configure Helm so I can use Helm charts for the deployment and once it's installed you just get a confirmation message with a big wall of text which is not really helpful um so let's go into the Azure portal and see how it looks there so we are back in our Azure Arc instance and on the left side if you scroll down a bit um you have here the tab for githubs and there you can see there's the github's extension which you just installed and if you click on this you get more information but you can see um it's the same information we used before um for example here the gitpole interval uh is one minute uh it's here the same name and what's also interesting is on the bottom here it creates a public SSH key so we're gonna need this for the authentication um so I copied this sh key and before I go to Azure devops I want to show you that the log messages it generates but again it's a wall of text it's sometimes useful most of the time it's not um for example here you could see it also brings the the same SSH key but everything else is kind of hard to figure out what's going on so since I know I have a private repository and the githubs has to authenticate to access it I copied the sh key I go to Azure devops and add the public sh key um in GitHub for example or gitlab it's the same you just go to user profile um you have sh keys and paste it in there and once you pasted it the github's agent has access to the private repository and Cal can download the changes so when I was creating the demo I I forgot to create a namespace and so I got a message error message here and here it says um namespace email not found so in this case uh the error message was helpful and I created the demo namespace and after I created it the github's agent automatically deployed my application and now I have a pod and a service running in my kubernetes cluster and you can see I also have a public IP address and if I go to this IP address I can see I'm a Swagger UI running and I can test the application then um I said before we use two git repositories one for the application and the other one for the githubs configuration and the most important file is a yaml file which describes where the helmet is in what a branch it should look for what path what git Repository um you can see the file um yes here um the git repositor of the helm chart uh what branch and the path and um the second folder inside this git repository is the helm chart itself so I can show you this um in a couple sites in the demo so you can see how the repository actually looks like and then we have a CD pipeline for this detox repository and what this pipeline does is it's reading the newest tag from the Azure container registry and it replaces the tag in the values XML file that's part of the helm chart and then it commits the changes and with this approach we can always have the newest version um deployed on the cluster and since we made any changes the github's agency set and pulls the changes inside the cluster and applies them to kubernetes and another nice feature of azure devops is that when you start"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:35:31",
        "seconds": 2131,
        "text": "made any changes the github's agency set and pulls the changes inside the cluster and applies them to kubernetes and another nice feature of azure devops is that when you start a pipeline you can pass parameter so um our developers wanted to pass a parameter for the version they want to run so they can either run the latest version or they can set a specific version which was quite useful for testing as I said for a compliance reason uh we had to be quite strict with testing and so we could make sure that we test exactly what we want then my experiences with the different versions uh version one is deprecated so when you install it you will get a notification that will be removed in the future um as you have seen it's very easy to use and it can deploy Yemen files or Helm charts so everything you need with kubernetes Standard Version 2 has additional features um for example it uses customize to configure the application you can configure dependencies but when I tried it I had um no luck deploying Helm charts it didn't work although the documentation set it works I did exactly the same steps and it didn't make any sense so it was my worst Azure experience so far okay and now after all the Talking I want to show you how this actually works so if I go to my azure devops I have here two Pipelines uh the CI pipeline which just builds the application uh builds the docker container around unit tests and then a CD pipeline which updates the git Repository and before I do an end point here and it says um hello um all day devops 2022 because that's the last conference I talked at and I haven't updated it since so um it's time to update this and that's what we're gonna do together now so if I go to my code um obviously usually you would do this in an IDE like visual studio um create the merge uh pull request uh and so on but since this will take too long I'm just going to edit it quickly here and the browser so we say hello boss I had an Azure Boston uh we commit this just keep it very simple and what this does it automatically triggers triggers the CI pipeline and we can take a look at CI pipeline it's nothing special foreign it calculates the the Git Version so I create a new version then it runs a build on the docker container the docker container or the docker file has a build of my application and also runs my unit tests then the next step is here I search for the test results inside the container and copy them outside of the container so Azure devops can access them then I published the test results so I can see them after the pipeline is finished I also published the code coverage and then I push um the the docker image to my container registry so this um it's gonna take um around two and a half minutes so are there any questions at the moment while we wait for this to finish so if folks want to ask a question on your own feel free to unmute and uh pipe in um while we're while I have the floor here I'll pop my question which is um when you do these upgrades uh in this manner is it possible to do them without downtime yeah exactly that's a kubernetes feature and the way kubernetes works is um you can have two two different versions of the deployment that default one is called a rolling deployment so what kubernetes does is it um let's say you have 10 parts of your application and then kubernetes starts one new one and then deletes one old one and then again one new one and"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:40:34",
        "seconds": 2434,
        "text": "um let's say you have 10 parts of your application and then kubernetes starts one new one and then deletes one old one and then again one new one and deletes one old one until it gradually replaces all old ones um this is the advantage that you always have around the same amount of pots running but you have to make sure that your application can handle two different versions this is especially a problem if you have a database for example if you delete a column in a database and then deploy it your old version will break broadly so you have to plan a deployment a bit um the second mold is called a green blue deployment and what kubernetes does here it starts all new parts for example if our application is tampons it starts 10 new ones and then redirects all users to the new ones and then delete the old ones so in this case you don't have to handle two different versions but you have the double amount of pots running at a time so you need more resources thank you and I can also show you I have to um quickly log into the tunnel and then I can show you how the deployment works um so we will see that a new Port is started and after it started the old one gets deleted foreign so here you can see that currently we have one pot running and it's running for 35 hours so now we're gonna deploy a new version and what we will see is that a new pod will be started and when it's once it's running the Old Port will be deleted so first uh let's start the pipeline for the new version so what it says run Pipeline and here I can see I can pass a parameter to my pipeline um if it's three times zero I use the news tag from the Azure container registry but I can also use a specific version so in this case I want the newest version and run this and we can also take a look at this pipeline foreign for this pattern I use a couple templates um just to make the the pipeline smaller so what we can see here is the the first template is I could configure git so what we do here is we configure um the git config so we said a user and an email address I think yeah here the email then um because we're gonna commit changes uh to our branch and so we're gonna have a user doing this change commit the next step is we check out um our branch then here we have um the if so if the parameter is set to three times zero uh we go with the Azure CLI to the Azure container registry and read the new stack and write it into the variable tag or if it's uh not equal to three times zero then and the last step is we do a search and replace so we use regex we look for the the tag inside the valley sample file and then replace it with the value we have in our tag variable and lastly we commit the changes so that's what's happening right now and here you can see that he has a new container being created it's pending and from here on we have the container running and um as this container was running the old container got terminated so now we have our new version running inside the kubernetes cluster without any downtime for the users and if you go back to our API and we execute it again we can see that we have here the the new version or the new message we configured before so the deployment worked and I didn't"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:45:40",
        "seconds": 2740,
        "text": "back to our API and we execute it again we can see that we have here the the new version or the new message we configured before so the deployment worked and I didn't have to have any access to the kubernetes cluster so the last thing I want to show you is uh the Repository so as I said um there are two parts in this repository once is the yaml file that says where the helm chart is located on what branch and the second part is the helm chart in case uh if you don't know Helm a Helm is a packet manager and it just helps you to take care or to to manage all the files you need to deploy application to kubernetes so inside this templates folder I have all the files that my application needs for example I have the deployment um with Helm you have this double bracelet um it looks terrible if you have never seen it before but it's very easy Once you used it and you can pass a variables you can create Loops so it's very powerful compared to normal yaml and the most interesting file is this value is file and what this file does is it contains all your variables and these variables are passed into the the files so as I said I've hit the tag and what the the pipeline did was it looked for this tag and replaced the value with the newest version so if you look at the git history we can see we had the version uh dot 41 and now we have the version.42. and that that's how we achieved the automated uh deployment okay so we are almost running out of time so let's go to the um other useful extensions um when you have a system where people are um using it especially sitting in it and being transported security is very important because you don't want to have a door open while they are somewhere high up or just two vehicles running to each other so we looked into using Azure keyboard as our secret store the Azure keyboard is matched by Microsoft it allows me to configure who has access I can create updates I have audit logs so everything I need to have my passwords connection strings and so on uh um save securely on the outside if you use kubernetes and secrets in kubernetes they are not encrypted they are just in plain text and they are not very secure so we wanted to use Azure keyboard with our kubernetes cluster and with the Azure keyword extension uh what this extension does is it redirects the request for a secret from The kubernetes Secret store to the Azure keyboard so the developers don't have to change anything in their application um it's all hidden away in kubernetes and with this the developers don't have to change anything but we have all the advantages and security from Azure keyboard and an approach how you can match this would be to have another Pipeline and this pipeline writes secrets in the Azure keyboard so you always know um What secrets you have and you could also create um for example automated automated updates that every week you write a new secret into the Azure keyboard and then the application grabs this new secret and uses it and here you can see um how this works so we have here in a very simplified way with here um our application actually with here our application and the application wants to access secrets and the Azure extension redirects it to the Azure keyboard and user station keyboard as The Secret store so um like here our application doesn't have to change anything and also doesn't need to know anything what's behind going on so it's very easy for the Developers another important feature for probably all applications is monitoring you want to know what's going on with your application with your cluster if you're running out of CPU of hard disk whatever and in best case scenario you get a notification when you see something is about to go wrong and you can fix it before it goes wrong and your customers don't even see that something went wrong and that's again uh an uh"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:50:45",
        "seconds": 3045,
        "text": "notification when you see something is about to go wrong and you can fix it before it goes wrong and your customers don't even see that something went wrong and that's again uh an uh extension in Azure Arc it's the Azure monitor extension and what this does it installs the Azure monitor agent inside the kubernetes cluster and this agent gathers information um about metrics logs and sends them to azure and this again from inside the cluster outside so you don't need an inbound connection to access the logs and then you can use Azure monitor as if you were using Azure services in Azure monitor you can create dashboards uh you can create alerts you have container inside so you can see exactly what's going on with every container and it's very easy to use and very helpful so here you can see in our Azure Arc instance I've installed the extension and now I can already see what's going on everything you can see here is out of the box I didn't have to do anything and what you can see here is at around 9 30 the CPU usage suddenly skyrocketed from around 10 to 75 and then over 80. and I also had an alert so um the support team got an alert message when it reached the 80 and so they could react quickly look into the problem and fix it and you can see it never reached 100 percent the SARS may have been a bit slower for the customer but it always worked and at 9 38 the problem was resolved and it was back to normal usage and here we also have like what you can see here is on the Note level so it's on the the machines itself and here you can see what's happening inside uh the container so what you can see here we have the the customer API container and um on the right side you can see the usage was very high so there was something going wrong so the support team fixed this problem and afterwards the usage was quite good again so this was everything about our proof of concept um so you can say it was very successful but we also wanted to look into the future what are other options we can achieve uh with Azure hack and Azure Arc is probably the most powerful service of azure so there are so many more features and in the last couple of minutes I just want to show you some features that are also available and are quite interesting um Azure Arc is flat split in different categories and the first character Decor is the so-called Azure Arc enabled infrastructure what this does is it allows you to manage your VMS for example um or your your Hardware more or less so you can match VMS you can match kubernetes cluster you can use Azure stack HCI that's a way to run Azure services on premise it's built on Windows Server 2022 um but it's a bit like having your own Azure portal inside your data center and then the more exciting services are the edge Arc enabled services and this feature allows you for the first time to run certain features outside of azure for example you can run Azure app services or logic apps outside of azure so you can say I want to have a website for my company it's only internal and I can use Azure app service to run it inside my data center so I don't have to care about setting up a web server managing everything I just use the app service Microsoft takes care of it for me and the probably most interesting features for the future are the Azure Arc enabled data services this allows you to run Azure data services on your on-premise kubernetes cluster so for example you can have Azure SQL matched instance or postcard instance running inside your kubernetes cluster this means that you can use Azure match services but don't have to give your data to Azure it always is inside your um facility and also you can do machine learning again you could keep your data on premise and just use Azure machine learning on it you don't have to upload it to the cloud all the services need a kubernetes cluster so um you have to know the basics about kubernetes and"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "00:55:49",
        "seconds": 3349,
        "text": "premise and just use Azure machine learning on it you don't have to upload it to the cloud all the services need a kubernetes cluster so um you have to know the basics about kubernetes and as said before you can bring these Azure services to your on-premise data center and especially in the EU we have quite strict laws about data protection who can access your data and there are some legal problems uh with cloud provider because the American companies so by law they are allowed to access the data but by eulog they are not so it can be quite complicated but if you use these Services you have your data on premise and Microsoft never has access to them so um this could open the door for many companies that say we want to use it but our legal team doesn't allow us and here you can see an overview of what's available so you can see it's a very massive service there's so many different features you can use and the most important thing to remember is here at the bottom you can use any infrastructure so it can be on premise it can be VMware it can be Amazon Google Ali Cloud it doesn't matter once you install Azure Arc you can bring Azure services to your infrastructure foreign the reason why you might want to use Azure match Services is because Microsoft takes care of everything for example if you install a SQL Server on-premise you have to make sure that you have updates installed you have backups make sure of the resources you need monitoring so it can be quite time consuming and you also have to have quite some skills and if you use a match instance Microsoft takes care of everything so you always have updates installed Microsoft creates the backups and also gives you a kibana and grafana instance so you can see kibana here that's a dashboard where you can see all our logs so out of the box I can see already what's going on inside my SQL Server and the same with grafana everything you can see on this dashboard comes out of the box so I can see uh what's the CPU usage of my SQL Server how many transactions do I have so it's a very good way to get started a popular tool so manage so while I change something it's a couple clicks and I have a new dashboard um as I said before you need to kubernetes to run these Services um it runs in its own namespace so it's separated from everything else and you can again install it with the HCL or the Azure portal if you slash silai it's quite simple so what you do is you provide a name a namespace and that's basically it and then it asks you for a username and a password to sign in and then it takes around 10 minutes and you have a full-fledged database running the biggest advantage of this is as I said before you are the owner of the data it never leaves you on premise you know what's happening with it and the only information that's sent to Azure is some metadata for billing for example how many CPU cores are you using and for how long is the service running and um I said before for the first time you can also use Azure app Services Azure app service is one of the oldest services in Azure and probably one of the most powerful and underrated ones because it's very simple uh to run apis websites and so on but it's very powerful like it says Auto scaling load balancing Microsoft takes care of DNS management you get a SL certificate you can deploy directly from Visual Studio uh so it's very easy to get going and um with this service you can use it the same way as in the cloud but just on premise so also Microsoft takes care of the DNS entries you get SL certificate if you want to have it public uh you can have load balancing so you don't have to manage anything and the best thing about it it's currently free um the reason why it's the case it's still in preview uh so there's no information about pricing right now but along the time you can save with not having to set up a web server configured and so on um it's probably worth it and the way it works is you create a custom location and then you"
    },
    {
        "speaker": "",
        "title": "Bring DevOps to the Swiss Alps",
        "videoId": "YcQt1svdu7I",
        "description": "This is a recording of the December 14, 2022 meeting.Most companies use cloud services for their projects nowadays. These companies leverage the seemingly endless scalability and the elastic pricing model of the cloud. Nevertheless, many projects still cannot use cloud services for various reasons. These may encompass regulatory restrictions, data protection, or just having an existing on-premises infrastructure.While these are all valid causes, why not combine an existing on-premises infrastructure with the power of the cloud? This is where Azure Arc comes into play. Azure Arc allows to project on-premises infrastructure into Azure and then apply Azure services like Azure Monitor or Azure Policy on the on-premises infrastructure.This session shows how a Swiss company uses Azure Arc to manage an on-premises Kubernetes cluster. Using Azure Arc enables the development team to leverage the power of the cloud and provide a streamlined DevOps process. All this can be achieved without the cluster being accessible from the internet.About the speaker:Wolfgang Ofner is a Microsoft Certified Trainer and works as a Senior Software Architect for Azure, DevOps, and .NET solutions at bbv Software Service in Zurich. He is passionate about software architecture, Kubernetes, cloud technologies, and DevOps.In his free time, Wolfgang writes on his Blog ProgrammingWithWolfgang.com.",
        "start": "01:00:55",
        "seconds": 3655,
        "text": "can save with not having to set up a web server configured and so on um it's probably worth it and the way it works is you create a custom location and then you deploy this custom location so since you're almost oh we are already out of time so gonna quickly show you a screenshots how this works so the Azure portal if you open the web service you have to select a name a resource Group so basic information and then where you want to deploy it um for example here you have a couple Canada um you have the us but once you have a custom application created you can select this custom location so in this case it was running on a Raspberry Pi in my basement so I called it a welfare basement and once you select this custom location you can see there's no app service plan that service plan is used for billing it gives you a certain amount of resources and then you pay for it monthly but since I'm using my own infrastructure I'm not using Azure resources so I don't have to pay for it and once it's deployed I can see here on the left I got the public URL and I can configure a custom domain SL certificates I can scale um so everything quite easy and with just a button click and if I click on the URL I can see it's running um on the internet I have here a valid Excel certificate and I can deploy my application there okay and to round it up um a proof concept was in my opinion very successful we achieved everything we wanted to achieve we had a modern workflows we had secure deployments secure access and it also showed Ash Arc is a very powerful service and in my opinion it's a major Focus from Microsoft so if you go to uh ignite or any other Microsoft conference you always hear something about Azure Arc to manage services a lot of knowledge about many things for example kubernetes is always at the base of your services so you have to know how kubernetes Works how to access it you have to know uh like firewalls networking for develop for deployments I don't have to know githubs it's not easy to get started um that can be quite buggy for example the Azure app service extension is still preview but it's sometimes unusable and I was writing about it on my blog and I had uh some reader text me if I could help them because it's not working for them but it was just not working and I said before documentation really needs Improvement and can be quite frustrating and here I have a couple links for you um so the slides they're on my GitHub but I'm also gonna send them out on Twitter Twitter later then I'm currently working on an HR series on my blog and also on YouTube um I haven't done uh any work on it in the last couple of months because I just moved to Australia so didn't have time but starting in January I plan to continue this and a couple more links and that's it so thanks everyone and if you have any more questions I'm happy to answer yeah meet here uh thanks very much Wolfgang that was uh a really great Glimpse at the the future uh it's uh you underscore how Arc is uh Central and how um you know kubernetes uh is taking on an even larger role in um uh you know probably more so in all of our futures does anybody on the call have um any final questions for Wolfgang yeah I have a question um Wolfgang this is a beautiful system uh this was a prototype that you made um this was a prototype so I worked as an Excel contractor for this company because they needed help with the know-how and just get new ideas how it could work and uh my contracts uh expired after the proof of concept was done so I can't tell if they implemented it or if they went another way um in my opinion it would be a great solution but um it's their decision so I can't tell uh well I can tell you I work for different company um it's a company that builds machines and um they go the same road route so right now I'm also building uh like a concept to bring the machines to the cloud to have Smart machines and we also go with f with hasharc because many of their customers are quite conservative they say we don't want the cloud we don't want internet connections we have to be highly secure and with this approach we don't have any connection inside the network so they can match the firewall and everything is secure but you can still use Azure services so we have the power of the cloud but the security from on-premise are those oftentimes when you deal with Hardware you have to have real-time systems is this is this is there a component to this because we never actually saw what the actual program how it interacts but is that is there a module of this that is real time uh the machines are real time but the approach because that we have the machine with the real-time Linux version and then in our kubernetes cluster Services running and the machines call the services for example um what should I build next what part or what is their configuration I should apply next so our kubernetes class is not real time amazing very nice just a quick question so so is azure art basically uh like an SSH agent that you just deploy in the on-premise systems um it works with https but uh a bit simplified yes you have the ash Arc agent inside the kubernetes cluster and that just sends information about uh over https to azure okay thank you okay well uh thank you again Wolfgang uh we'll uh we'll leave you to go have breakfast and uh and thanks everybody for joining uh this is our last uh session for 2022 and watch the usual spaces for announcements for 2023. have a great uh holiday everybody and uh see you next year thanks again Wolfgang thank you for having me see ya right "
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Jason Haley: Getting Started with Azure Kubernetes Service. This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com). okay did the little thing come up saying it's been recorded there we go cool okay so it's been recorded um okay so tonight's topic is getting started with azure kubernetes service i've posted a question in the chat uh if anyone actually has questions they're looking to get answers to tonight go ahead and post them and then we can make sure that we get them covered or at least address them uh i've given this talk a few different times and i've seen several different getting started uh about kubernetes or getting started with azure kubernetes so i've tried to structure mine a little bit different i won't actually be going to the command line very much but i should still be able to show you with most of the tools that i use on a day-to-day basis what i need to do or what you need to do in order to get started with with kubernetes service there's a bunch of other um videos and um tutorials oops i was going to switch screens but i guess not let me switch my camera around here so um let's get started so the the agenda's uh been moved around a little bit i've given this talk uh i don't know three four times maybe maybe half dozen at this point so it's always different um i've changed it a little bit this last rendition for the the code camp up in new hampshire because i needed to fit it into an hour tonight we don't have that time box of an hour so i can actually spend a lot more time in the demos which will hopefully you'll get more out of it for spending time in the demos so i've structured it so that all of my demos kind of piggyback off each other which helps with the time i'll start out with some theory and basics with the the containers in docker then i'll show you some visual studio tooling because i use a visual studio uh visual studio code also has quite a bit of tooling around docker and kubernetes but i'm not going to get into that tonight it pretty much compares it's it's looks a little bit different and you access it differently but it compares feature wise but i won't be showing that then we'll talk about some of the high-level kubernetes stuff because kubernetes is so deep there's there's really little you can do in a part of a two-hour conversation let alone um anything shorter then i'll talk about helm and how it can be used azure devops which is that that's the ci cd pipeline that i'm most familiar with getting uh projects deployed into kubernetes and then finally we'll land on azure kubernetes service so all of these other things are pieces and parts of what you're going to need to know to get kubernetes into production in the real world so that's kind of what i've structured this talk for things that i have learned along the way and the things that i found useful and there's a there's a lot of resources at the bottom of this at the bottom of this um uh powerpoint deck so i'll i'll post this online i'll put a link to it in the meetup so that you can download it afterwards to get all the resources but each of the each of the sections i've got a resource list that goes along with each section so several good books and videos and things that i found useful in learning these topics myself so i'll go ahead and get started so container and dockers oh and i'm gonna stay out of the presentation mode because i really do plan on spending more time on the demos in the presentation mode and i just get confused with the presentation mode quite often with the sharing sometimes it just doesn't do too swell so you get to look at my deck and uh you'll see that whenever you do so i'll link the deck and whenever you download it you'll see that several of them have quite a few notes at the bottom with additional resource links and just notes that i've taken given this presentation so containers and docker chances are pretty good let's see how many people we have on we have uh 20 people on so the chances are pretty good that you all have heard uh a bit about containers what they're for what they are and and you've most likely heard them compared to virtual machines so i'm not going to spend a ton of time on this but this is how most people explain what virtual ma what containers are they say oh well a virtual machine virtualizes the hardware where the containers virtualize the os and what that really means is when your application that so let's take for example a web application that has some services behind it so you've got say two things running and on a in the vm world you would have the web application on once one vm and then if it was a web api possibly on the same vm or possibly on the other vm if as soon as you try to put multiple sites on one vm sooner or later you're gonna run into that problem where they share a dependency but one of them has got a new"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:05:06",
        "seconds": 306,
        "text": "or possibly on the other vm if as soon as you try to put multiple sites on one vm sooner or later you're gonna run into that problem where they share a dependency but one of them has got a new version and the other one's got the old version and when you start doing cross-dependency issues and sharing of dependencies you get surprised when the latest fix that you put out actually broke something else you know it's like putting your your your finger in something i'm sorry my alarm's going off here to remind me to start the uh um the you know you put your finger in one place and water starts coming out somewhere else so with vms you kind of ended up moving to having one vm per application which is kind of expensive and that's what's showing in this diagram is you've got this extra layer that's called a guest os so the hypervisor was on the hardware so that allowed you to run multiple vms on that same hardware it was great it allowed you to utilize the hardware more but it's all the resources that that os is taking when you start stacking one only one app and a vm starts to add up especially if you want to get the most out of your hardware so the cool thing about containers are they don't have that extra layer of the os so all those cpu cycles and memory that that os is taking up and not to mention the disk space isn't necessary to duplicate across whatever's running your container the container itself is really it's like a zip file system of what is needed to run your application so you can have multiple containers running on the same os and all of their dependencies are going to be contained within them in themselves so they're not going to step on the other application that's running on the same uh on the same machine so that and then kind of high level is what containers are it's it's this phrase up here is kind of how i've come to think about it you know they're just isolated processes running that zipped file system of your application running on a host machine as opposed to a vm right being a whole virtualized machine with all your files spread out across the file system on that machine so kind of a long way of saying what containers are but the chances are if you're doing anything with containers you are doing it with docker it's not the same across the board there are multiple docker um competitors uh there's more now than there used to be but the the playing field that we're looking at now docker is really the one that revolutionized um the ability to create containers and not um because containers were available uh for linux long before docker or the equivalent um functionality that containers utilize was available in linux long before docker came along but what docker did is they they not only made them easy for just everyday people to run images and have all that isolation to be able to pack more stuff on each individual machine they made it cross-platform so not only could you do it on linux you can now do it on windows and mac and that's where i believe the growth really took off because then it wasn't just people running on linux machines it's now people running on windows machines because you could run a linux vm on a windows machine but you can now develop something on a windows machine that's going to run on a linux machine and mac the same thing so docker really brought this to the mainstream and and that that ecosystem is constantly evolving and um there of course these days with anything that really gets um popular you're going to get competitors in the environment so what happens when competitors start showing up with competing container run times and container images because you've got you've got two parts to the container aspects you've got the actual image that has your application but then you have that runner that knows how that run time that knows how to utilize that and run it as an application so um docker spearheaded the initiative to create this open container initiative which kind of wanted they wanted to standardize a container run time and image so that when other competitors came into the point they kind of had to follow the lead that they had started um that's kind of the viewpoint that i see on on it but now it's it's it's made it so that it's standard and that one image that you create on one runtime or one tool set to create the image can most likely run on another image as long as they meet the the open container initiative so they've they standardize it as well as really brought it to the mainstream and if you're doing um container development on windows you're most likely doing it with docker desktop once you install it it's going to show up as an icon down in your tray"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:10:08",
        "seconds": 608,
        "text": "it as well as really brought it to the mainstream and if you're doing um container development on windows you're most likely doing it with docker desktop once you install it it's going to show up as an icon down in your tray i'm not sure if the sharing shares my tray but whenever you open it you'll get this little application showing up and some settings and then we'll see this a little bit later in the um the talk here but docker is the one that really made the containers uh mainstream now the thing that i kind of brushed over with containers is it you get this image and it's it's sizable but it's stored in layers so that you get a pretty efficient caching um on the layers so it the the idea is you're you're building this layer starts out with the the os that you want to virtualize more or less and then all of the things that you get installed on top of that so the idea is that that base layer that you started off with doesn't change very often but your application that you layer on last will change every now and then so it'll be that last layer that needs the the latest download when you put a new copy of your image up there so the the caching is really efficient so you don't see that that 250 megabyte image has to be pulled every time so if you're pulling the image multiple times on the same machine it'll just utilize the cache and that comes along with okay so you're pulling these images or this this tarball or zip file of your dependencies in your application it's rather sizable where do you store that you need to store it somewhere else so that you can pull it into your application where you're going to run it that's that's what they call a container registry and there are multiple flavors you can have a public or private registry the most popular one of course is docker hub and then their azure container registry is a private hub so that you can put your own assemblies in there and you're going to want your you want you're going to want to use a container registry that's close to where your production environment is so that because they're not small and like i said once they you pull them across the wire once the caching is going to kick in so you're not going to be pulling them across every time you spin something up but if you bring up a new node or you bring up a new environment you wouldn't you don't want to be bringing them all all the way around the globe to land in your production so you'll want a container registry in the same data center that your production is and with azure container registry the higher level i think is the premium level you can you can replicate so if you have multiple data centers you can have your containers hosted in multiple data centers around the world as opposed to having to have a single one and then copy things over yourself so that's container registry that's kind of the high level docker container basics that i wanted to highlight now let's look at what you can do in visual studio 2019 in an example you can do quite a bit with visual studio 2019 and not have to fall out to the command line and especially if you utilize the docker hub app on your machine there's very little you actually have to do on command line so let me show you example of that so let's go to the demo slide here so let me open up a new visual studio do we have any uh questions before getting into the demo no i don't see any all right cool so let me just do a new project i'll do a simple asp.net application just to show you the example here also point out so you could enable docker support as you're creating your application here i'm not going to because i'm going to show you how to do it with an existing application so i'm just going to create this but once you enable it you're going to need to then choose do you want a linux container a windows container because they're not they're not compatible you do have to make that decision do you want to use a linux based os or a windows base os and the biggest difference is going to be the size of the image the windows images are so much bigger than the linux images so this is your typical asp.net core application out of the box let me show you it running here there's no docker goodness in it yet we're just going to see an application come up this is the command line so we'll see what comes out to the command line should see some trace statements and then a web application pop-up typical stuff for an asp.net application so now let's dockerize this thing visual studio makes the starting point really easy and getting into the more advanced is going to kind of be up to you to learn what you'll find to be pretty much fooling around with the docker"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:15:11",
        "seconds": 911,
        "text": "so now let's dockerize this thing visual studio makes the starting point really easy and getting into the more advanced is going to kind of be up to you to learn what you'll find to be pretty much fooling around with the docker file and learning how to do more advanced stuff whenever you need to so it's asking me which os do i want it to use for the containers and that's it it added a docker file so if i open the docker file and the docker file is pretty much a manifest that dockers build tools will utilize to create a container image and it's uh again this is the stuff that's not going to change very often you put things that are pretty solid at the top this is the base image that we want to use it's a buster slim image which i believe is boontu or debian linux um so this is this is the base image that we're going to use and you can see base is used again at the bottom here so this not going to change very often this will change because this is taking our project uh restoring it so it gets all the dependencies and then it builds the project and then it does a publish so that we can narrow down just the output that we want running in this image and then it copies the stuff from publish here that was the output of our build onto the image here so that's that's the final this is a i believe they call this a multi-stage docker file and they used there used to be this so the docker file syntax has changed over the years but this is the most common now because the idea is you want this container the final container to be as small as possible because it the bigger it is the the more seconds it's going to take to spin up and no matter where you run it so you want it to be small and compact as possible and it takes less memory it takes less resources in general so i'm not going to get into this but this is where you're going to spend most of your advanced uh research if you will is going to be whenever you need to like add a dish say say you've got a pdf generator and you're doing invoices you're going to need to install fonts on the linux file system so you're going to need to learn how to do that and then you know google for that do a bunch of digging and it's always case-by-case scenarios but that's that's when you'll find that you do the most with this doctor file so this is what will actually end up build the image some things that visual studio gives us because i right clicked and said dockerize it is it gave us the docker file if you look in the project file you'll see that it actually set a docker file context and it sets the the os in the project file too now this the dockerfile context is going to be important to you if you've got a file structure a few levels deep so say i this is a big solution and i've got a couple layers deep but i have dependencies that need to be copied in to do the build this is where you would want to play with that docker file context and as you start to learn to build docker files and all that stuff you'll learn more about the the context for the dockerfile contacts but this is this is important i often have to change this because um dependencies that we typically use are a couple layers deep so i'll have to change this to like dot dot whack dot all right something like that but i don't i don't need to do it for the simple one but that's that's nice that they put that in there with they didn't used to put it in the project file you had to know to add it um so that's one those those two things that they add for you um they add this um ability to debug the docker container it's using visual studio and that surfaces itself in the properties here so properties lunch launch settings it added some stuff to the launch settings here so this got added um that's what allows this button to show if i run it and you want to really understand what it's doing for because it's just using the docker command line under the covers all of this stuff if you look in the output let me pull this up here if you look in the output window i'm too slow in the output window and choose the build uh which one is it build package managers one of these guys container tools okay so it's container tools it will show you as if you were building this on the command line here's the docker file so here's docker build so this is the command that it's sending off to the docker image so this you could copy this and do it on command line and it would give you exactly what the visual studio is doing but you'll see they send it quite a bit of"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:20:13",
        "seconds": 1213,
        "text": "command that it's sending off to the docker image so this you could copy this and do it on command line and it would give you exactly what the visual studio is doing but you'll see they send it quite a bit of stuff and this is this is the magic that allows you to actually run it in docker so we've got the we've got the web app up running you can see it's using a different port than i i it was coming up earlier i believe it was 5001 earlier by default when i was just running as a.net core exe on the system it's running as a container now and this container is mapped it has a volume mapped which a volume is really more or less shared storage that's connected to the container and that shared storage is the file system that i have for my web application and i'll i can prove that here in a second so but if i go to let's go to pages oh boy i'm not super up to date on this stuff so let's uh go to the index this is razer file i'm used to the the old npc stuff so if i go back to here and i hit refresh it hits a breakpoint even though the logic is actually executing in the container i can step through this in visual studio and that's that's useful it does come with some caveats which i'll get to but oh wait let me show you the files prove to you that the file system is actually on my uh so let me sh let me open this up my explorer here so file system is here all right so this is the file system um i'm just going to add a text file at the the root level but first of all let me show you the containers window because this is this is really the killer app for visual studios container tools is this window right here but and and um you'll find whenever you're fooling around with docker files if you have to do anything outside of this simple template that they give you when you're when you're beginning you know because you can see we're doing some copies we're uh we're doing some building and then you know what files get created are there any extra files there you know you might be wondering what's actually in the container and then you you do this copy over to the final and you may wonder well did the file that i thought was going to be in a certain location did it get copied that's what these that's where these tools really really come useful this little tab right here says files it shows you the file system of the container so you can see right here it says app this is my app this is the directory mapped to this you can see it actually has a cs proj file solution file those wouldn't be published in this release publish here so let me prove that so if i go and i say let's do a new text file i'll just do a blank text file and okay so that is there so now let me refresh the file system and here so say what's in this container and i open app now that new text file is there so it is this is not the files that are zipped up into a typical container this is a shared volume using docker volumes and the ability to access that stuff so that they can allow you to debug it in visual studio so this is the actual file system on my machine but it's running inside of a container a little complicated um but um it's very useful um if you find a file in here actually since this is my file system's not doing much good but if you if you're really debugging an image which which i can show you you can download these files or you can open these files and what it's going to do is it's going to copy the file out of the container and then open it up in visual studio if it can because with the docker command line you may not notice it know this but you can copy files out of a container or into a container with command line and that's that's all it's using under the covers there's also a source directory down here it's mapped pretty much of the same directory so whenever i build a real container a lot of this stuff won't be in there but like i mentioned if you're doing like a pdf generator and you need to make sure that certain fonts get installed on the linux image in a certain location being able to navigate the uh this file system is super useful in that container because oftentimes you're trying to troubleshoot whether or not it got installed or if it got installed in the wrong place and that sort of thing so this files tab is super useful you can also see the logs and this is going to look pretty similar to what it was when i open it up in dotnet asp.net any ports that are exposed uh using docker you can click on these links it'll open the browser for you some"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:25:15",
        "seconds": 1515,
        "text": "going to look pretty similar to what it was when i open it up in dotnet asp.net any ports that are exposed uh using docker you can click on these links it'll open the browser for you some of the uh environment um variables not all of them which is kind of odd and i'll show you you can also terminal into the container so here's a terminal in the container and see these environment variables down here if i say print pnp print it would help if i spell it right you can see there's a few additional environment variables in the container that aren't surfaced in this tool but a lot of them are really the running environment specifically so it's not that big of a deal but they're not all surfaced here but it that just goes to show that you can terminal into it and do whatever you need to do which is another very useful aspect to it you can attach to a process running in a container if you need to you can remove the container you can stop the container you can look at all the images installed on your machine and then these are just the layers that's that's the highlights of the container tools and well let me show you this other one so once you get a container you're going to then need to get into a registry and if you don't have your devops pipeline set up yet you may just want to get it out test things out and you know to prove the point so another thing that container tools do is they add the ability to um deploy to a container registry so part of the deployment for a project that's been added had the docker files the docker tools added to it is you can publish to a container registry so if you walk through this you can go to docker hub you can go to azure container registry or some other docker container registry and then it'll publish that out on your your registry it'll then it'll rebuild the image and then push it out so that's that's also another useful tool that they added to your your tool set an additional tool that we'll get back to this this project later on in the talk so any questions so far we have one question from andrew okay so what kind of skill set list or skills or things do you need to manage this do you recommend a job role or person maybe idea for someone moving from on-prem to cloud um so so far with what we've covered um it's going to be someone who sees the value of containerizing their application this could be a developer it does seem like in most cases it's the developer that's doing this portion because it's their application that's getting put in the container and they can test it running on docker on their system this wouldn't necessarily be a devops person or an ops person it would definitely be a developer that's containerizing their application now as we get to the tooling later the devops pipelines that could be a devops person or an ops person that manages the devops pipelines but they're going to need to closely interact with the the developer as to what needs to be built any special stuff that needs to be any special sauce in the container and that sort of thing so you've been looking for okay yeah yeah so devops people um could play a large role um but oftentimes it's like devs and my experience is devs do kind of tend to need to be full stack no matter what even if they do specialize uh but different shops are different um so yeah devs is my experience devops people will definitely help with the same sort of thing but into the kubernetes cluster itself i have two questions for you i thought you mentioned docker's cross platform then why do you have to choose os between windows and linux good question okay why would you use windows os if image is so much larger than linux one okay so good questions very good questions um so with the the docker image having to choose the base image flavor whether it's linux or windows it used to only be linux you didn't have a windows choice but then windows became available and now you have to choose between the two the difference is it's basically they don't expose the same features in the os that's being exposed so containers really virtualize the os so if some features in windows don't exist in linux or vice versa they can't make a container actually cross-platform docker is because docker runs on linux runs on mac runs on uh windows the"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:30:19",
        "seconds": 1819,
        "text": "exposed so containers really virtualize the os so if some features in windows don't exist in linux or vice versa they can't make a container actually cross-platform docker is because docker runs on linux runs on mac runs on uh windows the the docker engine itself but the docker engine itself also has two modes let me see can you guys see my tray when i open it because i'm not yeah i'm not okay cool so if you right click on it you'll see that you have to switch to windows containers and then once i switch to windows containers it will then um ask me if i want to switch to linux containers so it gives you the the opposite option it's just a switch but you do have to choose which mode you want to be working and it's all because the underlying operating systems are so different and you'll see this also with windows subsystem for linux the the wsl or this new terminal windows terminal it also has moved backwards because of the same problem before the the wsl version one tried to do that mapping windows and linux actually it mapped linux calls to windows calls so that they would more or less have a linux translation layer between the two and they found that it just didn't work it wasn't optimal so with this the wsl2 it actually uses a container under the covers of a real os a real um linux operating system runnings because so they've they've realized that it was way too slow it was a very maintenance or i should say if linux pushed out a new fix well then that means they now had to add that additional call in that they didn't have to manage before because they were doing that translation to make the operating systems answer the same calls so we still have that difference they definitely aren't equal so i think that answers both of them okay so there are so there are really good reasons to use windows over linux linux by far is going to be your fastest cheapest option not everything runs on linux though um it's great to be able to write c sharp code and now with dot net 5 you can do your whole net framework c sharp code compile it and run it on linux but there's old net code that won't run on linux so it's got to run on a windows server image or one of the the smaller windows server images and those suckers are big and they take a lot more resources than linux just because because it's windows but okay good questions very good questions okay so kubernetes so kubernetes solves the problem that you start to get as soon as um you have multiple containers running so you know like what i just showed you we got a container up and running uh in my dev environment pretty easy and i could easily run that in docker on my machine or on a server but there's other things that you need to handle when you've got a production application going it's like what happens if the container goes down who's watching that so if you need to restart it okay what if you want multiple versions so that you can do a load balancing and spread the load across multiple instances for scalability how are you going to do that so these sorts of things that you start to get whenever you realize what it takes to be production worthy is where a container orchestrator comes in and that's that's really a system that's that's designed to provide these five chunks of functionality here so it it first and foremost is a clustering technology that will take multiple vms and pretty much provides you this pool of compute that you can run your docker containers on or containers um and you might want to specify some rules well you don't want this you don't want this backup say you have a site that you want three instances always running for high availability and you're going to provide a load balancing across them and you may want some rules and say okay well i know i have three vms behind the scenes i want to make sure that one only one is running on a specific node so i want three of them running but i want them spread across each nodes i don't in case one nodes goes down you know the site will still be up rules like that are production rules those are things you will want to do in production and that's one of the things that orchestrator will do for you which that gives you the ability to do high availability because you're able to have multiple instances running and load balancing on top health monitoring is important because if a container goes down you know it's like if a tree falls in the wood who hears it well if container dies who's going to know that that container died to start another one or you know troubleshoot what's going on so you need some health monitoring in there and along with health monitoring goes the life cycle so when you start up a container you want it to be"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:35:21",
        "seconds": 2121,
        "text": "going to know that that container died to start another one or you know troubleshoot what's going on so you need some health monitoring in there and along with health monitoring goes the life cycle so when you start up a container you want it to be able to go through certain life cycles because you may have maybe maybe you have an application that really is needs to be really performant so the first thing it does when it starts up is it pulls a lot of data and caches it locally so that it can behave really quick and you don't want it to actually be available to any traffic until that cache is ready to be used well then you need the ability to tie into a life cycle so that you know you know is the cache ready yet you know is it ready to be put behind a load balancer and those sorts of things so you need a life cycle to go along with these containers running not just on or off you need a life cycle and of course when you have more than one of anything you need to be able to communicate between the two and it doesn't do you any good if you can't communicate in and out of the cluster so you want to go in between the pods or containers in the cluster and you want to be able to go in and out of the cluster and you know there's a lot of stuff that goes with these five pieces of functionality but these are the main pieces that a container orchestrator is going to provide for you and that's what kubernetes is it's a it's a container orchestrator some of the highlights if you look at the kubernetes web kubernetes website it's going to say that it's the system that provides scheduling for compute so like i said it's a clustering technology so this scheduler you know one of the presentations that i've seen says that the schedule is like a maitre d when you go to a restaurant you walk up to the the little desk and he asks you how many is in your party and he finds you a table to sit at and that's what this scheduler does is it will look at what resources your application is requiring and then it will look across the compute nodes to see where you would fit into the mix and whether if you can't it will then go into a pending state and not get you scheduled and there are other things that could be done behind the scenes to free up room so that you can be scheduled but that's what the scheduler does is it finds a place for that pod to run when it shows up on the kubernetes doorstep it's self-healing so it has that health monitoring if a pod goes down and it is unhealthy it will shoot it and then bring a new one up um that's one of the huge changes so myself coming from you know pre dotnet.net and all of the deployments being file based uh iis for so many years um you know you didn't blow away the vm you fixed the thing when something went down you fixed it you know you remote remoted into the machine it if you were an automated shop the way you had a devops button that you would push and it you'd fix the code and then it would push the new bytes out but it would be file based going out patching that running instance the biggest difference with container applications are you don't fix the container you shoot it and bring up a new one so if you um have a bug you would fix the container push out the new container and then bring it up in your environment kubernetes if a container is down it assumes that it's a transit transient issue kills it starts a new container if that new container fails it will try it again there are definitely a lot of settings that you can set in there as to how many retries what happens when it fails does it try to restart it there are all kinds of bells and whistles there but self-healing is a huge point self service discovery load balancing that's just the networking stuff that has to you know if any uh framework is going to give you the ability to run multiple containers and give you a production worthy environment it's got to have the ability to discover discover services and do load balancing horizontal scaling is the most natural scaling when it comes to containers because it's not easy once a container gets baked and running um you can't really say oh no you know i said i wanted to have this much of a cpu but now i i need to have i need to change that and make it more there are things you can do but it's a much better if your application horizontally scales it's like if it's starting to get under a lot of cpu usage it can spin up another one so you can set rules and say hey whenever this web server gets to 70 cpu or so much ram or some external metrics so you can set it on spin up another instance and then it can just continue to stamp out and of course you can put rules around that as well but it has the ability to horizontal scaling and it can spin up additional instances whenever thresholds get hit very very useful automated rollouts and rollbacks also really useful i mean we do have our devops pipelines that allow us to do that as well but in kubernetes you know it's right there it can roll back to the previous version and"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:40:23",
        "seconds": 2423,
        "text": "very very useful automated rollouts and rollbacks also really useful i mean we do have our devops pipelines that allow us to do that as well but in kubernetes you know it's right there it can roll back to the previous version and the cool thing about containers are is it's just it's just that name of the container and it will if it already has that old container locally it'll just start it up it doesn't need to pull any new bytes down so you know comparing to iis application where if we needed to roll back and didn't use any of the web deploy features we would have to redeploy that old version so we would have to again push all those files across the wire but with excuse me but with containers you don't have that problem everything's already containerized stuck in that zip file system and you know you only have to tell kubernetes which one to look at and it it will uh roll out roll back um you can you can set a lot of parameters around that too um the default is it will do a rolling update so say you have three instances and you do a deployment rollout it will bring up a new instance of your new version and then once it's up and healthy it'll bring down one of the old ones and it'll bring up another new one until it's replaced all the instances that you wanted running but the caveat to that is that works really well if you have more than one instance running so you if you have two running that's kind of what it's designed for high availability scenarios if you have one running always in production then you're kind of going against what all of the good feature set is built towards so you could have some downtime if you just spin up that one and bring that other one down there could be a window there but if you had two coming up you know you would always have one up and running volume management that's just your storage every system is going to need some ability to have some secrets and configure management so kubernetes does that as well so a little bit about the architecture don't want to get into this too much um it's basically made up of two types of nodes um this is the master node it provides all of your overhead i guess so it's got the api server that is your communication in and out of the cluster logic your controller manage controller manager that is the that's the one that makes things happen so everything that's done in kubernetes is pretty much done by a controller the controller manager is the one that decides which controller needs to actually be doing the work for the scenario that's come up you know did did a job show up that needs to be run did a cron job trigger and need to be kicked off did a new pods show up and need to be scheduled so the controller manager is the one that really drives the logic the scheduler is the one that talks to the worker nodes to determine where the new workload can go and fcd is just the key value storage that the state of the system is stored in the worker nodes that's um what you'll see you actually manage in azure kubernetes service you don't see the master so much you interact with the api server and you can get a lot of the logs of things that are happening but you don't you don't see the other components you basically only focus on the worker nodes uh the working node the worker nodes are connected to the master with this thing sort of called a cubelet and the cube proxy that is the one that deals with the the networking in and out so this is the one the cubelet is the one that connects you to the master and the the cube proxy is the one that deals with the network docker is here in the image it's the better terminology for this would really be just a container runtime because it's a plugable piece you can put in different container runtimes actually docker is being deprecated from kubernetes 1.20 and that may surprise some people but when you start to look into it docker's being removed but that's because docker is a lot more than just a container runtime it's container run in time container d is still going to be there so they've they've just narrowed the surface of what they're using out of docker which which is a great thing um so docker deals with containers but kubernetes deals with pods and a pod can have a pod can more or less uh connect multiple containers so let's talk a little bit about these so some of the common objects so everything in kubernetes is typically referred to as an object or resource these are the these are the most common you're going to see for example for a website or a microservices environment um the pod that's the most basic level of execution so if anything's running in i should say this is not completely true but for the scenario where you want to run your application in kubernetes it's going to be running as a pod so"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:45:26",
        "seconds": 2726,
        "text": "um the pod that's the most basic level of execution so if anything's running in i should say this is not completely true but for the scenario where you want to run your application in kubernetes it's going to be running as a pod so this is going to be wrapping your container with some additional metadata and that's your pod um there are scenarios where you want multiple containers running oftentimes it's like a service mesh which i won't be able to get into or a translator maybe or a logger a logger is off also a common scenario maybe your application um does a lot of work and you want another container to more or less pull the logs out of your application deal with sticking them in storage that way your container could kind of plug and play and your your logger could be more general purpose that you could also use in other pods so there are scenarios where you'd want more than one container but when you're starting out it's just going to be one container one pod so it's container plus metadata about what that is a deployment is a layer on top of that pod so the deployment if you're utilizing deployment object it uses things under covers it's going to utilize a replica a replica set is what they it's a controller in kubernetes and its only job is to keep the desired state of the system that you've said if you said you only want one instance running it will make sure that one instance is running so and the instance in this case is going to be pods so if you say i have a deployment of this web app and i only want one instance running but you want to restart that website well there's no restarting in kubernetes you kill the pod and then the replica set says oh hey it's now zero start a new one so you don't have to say oh i need to do multiple commands to remove an old pod and put a new one and you remove the pod kubernetes just spins up a new one same thing if you have two or three instances say one goes down it would then say oh well there's no there's now only two it they want three so i need to start another one so the replica set is the controller behind the scenes that is watching the state of the system to make sure that the number is running that you want to be running so it's it keeps the desired state going uh another part of deployment is the ability to do the the updates the rolling updates and there there are a couple different flavors or rolling updates one is the one i um i should say there's a couple ways to do deployments of your application out one is the rolling update another one would be where it will bring a new version up uh if you have three instances it will bring three new instances up and then take all your other one down so there's there's different flavors of the update in capability but that's all wrapped in deployment and gives you this extra functionality on top of just a pod because you can just spin up a pod um it's it's pretty much the equivalent of just bringing up a container in docker it doesn't do a lot for you the deployment you bring up a deployment and you tell it what image to do and it manages bringing up the pods the replica set it manages that stuff for you the service is the layer above the deployment because the thing is you know if if you're doing high availability and you say have three instances running you want one endpoint to go to so that it can then balance across those three you don't want to handle the logic of going across those three and if one goes down and the replica set brings up another one you need something that's going to now know what that new ip address is of that new pod that's what the service does for you it it connects the dots of what the deployment does for you and then of course there's there's multiple types of services so that you can surface the ip at different levels but the ingress is the piece that gives you the external access so it sits on the edge of your cluster and is integrated with your cloud providers so in the in the case of azure it's going to interact with an azure load balancer or a app gateway so this the ingress is really that gateway to the external world outside of your cluster okay so any questions before we get moving here i see a few here however all note zero will be linux and then one n would be windows yeah in aks that's that's how it works it works with node pools so you write on that one it makes it easier for high availability configuration okay it makes it okay during updates such as rolling does it have a mechanism to drain running pods before deleting them for example active yes it does so it will remove it from the load balancer and let those connections die out there's also the life cycle of a pod so if you have a container that really or a container in this case that needs to do some cleanup before you want the plug pulled on the pod"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:50:30",
        "seconds": 3030,
        "text": "out there's also the life cycle of a pod so if you have a container that really or a container in this case that needs to do some cleanup before you want the plug pulled on the pod you can do that too you can you can specify that certain things need to be done before your pod says okay i'm all right to shoot at this point so there there are definitely things you can do on that okay so kubernetes conformance this is the reason in my opinion why kubernetes and the cloud has really taken off so there's this idea of kubernetes conformance and what that means is say the cloud provider in this case azure kubernetes service meets a specific level of feature implementation that other conformant kubernetes implementations meet so if you have your application running in azure kubernetes then you can with less effort move it to another conformant implementation versus you know say a custom orchestrator it could be completely implemented it would may not even exist in another cloud provider so the fact that kubernetes has this standard set of features that are available and if it's certified kubernetes then it's it's not completely effortless to move from one environment to the other because like i mentioned on the last slide there are pieces that do interact with the cloud infrastructure like the ingress in that case it's a load balancer the other cloud providers are going to have the same thing and the networking layers almost always uh i would say is always implemented also by the cloud provider because it's their network it's got to integrate with theirs and that's that's just a plugable piece in the kubernetes infrastructure is the networking so um certain things are going to be specific to a cloud provider but the fact that they're conformant means that their implementation is pretty much the same as yours in another cloud provider so that's that's a key thing so uh if you have docker desktop installed you have a version of kubernetes running so let me show you that i have it open here so docker desktop if you go to the settings of the gear here you'll see that on this tab there's a kubernetes you can enable kubernetes and it will have a local cluster running on your machine which is really cool it's only one node so you can't do multi-node stuff and the grand it's on your machine so you may not have the ability to ingress and a lot of other things but it allows you to test your code relatively easily on your local machine so we've got a question here what kinds of factors determine how many containers run in a pod it really depends on what your application needs it goes with life cycle so if you have a web application say and maybe it uses a api and maybe in the iis world you had both of those running on the same machine you wouldn't want them really in the same pod unless there's a security need where you would make you want to make sure that's only ever available to local host or uh for maybe performance or some reason like that you would want those to be separate pods because if you needed to update say the api and not the website you wouldn't want to have to bring them both down so you really want it to be granular in your system sense some of the some of the most common scenarios for multi-containers pods are loggers adapters something that needs to uh logger and adapters are actually often pretty similar there's another pattern called an ambassador pattern where it's actually the opposite of a adapter but there's always specific scenarios where you would want a container running alongside another container it's not very common most likely if the logic is so related that you're thinking about putting them beside each other you would most likely just have them in the same container not multiple containers running in the same pod you would you'd want them separately typically the multiple containers scenarios i see are injected containers like a service mesh will inject a container um into the pod whenever you deploy it so there's this thing there there are hooks and kubernetes that will allow you to inject things uh when they're being created and service meshes are good at that there's a few other instances but logging is the only scenario that i've seen where it's not something that's being injected i have a question price wise when it makes sense from app services containers to aks app service oh okay so app service containers so price wise that's a different story i wouldn't necessarily"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "00:55:32",
        "seconds": 3332,
        "text": "being injected i have a question price wise when it makes sense from app services containers to aks app service oh okay so app service containers so price wise that's a different story i wouldn't necessarily say it's um a price thing we'd have to look at that but it's more whenever you have more than one app it's a lot easier to maintain them when they're all in kubernetes versus having them maintain multiple app services um you'd have to kind of price out your scenario to see how it would work out for you because hardware is also different because some applications need more ram than they do cpu some need more cpu than they do ram so it is kind of a goldilocks that you have to figure out what works best for your application and then of course once you figure that out on vms you could then understand more of whether or not app services is more relevant versus you know if you're just running one container versus a cluster of containers so it's it's all case-by-case basis if if you have a website that uses microservices behind the scenes i would say kubernetes just makes more sense you may still want to use app service to front the micro services in the back that's that's perfectly okay too so it is totally uh case-by-case basis no clear answer on that one okay so helm helm is a package manager for getting your applications deployed into kubernetes when you look at home and you see presentations at home in my opinion it's presented in a way that doesn't really highlight its value for custom development so for instance a package manager in this case means say a package like wordpress maybe i want to deploy wordpress in my um cluster helm has a chart out there for wordpress and a wordpress is typically a database and a website that's written in a technology that i don't develop in so i wouldn't necessarily want to configure it myself but there's a web press chart out there and and the charts are what they uh the chart is a term that they use for package and helm i can install a wordpress environment which will bring up the database and the web application running in containers in my cluster with one line in the command a command prompt using helm because it will pull down the chart and do all the configuration bring it up in the cluster itself so that's how it's usually [Music] presented so give you the idea hey it is a package manager you can deploy these well-known packages in your cluster that's cool but from what i found for people implementing enterprise software helm is more powerful as a templating engine for your application for instance i've found you often only have a few different flavors of application say you're a shop where you have certain websites that are asp.net core and you have services that are that are really web apis and they really have the same deployment scenario you may only need one chart for those web apps even though you may have 50 of those web apis you may only need one chart and then you specify the different feature flags that you would want to change when you deploy it but you may only need one chart and you can deploy your application in one line and change those flags as you need it's kind of an abstract sense but we'll we'll see it here in action so azure devops before we get into that let's do let me show you helm so if i go back to visual studio here uh so this was the template that we dockerized very simple application another thing that so this doesn't come right with the container tools you have to have put it on the slide deck all the way up here you have to have um the azure development features installed of visual studio to get the helm chart creation so let me show you helms chart creation we just talked about helm so simple web app um i showed you the creation of a docker file that was simple enough to get this web application built let me show you creating uh so i go to container orchestrator support and i say oh man why is this not here what i do wrong oh well um let me show you another app here so this application is the same thing before i'm not going to debug"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:00:38",
        "seconds": 3638,
        "text": "oh man why is this not here what i do wrong oh well um let me show you another app here so this application is the same thing before i'm not going to debug what what step i took wrong on the other one it may be the wrong version of the os i'm not sure so if you right click on this and add container orchestrator support it gives you multiple options one's a docker compose and one's container helm so if i choose this and i hit ok what it's going to do is it's going to create charts directory and in this chart directory is a helm chart that will install this web application in kubernetes for us so if if you look at what's contained in here you'll see there are two levels of things and the most powerful piece of helm in my opinion especially for enterprise development is this right here this capability this is a templatized yaml file so if you look through here you can see let's look at the image so here's image so the image is going to take this piece of information values image dot repository and concatenate it with image.tag and it's going to create the output of the image um whenever it transforms this this template to push my application out to kubernetes so let's let's prove that so this is the one place i will drop to the command line so this is web application two let's build this so [Music] i'm [Music] i'm in windows uh i'm in wsl2 or or windows terminal i guess this is a ubuntu version so i want to go to the charge directory so the ls charts so here is the chart web application two um let me show you yeah so i've got the docker desktop running so okay so i have an alias set um for those of you who who are new to linux which which i was for the longest time cube ctl is the command that you have to type over and over and over it's a lot easier if you just say alias k equals cube ctl so you can now just say okay i want to see what context i have what so basically what cluster is my command line looking at and we'll get a little bit more into the command line a little later how to set it up config current context so my current context is my docker desktop so that's the cluster that i'm looking at and helm is going to follow the same tools that my cube config is currently pointed at so if i say helm install web app oh i call this one two let's let's call it i'm not sure so let's be safe and call it web app nine because this is just a name that's gonna use and i want to use the chart in the uh charts file chart web uh hold on let me check this first 3d charts okay so yeah web application 2 is lowercase not uppercase there's no casing in so i want to go uh helm install web app 9 and 0 would work too dot web application 2. so what this is going to do is it's going to take and let me just run this oh i'll do wrong now the web application i can't type for some reason okay so that's all i took it's installed in the cluster now so if i say k get all you can see we have web application 2 pod running we have a web application 2 service running and we have the deployment running and it's only been running for 8 seconds so this was just deployed and all it took was that one command but the cool thing and this is where it becomes useful in the devops pipelines is you know i did the helm install for what was out of the box but here let me show you so let's do an upgrade upgrade sorry handicapped here upgrade and let me show you this so this is the template it's plugging these values in for the image see that the tag is here um i'll substitute the tab so the way the helm works is there's"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:05:42",
        "seconds": 3942,
        "text": "and let me show you this so this is the template it's plugging these values in for the image see that the tag is here um i'll substitute the tab so the way the helm works is there's two levels one is templates that's where all your templatized jammel is the next level is where the default values are so this created the default values for what's in this um this build so it used to tag stable so let's change what's deployed to use a different tag say latest without changing the file so this is this is where the devops stuff comes in useful or helm comes in useful with the devops so i'm going to do the same exact thing i want to upgrade that i don't need the chart anymore because it's already deployed i want to say set image tag equals latest so it i'll upgrade so i guess i do need the chart upgrade dot black okay so it upgraded it so now if i say okay get actually let's just do it quickly okay deploy get why this should show what the container that is deployed so this is the deployment like i said the deployment's the one that kind of manages the pods and this is the image that it's working with now it's using the latest where before it used the stable so all i did all i had to do is run that one line so in our devops pipeline you can change that you go into qa well you can change it to the version you want deployed to qa piece of cake that is where helm really comes comes to light for my opinion with enterprise development it's that ability to deploy your applications so azure devops now this is going to be the way to get your code into kubernetes and it'll you either use um cubecontrol or helm to do so and here's sort of the chart that it kind of a an interesting one here we got bill moving some stuff i just muted you build so um i just lost my spot okay so this is the flow this is this has to do with uh debugging there's an azure there's this thing called azure dev spaces which allows you to interact with an existing cluster but dealer debug locally um i'll ignore that for right now but this is where the pipeline comes into play so the developer works on this source checks it into the repo the pipeline kicks off builds the image sticks it in the container registry and then the pipeline utilizes a chart to then deploy to the kubernetes cluster so all of this past the source control can completely be automated so all the user has to all the developer has to do is check his code in and within minutes it can end up in a cluster so let's look at how you would do that you're going to use either cube controller helm and you'll see an example example of both here now i'll also show you how to get this running for yourself so you have it for reference later so devops so in your azure portal what you want to do is do a search for a devops and find the devops starter that's that's what i want to show an example of and this is this is really useful to give you more or less a reference implementation that you can look at and reference to build your own pipelines so i want to do.net next asp.net core kubernetes as you can see there were a lot of different choices um we're just using it to look at kubernetes tonight so we're going to say okay so i don't really care where it goes this is just a demo um one thing you'll want to do when you set this up yourself is you're going to want to go to the additional settings and change this node count to one if you want three that's great but you're going to be paying for three vms to run and you can change that later so i would i always set it to one first you can choose the flavor or i should say the version of kubernetes that you want i'll go with the latest this is the general information this is the container registry that's going to create for me i'm going to put it in the same data center so east u.s east u.s stick with the standard machine if you wanted to change the size so maybe you have some code that's uh more memory intensive you can change the machine here but i'm going to leave it and then hit let it"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:10:46",
        "seconds": 4246,
        "text": "stick with the standard machine if you wanted to change the size so maybe you have some code that's uh more memory intensive you can change the machine here but i'm going to leave it and then hit let it go so this actually amazon only doesn't take too long but let me see if there are any questions any questions sound test so what this is doing right now is it's going to a github the the source code for all these little sample apps uh are in github so it's going to github cloning that github repo and then it's creating azure repo so a place to clone that source code then it's creating a pipeline to do the build and then it's creating a release pipeline to do the release to the cluster and see it's done already so this is now i now i have this uh reference implementation you can see right here right now nothing's deployed it it'll get to that but what we have here and i'll start kind of from the beginning uh for those of you who aren't super familiar with azure devops so we'll start at the top this is the git repo i see your questions i'll get to them they're they're def there's definitely a lot of help but really um you'll see that this little starter thing um once you get it going then it'll actually give you more information to search for more detailed explanations versus a tutorial but there is one and i do have a link to it my slide deck that walks you through um how to do this there are multiple ways of course but this is one way so this is the the repo so this is just um the file system on the github repo or it's not github it's it's git repo and azure devops so there are a few things in here other than source code let me show you so first of all this thing called arm templates so this is your infrastructure's code on my slide i had a little symbol for terraform this could also be done by terraform it you know it's more or less the stuff that's going to create the infrastructure so there's also another piece of that here um there's actually there's not another piece of that this is the web application and then here's the helm chart to install the web application so this this is an example or a reference implementation of how you would create a devops pipeline and the helm charts to put a simple application out into um kubernetes so this is just source code only files so now the build pipeline so this is a build pipeline there there are two pipelines this is build pipeline and this is the release pipeline the little rocket ship here so the build pipelines let's look at what this looks like if you hit edit it shows you the steps things to keep in mind with the build pipeline you can have triggers turned on so these are under the trigger tab by default this reference implementation is continuous integration so it's going to automatically build it and release it so it's ci and cd automated so if you didn't want it to do a build automatically when someone merged the code in with the master branch in this case you would not check this you would you would uncheck this if you want to schedule set a schedule or whatever to do the build you can do that here under the triggers but um by default this is this is the thing that makes all of these boxes start to turn green um on the this so the one that i did uh was it ba demo i've done a few of these okay i noticed oh yeah it's not bad demo this is a different one but um all of these all of these uh it will end up releasing the thing and putting it out into kubernetes by the time i get through this it should be deployed so um that's what makes these steps continue to go as i'm talking so here the task so the pipeline you need to determine you know is it linux are you building on a linux machine or a windows machine this is where you would choose those uh this is just setting the source to pool in order to do the build and you can change your your repos your your branches and all that stuff here and then these are the individual steps since this is an example of a containerized application they've added in this step for infrastructure as code so this will actually create a container registry so all it does is run an arm template that's in the source code under the arm area that we looked at so this here is the arm template to create it so they've put that let me actually step this out they've"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:15:49",
        "seconds": 4549,
        "text": "all it does is run an arm template that's in the source code under the arm area that we looked at so this here is the arm template to create it so they've put that let me actually step this out they've put that in the build so that if the container registry isn't there yet it will actually create the container registry and then it builds the source code so here's where it runs the docker build and then it actually build an image this connects it to the container registry so this connects it to your azure resources this runs the docker build and then this is some of the stuff that needs to go to the command line to create the image to output it the next step is the one that actually pushes that image to the docker registry the way that these are structured is the azure connection is at the top so the what azure resources it's connected to her at the top and then the utility information is at the bottom so this is the step one build it step two push it uh step then this brings down the helm tool because it's not on the build machine natively and then this builds a package which means it takes that chart that we looked at the directory builds a helm package and puts it onto a staging directory and then uh it copies the other additional arm templates because the release will actually create the cluster if it doesn't exist so that's what the other arm templates are for and then it pushes those artifacts that it just copied which is only the helm template and those arm templates to a staging directory that is kind of the data handoff for the release build and you can see these so if you go to the build and you click on this and click on the actual individual build you can see some stats and you can continue into it and look at the logs if you want but this right here this is where you can see actually what has been published so you can see it's very small we've got what 10k here for the actual data handoff to the release to do this cluster build and deployment of a web app this is the helm template this is the arm template that's used to create and see if you had another pipeline that actually did your infrastructure build you wouldn't even have these in here you would only have the helm template so this is all that's needed to pass over and and that's solely due to the fact that your application was built put into a container and now that container is actually in a repository so if i go to the azure portal and go to the container registry this again is where the question of what was the name it doesn't matter these are all the same so if you go into here and go to repositories you would then see the container for your application here of course i chose one or it doesn't have a container but um this one has one so here's a container and then this is this would be the application that was actually built so uh back to the pipeline so uh yep so that's the source this is the pipeline so that's the build at this the at this point the build has created everything that is needed to deploy but hasn't deployed it the release is the one that does the deployment so let's and it's currently doing the deployment so let's look and see what is this does this is the artifact so this is the starting point for what the release needs to do if you look at this drop if you click on the artifacts you would then be able to get a hyperlink to go back to the build that is the source for this and then you could look at the individual artifacts so that's nice that they have this hyperlink because oftentimes you need to see once the build goes out it's like it did it deploy the right one so that's this is the starting point these are the steps you can have multiple of these but uh this is the release step um let's go to this is all infrastructure stuff here it's gonna bring up the cluster um this is just extracting the key for the ai which is application insights to be used later on these two steps are only used the first time because once the name space in the cluster so this is this is azure infrastructure set up and these are cluster setup so your application needs these the pull secret is what the cluster is going to use to pull that image out of the registry and then here it installs the helm tool and it runs that helm install so when i ran the helm install on my command line i set the image tag but you can see here out of the box this this reference implementation sets some additional ones it sets the repository so this is the image name the tag and then this is the application key"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:20:54",
        "seconds": 4854,
        "text": "set the image tag but you can see here out of the box this this reference implementation sets some additional ones it sets the repository so this is the image name the tag and then this is the application key so this is a good instance where this is going to be different for each environment you deploy your application to so the the way that it uses these so it uses some variables and passing stuff in and around this tool that you can completely reverse engineer good examples of how you would actually do this stuff in production and and this is going to be different for different repos so this helmet upgrade is going to deploy that sample web application out to the cluster so let's see if uh this is buzz azure one so let's see if we can actually find the correct devops now so let's go home starter there we go so this is the one that is working on deploying okay so it's deployed so here's the sample web app if i click on this link this is the sample so this is the sample or the reference implementation very simple asp.net uh core web app and it must have just went out because it's taking a moment to come up all right so we'll come back to that in just a second so that's the public ip that it has exposed an endpoint to and all of this stuff oh great now we can we'll get it working this is the kubernetes cluster that is spun up from that arm template uh and eventually some data will start coming in app insights down here so if we go to the cluster we can go here so you can see the application came up it was just transitioning over so the cluster is now deployed and this we'll get into in the next demo but that's that's the reference implementation so so what it did is it created the the the replo and it all connected all the dots in a realistic cicd pipeline that you could actually use in production to get an application up and running on the public internet so that's a really super useful starter kit for a reference implementation so let me get back to my slide deck uh any questions so far before we finally get into kubernetes azure kubernetes service i mean we've we've touched on a lot of the stuff that you really need to do kubernetes in production so now we actually go into the hosting environment which is the kubernetes service okay cool so i'll keep going here so kubernetes service so kubernetes on so aks it's a managed uh service which means they manage some of the infrastructure for you not all of it but but some of it you don't have to pay for the management control plane so back in this diagram here microsoft manages the kubernetes master for you um so what what does that mean for you um means this thing that would have to be on a highly available set of virtual machines because you would make you would want to make sure that there's at least two to three versions running because if one went down you want to make sure that it's still up so it's going to be highly available and this scd data store also needs to be highly available so they take care of managing that stuff for you you don't need to you worry about the worker nodes and not not the master stuff and that means you don't pay for the master stuff either you don't even pay for a portion of them i believe in amazon and google you have to pay for a portion of the master uh plane up and running um so you only pay for the worker nodes which is which is kind of cool um so it's easily scalable so you can you can um scale your your instances out and i'll show you this here in a second and it's it's also a kubernetes conformant and there's also this idea of a virtual node which works with azure kubernetes instances or container instances which more or less allows you to have a node that you know because when you have a node it's backed by vm so there's only so many cpus only so much ram on that vpn or vm sorry um so if you need more you have to spin up another node but with azure container instances that you can treat as just this this endless pool of compute resources and just keep creating them the caveat of that is they can be slow to start because it's in an external environment from your cluster it's not on the vms that your cluster's on so let's go through the portal here which is where we left off so this is azure kubernetes service landing page shows you your your typical information for the the resource at a"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:25:58",
        "seconds": 5158,
        "text": "on the vms that your cluster's on so let's go through the portal here which is where we left off so this is azure kubernetes service landing page shows you your your typical information for the the resource at a high level so it shows you some information about your networking it shows and where the the api is for interacting with the cluster it shows you the version that it's on the type of network there are two flavors of network one is cubenet and the other is azure cni for production you're most likely going to use the azure c and i but that starter kit uses the cubenet um this is the node count right now i've only got onenote which is cool your subscription stuff which don't need to know and some capabilities so this is just highlighting stuff um so let's go through here uh let's see what's gonna be the best place to start so let's look at the node pools um so aks works in node pools what we created when we created the cluster is uh it's a system node pool if you will this that means that this is going to be the minimal set so you you have this node size which you can't change you can create additional node pool so say you find that you need more memory than what you initially created and what you can do is create another node pool with that larger set of vms and once you create that second one you can then remove this one if you need to or you can create multiple different node pools and you can create a node pool that's a windows os so you can create different compute profiles if you will in different node pools and then treat that as part of your compute power if you will if you want to scale scaling is here i believe so we go scale this is where i can ratchet it up so say i want uh you know five machines i can change it to five and i hit apply and it can just start stamping out additional nodes it will take a few minutes for the vms to come up and then the kubernetes to put them in the rotation for the compute pool so it will take a little bit of time okay so that's how you could scale out out your number of nodes because the ability uh of a compute that you have for your application is going to depend on on how many underlying nodes you have uh cluster configuration this is the ability so once you have a version to upgrade to you can upgrade it here uh scaling has been moved to the app pool so it's no good networking just information um typically you're going to have it on your your virtual network for your your company you can uh you can also put it in a private um so one caveat to this if you do go with a private cluster you're going to also have all of so you get all the security goodness of the fact knowing that everything is behind your v-net but you also get the caveat that you need to know the workarounds for that so i showed you the azure devops azure devops can't deploy inside of your virtual network so you'll have to then have to look into hosting the agents inside your virtual network and do all of that work so you kind of um you get a lot more security or i should say you get more security um but you will have to do additional workarounds in order to get things in and out of that network uh so that's something to keep in mind if you just click on the ability of the private cluster you could shoot yourself in a foot until you figure out how to work around it deployment center this is this ties into the release side it's great for informational purposes or finding out what's released um it's not always used policy allows you to tie into policy to set a lot of things around kubernetes um you definitely want to dig into that it's like for instance so you're moving out to production and one of the security practices that people recommend is to minimize the number of container registries that your cluster will pull from so right now we've configured the application to pull from the azure container registry that the starter kit or the starter spun up for us but i haven't limited it either so it could also pull from docker hub and by default it will pull from docker hub but um and when you move out to production you'll want to make sure that just miscellaneous repositories aren't being reached out to and pulling images back into your cluster that way you know if someone's hacked into your cluster they can't start bringing in bitmining images and taking over the uh the compute of your cluster"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:31:00",
        "seconds": 5460,
        "text": "repositories aren't being reached out to and pulling images back into your cluster that way you know if someone's hacked into your cluster they can't start bringing in bitmining images and taking over the uh the compute of your cluster so you'll one of the things and one of the ways to do that to do that is through azure policy you can put in what registries that you'd want to uh minimize it to or limited to i should say have you ever experienced a situation where not having control of the master was an issue yes so anything as with any managed uh complaint control plane sooner or later you will most likely run into the case where something needs to be rebooted you know it's gummed up so you have to contact microsoft and have them uncomment for you that has happened it has not happened very often in two years i think it's happened maybe maybe twice so it does happen um insights this is the container insights this is where you can find a lot of information out about how your cluster's performing right now we don't really have much running in here but if we had a lot running in here you'd be able to see how much cpu is being used how much memory is being used across the cluster and that that will help you determine you know what size of nodes you should have how many nodes you should have and that sort of things you can drill into a little bit more detail on the nodes the different types of controllers that you have and the different containers that you have with the containers one you can actually let's see the web app here the web app right here so if i choose the web app i should be able to look at the logs for the web app so if i i've selected it over here and i can say show me the container logs for the web app so it goes in and these are the the logs that have gone out to the web app so if it was running on the console on my machine i would be able to see these in a terminal window so that's that's the logs which is which is very useful um it's really useful for jobs and cron jobs for instance jobs is a way to run a pod in kubernetes so there's always two types of containers one is the type that runs some logic and finishes goes away it's done so you're not paying for it after it's done and then you have the others and the great examples of website it needs to be up 24 7. so it not only doesn't ever return you want it up and running all the time so there's those two flavors and a job is a great way to run the type that runs and goes away in kubernetes and a cron job is one that will start one of those jobs on a on a cron job on a cron schedule so those are the two types the drawback is with a cron job and and jobs especially cron jobs because say they're running every hour and you have a problem with it um you have uh you have um limits that you can set so you can say just keep the logs around for the last two successful the last two failures you won't want that number to be too large because you do pay for quite a bit of logs going in and out um and let me bring this up too because this is important once you put your app out into production or or get a sizable number of pods out running and you have the default setup for your containers what you'll want to do is go to the advisor not advisor the metrics it's not metrics settings it's not advisor either here logs i thought it used to be called metrics anyways you'll want to go to logs um and then in this this set it will show you less pods view data ingestion by completed jobs um you'll want to play with these default ones because you want to see how much how many logs here we go billable log data per name space billable log data per log type you want to see if you've got too many law too many things spend putting too many pieces of data into the azure monitor because you get charged for every byte that gets ingested into that that that data set so you'll want to check these every now and then to make sure uh one of them's got a pie chart it's pretty pretty slick but you'll you'll want to um you want to keep an eye on that because your your data ingestion can end up costing as much as a cluster and i've i've seen that happen so"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:36:03",
        "seconds": 5763,
        "text": "pretty slick but you'll you'll want to um you want to keep an eye on that because your your data ingestion can end up costing as much as a cluster and i've i've seen that happen so you want to you want to be aware of when you get a lot of stuff out running how many things are you logging are you logging just stuff you need or are you logging too much so you'll want to keep an eye on that so i just want to make sure that i'm covering what i want to cover here so let me show you going back to the command prompt how to wire this up to your command prompt i'll show you the equivalent of the kubernetes dashboard i won't actually show you the dashboard and i'll um i won't i probably won't get to the kubernetes deployment and then when you download the deck you'll see that there's several resources at the end okay so let's get the let's get the um cluster uh connected to my because i just created it that means my terminal doesn't know anything about this the way to do that is this button called connect it gives you almost all of the necessary commands if you don't have cube control um let me clear this if you don't have a cube control cube cuddle cube ctl installed whatever you want to call it you want to once you connect to a z so a z is your azure command line interface you want to run a z aks what is it install cli actually let's do help so aza ks help and it is the install cli command so that will download and install the the cube control and and configure it for you it won't set it up to the cluster yet the to set it up to the cluster is this next command here this one so uh if if you don't know that you're using the correct account you can copy that let me dock these jumping back and forth okay so here uh this will do the correct account because it could be on a different account um and then the this get credentials this is the one that will connect it so i run that command and it pulls down everything it needs and puts it into my cube config so now if i say okay get say config let's say git contacts con text what context do i have the ability so basically what clusters do i have the ability to connect to so i have several here and you can see it's already currently connected set the current one to the one that i just looked at so now let's run one of these commands let's just run it like this i don't need this anymore so now that it's it's connected to the cluster let's see what's in the cluster so the way that i typically do is i just say get all and if you do this you might be surprised that there's not much in there and the drawback to that really cool and useful azure starter is that it follows the practice of putting all of the stuff in a specific name space and by default it's going the k get all since i haven't said default it to that specific namespace is it's only looking at the default namespace so you have to do the show all namespaces which the shortcut is dash capital a this will show you all namespaces so we can see here's the namespace so if i say just get all and then only for that namespace this is the information this is the stuff that was deployed and helm also works off of namespaces helm ls will show you all the helm items installed but look i didn't install the namespace so if i do the namespace it will then show me this is the azure devops so this is the helm chart that the azure devops starter created installed if you do like helm um get values all right an azure devops whoops azure do i spell wrong oh anyways i guess it's not important but if you do helm get uh there's a couple options one is a couple options that are useful manifest and values those will show you what was actually the translated version of your helm templates so it'll show you what helm used to install what is on the cluster which can be useful if you've if you've got problems with what was deployed deployed so that is the command line stuff now let's"
    },
    {
        "speaker": "",
        "title": "Jason Haley: Getting Started with Azure Kubernetes Service",
        "videoId": "Yio7DAvHNDE",
        "description": "This is a recording of the December 15, 2020 virtual meeting.Getting Started with Azure Kubernetes ServiceAzure Kubernetes Service (AKS) is a managed Kubernetes service that you can use to host your containerized applications with in Azure. If you are looking to get started with Kubernetes - AKS is a great place to start. This presentation will cover topics that should help you get started, such as:1. High level overview of containers, Docker and Kubernetes2. How to provision an AKS cluster3. Using the Kubernetes dashboard4. Using kubectl with AKS5. Deploying an application to AKS6. Helm - what it is and how to use it7. Walkthrough a DevOps pipeline8. Visual Studio 2019 toolingJason Haley is a Microsoft Azure MVP and Independent Consultant specializing in Azure and Angular. He lives in the historic city of Salem Massachusetts and also involved in the developer community around the Boston area. (http://jasonhaley.com)",
        "start": "01:41:07",
        "seconds": 6067,
        "text": "helm templates so it'll show you what helm used to install what is on the cluster which can be useful if you've if you've got problems with what was deployed deployed so that is the command line stuff now let's look at what's the equivalent of the dashboard is and and there's this application that looks like this screenshot in the back here um it's it's a pretty nice tool when you're learning kubernetes allows you to navigate all of the objects you can see the yaml you can change the ammo you can create stuff it's called the kubernetes dashboard there are several other dashboards there's even some commercial ones that you can install on web applications there's even a mobile application that you can get to manage and navigate your kubernetes cluster with um azure kubernetes service they stopped including that dashboard with 1.18 or 1.18 because they've added in the functionality in the portal themselves or itself so here you can see the different namespaces if i go into the namespace i can the namespace one is kind of useless but you can see the yaml that was used to create it you can change it if there are any events on the object you can see the events if i go back the workloads is where you would get your deployments pods replica sets these different object types so if i narrow this down to just the the one that our application was in we can see well there i'm under deployment there is a deployment there are two pods deployed there's one there's two ready both are up to date it's been up for 22 minutes if i click on this it will show me the contents or what it's linked to so it's linked to these two different pods some information about them the ip it's basically what you can see by the command line as you navigate around if you want to see labels that's one way you can start doing filtering for stuff here's the replica set that is keeping track and making sure that there are two pods running you can look at the individual pods so you can say okay well here's some high level information about it let me wait this is the container so let's look at the container if there were two containers there'd be two containers the container is running so let's look at the container um there's no vault well there is a volume it's the it's the mount for the container um actually yeah so here's the environment variables not much going on there it's the app insights key that was injected some information and high level information about the container but with the breadcrumbs you can navigate around what's in the cluster pretty well inside of the azure portal if you want to change something you can go in here so say i want to say where's the image the image is down here let's go to image and change the tag so the tag says 34 let's change it to 33 hit ok and save okay so you can change stuff in the portal you can also see if there's any events um all of that stuff is is pretty useful through through the portal you can also of course do that on command line but it's kind of nice to have a ui and this is exactly what the the dashboard did for you or it does for you if you install it yourself and this is some networking stuff the services and the ingress so we don't have an ingress running um if there are any storage volumes or persistent volumes or storage classes are set up by default um so you can do storage and output it to azure files as your premium that sort of thing configurations where your config maps and secrets are going to be so all this stuff's visible you can see helm release packages are stored in a secret to keep it somewhat um secure secrets are stored um secured at rest but they're only base 64 encoded if you look at them in memory so keep that in mind um so that's that's the equivalent to the dashboard and i believe that is that's everything i wanted to cover i don't actually have a end slide i have all of these resources so um docker resources i found these really useful when i was when i was learning docker and containers and this one's really relevant because it's not just docker but it's it's taking docker beyond and running in kubernetes this was really useful um here's this basically the docs for the container tools and everything it does do this is just a blog entry on them uh this was a really good talk on microservices docker and kubernetes uh 55 minutes long it's kind of long but it's really good for getting started to get the concept of all the pieces involved learning path for kubernetes it's it's it takes you many days i forget how many days to actually go through that but it's a mis mixture of um tutorials and there is one of the tutorials in here is the um tutorial that will walk you through setting up a devops pipeline as along with many other things this is a really good overview of the pieces of kubernetes it's nice to visit after you've played with it for a while because then it makes sense of it helps it gel some resources for helm helm along with a lot of the kubernetes universe has a slacks channel so once you get on that you can easily just add the different channels with kubernetes related things devops resources here's some interesting links and aks in general um this is actually the most recent one it was pretty interesting here's here's a link directly to that workshop that will walk you through setting up the stuff step by step uh this is this compares eks jke and aks this is actually pretty good as is oops it's not very long but it's really interesting and that that's it if uh anyone has any other questions um go ahead and post them or come off a mute and ask them if not i guess we can wrap up cool all right awesome good thanks yeah and for free um so let me go back uh wrong one feel free to reach out to me either on twitter or email if you have any questions i'll try to get them answered all right i guess that's i guess that's it guys um veronica did you um have any announcements to finish up with i will share the deck uh i'll up if you look at um i'll i'll i'll put a link on the meet up for where the deck's going to be that way you can just go back to the meetup site sorry about that bill let me unmute you oh shoot you are permanently muted you're gonna have to leave and come back bill oh it shows you're off mute now can you talk i hear you i can't hear you all right cool okay all right you're back so i didn't have any further announcements other than that um to remind folks just to come back check the meetup sites and we'll be uh we'll be announcing shortly our first quarter the beginnings of our q1 2021 schedule yeah i had two things them reminder about our youtube channel we have all our recordings there and we'll post this one uh probably later tonight and um another um i kind of mentioned um that iot event it will be a free iot virtual event in january so let me share both those links so the first one is for our youtube channel second is for the iot uh virtual event it's azure iot so um really related to the main topic of our group and yeah thanks for joining us and um happy holidays yeah thanks everybody happy holidays all right we're out awesome uh outstanding uh job jason such uh high level like understanding coverage and then down and "
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:00:03",
        "seconds": 3,
        "text": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy. This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.. okay cool all right uh and hey everybody who's who's on the phone here um this is the first i think hybrid in meeting for me at least from a presentation standpoint recording okay cool we're good i'll close that just to make sure we get all the screen uh i can't i can't even get to it [Music] okay um yeah so good evening let's see if this thing works too maybe ah there we go all right um yeah hey everybody i'm christopherless so i'm a client technology lead here at microsoft i've been here for the past three years um spent a little time at a microsoft partner pragmatic work for a couple years and prior to that was a cio for a couple of seafood companies here in the northeast um i grew up in i.t so a lot of the stuff that i do now as part of my job is to try to understand this stuff at a at a high level from a strategic standpoint to be able to help align the microsoft technology stack across the stack um with their goals and objectives to meet their business needs and so um i still play with some of this stuff for fun and i sh it's been a while but occasionally i throw a video blog out there um and i i do like to engage the uh the various communities and stuff um which which is a fun part of my job i got some other stuff here you guys can all check that out later um uh real quick shameless plug i am writing a book um got approached from pact last year about cognitive services um so it actually kind of made it easy to do this presentation because a lot of what we're working on um here with the cognitive vision computer vision custom vision all kinds of vision uh is is based on what i wrote for a chapter in the book um the book is largely based on a fictional seafood company given my experience and the way that ai using cognitive services can essentially help them be more efficient you know optimize operations uh improve customer service experience and all that uh and it should be a sometime october november time frame assuming we meet the deadlines which we have not done a great job of so far um so if you are interested um online or here in the room if you're interested let me know um we are looking for reviewers um you get a free book you get a free um uh subscription year subscription to pact which is all their books online um if you guys are familiar with like the o'reilly subscription and stuff i'm gonna trip over that um uh but if you're familiar with that you get a year subscription so you can you know get all their content and stuff like that um we do ask for you know basically reviews of the book and and somebody to actually read plug done all right so computer vision um the the topic of the night so what is it um according to wikipedia it's it's the study of building artificial systems that process perceived and reason about visual data what does that mean it means that we're using a computer to see what a human sees ideally right and then you know essentially being able to uh extrapolate what it is that we're seeing describe it um and then be able to do more with it which we'll get into here and so basically when when we look at how a lot of these um you know somewhat public computer vision uh models look like um an example would be this right we use recaptchas all the time you know we use captchas recaptchas right and in essence um you go and you pick those images those are building a machine learning model to be able to capture the images so in this case we're looking for a stop sign you can see it's a it's a it's a somewhat blurry stuff sign and if we don't hit it in time then our car is going to crash uh um obviously it's somewhat of a joke on the computer vision that we're seeing day-to-day but every time you see a captcha or recaptcha what you're doing is actually building and feeding into that machine learning model to be able to capture um you know what's happening in those images so simply simply some basic versions right we've got image classification so in this case it's an airplane right um but if you notice there's a whole bunch more in that picture you've got people you've got the plane you've got another airplane in the background right you can go so far to say that you know if this were an airplane use case you know we've got the uh what do they call that thing the gateway or i forget what they call it uh no it's the um the thing that extends out um there's a name for it i can't remember anyway um so you know you've got other elements here that go beyond what the actual focus of the image is right so we look at the object detection what's happening in there right and then finally um we want to"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:05:06",
        "seconds": 306,
        "text": "anyway um so you know you've got other elements here that go beyond what the actual focus of the image is right so we look at the object detection what's happening in there right and then finally um we want to look at the segmentation of the image to say well where is this stuff right because as we start looking at some more business-like use cases um you know we want to know through a quality process where something is located within a grid right and because of the image segmentation aspects of computer vision it gives us that ability to be able to uh pinpoint exactly where that is okay um so as this has evolved right we basically have something very familiar i would say yeah yeah right so we've got self-driving cars and it looks like the normal driving experience that we're all used to when we drive in a car on a day-to-day basis however what's really happening is we're seeing all of these other things right we're identifying them so we know what to do with them right so if we see a stop sign of traffic light coming up we need to be able to um interpret what we're seeing to be able to stop or continue the same red speed or begin to slow down we see objects in the road um we're following the lines to follow our lanes right there's a whole bunch of things going on inside this image and the the you know cpu gpu inside the vehicle needs to be able to know how to respond to these certain elements and so um ultimately where we started with this was believe it or not back in the 50s late 50s um you know scientists said well can we mimic the way that a human sees geez how do we do this what's what's the best way to do it and i said well a cat's brain is eerily similar to a human brain and so if we take this electrode and put it in the cat's brain and we show it different images we start to actually see how they're processing those images and so what we wind up starting to see is is the various elements of the image as they're looking at it and you start to get the ability to add those features of that image to what is actually happening in front of you and so when we think about an image right from a computer standpoint it's it's a flat image and it's a bunch of pixels right and so when we want to identify what's happening in an image we run a um you know a filter of sorts over that image and you basically span the whole image up and down and as you do that it starts to create an image map of what's happening and it's signified in number value just like we're used to you know for everything with computers everything ultimately turns into ones and zeros right and so essentially we're assigning um areas of that image into um an algorithm and then we build um our matching based on that and that sort of the the foundation of um the image recognition process right so we look at how they're processed um first things first we're going to take an image and we're going to convert it to grayscale right and so basically we're going to um lessen the complexity of the image by making it only two colors theoretically only two colors less colors right um and so this allows us to then um give us the ability to you know basically not pay attention to you know the blues and the reds and all that and we can just focus on you know our grayscale images and then as we equalize it we're going to increase the contrast of the image to be able to then again take away some of the detail you know when we think about captain america's shield and his chest and all that stuff right we're going to lessen that so that we can you know get a sense of what's happening because when you think about an image in the pixels within an image they're you know depending on the size of the image and how much it's pixelated there could be millions of pixels within an image and so a lot of that can be noise right and so what we're doing is is here is we're actually simplifying what's appearing in the image because to a human we want to see this nice and sharp and clear including the color one right but to a computer rather than having to process all those pixels and make it super complicated we want to strip up some of that complexity so we increase the um the contrast and then we remove that noise right so this is our our uh contrast increased image now we've we've basically taken it and we've said okay and now you can tell this is a lot blurrier than the original image we're looking at by pulling out all the stuff that"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:10:12",
        "seconds": 612,
        "text": "is our our uh contrast increased image now we've we've basically taken it and we've said okay and now you can tell this is a lot blurrier than the original image we're looking at by pulling out all the stuff that we didn't need in that image right and again this all works toward that process of being able to build a baseline for what we're trying to recognize so after we remove the noise right then we're going to look at the edges right and a lot of this stuff is is how um again when we go back to the cat example the cat was seeing the edges of an image they were seeing you know the arcs they were seeing um the the the different contrast elements the the um shaded areas and things like that and so now we're going to detect the edges of the image so that way now we've got an outline of what it is that we're looking at right and at a um a simplified level of how this gets built up and ultimately we classify an image is you take the original image you do this spanning like i mentioned in your pixelated areas you run it through your various filters if you will and then you identify the parts that are happening within that image and then essentially from there you create a classification okay um and so what after you've built this original model and there's a bunch of them um imagenet and a couple other ones i'll name here a few um but essentially you have that baseline image classification model that you're working against and so on on the right there it's basically running it through here it sees this is a cat so it says yes this is a cat okay now there are obviously some challenges with this right this is a cat who is sitting there prone relaxed right you can tell by its face that it's a cat somewhat by the body that it's a cat right but if it were backwards as a human we might be able to interpret that as a cat as a computer kind of depends how good your model is have you trained it on the rear end of the cap right so and and these are all the types of things that we have to consider when we start talking about custom vision um and so again we we have this this base classification that we've come up with right we've got a data set that working against we process that image we classify based on what that is and then we interpret it to say what is the image that we're looking at okay trying to keep this somewhat high level um there's a whole bunch of um you know convolutional neural networks and all that kind of stuff going on in the background there um but again trying to keep it high levels so that we know we're looking at when i start looking at the custom vision.ai portal that that we offer as a way to build your own custom models okay so now when we start thinking about the computer vision aspect of things in the azure tool that we've created um you know we basically saw that we've got a massively growing adoption of computer vision as it goes to a whole bunch of different industries you can see the largest here are um automotive and and some of the consumer industries and they you know massive gap growth and anybody want to say what happened from basically 2015 through the current i mean what have we seen a massive explosion of in the last five ten years self-driving cars no iot and cloud i don't think cloud self-driving cars okay um i was looking for more why we're seeing this growth more more pictures everyone is taking pictures compute a lot more gpus right a lot more cpus gpus a lot faster cpus gpus fpgas right and with with cloud right so bill to your answer yeah iot because we're able to capture that information better now right but we're able to process it a lot better because of the gpu capability and the advances that we've had with gpus in fpgas right and so now we're seeing a lot of a lot of these companies want to be able to take advantage of this for a whole bunch of different ways of you know of building out solutions based on what they can do with computer vision so in essence um when we start talking about um some of the existing networks right so alex that resnet these are some of the um the some of the base models that have were created you know way way back i mean some of these go back to like the 60s 70s and 80s when we didn't have enough cpu gpu fpgas to be able to process these images and process these massive swaths of data and so you know in essence we learn based on what we've already created and then enhance"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:15:16",
        "seconds": 916,
        "text": "60s 70s and 80s when we didn't have enough cpu gpu fpgas to be able to process these images and process these massive swaths of data and so you know in essence we learn based on what we've already created and then enhance based on our requirements okay so um on on the the base model approach you have the ability to take a an existing model that sits in cognitive services that microsoft already wrote for you and this is true of all the cognitive services right you've got a base model that microsoft is providing that you can use against uh you can use for your solution to be able to do things like you know speech to text text to speech language decision all these different categories that we have in cognitive services and many of them not all but many of them have the ability to build your own custom models using similar technology knowing that some models are business domain specific you know things like that right so we want to be able to give our users the ability to do their own thing so in this case when we build a custom model which we'll go through in the portal here um we can start from a baseline and then build our own model to bid to then be deployed within the service ultimately in order to ensure that we've got a process by which we are um constantly improving our model there there is a best practice standard right you capture your image you transform it you analyze it and then you have your output and then you're continually retraining that model to make it better and better and better right so if we want the rear end of the cap to be identified then we need to train down the rear end of the cat to know that it's also a chat right so in essence we've got now um uh the tools to build it we've got a baseline to work off if we want to or we can build our own um when we get started with the tool the recommendation is to use about 50 baseline images when you're building your model in order to have a good data set to work against and that's per classification if you will on what you're building against and so um you know again i'll i'll show the the pre-can example that we have you know on the microsoft learning site um some of the use cases that we're seeing in industry you know workplace safety is a really big one right where um you know we've got the ability to now be able to determine if somebody is wearing a hard hat you know um or if somebody falls on a on a production line or something like that where there could be a safety issue so that you can instantly react to a situation like that shut down production so that nobody gets hurt things like that right retail floor tracking we have a newer um cognitive uh computer vision service called spatial analysis where in essence um you can see where people are in proximity in a location so you think of a retail example what are people gravitating toward right um do they really like a specific dress in a store right does everybody go check out that dress because it's really pretty or whatever right and so um it gives it gives retailers the ability to somewhat understand what's happening within these locations to be able to then say well we need more dresses like that or maybe it's the color or whatever right um and then you know there's a bunch of examples where we're doing this in real time um you know for a lot of customers if you get a chance to go upstairs into the mtc um you know we've got a couple of examples where manufacturers and things like that are using some of this um you know again for things like work work place safety uh quality control those types of things as well um here's just some little lists of the services um and then the uh you know the full list is there um we we do have um some some interesting things um i'm not sure if anybody saw the announcement that we just recently announced that we will no longer use our facial recognition software to identify things like um expressions uh race gender those types of things right in order to make sure that we are not um discriminating and things like that so um we do have a facial recognition component in there um but it's it's it's kind of it's a little bit in limbo where it is we do have a statement on our website saying law enforcement can't use it and things like that so um so some interesting things to come there on the facial recognition side because there are some really good practical uses for it but then on the flip side there are some really bad uses for it too so um our our video indexer service uh allows you to you know capture different elements of a video um identify speakers and things like that um you know the computer vision has a bunch of stuff you know standard things like ocr and those types of things um and then"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "allows you to you know capture different elements of a video um identify speakers and things like that um you know the computer vision has a bunch of stuff you know standard things like ocr and those types of things um and then of course um you know the things we've talked about image classification um scenery descriptions pretty cool because you can give it a picture and it can describe the whole picture for you um you know and just some of those types of things so there's somewhat of a list um you know and go check out the site to go from there um i thought it'd be good to share a reference architecture just so folks get a good sense of what this looks like as it's deployed um because the example that i'll show uses the the customvision.ai website which is a you can use it to build your model you can use it to classify images you can use it to label images but it's not something that would be used in a normal production scenario to operationalize a you know computer vision use case it's really meant for for those tools but then you basically export your model for consumption using an api but so in a typical scenario here um you know you essentially bring your your image in you drop it into storage um you know it you can use any number of things they got an azure function there you could use data factory you could use a whole slew of our different tools to pull it in there it falls into a storage account and then you've got a notification the event grid that says hey we've got a new image again this is just a reference sample reference architecture there's a million ways to slice a cad as they say right you can you can uh trigger an event you know again using a function app uh to pull in uh and essentially um you depending on what service you're looking to do um you know you would either use one of the canned models one of the um the pre-built models that microsoft um you know has won awards for and all that or you could build you can use your own custom vision model that you've created um and then from there basically you can post the results to a database should you want to uh you know and then there are other downstream streaming activities that you can do with it um you know but in essence i think you get the the picture here right where depending on what you're doing with this image um you know there's a whole bunch of ways to do it i don't know how we get out of this though i'm gonna double check my reference architecture because i'm just stuck there at that point all the arrows point back to it huh that's kind of funny anyway um but yeah so that's that's a general reference architecture where you know you can you can get a sense of how it would be used and how you'd use the service so let's look at the the port all right so i have a um one uh example that's pre-built again if you go to the microsoft learn site this example um it'll walk you through it how to build it and everything um for all intents and purposes we'll just kind of go through what what a basic project setup would look like and then we can we can loop back and look at the existing uh project right so you're going to name your project you're going to put a description all that kind of stuff you're going to determine where your resource is where it's coming from essentially you're defining your azure cognitive service that is for the custom vision portion of this so basically the compute that is doing all of your model creation in this case the artworks one it was already built that's on a standard tier we do have a free tier you can only process a certain amount of images and you can only use certain classification and domain types but you know there's a lot of options there to play around with that you can also create your new resource here uh so you have to log in as you need you need to have an azure principal id or something like that uh yeah you'd have to have you'd have to manage your account of some sort um you'd have to have contributor rights to be able to create some kind of resource when you log in you know you just you go to customvision.ai yeah i'll show you um i'll just show it i'll just do a uh a basic one you can see what the portal looks like it just gives you this login you know right here sign in and then send it with your azure yeah yeah um so a few different things right so you've got project types right where you're doing either a classification or an object detection right and depending on which one you pick here it's going to determine um you know some of the downstream operations that you're looking at right so whether it's going to be multi-label or multi-class or you know which domains you're going to be able to choose"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:25:22",
        "seconds": 1522,
        "text": "on which one you pick here it's going to determine um you know some of the downstream operations that you're looking at right so whether it's going to be multi-label or multi-class or you know which domains you're going to be able to choose um you know and and so basically when you think about the definitions there of object detection or classification is are you building a model um to create your own custom classification to then check images against or are you looking for what's happening within an image based on an existing model right the existing wall microsoft is built um in our case for the artwork example we're we're going to use the um the classification piece now what is so what is the output of this arm template second what is the output of all of this it's an arm template which you deploy in your azure account or no no so actually what it does is it allows you to publish a model and i'll show that in a minute here but it allows you basically to publish that model to then be able to check images against that mall my question is i get it in the sense you'll upload images and it will do something but what's up or it'll create a model which can be operationalized using your azure account yes so it will create some kind of arm template which will go into it it's not a template nope it's an api call yeah it's an api call so basically the api call calls the cognitive service so i've got my image that i want to test against my mom right you say hey can it does this match my model you know is it a cat right and so i'm calling that api sending that image to it okay and it'll say yes or no all right okay and so when i like in the example that i use in the book um i'm testing lobster tails right and i'm saying is a lobster tail uh good or bad right and there are certain elements of a lobster tail where i know whether it's good or bad right um is it missing any of the flippers right um does it have any cracks in it does it is it miss color right does it it doesn't have a weird looking color to it um you know are there pieces of shell missing things like that and so when you do that detection i've got that pre-trained model for good lobster tails and bad lobster tennis right and so it returns back with a certain percentage of accuracy whether or not it's a good or bad lobster based on the image that i based on the model that i created okay now when we look at the classification types right um is it is it a single tag within an image or is it multiple tags within an image right so are we are we looking to classify multiple things and this was tricky when building my my lobster tail example because it proved challenging to have multiple lobster tails within a single image to be able to say yes these are all good or these are all bad right because that was really the only answer otherwise it would be confused and say oh you know so basically we went up boiling it down to a single that was kind of an unintended pun um to a single uh through a single you know uh like seven lobster tails just don't take it literally and see the third one is so it draws a triangle around the third one and says this one is bad well no um it's not that sophisticated of a system to be honest with you um what we wound up having to do was isolate each of the tails to do our classification based off that you couldn't send it several images now what i did find was that um it handled noise very well and what i mean by noise was let's say we've got a nicely perfectly shaped lobster tail right in the middle but then you've got two on the side that are a little obscured maybe you don't see the whole tail or something like that generally it would take the one good image and classify based on that right um in the example in the book we use a single tail and a grid right and then basically process the um the identifier of the grid to be able to say this tail in this grid is bad pull it off right and then we've got a reinforcement learning system in the background where it says is it a false positive where in this case a positive would be a bad tail right so was it actually a good tail so you give it that feedback to say nope this was a good tail or yes it's a bad tail i know it's a little weird but you know what i'm saying all right yeah so um basically um we've got a ways to go on being able to handle multiple testing and things like that within those images so really we had to isolate the tails individually when we look at the domains these are all based on your use case so um you know the general um a1a2 are based on the size of your models how many images you're throwing at it what are you trying to do with it"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:30:27",
        "seconds": 1827,
        "text": "all based on your use case so um you know the general um a1a2 are based on the size of your models how many images you're throwing at it what are you trying to do with it i actually want to use in general a1 um and actually i think you can oh you know you got to go you got to go to the um the documentation site to specify what you shoot them are we've given some you know some general categories on what we see anything here that's um compact is designed for deploying to a phone right um you know because basically um a lot of these examples are being used you know for quality purposes and things like that with using a phone to scan for it right the latency is to you can't go in the cloud because the latency is very low for those kind of things right um it's partially that but then it's also partially um you know you think about your phone it's probably got like a 12 megapixel camera on it right and so it's it's sending a massive image up to the cloud to test against right so it just it's the size of the image and then how long it takes to come back and get that um whereas for the compact version you can actually store that right on the phone within a database on the phone and do that from a pricing point of view is it like when it's on the phone it's like a little bit cheaper but it's per api call like the other one yeah there's a few factors in there it depends on the tier that you're using it depends how many um you know how many transactions you're making um uh the size of the data that you're using so it's got a few factors in there um but yeah so i mean you can you can basically build an app on the phone so we've got an app called seeing ai that's out there on the app store i think it's only on ios i don't think it's on android um but it basically will do object recognition uh actually i can demo it real quick so it's just a regular iphone app short text yeah so let's see description project description resource resource per stones project types faces right so words faces two faces zero faces you know there's barcode readers there's currency readers there's all kinds of things like that this is more used to be for like an accessibility tool so that you know people who are seeing impaired and things like that have a tool to be able to use it but that's an example of sort of a compact model being deployed up to the phone okay um and then you know again depending on what your use case is here i think i use general a1 if i'm just going off memory and that was just based on um how much data i was expecting you know from the images how many images were going to be there and that all kind of goes into um what's uh how much processing time and how much processing power you need to build your model and then test against your model after the fact so then we deploy you know and and in essence then you start to upload um so if we go into the artworks project here um you can see that i've got some images already loaded um you know and and we've got some labels right we've got a label for a painting or sorry tag we've got a tag for painting we've got a tag for an artist and two other artists and so what we can do is we can um you know quickly train against what we've learned you could do a quick of sorry not train you can quickly test against what what our model is right and like i said this is more for testing purposes it's not really made for production purposes we'll get into the production aspect of it here and you can either upload a file or you can just put in a url so if i go in and i've already done a search here on picasso paintings and if i go and look at this painting and i grab and i grab the link let me copy the link go back copy the image so it's pretty sure it's picasa right there's there's 99.9 sure it's a painting right it's 99.8 sure it's a picasso name another artist besides the three listed let's"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:35:43",
        "seconds": 2143,
        "text": "copy the image so it's pretty sure it's picasa right there's there's 99.9 sure it's a painting right it's 99.8 sure it's a picasso name another artist besides the three listed let's test a different one then go it's two words right yeah use my handy bing company guy here you you gh yeah all right so if we look at van gogh oh this is a familiar one by one of my wife's favorites [Music] check here again really sure that it's a painting right um could be a picasso we've got a six percent chances it's picasso right and and so basically um with our very very rudimentary trained model i mean we're only talking about 19 images total that we've labeled here right we haven't we haven't given a massive data set what's that how do you label an image here i'll show you in a second um but you know when we're when we're looking at you know a very very small subset of images that we've built our model off it's going to basically analyze those images look at the various you know what would be strokes it's kind of hard to pick up the actual brush strokes because we're not looking at an actual painting you can't get the depth of and stuff like that like a real art curator would know the difference based on some of those things but based on a quick test based on the image it's like hey well there's a chance that it's a picasso right yes sir can you upload a picture of a cat or no not a painting to see what the model says yeah yeah i uh that's a good question because um i wonder if it would still see it as a painting you know maybe a cat or a dog we'll even we'll use the front of the cat not though there are two women on that so you have to be careful i don't want paintings though yeah and we don't paint like a picture yeah yeah yeah oh this guy's cute she comes i'm guessing it's gonna think it's a painting still let's see this is what i would like to do to see yeah no good yeah good yeah so yeah that's a great test i didn't even think of that thank you um he's got some messed up whiskers though he looks like he's been up to no good uh but yeah so you know the the point here is right we've got a very very small um model built right like i said the the recommendation for microsoft is um 50 tags um or 50 images for each tag right so as you get more and more accurate um you know as you add more and more examples it gives you the ability to get more and more accurate with your predictions now one other thing too um uh there's there's a term called over fitting in in machine learning if you guys are familiar with that um and in essence to avoid overfitting um you wanna make sure that each of your tags is sort of built um equally right so you wouldn't want 50 picassos and then five of pollock and rembrandt right because you're going to have issues where it's going to be swayed way way too far in one direction it won't work super efficiently so um just something to bear in mind as you're building out your your model here um now we've got a couple of things we can do so let's just download my my cat image here and you asked the book tagging so if we add a new image there's my image and then i can choose from one of the existing tags or i can actually just upload it and here i can get a suggested tag this feature is called the smart label so what this allows you to do is upload a bunch of images and do its own labeling of these images to say well we think it's a rembrandt we think it's picasso we think it's a painting whatever it is based"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:40:45",
        "seconds": 2445,
        "text": "so what this allows you to do is upload a bunch of images and do its own labeling of these images to say well we think it's a rembrandt we think it's picasso we think it's a painting whatever it is based on our model as it exists or in this case right we would want to um create our own tag um you can call it so what if i want to uh segment it like i have objects in that picture if you wanted to segment objects within that picture itself you would actually use a different model for that so remember when we were looking at building a new you've got the ability to do object detection or classification and then within classification you've got to do you've got the ability to do single label or multi-label you would have to label the various areas within those specifically so i'm just trying to understand so now once i do this labeling it creates a model me a model of my thing on azure services right so how would i uh go to the next step in which okay the model is created how can i consume it right i can either use logic apps or azure function code how would what is the next step here i'll show you i'm sorry let's see if this can detect that it's a cat now that's oh i didn't retrain this actually i've got to do a quick train before i do that because i didn't retrain it on the new label so just now it's running your azure build as you're doing the training doesn't like something non-negative target and five images yeah okay we're not going to mess with that because that'll take too long but i think you get the idea right so then you retrain then you test against it again and go from there so does it tell you how much of your azure bill is you'd have to go into the azure portal and actually look at the service as it's doing the consumption and by popping that up right now i i don't know what will pop up so i don't want to go ahead and go down that road tonight that that i just i do a lot of like testing and stuff in there and there could be other stuff that i don't want you to see um so yes sir so when you have for example your modeling production and you would like to do this read re-enforcement learning yeah so you could start to add new tags or fixing wrong tags you need to retrain again right yes okay so and you can trigger that retraining via api call or you can do it right here in this portal yeah but i'm i'm i'm guessing that okay you don't read it you don't train every time to do the bunch of changes yeah yeah and we actually had that discussion as we were building our example for the book again right where it was like okay um you know go back to my lobster tail exhibit and let's just say over the course of a day you've got you know 50 tails that either are false positives or are positive positives right and you want to you want to go in and retrain that it's not efficient to retrain it after every single one because what what's happening is you're basically you're taking your model offline to retrain it now i think there may be a will to leave the existing model in place while it's retraining um i think that requires a higher tier because it requires a whole separate set of compute to be able to process it right um but in essence the way we set it up was let's let's retrain it every night at midnight so we get an image that comes in it's a it's a false positive that we want to retrain on tagging it as a good tail because it was detected as a bad tail we want to tag it as a good tail so basically you make um we sent it to a storage blob for reprocessing it gets picked up by the training engine essentially tagged appropriately and then retrains the whole model right clear other question that also is really related to the training i have been here discussion about the bias in the training set yeah so uh any thought about that is covering the book as well it is that's why the phase region is yes yeah it's um it's a touchy subject right it's it's a um uh so we have what we call the responsible ai framework are you familiar with that yeah so if you guys aren't familiar with it we have you know basically a um a guideline around how to appropriately build ai models right um and and then operationalize those ai models right and so a lot of it goes to um you know uh being public about what it is that you're building right um making making the code available so that folks can see what you're building right um what steps in documenting like what steps did"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:45:47",
        "seconds": 2747,
        "text": "um you know uh being public about what it is that you're building right um making making the code available so that folks can see what you're building right um what steps in documenting like what steps did you take to remove bias and things like that right so um it's it's it's a set of guidelines again you know there's nobody forcing it um it's so it's it's just a matter of um trying to have you know the right folks doing it right ethical people that are building these but there's no there's no real enforcement at this point now as a microsoft employee right if i witness something um you know within a customer use case where i identify something that breaks the rules of that responsible ai checklist as i know it i'm required to report it you know to our legal to be able to say this is being inappropriately used for instance using for face detection for some reason right um things like that it's a big challenge it's it's a big concern um uh all of the major cloud vendors have um this type of framework for people to to work with there's been some collaboration amongst you know google amazon ibm microsoft right to have some set of standards around this um but again it's more of a um more of a consortium than it is a law per se right so right and this is one part of the bios that is well covered by the by as you explain but i'm i was thinking more in the bios in in conscious bios that we have with you have data so for example in depicas example picasso has different kind of paintings so that the first he used to to paint cloud cloud cloud clouds no and the pictures that you have there are all cubists right so if i put a joker there maybe it will not classify picasso paint possibly yeah so the the the point is any thought how how to create the appropriate set for yeah that's training good question it is because like you said i mean and i'm not familiar with his artwork right but i'm assuming that was like a good job earlier in his career right yeah he through he painted the jokers and then later in his career he transitioned to something else right that's a good question around how do you train a model appropriately to make sure it's encompassing everything you need it to it goes back to the cat example right as a human we're looking at the rear end of a cat we know it's a cat we're pretty sure it's a cat right um but the computer if it's not trained that way it's not going to know any better right and so i mean and i think um i think that's a big uh focus area for like unintentional bias right um just being naive against something like that right um and and yeah it's it's a big challenge how do you know um that you're you're providing enough uh of of you know details if you will examples if you will to be able to build an appropriate model it's it's a very good question it's it's a hard one to address so yeah i don't remember i don't remember if you remember a few years ago microsoft had put some kind of bot and the hackers figured out a way and it started saying all sort of yeah they made it a racist thought within within an hour i believe yeah it's very quick yeah so even images could be the same right yeah yeah absolutely absolutely um so this is the result that you get when you train your mom right so we've added all these images in and essentially now we're showing the accuracy with which um we can do our predictions based on the results right and so um you know just when you when you when we hover over these right the the precision number um is whether a tag is predicted um by the model how likely it is it's going to be right so this thing is going to be 100 right and i think that's because all of the images have a tag and all of the images are tagged as a painting right so if if it's if it's a painting it's going to be right 100 percent of time we saw 99.9 right um but now when you start looking at where some of them are tagged um as one thing and then some of them are tagged as something else then um you basically it's it's your precision is going to change right next we've got our recall so um"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:50:50",
        "seconds": 3050,
        "text": "of them are tagged um as one thing and then some of them are tagged as something else then um you basically it's it's your precision is going to change right next we've got our recall so um it'll basically tell you out of the tags which should be predicted correctly okay what percentage did your model correctly find and so this is this is more um okay well we have you know four or five different tags that we've got here um we know that all of them are tagged as a painting again so we're definitely going to be right on one of the tags but then all the other paintings have another tag and so you're 50 50 and whether or not that'll be accurate and then finally your um if you know what ap stands for yeah performance that's right measure the model performance summarize precision recall at different thresholds and so what you can actually do is you can change your probability threshold and so you get your minimum probability score for prediction to be valid when calculating precision and recall so now if we increase our probability five percent say so their numbers are supposed to change they did not change why not normally you'd see these change not sure what's wrong anyways so now you recall this lower i don't know why that didn't change though anyway um and then let's see we've got our prediction url um which is that basically that endpoint that api that you can call to call against your prediction essentially how did you go there on the top prediction api prediction url and then when we go yes sir what's happening with the image after the model evaluate for example what's happened with the image after you submit to api models runs evaluate what happened this one is stories please you can you can determine what it does um it'll stay in cash for a little while um it'll eventually get cleared out of cash unless you tell it to go somewhere else so because you're storing it in a model right and so then that sits in that um the the model will reference that that set of images right so it'll sit there um but you're talking if we add in a new image yes you know for example uh with this cut yeah you use the you have a load to your application your right is in your storage and you set the cut through the api yeah so the api get the full image you use it for the evaluation yeah give you the uh the score yeah yeah what's happening with the image so yeah so the the results of the image get sent to the model i don't think it actually gets stored in image form i think it gets i think the details of the healthy image the image itself doesn't get stored in there okay and and that will sit in cash now you can do something else with it right so if you want to keep it for later you can send it to a different location if you wanted to um yeah you know but basically we like to know if the services keep the image of the customer all the image that the people are sending uh it looks like not in yeah no in this case right these are being stored because we're using them as examples yeah right um but when in the actual model itself it's all just a mathematical formula right for the algorithm that you're building for that mmo essentially yeah um in our case we processed it and then sent the image to you know blob storage somewhere else to just store it long term so we had so um what else did i want to show um here just some more of the details right so when we we want to access the cognitive service itself right it shows some of the details around it you know what your usage is that that type of stuff i guess it will i didn't think it would let you change it um and then you know you can set your limits you know and that's basically to to somewhat um control your spend right you don't want people to blow up your your azure bill by playing around with some of this stuff so now i want to go back and i wanted to check the search on the picasso should be a good example right don't know what you're referring to so something tells me that based on this image here might have a match let's see in fairness this is"
    },
    {
        "speaker": "",
        "title": "Chris Seferlis: Azure Cognitive Vision - Computer Vision made easy",
        "videoId": "yMwMpsIX9oQ",
        "description": "This is a recording of the June 30, 2022 meeting.Computer Vision technology has been a dream since the late 1950’s when scientists studied how the eye recognizes features of images. In the present day, we have the technology to make it a reality. The Computer Vision service can be deployed in a matter of minutes for a simple proof of concept, but features robust capabilities for AI use cases at even the enterprise level. This session will discuss a brief history of Computer Vision, the Cognitive Vision service, demo some of the capabilities, and help you build an example of costs for deployments.About the Speaker:Chris Seferlis is a Client Technology Lead at Microsoft where, for the past 3 years he’s helped customers bring their technical strategies to reality with a heavy focus on how they are using their data. With over 20 years’ experience in IT and a deep background in Data Warehousing and Business Intelligence, Chris brings a practical and theoretical approach to business technology challenges using a data driven mindset. Chris holds an MBA from the University of Massachusetts, is a Microsoft Certified Trainer, is a guest lecturer at Boston University, has a data focused vLog on YouTube, and is currently writing an intermediate practical approach to implementing Azure Cognitive Services and Artificial Intelligence.",
        "start": "00:56:02",
        "seconds": 3362,
        "text": "should be a good example right don't know what you're referring to so something tells me that based on this image here might have a match let's see in fairness this is a funky angle on this desk all right so 77 right and and again i think a lot of that is based on sort of just the um the structure of the painting itself right you know some of the features of it but if you know you're in person looking at the painting side by side you know there are certain elements or aspects of that painting itself and that distinguishes it a little separately you know so um [Music] what else i think that covers the service pretty well um any other thoughts questions or formulas um yeah so that goes into the tiering a lock so if we look at um the custom vision services we go to spin it up so can you also just show us like on the azure what service is it roughly just an idea to get an idea how bad the bill will be so we test it because we don't have a account like yours right from microsoft limits on my accounts too actually um all right so this is actually only there so there are different tiers of the standard tier um you know but you can see for the most part it's based on number of transactions um compute hour things like that right and so that's kind of the way it gets broken down now it does have a cap of six megabyte images um this is something that i found really interesting um the the deeper the image the more um uh sophisticated the image doesn't make it a better image for training because if we talk about you think back to breaking down that image you want to actually simplify it to be able to pick up the picture the the features of it and stuff like that you don't need that super clear crisp image right so you don't want uh super uh high rents image yes sir when you add additional um images for training your model does it just add does it just need to do the training on the new set or does it need to return that's the advantage of using the microsoft model right because it's been trained right for uh yeah but you know in this case um it would you know using this example it would have to be trained on the artwork the existing microsoft model would have to be trained on what that artwork is right that that base my microsoft model is more based on those domains that we're seeing like food people right you can do um you know celebrity recognition is one of them um what else ocr is obviously one uh what else is in there uh landscapes scenery um uh major um landmarks you know so like it can recognize the eiffel tower and stuff like that right so those that's a pre-trained model but in this case i don't think you'd be able to load a picasso and be able to come back to you and say it was a picasso you know what i mean it it it's a and that's why i demonstrated the customers yeah yeah um see actually if i go to the pricing calculator so it will create a resource group for you when you start automatically uh nope you have to create that yourself uh well when you think about it we remember and said create um your compute when you when you because you can actually just go straight into custom vision.ai and you have the ability to um create your compute right there it'll have you specify a resource group in your azure tenant or create one so it's similar to any other resource existing or new kind of thing and this is image storage is for the training set right yes even for prediction yeah what do you mean well when you load the picture up oh okay right you're predicting against it um better than the free i thought there were more yeah and there's some oh that's right they get thumbnail so you the part of the service will create a thumbnail of your image um i don't really have a great use case for that to be honest with you um i'm not sure why you know describing recognized text um ocr is it an adult image landmark celebrities all that um jason can you check what i don't see the chat um yeah the question might have popped up i just asked if there were any questions oh okay oh it was you the message everybody's asleep i put them all to sleep they're all and we lost veronica too i'll have to harass her later you can tell them that hey i'm raffling out uh like uh ten dollars of credit for azure now that you mentioned it you just reminded me i brought i brought chat keys tonight stickers you need some socks you don't have any on your socks on so the irony about these socks is that um i've had them in my garage for the last two and a half ish years yeah oh yeah so here's your uh your s1 s2 s3 so these are actually built at higher rates um so just for comparison's sake wow same thirty six hundred dollars well but remember that's five million images oh that's a thousand good one yeah oh yeah yeah right thousand tons yeah so the s3 is slightly higher than s1 and s2 yeah so um in the book um and and hopefully i'll come back and give some of those away when i get some demo books um you know for all that kind of stuff but um you know i i do pretty deep dive on the service you know both the the custom model as well as the can model um some of the capabilities some of the options and stuff like that um but you know hopefully um hopefully this hit the mark and you know give you guys kind of a good overview of what the service looks like and stuff so i appreciate i appreciate the questions and stuff so and it's great to be back in person absolutely so anything else before wrap thanks for pizza yeah there's more out there too let's take some i actually may bring a couple slices we've got an empty box eight six other ones yeah you "
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:00:02",
        "seconds": 2,
        "text": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID. This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.. awesome okay perfect so welcome everyone um to our virtual boston azure meetup and we are super happy to have you all today and we have an awesome awesome presenter all the way from vermont um kyle mitovsky is the principal software developer at vermont department of health and he has a great experience with chatbots and he's gonna share that with us um i met kyle personally a couple of times so that's awesome um i miss meeting people all the time um and kyle is really active in tech media he's presenting attending different meetups and events all around so he's a really knowledgeable great person and i'm sure he'll tell us awesome stuff about chatbots so kyle go ahead okay okay thank you um uh appreciate the introduction uh yeah certainly we've seen each other cross paths at a lot of different uh tech events and i'm involved in uh helping do the site stuff for vermont code camp which we have annually and this is the first year that we're not going to be able to do it because of coved um so uh i i love and uh really appreciate getting to jump into meetup groups that are virtualized and i wouldn't have otherwise had the possibility to do we don't have a huge azure community or not one that i've taken time to foster up in burlington so it's really nice to be able to kind of come together virtually um so this is an awesome opportunity um the uh the self cudas i want to do uh so i wrote this uh thing today i've been making commits all the way up until like 5 55. um we have this uh uh site that we wrote for the uh uh all of our kind of documentation it's kind of tech bloggy uh but it's for the department of health and we have you know uh different articles in here that talk about how we're solving problems and so uh in here today this presentations thing is new and uh what it will do is go grab this and this is just a markdown file we can look at i'm really just nerding out before the presentation this has nothing to do with it uh but built it all today uh edit this page will take you in github where this page actually lives um it's a markdown file if we look at the raw version of it some other presentation frameworks work the same sort of way where in markdown three hyphens is just a horizontal rule and uh this works by just taking uh and this entire files worth of contents it just splits on here and we'll make slides for each one of these different things so if we come back to uh where were we in here uh we can take this whole thing and play it as a presentation so that's where to find our slide deck and a little bit about how it's composed um there it works with key arrows so we can step through stuff like that so if you're ever looking for the two links that i want to publish uh or make sure people have a chance to um have to go review information is uh this one right here dot gov dot dev uh slash slides slash chat bot uh then each different slide gets uh put on its own uh link and then also um everything we've done for the um that we've done for the bot itself um we've kind of set up as a big old mono repo on github for lack of better governance so um every single one of these folders relates to some component of the chat bot that we've deployed or customized or had to involve in some way there are some big notable sections in here and some smaller ones um and each one of these has like a readme inside of it and using jekyll to publish those readmes we can get them so here's just the readme at that root level um and we can get them all on the github pages version of it so here's the docs for that entire repository um uh and so this is the other link that i think if people are looking for follow-up um those are the two places i'll point you to uh veronica said feel free to type in your questions here in slack uh i would definitely echo that um it's gonna be really stale if i just come in and i think chat for an hour and a half a couple hours and lecture at you i'd love for this to be as engaged as possible i will take any question about any topic and no promises that i'll know the answer uh but i think that'll help break up things as much as possible um let me move on to starting this presentation okay"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:05:05",
        "seconds": 305,
        "text": "be as engaged as possible i will take any question about any topic and no promises that i'll know the answer uh but i think that'll help break up things as much as possible um let me move on to starting this presentation okay so uh uh i i appreciate veronica saying i know a lot about chatbots it's really just been the last three months of kind of uh poking around at them and figuring out how they work um and spending some percentage of our time uh as a dev shop implementing them and working with them so this is really it's a a good survey and kind of level and summary level of some of the technologies in play but uh it's definitely just scratching the surface i know there's a lot of um in our if we look at our backlog this is an open source repository so anybody who wants to spend time working on kovid can feel free to tackle any of these uh issues um i know there's a lot of uh aspects of this technology that we're not yet taking advantage of and just need to prioritize or need to spend some more time uh working on them we've had tons of other projects um in the same window so it hasn't been an all-out push to get just chatbot features implemented um but i think we're really happy with what we've done so far um like veronica said i work for the department of health um i'm a principal i'm the principal developer there uh but it's a title i gave myself so don't read too much into it uh so far no one has objected um to that uh but i have a team of five developers um and five like application developers we have some database developers some qa some ba folks all part of our uh internal dev shop for the department health and we have lots of projects we maintain and programs and divisions that we service and a lot of that has been mission central for covid uh stuff as we kind of work through data and work through setting up infrastructure around pop-up test clinics there's just a phenomenal amount of work that our developer group has certainly been a part of but everyone in the department health has just done a fantastic job oh uh i'll color that i certainly don't speak for the department of health um i don't think they have a problem with me giving talks and stuff like this but um uh take any of uh you might be able to trust my tech opinions but i'm not a doctor i don't know uh uh i'm not an epidemiologist they're certainly people who are better informed uh as we kind of overlap with covet related topics for uh this uh presentation uh here's kind of what i want to talk about um just some acknowledgements uh for the people who have worked on this project so far um i'd like to then kick things off with a demo of what a final product of a chatbot looks like and what ours is doing right now in a version of production really against tests because i don't want to mess with their telemetry um some of the technologies that are in play some of the training that you'll have to do if you have a bot um everybody always asks about pricing so we can go over uh the costs for things they can scale i mean it's it's azure so there's no one sacred version but i can share uh kind of the overview of uh what pricing is some of our lessons learned uh and towards the end of getting into an azure demo um and just looking at how to spin up all this stuff i think most of it's kind of spin up able relatively quick but it's always one of those things where i was having this discussion at work yesterday i really uh i hate when kind of we as developers like to flex a little and be like oh i spun this up in a weekend or you know i spun it up last night or in a day and then we have to maintain it for the next like six months or we put in like another two four weeks and so that's the real cost of that implementation so getting something deployed to production or spun up quickly isn't necessarily like the golden egg that it's made out to be but certainly we can try deploying something relatively quickly um there were kind of four teams that came together and these are all internal vdh things so i won't go through uh people you know specifically i want to give them credit because certainly i'm presenting a lot of work that other people have had a hand in doing um but mostly to the point that this was a large collaborative effort this wasn't just devs this was communications team played a huge role it was the first time i'd worked with all the members of our communications team uh because we just don't normally cross paths um in a lot of the applications that we build internally um vermont is kind of structured such that we have all these different agencies and then each agency has departments and then each department has divisions and then each division has like programs which is just lots of levels of bureaucracy um as any large organization can or should"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:10:08",
        "seconds": 608,
        "text": "that we have all these different agencies and then each agency has departments and then each department has divisions and then each division has like programs which is just lots of levels of bureaucracy um as any large organization can or should but we also have a group called ads which is the agency of digital services and they kind of oversee all of our development effort and so uh they kind of got the ball rolling on some of our azure stuff some of the chat bot stuff um and then microsoft themselves and i have a slide later uh talking about some of the stuff that microsoft they were very helpful and instrumental in getting the ball rolling on this they did this for a number of states um oh boy i'm gonna missouri was the group that first kind of set up a chatbot through the same exact technology stack that we're deploying it through um and kind of shared some code with us and but microsoft was kind of intermediaries for that they held for weeks on end they had held daily uh open office hours and anyone could co go ping them and ask them questions and if they were getting stuck somewhere uh uh they helped out a lot of states and a lot of state's health departments uh get some of this stuff up and running so credit to them where credit studio uh they were very helpful in getting us off the ground uh and then the teams kind of been very helpful in keeping us off the ground so without further ado and because this is uh because this isn't a powerpoint and it's in my it's in my beloved webland i can embed some iframes in here so uh this is our chat bot that hits against our knowledge base of uh quest frequently asked questions that we get um from the community about coveted related stuff and we're publishing that or syndicating it across a couple different channels um so does anyone this is a one of the few uh uh high value engagement opportunities in meeting chat if people want to post a question uh i can type that in i certainly can uh probe with some uh questions myself but i'll give folks uh a second to see if they want to type in the meeting chat covet related question uh and then we'll go give the bot a live run for its money and see how it does while people are certainly thinking about that um uh have slate cough and fever sweet thanks uh thanks ricardo uh uh let's say so uh have slight cough and fever sweet so uh here's what the bot returns what are the symptoms of covenanting some of the backing technology of this and we'll get to technologies later is there like cognitive services that does natural language processing it's certainly not uh a world of dev that i know how to do out of the box so it's like i'd rather buy that you know i'd rather get that software from microsoft to have them do it uh so it says what are the symptoms of cova-19 uh we talk about cough we talk about fever in here um and then you can kind of optionally provide all these follow-up prompts to say hey i asked about this here are all the other related questions that we know people care about or are interested in so once i have that information maybe i want to know if i can get tested for cover 19. so i can click that and we get this kind of multi-turn conversation where it submits that query and then i get that bill also asked is it important to wear a mask and i'm normally very stringent about fixing my typos but i'm going to leave it in because i want to make sure that you know it's doing the work of figuring out how to uh parse that question because in the real world we'll certainly get typos um what can i wear if my health or work uh environment doesn't allow me to wear a cloth or face mask covering so i think this is a good example of where uh when we have this language processing we certainly like have hit some of these words right um where mask but maybe important here is like uh the real critical world word uh and this probably enumerates some of the pros and cons about it um and there are certainly other follow-up questions that we could ask but maybe this maybe there's a slightly more a better option within our knowledge base to land that and so we can talk about how um maybe we can try to take input queries and make sure they return the right output query um one piece that we manually add to every question there are ways to put uh attach card footers to everything that gets returned but we just say all right this did not answer my question then we log those and we kind of give them a sorry we couldn't find a good match you know here's different things we have a 2-1-1 we have a call center line that people can call into this was kind"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:15:10",
        "seconds": 910,
        "text": "did not answer my question then we log those and we kind of give them a sorry we couldn't find a good match you know here's different things we have a 2-1-1 we have a call center line that people can call into this was kind of our first wave of defense against the call center to say hey if we can answer something automatically and uh not to paint this as a generational thing but i'm certainly of the mind that if i can get through finding a piece of knowledge without calling someone i will definitely do that um uh i i hate being on the phone i hate calling people i hate waiting on the phone i'd much rather do a chat bot where i can kind of wait asynchronously or find information immediately um so i think that uh multi-pronged attack kind of helps that this is a wall of defense against uh uh huge call center volumes uh which historic uh i think i put this in the project reflections historically we didn't even have a call center we had a couple temp positions uh and that was it we just don't have uh oh good where can i get a test um uh we don't we didn't have a a huge volume of incoming calls and so we had no reason to staff anything and with the onset of kova 19 and how much the health department has really taken point on a number of those things it's just cannibalized almost every other department we have and program we have so people are volunteering hours where they go become informed like figure out all of our faqs but then answer public questions and kind of work through some hierarchy to make sure that they have the right answer uh where can i get a test from jason um and we get where can i get tested for cover 19 um uh as someone who doesn't type in this off uh often and whenever we're doing like live demos it's nice when this returns back uh a result uh somewhat mirroring the question so uh thank you for the question jason um here's some information about that uh the substance of the knowledge base allows like rich text formatting via markdown um so we can have links in here we can have images if we want but we don't have any we can have bold and list and stuff like that um and then you know if we we're off the mark a little these are all questions we've manually said well you know if you got to this question maybe these are relevant things too what is serologic testing or how long is the turnaround for testing if you've already done that um so that's a demo of our bot um one thing just to kind of paint the whole stack of technologies the bot is the front end for specifically the web chat piece of the bot is the front end for how we leverage those technologies one of the technologies in play is just q a maker which is where um the knowledge base is maintained and one thing we can do is syndicate that across other places so one place we have is definitely the bot um the other place where we take what we put into q a maker and we build out is through this faq um so here is every single question that we had access to over the bot and just kind of in a different way to discover that same information this is something where we read in uh the api data we just get a json payload for that and then we take that through a site builder and we just scaffold out that data and template it out across this page um so here we have uh all of the questions that we have covered overall we can expand them and get information about any one of them um and one of the things we have on here is just kind of a filtering um and for me this is kind of my favorite way uh in terms of ux and uh how we can architect things i think uh filtering a lot a big list of things is one of my favorite ux patterns so if we say uh you know something like test in here we're gonna get all of these answers that have to do with testing either somewhere in the question somewhere in the summary if we don't have anything highlighted here it means somewhere in this body we're talking about testing if we want to know stuff like pets we can take some of the stuff that we've aliased um so we have some synonyms at the question level and so if i type in pets i get pets but also if i type in dog uh i should see more things but i also see dog is synonymous with pet um and so pet gets highlighted all the same and uh that gets uh maybe if i type in dogs it will yeah uh reduce the number of things um so can pets get sick from cover 19 or are pets from the uh from a shelter safe to adopt or can i get cover 19 from ipad or other animals um these are some of the things that we have answered um we have kind of everything grouped into some categories and subcategories so on the left we can navigate to any one of those categories we can link to categories we can link to particular questions and you can send them to your friend or to your family and this is all generated based on the information that's put into the knowledge base uh and again these"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:20:12",
        "seconds": 1212,
        "text": "of those categories we can link to categories we can link to particular questions and you can send them to your friend or to your family and this is all generated based on the information that's put into the knowledge base uh and again these are just two prongs um here's the chat here's a demo of the chat bot we have that on our official healthrun.gov site and this is our vermont.gov app domain that we normally deploy all of our kind of internal apps through that are authenticated and stuff like that um so these are two of the ways that we expose all of that information are there any kind of questions about that or um hopefully one of the things i kind of want to do is like get people thinking about you know how can i use this sort of stuff for uh how can we assemble uh uh it's certainly uh gotten us thinking about how we can leverage a knowledge base as an organization outside of covid specific response where it's kind of been high priority it's like yeah i just kind of want a knowledge base of things that doesn't seem like a bad thing to have if i get some natural language processing for free on it um if i get a structure to that data that kind of makes sense and i can scaffold it out somewhere else that kind of helps so i think those all play a role in that um let's pop back into here so those are the two kind of live demos of the end product um and now let's kind of poke under the hood of that car and see how we got there um in terms of the technology stack and i already kind of gave this overview um first up is just q a maker and what q a maker is responsible for is actually maintaining that knowledge base uh it's a microsoft product um and it stores that information into azure um but it's entirely sep you could stop at the q a not that you'd want to but you could stop at the q a maker level it doesn't come with a bot for free you have to also instantiate bots and however you want to consume that information uh bot framework is the next thing that logically you do with q a maker most of the samples go from one and then to the other um 11 d is what where is q a maker and azure service it is so it's q a maker uh it's not actually let me uh it's fair to think of it that way um uh q a maker is really the gui piece or the set of apis that interact with an azure service uh if you're looking at your subscription or you're looking at the billing the thing that's actually running is cognitive services um but yes when uh you need nothing beyond an azure tenant or an azure login to be able to uh log into q a maker and uh deploy q a maker so everything that is done inside there is uh stored within an azure resource group uh i don't think the name of the service itself is q a maker um and maybe that'll be a little clearer when we poke at these things live in azure but good question bill thanks um uh and then uh uh i'm a big fan of static site generation i think anytime we don't need huge rich interactivity i mean in fact we have some a non-zero amount of interactivity here when we say you know there's a little bit of javascript running on this page uh to do some of this filtering but it very gracefully falls back if you have no javascript if i come into here and i go to disable javascript and i go refresh this page everything's going to be perfectly fine and in fact that filter box goes away too that filter box only comes in as soon as uh it's hidden by default and as soon as javascript comes in it says oh i'll unhide it with my js you know voodoo uh because if you don't have javascript enabled i shouldn't be able to see that filter thing um so this very gracefully falls back um on old machines uh server side rendering has some of these same benefits but in terms of performance you're very snappy on mobile devices if you need to run you know a lot of people are asking stuff on mobile devices um so we want to be able to support that environment um and so you know even if this is small we're still going to have a decent experience which is more the layout and css properties of the thing but this is kind of what we have in terms of a site experience and not that um 11d is the only way to get there there are tons of static sight generators and i could uh my talk at boston code camp and uh vermont code camp last year uh in the fall was about static site generators uh with the gentleman i worked on the vermont code campsite with which is a static site generator so i can certainly talk about that all day it's uh something that i think is a really good space on the web um but we're using 11d to build out that faq page so we'll go over a little bit of that piece of things oh probably uh yeah um probably if"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:25:14",
        "seconds": 1514,
        "text": "it's uh something that i think is a really good space on the web um but we're using 11d to build out that faq page so we'll go over a little bit of that piece of things oh probably uh yeah um probably if uh uh that's something people are super interested in either we maybe we have time at the end if that's the direction uh uh uh enough people want to go in um certainly you can hit me up later um i think the first slide had my twitter handle and my dms are open if you want to talk about that specifically or maybe i don't want to bombard azure boston but i know static uh um static web hosting uh is something that azure's kind of recently uh put their hand in uh so they're starting to that and markdown i love markdown also um that's probably as i move to senior roles and i spend more time helping people build stuff uh and in on meetings i i write in markdown more than i write in probably any other uh programming language so uh i like things that are powered by it um q a maker we talked about that's the knowledge base uh as of build 2020 um they finally have a rich text editor um uh in there so when we're talking about the people who i really want managing that content are not necessarily developers not that developers can't um or shouldn't but the goal of the q a maker is to put it in the hands of a subject matter expert or a communications expert who knows how to do that and our communications team has done a fantastic job they keep a lot of first order principles in mind about using simple language uh um one of the things that uh um i want to be able to show at some point uh and we oh you know as we look at this stuff we can this is a secret little hidden view that is not uh uh there's diff.html and one thing that's in here is there's a little yellow dot if that question has been changed at all um and there's a green dot if it's a new question and these are all just changes in the last 24 hours and every day there's just a tremendous amount of ways that they're very careful with wording and language some of them are tiny and some of them are conjugations and some of them are just converting things into plain language so every day they spend a lot of time just managing this inventory of questions and really carefully thinking about what is the easiest to read um and so that's something that i think uh relies on their expertise um and it's something that i certainly don't uh don't want to spend all day doing or don't necessarily have the uh skill set to be doing all day um so to that end uh having that rich text editor for them is so much easier than having them edited and marked down that's not uh it's not a hard language to learn i don't think for a lot of people um but uh certainly uh wysiwyg editors um are far easier to i mean i if ever i'm using it on the q a maker i always use the wysiwyg um so here's the gui we'll actually get into it later but here's just a screenshot of it you're gonna have to zoom in i can do that i'll zoom in for you um here's the rich text editor here's like the bolding piece of this here's italics here's lists and paragraphs and if you want to include the links you can do that and it's going to go convert it to mark down in the back end here we have one of the training things that we'll talk about too which is uh there's the question of can i wear a mask but then there's alternative phrasings to this so if someone says alternatives to a mask or face shields these are all kind of things that uh questions uh that are like this are similar to these questions will all feed into this answer uh and one of the things we do is we just see a huge volume of questions and we see a huge different uh there we did a little bit we did i think like a week of uh some qa and ua for this and as soon as we opened it up to uh the public we just realized how entirely insufficient qa was to kind of uh think just what spaghetti uh the public is gonna throw out the fridge and see what comes in and they're all perfectly valid questions they're all great things to make sure that we're mapping so we've grown that out a lot over time um what that looks like if we go hit it over the api in terms of if you just want to get into the meat of what the data looks like is it kind of looks like this there's some i simplified this down a little bit but in each one of these particular questions we're going to have uh alternative phrasings uh across the board uh and interestingly this order is not deterministic so when you first enter a question uh it will just have one of these values so it's like here's the question what are the symptoms of cover 19 uh and then we'll have an"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:30:20",
        "seconds": 1820,
        "text": "across the board uh and interestingly this order is not deterministic so when you first enter a question uh it will just have one of these values so it's like here's the question what are the symptoms of cover 19 uh and then we'll have an answer and that answer i don't have wrap on so it will go here and our answer is actually much longer than that but i cut it off here um if you want to add alternative phrasings you can do that but these orders uh can sometimes get shuffled around these are all uh on even footing there's no one true question that maps into this is if i ask any one of these things i'm likely to get this answer as a result um there's ways to manage metadata at each one of the question levels um those keys for metadata are just free text you put in whatever key you want whatever value you want and so we're using it to at the question level identify groups and subgroups that uh things are part of you can see that very easily here so it's basically that entire organization effort was just done for the faq piece of that it doesn't uh you have if you want to extend to the bot service you certainly have access to the metadata at the point in time that you are returning an answer uh but we're not leveraging that in any way right now but as we template out stuff we say all right put everything inside of its groups put everything inside of its subgroups and then give me all the symptoms and put that in here um so that makes this list much easier to parse than just an alphabetical listing of 150 questions um so you can put in whatever metadata you want uh we started with just categories uh and then we extended it to subcategories we have some other stuff if we need short text for something if we need sorting these are all things that you then manually have to go take advantage of programmatically if you want them um so you know just obviously because it's just free text you're just putting sort doesn't do anything it's just whatever keywords you want to use uh to shove data in there you can uh it comes back it's a little weird it comes back as this array of name value pairs instead of like an object with that already has key value pairs um so uh which is fine but when we're talking about manipulating and like etling and massaging this object shape sometimes it gets a little uh tricky at that end but this is essentially the unit of work that is being saved per each one of these questions um then the q a maker api so we had talked about in two slides ago you know here's the the gui for this thing this is the way that you're by and large can interact with q a maker um the entirety of the the way that they communicate is over a rest api so this gui itself kind of dog foods um if you look at the network traffic it's implementing the rest api as well um and so they have a rest api endpoint for anything that you can do in there if it's questions or stuff like that um i have that if you want to do that we created a postman collection just as the kind of easiest entry point into here um and you can share collections and import collections in postman and you can import and export environment variables this isn't any one of our keys but you can template out and scaffold uh what environment variables people need to populate and here's kind of a walk through of where to go look for each one of those environment variables what to import uh what kind of things look like in general um and what it will give you is here's postman here's the knowledge base i think people are probably familiar with postman uh uh if you're not this talk probably isn't scoped to that but suffice to say it's a popular kind of api runner um so that uh you could also curl things you could also there's a lot of ways to hit an api but when there's uh you have to pass certain authorization headers in here there's certain stuff you have to do so it's nice when you can kind of store all of those wraps inside of here so they have some apis for the knowledge base and so one of them's like if i just run a download it will send off that request to knowledgebase it will pass in our knowledge base id it will pass in the environment we want and then we can see all of these things that come back and here's like an example of here's that question we were just looking at is where the symptoms of cover 19 here's the full darn response here's the whole list of questions that we have that map to this question uh here's some more of the metadata and some objects that let me zoom in on this too oh i can't uh unless this works uh sure sure does and then each question also has some sense of what the follow-up prompts are so that whole list of things this is ordered this order is deterministic when it's saved so whatever uh order things show up in here that's usually how they get um preserved but you can also forcibly say this one should be first or last or something and so"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:35:23",
        "seconds": 2123,
        "text": "ordered this order is deterministic when it's saved so whatever uh order things show up in here that's usually how they get um preserved but you can also forcibly say this one should be first or last or something and so uh oh you know we might not have done this enhancement but we had intended to this did not answer my question we always put at the bottom and i think we had intended to you know put this as like 9.99 oh i can't change data but like change this to like 99999 because this should never uh we want to ask it on every question to make sure we're capturing which uh you know input output pairs didn't return good results but it should never interrupt all these other things i want to get to these things first um and then it's just a whole big document this is if i download i'm getting literally everything um one piece that you have to rely on postman for so they have all these apis to go interact with uh how they're storing uh this data and updating and deleting the data and reading it the gui will give you access to uh all of these operations alterations are something that is not available over the gui the only way you can possibly add word alterations is at this level so i don't want to get ahead of myself in slides uh we'll talk about it in a little bit we i think i have a slide on training and it's about the things that we can do to train but suffice to say alterations are one piece of that and you're going to have to at some point call an api there's tons of clients to call apis uh we're just doing it with postman right now i mean we call some clients to uh hydrate our faq site as well but there are lots of ways to do it i think postman is the easiest one if we just want to go modify some stuff without building anything custom okay back to slides um so you can import our collection that's published on our github repo it's the only way to modify alterations over the api most stuff though uh certainly anything we've had program people do is all over the gui um bot framework okay this is ripped right from the bot framework website let me just read it directly it's an ai and natural language uh maybe there's supposed to be more there uh create a bot with the ability to speak listen understand and learn from your users and cut with azure cognitive services okay so that's their kind of like sales pitch for bot framework with some missing word somewhere um uh what this does is still uh so q a maker there's two there's a service on top of a service here um when i run q a maker uh not the gui part but actually live there's a run time for it and it goes and hits this generate answer endpoint uh you know if we have a question like this uh we send this body message to q a maker uh to the runtime endpoint we send something like that and we get a response back from them uh oh and we get uh uh surprisingly we get an answer back i was expecting we wouldn't unless uh something came in but um is this piece uh interesting uh folks here you do that here uh and i think we'll just to prove that we're getting some live response back okay uh somehow we got this response back too i i won't mull on it during the presentation uh uh but i'm surprised by that so uh that's the cognitive services endpoint which is a service that's running it runs over a rest endpoint it returns back um this json object as well the bot framework really runs a service under the hood so the bot framework returns a um kind of a what they call an adaptive card it's information to go get parsed by whatever front end you're attaching this to because the bot framework is uh really the telephone wires between all this stuff it's it depends on what your front end is going to do but it's kind of managing all of these things so it itself is over a rest endpoint and you call the bot framework and you say hey i have this query um it submits the query to the cognitive services endpoint um and then gets the response back and then also bundles that response and wraps that response with adaptive cards with any of the information that is applicable to where it's getting deployed um to that end it can get deployed to um if there's a place you can think of having a input question and an output response but framework can probably do it they have out of the box i think they have a couple dozen uh different native supported uh channels to publish things over um and then there's a custom adapter so really and i think there are enough community projects that have taken"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:40:26",
        "seconds": 2426,
        "text": "it they have out of the box i think they have a couple dozen uh different native supported uh channels to publish things over um and then there's a custom adapter so really and i think there are enough community projects that have taken those custom adapters and put them to weird places but you can also write your own so for example things like web chat are the things that we looked at first so that's just a web chat framework uh i have like a little grid there we're embedding it in our page with an iframe uh you can also do it with the js library stuff like that uh but also that framework you just have a knowledge base right i think that's the biggest difference or the biggest reason to kind of hit on those two different technologies is solving different goals you have the knowledge base that can be published anywhere and the bot framework is responsible for the publishing so if you want this on slack if you want it on ms teams if you want it on discord if you want it via a phone call if someone calls in you can do that over twilio you can also do sms you can do alexa or any smart speaker there's a lot of ways that you can publish that information you can do it over whatsapp so uh i think the obvious use case or the first use case they anticipate you hitting is to do it over a web chat but once you have that available is if you have customers who are looking to do this over sms or if you want to you know implement something for your teams on slack and you know this is your own organizational internal knowledge base and repository maybe slack returns that answer and so the bot framework wires up uh that handshake that exchange in between that end service and the knowledge base and then specifically the bot framework web chat is another piece where microsoft writes the bot framework so that's taken off your plate a lot of this is like given to you to extend if you want but comes out of the box so a bot framework is that service the primary consumption of that service is the web chat piece and so they also write the bot framework web chat front end for that this is their repository for that um and uh you know here's one way to new this up is you can put it in an iframe that goes talks directly to that or you can kind of wire up a script that goes and hits their web chat you can also hook it into react if you're using react on any web front ends and then render stuff with whatever kind of settings you want here um different colors or different user ids or different pictures for your avatar stuff like that and so yeah you can change colors you can change sizes update the css styles if you're doing that javascript invocation it's a little bit harder to do that in the iframe listen to events uh interact with webpage hosting and then if you choose react on top of that you have kind of some react extensions uh to render ui components stuff like that uh so they also produced the web chat um all three of those kind of technologies together were in what we got out of that first demo is all three of them have to come into play the q a makerbot framework in web chat um we already looked at the faq site um oh i'm missing a slide divider here um only read the top half look at this uh look at that okay uh this part uh 11d it's a static site generator um we go uh this is a gimmick we don't need that um uh it's a static site generator there are lots of others and if you haven't explored static site generators there's a website called static gen um netlify produces this site but it's kind of agnostic to them at the same uh end of things they're just very much into this jam stack and uh uh site generation and uh they have these filters here so this is just an aggregate of all the static site generators and you can pick a language uh if you want to write things in c sharp or if you want to write things in elixir whoops uh if you want any templating uh language so you know handlebars or mustache or react or markdown or jade or jsx you can kind of filter what your conditions are and then find a static site generator that kind of works for you and the main thing i i always want to do as my like soapbox as my psa to dispel is that static site generators uh uh say the word choice in them is like it makes them sound static they can get r uh they're so inexpensive to deploy that they can get rebuilt every minute it's never hard to go rebuild a static state generator so you can get a lot of live data in them it doesn't necessarily mean uh you set it and forget it forever ricardo says you can also use cengrid to send emails yep that's true uh one of our devs uh uh managed to do that cool that's awesome um so uh we're using a static site generator uh we go hit that uh q a"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:45:29",
        "seconds": 2729,
        "text": "ricardo says you can also use cengrid to send emails yep that's true uh one of our devs uh uh managed to do that cool that's awesome um so uh we're using a static site generator uh we go hit that uh q a maker api go get that json data we looked at earlier and then template it out another piece that we just added and i don't do i do a lot with web apps and i don't do a lot with websites and so i'm not very strong on my seo game um but uh i kind of explore some of the stuff uh occasionally um uh google has all of these structured data pieces maybe this is news to some people maybe it's not um but you can have a structured data within a page and that kind of gets a lot of the feature cards that you see when uh querying google is because that site provider or some site aggregator actually took and spent the time to actually build out uh this information as specific metadata for google to parse so they have things for movies and you know they if you get these movie cards i mean some site provider uh put the data in the correct structure to be there they have things for recipes and they look like this so if you've ever gotten search results like this this doesn't happen by accident it doesn't happen because google smart and scrapes the right fields it happens because somebody puts in the right metadata tags and so they have one for faqs also and so we recently just kind of adapted we're already getting the stuff over json um all we have to do is kind of have it look roughly like this in fact exactly like this it's really not more complicated than that so we just take all of the data that we pull in over the static site generator and map it to this format we say here's a question we have the name of that question um and then we say here's our one accepted answer you can only put one um and the type of that thing is answer and then here's the answer and it even supports uh um some html uh inside of there um let me refresh this uh i can't scroll but you've seen an answer before um oh because the site got big um so uh that piece is going into the way that we build out that site and if we google for stuff we actually get to see these things returned explicitly uh i think google crawled it like overnight when i was poking at this um we can see if we can invoke live results by just querying this um this only got pushed out last week but i'd like to see okay so i'd like to see us show up here apps.health.vermont.gov which is the website and here's all the questions from that faq and we can show more and then we get kind of their prioritized list of uh questions from there so that's kind of a third place to go syndicate this information some people are actually going to go land on the page and that's totally fine i'd love for them to and explore it but if some if we can answer a question straight over google that's how i prefer to answer stuff so that's another way to publish this information um okay so training this is i think uh i might have this in one of my lessons learned too but this was absolutely the biggest volume of thing that i think caught us off guard when we started doing this um there is a ton uh just getting the volume of incoming questions we have and making sure they map correctly i think the natural language processing takes care of maybe that piece of the lift um but there's still uh you know hundreds of alternative phrasings that i wouldn't necessarily expect a natural language processor to do um and pick up on um they can certainly kind of figure out sentence structure and maybe figure out some uh some synonyms but you know can i go to dinner and is it safe to go to a restaurant i really need the same question right now um in this context for these particular set of users but they have very different words um and it's kind of hard to make sure that they always map to the correct thing and so one thing that we we wound up throwing a lot of labor hours at this um just in terms of when we uh here's uh one thing we do is we export all of the queries uh and as time allows we go through at first we went through pretty much every darn near every query that came into production uh the irony of which is we had done this explicitly to make sure we could scale up call center so that we didn't have to individually look at every single question that was coming in and what we wound up doing is looking at every single question that came in um and so i don't want to share people's exact questions most of them don't have any phi in it but this is where we we just throw everything into excel and we kind of triage it and we throw our at each question we say you know did that person answer it was there a better ques you know we break things up into"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:50:32",
        "seconds": 3032,
        "text": "phi in it but this is where we we just throw everything into excel and we kind of triage it and we throw our at each question we say you know did that person answer it was there a better ques you know we break things up into two categories of training opportunities or missing faq so if it's training opportunity it means somewhere uh that question existed in our knowledge base and we didn't correctly get from that input to the correct output match um so those are training opportunities we have to go figure that out uh the missing faqs we said all right hey it you know i couldn't find the answer anywhere in the knowledge base to this particular thing it looks like it would be really beneficial if we added an faq um and we do our best to kind of aggregate those it's you know soft science but we say you know these missing faqs all kind of had the same theme a lot of people um you can see uh because we have a daily scrum that meets and looks at this every single morning uh and you can see these themes that grow uh with the data like if the governor has a press announcement about you know we're doing this particular thing all of a sudden the next day we get tons of questions you know am i eligible for this or does this impact me or does this affect me and so kind of being timely with uh receiving those uh new questions and getting them published and kind of the feedback loop of all right people are asking about this thing let's get it over to communications uh because we're kind of the uh devs on our team are the one doing that triage um just because we got saddled with that work communications is flat out so um our kind of uh pitch was any way we can help and kind of make this product better over time i'm all for um uh so we're kind of taking on that work we give it some metadata flags you know internally just say it kind of matches these criteria it looks like this uh one thing that q a maker does is it assigns a confidence score whenever it's giving a response back um and this uh p you know this pivot table is kind of interesting this is our own accuracy as assigned by triage is pretty darn good it means that we looked at this particular question we made a determination about yes or no did we answer this person's question um uh and it's you know we have we're not fudging this you know it's only for our internal uh benefit and uh what's interesting is that uh are you mainly adding questions and answers um we uh not developers on the team communications definitely are um uh and it i guess it depends on where and i'll talk about the different entry points for how we uh manage stuff um uh there's definitely some uh building of the knowledge base that actually helps solve gaps in uh accurately answering stuff and then for the training stuff i'll look at where we're actually going and adding those things um but here's the score range that was assigned by the bot and here's kind of how accurate it was and it tracks pretty well um one thing that accuracy by day if we look at um early on we kind of had this triage log this was how many of these questions have we triaged because as we started getting early uh responses back it was just not great um you know this is like one in five this is even less than that uh it uh this is before we had very widely publicized that we were doing anything with the bot and i was like we got to pump the brakes on this we can't really be uh we can't be tooting our own horns about the bot when we're getting one in five correct based on you know genuinely going through and seeing if it answered the question or not um that doesn't seem to be accurate enough i don't know if we've really wasted anyone's time and we already at that point had the fallback text to say hey you know if this didn't answer your question give us a call which i feel like is the best way to kind of treat those cases um but this was not very strong and we built this up uh um very well over time like via training things and there's still room for improvement and they're still a depth of questions that is just huge the number of things that like uh we have 150 questions uh ish there right now as of today and we do a lot of management on the same questions every day just to kind of keep up is can i get tested the answer to that changes pretty frequently over time uh based on what we have available based on uh guidance from the cdc based on incoming supplies um based on systems based on uh you know college students coming in there being different answers through them so in our particular case things evolve very quickly um but training is a big piece of how we get out of this kind of rut uh that we started in um so the triage is the biggest thing that i think uh i would caution people if you're standing up a bot and it's public facing uh and it kind of represents you and your brand and what you're trying to put out in terms of information that expect to do a non-trivial amount of triage and expect to kind of read through every single one of these questions the plus side to that or the upshot of it is that we actually got really good data in terms of what people are asking what"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "00:55:35",
        "seconds": 3335,
        "text": "do a non-trivial amount of triage and expect to kind of read through every single one of these questions the plus side to that or the upshot of it is that we actually got really good data in terms of what people are asking what people are anxious about uh i think people are we had phone data or like we had a phone center that uh people were fielding those questions but it's very hard to take notes and kind of try to answer those questions at the same time so we weren't logging the same depth of data from the call center as we were able to get from the bot so it's actually given our communications team a huge window into what people are actually worried about what people are asking about and it's helped motivate extending our faq which benefits both the call center folks and the bot and the faq page and you know the google search results it's once we can get that in the pipeline it benefits a lot of people um once we have so the biggest thing to extend stuff with is just extending the knowledge base i think that helps a lot um if we have a training opportunity where we just crossed wires where somebody asked a question it absolutely existed in our knowledge base and we didn't have the cap the cognitive services didn't figure it out itself that it showed up and that's the goal right is for it to do all of that work for you um what we're doing also is adding alternative phrasing and alternative wordings uh the phrases we looked at from uh cognitive services at the q and a maker level so here's uh our production q a maker instance um this interestingly for i think bill asked about is this on azure it is but the uh it's not like uh portal.azure.com qna maker you log into this site with your azure credentials uh can you support answering a dynam uh questions with a dynamic answer say with a database lookup uh what's the wait time to get a test how many cases uh confirmed uh are there in from right now yes you can um uh we haven't done that uh yet uh you can do it at the bot framework level so um the adapter you can't do it from cognitive services so cognitive services just owns this knowledge base that static text um one thing i have pulled up here is uh the bot service which comes in and asks a question it forwards that question along to the cognitive services it says hey give me an answer if you want uh at any point in that pipeline you can tap into this and return a custom response if you want and so if you parse through a question well enough to say uh someone's looking for how many confirmed cases are there right now we could tap into anything at that you know here we're just running c sharp on.net so here we could call any other api we want call any other data set run a sql query and return back custom information from within this uh workflow i think most of the information exists at the base dialog level where we get in some information then we return back some option um so yeah you could do that we haven't taken on that kind of technical work um for what problem we're solving the the low cost thing right like the agony approach you ain't gonna need it is like if somebody asks how many tests there are in vermont right now we just send them to a link on our dashboard that has that information there so i think the beautiful elegant ux approach would be to just say you know in line here's my results uh without having to go way fine to other places um but right now if you ask that question you should just get a link that link should be your dashboard that dashboard is always uh under review to publish more information um but because we have a small state in small districts and stuff um uh the data team has kind of been reserved about what information is going out right now uh to the to the as best they can i think that information goes out as uh and so there's a lot of information there i think we should get how many come from cases stuff like that um uh andrew said hey can you train a uh aiml to analyze the calls from a quality point of view or maybe uh pick out specifics uh uh upon your phone system through cisco uh you know i don't know uh uh it's certainly a question that uh we haven't explored um uh most of our calls i guess are going over voip so there might be a way to like you know tap into uh that information and try to kind of get some sentiment analysis or something like that um the managers do record calls to review yeah and like you know like i uh uh uh said two we're just so new to the call center game so much of this got spun up uh kind of at the last minute no it's a great question it's something that like i like kind of seeing these things and think through oh could that fit into our use case and you know um have we actually asked ourselves about that um so yeah we don't record calls i think because it's from"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:00:36",
        "seconds": 3636,
        "text": "it's something that like i like kind of seeing these things and think through oh could that fit into our use case and you know um have we actually asked ourselves about that um so yeah we don't record calls i think because it's from the public i think we probably have different uh uh kind of sensitivities to how much we're gonna uh collect information from people who haven't consented to that yet we're very like cognizant about um those sorts of things in ways that private companies might not need to be as concerned and that little voice style that says you know it's probably being recorded is probably enough um but yeah uh certainly uh we do get that sort of sentiment analysis manually through triage through that kind of painstaking task um but it would be good to get more metrics out of what i call center folk are doing too um or asked a question to them maybe if you're not asking something you might be missed yeah i totally agree um and it's uh uh you know it's like building software right that's like uh these are separate teams and there's a lot to and we historically haven't done a lot of stuff together and it's not like we had this as a project on our priority log to like go write a bot um you know five months ago this was nowhere near something we were looking at uh doing and it just kind of spun up and communication is a big piece of it and uh uh throughout like the length of this we've kind of been uh getting on the uh we send a lot of messages back and forth uh through email and teams but we've been getting on the horn with like communications at once every week once every other week uh to kind of hash through what their options are um and see if there are ways that we can uh better improve services uh and with you know that brainstorming mentality of no bad ideas let's throw some ideas out and uh see what we can do uh not crossing turf though i do look at call center teams it's not my main job and don't like getting involved too much though we had to help on storage for voice calls and that's how you got involved interesting yeah um certainly there are huge storage demands too if you want to store that much voice data um across time especially with a decent enough call center volume um okay so uh uh we can add alternative phrasings and alterations so i had i think uh picking up i had got into here i said you know we're we're not exactly in azure we're at q a maker.ai you log in through your azure account um and so i can go to this knowledge base and see what's in here now um and this is all public facing stuff right so this is all what we're eventually seeing on the faq um this is what was in that screenshot and so uh one of the things we do during uh training is to say uh here's uh alternative phrasing for this question and we do this anytime we've identified somebody having asked a question that this answer specifically addresses and we'll put it here um one thing that so this is at the phrase level this maps an entire question to an entire answer at the word level uh one thing we want to do is they call alterations right these are just words in english that also carry other semantic meanings behind them so there's no reason to kind of think about them as different other than this is kind of how q a maker has drawn the line alterations exist at a word level and the examples of that if we go over to postman which is the only access point for alterations are let me go do get alterations uh what we have in here are things like doctor health care health care provider as soon as it's done sending this request primary care provider primary care physician physician pcp doctor md um what we had before we found out about alterations what we were originally doing and this was true of coronavirus too are um you know can i get sick from coronavirus and then we'd add an alternative phrase can i get sick from covet 19 and then can i get sick from covid space 19 or coveted hyphen 19 or coronavirus 19 or corona and so uh you know here are all the different alterations for uh sometimes the novel coronavirus here there were all these different wordings and i want all roads to lead to rome in that case i want all of those to be considered the same and it was too hard to do that alternative phrasing at every single question level so we can say yeah treat all of these as identical and that also we're consu uh we're consuming so the cognitive services engine consumes that data uh we consume that data as well on the faq so on here this is leveraging that same thing where if i type in koved uh you know i think we call this covet so if i type in uh corona corona i should also get covered here just the way that we've implemented this search feature to leverage those synonyms those are different processes but it's the same data um that is leveraging both of those in that case um back to here that's training a couple things came in the main query is that uh their software can pick up on"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:05:39",
        "seconds": 3939,
        "text": "search feature to leverage those synonyms those are different processes but it's the same data um that is leveraging both of those in that case um back to here that's training a couple things came in the main query is that uh their software can pick up on specific words i think yeah and you know i uh i don't think we're even doing sentimental analysis uh to too large an extent on the bot where you know then we don't even have the uh difficulty of recording voices and uh i think the the first entry point we'd have to sentiment analysis is probably just on the bot traffic coming in because we already have it in plain text you know it's already something i can send to an ml or ai engine uh to tell me hey tell me how this was going in general because we've definitely got people who were uh frustrated uh as certainly uh i would expect or you know can believe at uh how they're getting services uh just across the board there's a lot of frustration i understand that um and i think we wanna do our best to help people through that um so yeah i mean i certainly think if we do poke at that it might be worth doing it against our logs of existing questions that we have already on paper already um and just kind of see if it's gotten better see if it's gotten worse that might be interesting um how do we get questions out of uh azure you might be wondering and if uh uh we were you know we have a lot of stuff deployed on prem uh i'm kind of getting excited about private link in azure and uh having that you know how we can provision some ip ranges within rvnet and uh still deployed to azure services but mostly we have uh yeah private link's super cool um because there's very few things that historically we've wanted any public endpoints on uh almost every project i've been attached to has not been public facing um cove it's the first one where it's like hey this is intentionally public facing but most of the time it's on applications that are uh private facing it's for our internal partners to uh you know we have the birth registry and the death registry and the immunization registry and if you want a birth certificate it's through our it department that like has the software to go route it and so the public should not be logging into that um and so we have uh um some uh you know some servers that do iis stuff and that's kind of been where we've deployed web apps to and it's been pretty comfortable and not that controversial and not that difficult to maintain um and so it's only recently we've kind of uh been starting to migrate most of our stuff to azure that's my goal um because i just don't want to do the server maintenance i mean i want some of those problems to go away which is all to say if you've been using azure already you are familiar with application insights probably to some end and cousteau and kql we were not um so uh all of the data that's available from the bot you can get through application insights it comes wired up by default and it kind of has this uh interesting syntax um there are some and you know if we look at where we have our documentation and we have our repo structure and here's the actual queries we're using so here's our app insights query um i think i have this uh on the github page in ai query here's the kql that's we're actually running to go get some of this information out of here um and then i have some readmes trying to talk through and one of the resources is sequel to a cousteau query translation if you're kind of new to that but familiar with sql i kind of had to wrestle with a lot of these things um to kind of think through how they're working um and one interesting piece is just the order of operations that things happen so normally in sql you have like you know select from where and then maybe a group buyer an order by and you write it in that order and it's sacred it's important that you do it but the execution order bounces all over the place first we care about the from and then we care about the predicate and actually evaluating the where and then we care about like the projection operator the select and so it happens all over the place in a normal sql query and if you really think about it with fresh eyes that makes no sense and usually if i'm writing a sql query right i'm probably writing like select star just to immediately get to the from alias that table and then i can go write you know some uh select statements out of there or i don't think of it in that order i think of it as like where am i getting the data what uh predicate or filtering operations am i doing to it and what data do i want to project and so i think the biggest thing kind of in addition to the syntactical differences to think through in app insights are this order like if you're familiar with powershell or a lot of other scripting languages this uh executes this one piece and it's possible here you could be done and you say yeah i'm just traces and by default it projects out whatever the last result is and then if you just highlight this piece it runs traces and then it runs the where clause you didn't need a where clause here um and certainly you could follow it up i can't modify this but"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:10:40",
        "seconds": 4240,
        "text": "it projects out whatever the last result is and then if you just highlight this piece it runs traces and then it runs the where clause you didn't need a where clause here um and certainly you could follow it up i can't modify this but you can write one where clause and you can put n statements on there um oh and i forgot to get rid of this end in like this code sample um but you can put multiple things and this is independently runnable and if i want to filter stuff more i can add another where clause um there's kind of some cool operators in here uh that sequel doesn't have stuff like extend so extend says i want you to keep every single bit of information you have uh in the table so far but also put these additional columns on top of there and that kind of has helped us you know on traces it has a custom dimensions field but one of the reasons why i think they couldn't get away with i was trying to read hey why didn't they just write sql um or make the uh application insights logs queriable over sql and one of the reasons seems to be well it's storing complex document data that's not necessarily um built in a way that sql's always been able to handle i think sql now can store like some json documents in xml and stuff um but this is like an object that's stored in that column and it can have uh nested arrays and properties on here so here i wanted to grab the question from custom dimensions and i extend traces to you know put that as an input property i'm not getting rid of anything else i could have done the keyword there's project we could have projected to only get these four fields but i wanted all the fields plus these four um so what we end up with in this case is like a complicated little query but we only have to write it once and anytime we want to run it that can be what extracts data out of there and that's what we put into the excel file at the end of the day if uh you've done a lot with kql before um that's not gonna be super new um maybe exactly where to go look and i think the documentation on that is a little bit spotty as to where to go look for stuff necessarily um but definitely you know if you want a starter thing uh hit the repo and i think that kind of rolls around some of those concepts um pricing oh uh uh as i said i just built this whole slide show presentation thing today and i probably would have uh put some borders on this um here's a little pricing chart um it uh there are other services uh if we go to azure right now um here's uh oh and i good i already have this open to our resource group for covetbot test here's technically all the services we're provisioning uh most of the ones that cost any amount of money to run are the cognitive service search the app service plan the cognitive services and the bot service the cognitive service search gets really expensive really quick if you need uh high volumes we are not seeing anywhere near the type of volume that b is uh second from the bottom uh in terms of pricing tier we're not seeing anywhere towards the volume that we'd even need to uh jump out of this and move to a higher tier but we basically have two uh systems right now we have a test and prod um test cost zero dollars um for that service but you can only have one per subscription key for a lot of those freebie things so uh uh if you wanted a test and product you can't just do two zero dollar ones and we absolutely would have a dev environment if it didn't cost us an extra 164 dollars a month just so we have the full darn sdlc but it's going to cost us those prod pricings so i'll make do with test and prod not that any of this is super expensive um on a broad scale so uh azure cognitive service uh cert azure cognitive search is definitely the most expensive thing between test and prod that runs 75 bucks a month uh service plan we're doing a d1 and an s1 that's 82 bucks a month for both those environments cognitive services again a free one but you can only have one instance per uh subscription uh you could put down another credit card if you really wanted a second subscription um but i think some of those things scapegoating around i think azure has a lot of free things uh aren't in the spirit of that whether or not it's uh you're allowed to do it or not um and then we're just doing an s0 for our cognitive services uh bot services is like 50 uh i think this is oh 50 uh cents per 1000 messages so it's running you know six bucks a month maybe um so in total 174 bucks is not anything that's making or breaking the bank i think for uh what we're getting out of it um and leveraging free tiers on all of our test environments um lessons learned okay plan a lot of time for training we already talked about this but you can't get it off the ground unless you can have some degree of accuracy especially if it's public facing and i always work you know my own personal end user experience with"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:15:44",
        "seconds": 4544,
        "text": "lessons learned okay plan a lot of time for training we already talked about this but you can't get it off the ground unless you can have some degree of accuracy especially if it's public facing and i always work you know my own personal end user experience with bots is when they're bad it actually makes me more upset right like i don't have any data to back that but that's if bots are bad i get more upset i feel like i've wasted my time uh waiting for the bot and not getting any answer back so uh i think it's important i think you learn something in the training time uh that is a valuable thing to learn anyway but i would guess that out of the box that's not going to be exactly what you want get content authors involved early and a big piece of that this is that as bill kind of talked about earlier or at least i think of them as related is that what makes a good bot answer is not necessarily the same thing that makes a good faq answer so if i ask is it raining out right like uh these things that you know maybe google or your voice assistant do really well i don't want to link to the weather i want to know yes or no like that's it it's uh uh if it's a one line response perfect as long as it's exactly figured out what i wanted to ask it um and giving me that answer back so we originally had uh the start for our knowledge base which i think only had like 70 questions i think we've grown questions about every single week um but and still to this day it's all very faq themed um and there's a lot of information per question but on several occasions we've actually broken that up and forked it into two different questions here's a little bit here's another little bit we'll link those two together um bot answers should be short and sweet and immediately just answer your query um which is what bill was asking about hey you know if i ask how many people i'd left about to just tell me the answer to that uh and while you can do it um i think as we look at our faqs all of them to be specifically tailored to what a bot is really good at uh they should all be shorter um we're kind of double dipping and using it in our faq site and our call center folks use the same faq that's available to the public so it's helpful for them to have longer version so we're kind of dealing with you know a left brain right brain and a couple different you know use cases for that data um but the earlier content authors can be involved in kind of helping figure out what's going to be on that framework i think the better um some tips and tricks uh one problem is multi-author editing is still difficult um especially if you're coming from like the holy grail of multi-author editing uh which is like you know google drive or something on like a word document i think microsoft is actually kind of caught up a little bit in their uh online office 365 products where you see a little head you know chat but head and cursor position and all the stuff that other people are doing simultaneously on stuff uh we are the exact opposite of that on the q and a maker gui um two people you know they're it's uh they're two separate web clients two people can be on it at the same time but you always are you're gonna there's no like locking there's no way to like just be working on a single question so when you hit save you can definitely overwrite what other people are doing um on their end and so while it's technically possible to have as many clients connected at the same time you'll never know through q a maker if somebody is in here right now working on this same question uh while you're working on it i'm not getting live updates while they're working on it if i hit save it's gonna go undo whatever they've worked on and sometimes it can be a little finicky on here's you know this knowledge base has uh paginated all the different pages but you can kinda you know if you want to look at everything all at once you can say hey view all and everything comes back uh in this source here where this gets really long um and so that poses some challenges the way that we have addressed those challenges is more of a workaround than anything but we just have a microsoft teams chat and anytime somebody wants to go in and make updates uh they bop the group and they say hey i'm making updates and then they say hey i'm out um and for the frequency that we've been doing updating it's not been that big of an interruption i think anyone who has uh right permissions to their uh to q a maker is all part of one group uh that's how we're managing it um the question order isn't deterministic one thing you might have noticed um repeat question wording and answers kind of our solution to this is here's all of the different questions um that all filter into here when we have this answer we don't uh uh this might not be obvious if you've never been in this knowledge base but this is just text that's part of the answer when we have this question here it's not something that uh q a maker has done by default it's something an intentional thing that we've done uh one thing we uh another reason why we wanted this to be uh the case was if somebody asked a question in the positive or negative you know can i wear a mask and i don't think we have any answers now that um uh"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:20:49",
        "seconds": 4849,
        "text": "uh one thing we uh another reason why we wanted this to be uh the case was if somebody asked a question in the positive or negative you know can i wear a mask and i don't think we have any answers now that um uh directly kind of have this structure or format but if it was like you know if the question is can i wear a mask or should i not wear a mask those have different those have opposite kind of interpretations and if our answer is no you know if both of them map to an identical question and the answer right off the bat is like no or something like that it's like well which phrasing got you to this answer so i'm always worried that the mapping between questions and answers probably means that they're getting topics and information related to what they were querying but it might be uh not the exact phrase that they queried so i kind of always want to level set what the answer is with exactly what we're answering and that way too if these get long they can kind of before reading this whole thing make the investment of oh yeah this does look like the question i was asking or if this is totally off base just scroll down and do that quickly so we change these questions out uh by training and by adding alternative phrasings but uh when we parse this out for the faq page this is our one canonical source of that question this is what we treat as the actual way to do that and here we just like reject scrape out we get you know this whole thing as a string in fact here's you know when we convert it into the markdown representation here's what that string looks like when we get that information over the api uh and i say hey uh i'm expecting the question to start with you know some characters that are in between two asterisks and end with two asterisks and i want you to consider this the question because i don't know you know part of that is determining what the actual authority of the question is um so uh i don't want to just you know pick is diarrhea virus necessarily is what are the symptoms of covet 19 when we're publishing the faq if somebody asks that it should map there but we should be uh you know be able to deterministically assign what the question text is so that's how we're grabbing that out now um uh yeah this is another thing we've worked through ids are lossy during publish uh for a lot of things so when we had looked at um let me pop open our faq site um this is uh if we go all the way to here this is what happens when i call that postman route or and i when i say hey download this entire knowledge base this is the exact response we get back um and uh there's an id here and there's an id here and one of the things we saw already right is i do diffing based on how these change every single day i say all right uh i want to know if this answer is substantially different than the day before and the only way i can reliably do that is based on an id because maybe the answer itself changed or maybe the body change these are all things that are legal to change so the easiest way to do that is just say all right what was the uh you know uh grab the id from yesterday grab the id from today then diff those two um and i think probably out of scope for today when we're talking about uh the knowledge base but even that diffing of here's two markdown strings and you tell me the differences between those we had to write a custom like mpm package that does that um i couldn't find anything that organically gives us uh when we're looking at here's our diff slide and i have two strings and i want this kind of level of processing of give me the final product uh with you know if they're bolds or lists or links don't break those things but let me know when things have been scratched out and added between two strings there were some things that were similar but none that worked with markdown none that kind of did that stuff um the warning call is these ids can be pretty lossy if you're doing a publish through the gui the way that that publish works is just by taking literally it just deletes the entire knowledge base and adds it back in and these ids just uh increment up so if the bottom one here is all the way at four seven one three then we'll just start over and four seven one four will be the very first id and we'll uh start over from scratch so if you want to uh if you do anything that's editing the content through the gui it doesn't go bulk replace the id but when you're talking about moving between test and production that's when it will um and so we have a huge cli set of things where um in this same repository where we're building out the site and templating it out we also just added a whole bunch of commands to archive the data or deploy it or you know fetch data or link the data or list changes and we're doing some cool stuff again out of scope for this i think this is all just oh uh yeah i should be able to do this faqcli we'll run all"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:25:52",
        "seconds": 5152,
        "text": "know fetch data or link the data or list changes and we're doing some cool stuff again out of scope for this i think this is all just oh uh yeah i should be able to do this faqcli we'll run all of these and then uh i played with inquirer for the first time uh on the node end of things and so you can kind of pick what you'd like to do um uh and so we can get help text and that kind of gives us help information for all that cli stuff or we can go run a command and so i can run like list changes and i can say hey here's all the stuff that's been changing or i can link stuff i can do any of these commands which is all to say if you do find yourself in this problem uh the method that we have for taking uh you know i wanna make some modifications here i'm doing this on the back end i'm doing a bulk publish uh this restore operation goes in and takes uh figures out what's currently live and looks at this existing faq and makes all of the what they expect to see uh submitted is every single delta so if you're changing metadata for example and i if i change it to this what i really need to do is submit a delete operation for this for the old one and submit an insert operation for the new one um stuff like that it gets very hairy and you want at every single field level it wants exactly what changed and that's the only way you can preserve the id so uh if you want help with that this is kind of the script we came up with to do that it's not trivial in terms of getting things exactly in the right structure you need to say here's exactly what we're adding in terms of questions adding in terms of metadata these all have specific shapes to them here's the context that we're changing if we change any of that otherwise you run the risk of losing ids unless you're doing diffing ids might not be super important to your process um but i'd always rather have them um i guess um i think uh you know we go till eight i think uh uh in my dry run for this demo i think it takes about 20 minutes i think we go straight till eight and do a demo of uh getting this stuff started just uh if people are still interested and still wanna stay on the line uh we can look at that um uh if folks would like um uh um because i think that you know one of the things is the deployment of this is actually not super scary um so as long as i get a thumbs up from folks um it doesn't leave much time for questions but we've had some come in throughout so i'll get started on this i guess and if people want to ask questions ask away as well let's say you're starting from scratch i think this is my own personal azure account i don't have any resources uh related to this you log into q a maker uh you can log in uh you can go to my knowledge bases but this should be empty i don't have any and so there's an operation create a knowledge base and where this sends you to is uh i i don't know what the term for this is in azure space but they kind of template out and scaffold exactly what uh newing up this resource is going to be so if i hit create q a services it sends me over to azure i get this you know instantiation blade where i set all my settings for it um so we're gonna create a service and i'll call this uh boston azure bot um the pricing tier i want for this is free the resource group i'm going to create a new resource group and call it boston azure bot uh somebody who works for azure is going to have to explain this to me at some point uh oh i'm gonna choose from here yes you if you choose east u.s i have to choose east us like an another dozen times i don't understand why as long as i said i'm in east u.s just take things in east us in general website location still in east uh app insights location still in east us um let's hit create make sure everything is fine here this deployment process takes a moment so uh deployment is underway right now while that's underway uh is a great little window for questions uh but i'll leave it on this screen because uh i'm waiting for these little bubbles to stop so uh what questions do you folks have i think this will take five minutes so uh somewhere abouts uh certainly i hope it does if we want to hit eight o'clock bedtime for everyone uh based on cost 6k does that mean you're turning around at twelve thousand monthly queries uh into self-service questions i guess this would increase responses uh that do not answer the question yeah i mean uh"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:30:57",
        "seconds": 5457,
        "text": "eight o'clock bedtime for everyone uh based on cost 6k does that mean you're turning around at twelve thousand monthly queries uh into self-service questions i guess this would increase responses uh that do not answer the question yeah i mean uh and also uh some of those numbers are based on the follow-up prompts that we've said so uh um uh i don't know exactly what our uh count is twelve thousand actually seems high i think when i was doing that estimating uh for monthly i think it's closer to like five thousand monthly um uh and i think six dollars was just you know an armchair estimate at uh you know uh what we might expect for that um uh and you know we're we're a small state right so we have like 623 000 people in the entire state um and so you know the volume of traffic i've actually i think is higher than i was anticipating originally uh based on how much we've publicized this exists um uh so uh yeah but good question um okay so this is complete um no yeah totally agreed um we should refresh this down below and it will go look for your azure subscription and i think i have two like you go subscriptions i'm sure i'll figure out how to delete one of them one day and i can select azure q a service and this is the boston azure bot this role does not have permission for the section let's uh hard to refresh this page see if that does anything differently uh select subscription pay as you go cool boston azure bot we're going to do english and i'm just gonna i i'm a fan of just naming things mostly the same there might be better naming conventions um we're not gonna populate it with anything initially there are some options for um chit chat and so uh um you know things like uh are you a robot or something like that should those questions should not map to something in your knowledge base uh and so i think one of the chit chat things it's trying to do is steal those questions that you might be asking uh people might be asking kind of uh jokingly or sarcastically or uh you know just the way that you might engage with the bot um some people legitimately ask am i talking to a real person and to that we always want to have a response that says no you're not talking to a real person like don't give me medical info don't say you know i'm having trouble breathing like uh this is a bot and so we try to make that clear in the copy going into the bot and also the responses that come out of the bot um but the chit chat is a little like snippy and a little like uh wisecracky even at the professional chit chat level but you can review what's in that file and figure out if it works for you um let's create a knowledge base um this should provision those resources and if you see a spinning icon feel free to ask me a question um i could ramble some more too on uh stuff we've done uh okay so i have a knowledge base uh guessing stuff is still loading because i thought i put in the chit chat but let's add a q a pair to here um we're gonna add the question itself um and say like uh oh here we go it loaded in the professional chit chat here's the kind of example of like all of these alternative phrasings you know do you ever get hurt and that says i don't have a body sometimes that's a little weird and out of context if i ever get this response back and somebody's querying something about breathing uh for covid and it says i don't have a body is like we just didn't like any of these things so we didn't deploy with professional um you can kind of use this as a starting point to be like alright if these questions came in how do i want to actually respond to those you can add a q a pair and let's add a q a pair saying like uh you know oops can i go to the store um an answer uh sure [Music] i don't see why not just wear a mask uh when we were talking about metadata earlier um in view options their show metadata and this is where we added those category fields categories like shopping or something you can put in whatever you would like in terms of that metadata um we there's a couple different so you know think of this as uh we have this asterisk here it's like this is edited we haven't saved anything yet um if i make a change to the knowledge base approximately how long does it take to run the regeneration process we'll do that live right now right so uh i think you know it depends on the size of it but soon um and i uh this should be an in-place upgrade you know like when we're publishing this nothing comes down uh however that's being handled"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:35:59",
        "seconds": 5759,
        "text": "that live right now right so uh i think you know it depends on the size of it but soon um and i uh this should be an in-place upgrade you know like when we're publishing this nothing comes down uh however that's being handled on the back end i'd assume it's not dropping anything um when you save and train within one of the other features inside of here is if i test this knowledge base out i can say hey can i go to the store uh and i should get the response back that we put into here and if i don't um or i'm trying to figure out why it's not um coming up correctly there's an inspect feature and it will tell me you know here that it was the exact phrasing so the conference score is a hundred um and it gives me alternative things the conference score is much lower and it picks the highest confidence score um you can set a setting in the bot service to return top three results or top end results um if i just say store go to i might get the same answer but when i inspect that its confidence score is a little bit less right it's not i haven't hit an exact phrasing there um and uh you can rank them and say yes i'd like you to choose this instead or this instead or add alternative phrasings at this level um so let's uh to dismiss this you can't just click off of here you have to close that blade um we can publish it from here and publishing uh you know when we talk about deploying we have our test service and our production service each one of those services has uh what's running on the knowledge base itself is technically they consider test and publishing it makes it available on production so bill to answer your question that publish means it's on production now so that save and train plus publishes the full life cycle to getting that question into production um those are the two clicks that you have to do there um and then from here we can create a bot um which is the last thing that we'll have to stand up specifically to get this running so the link to that is just when you publish it says create a bot um if you want to hit it right away you can use postman or use curl to go hit that api but we want to use the bot service and the web chat framework to actually deliver stuff um so here's the next set of azure resources we have to provision we're going to do same bot handle is fine resource group is still boston azure bot uh location it should just this my sandbox uh just say east us uh we're gonna go free for this um app name is fine you can download a client in c-sharp or node.js and i put a pr in for their c-sharp client and they accepted it so if you downline there's a tiny tiny bit of code that we wrote um app service plan location app insights and it wires up everything i mean uh when we had to uh change out uh one of the services originally all this stuff is wired into the config values and all these services that we're provisioning and when we had to swap one of them out it was hairy it was like a lot of stuff to do so it's really helpful that it stands up all of this stuff um here's what we have in this resource group so far it is still working on the deployment of the bot service part of that so as soon as this is done we'll see it in this resource group and i'll refresh and we can finish out the last leg of this um questions in the meantime while that's running if something's going to take a long time it's definitely creating the cognitive service thing so i think we're in the clear here finishing by eight sweet so i think we've deployed successfully let me refresh this view into the resource group and i don't see it yet hard refresh okay so it looks like this has this little icon the type of services web app bought um here's what we have for the bot and we can test it right away to say hey did we get all the way to here um and so something about you know store info probably should return something about the store and we should see that down here as soon as it kind of i think that cold boot um is sometimes a little bit slower um uh for the first client to hit uh something uh we should get that back andrew said one of his favorite bots is uh cherrybot for a uk football club that's awesome um uh yeah says sure i don't see why not just wear a mask so good we've kind of proven uh that this is deployed and the bot framework is working and now we want to choose where we're going to publish it to and that the concept for that um is channels and so the channel that comes for free is web chat um and then here all the other channels that i was talking about there's teams there's a direct line channel which is the way to configure anything onto there um cortana channel alexa directline speech email facebook skype uh kik group me slack telegram twilio"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:41:02",
        "seconds": 6062,
        "text": "and then here all the other channels that i was talking about there's teams there's a direct line channel which is the way to configure anything onto there um cortana channel alexa directline speech email facebook skype uh kik group me slack telegram twilio and then directline is your extension point into anything else and a lot of people have put stuff on top of direct line that you can grab as a package um but let's just use uh web chat because that's the one that we have deployed that was the one we demoed from here this is already selected right if i add another one it's going to show up on this list of existing channels if i edit this i can see what options are configurable i can block attachment i can enable preview stuff like that here's this embed code so let's go launch jsfiddle or just anything that can run a tiny bit of html we're gonna paste that in here and the only thing we need to do is your secret here uh i'm gonna delete this anyway so here's your one chance to grab my secret um and we'll put that here and then this iframe is part of what they're just providing uh this is going against webchat.framework.com if you use the js you can embed your own resources but it goes against their uh iframe and we pull it in and now i should be able to say you know uh uh go to store and get a response back um or are you a human if we want to get some of the chit chat in here um i'm digital in other words i'm not human fair enough um so that's the whole life cycle of getting all of this stuff deployed if you want to go customize uh the way that that bot works uh you can go grab into uh believe it's here into build um and download bot source code and this is it will download a zip that will include some of the uh app settings and config files that come in this configuration but this is what we had looked at in uh visual studio here this is essentially what it will look like when it's downloaded this is the code it's running it gets you started with this starter uh project and template but then it's yours to own for the rest of its life cycle so uh it will work out of the box but if you want to configure it here's what you configure and then republish it up to that service plan um that's our demo pieces um some resources um this is the chatbot presentation you are here it's available at dot gov dot dev slide slash chat bot um and then our repo for all of this stuff is the docs for it are available at this link and we didn't go through them in huge detail but here's you know the markdown diffing library and here's the kind of stuff this is on npm you can grab it from there also um but here's some stuff to get it set up and here's all the rejects we had to kind of figure out to um get some of that diffing to work correctly so if you just want to explore uh you can do it through uh all of these documentations uh this is really just taking every readme or markdown file we have um from this repo here um i mentioned before microsoft was uh really helpful in standing this up originally and they have their own kind of github readme page um that is available and they walk through a lot of how to stand up a bot and a lot of ways to customize it and a lot of this is actually kind of covet centric because this is something they stood up to help with the epidemic um and with that oh i don't have a thank you slide uh so thank you uh i can definitely take any other questions i can stick around uh for as long as people likes but we're close to eight uh regarding the secret you pasted in is that visible by a view source in the public-facing web oh you know what i think it a it 100 is bill i asked microsoft about it um and it's uh not that secretive it's really just the id that's being used to identify it if it is a concern of yours um uh i think they say well best to delete asap uh uh no uh uh they they think it's fine the only thing that that secret allows people to do is run the uh um the web chat itself so what oh this is uh in firefox um the only thing you can do with that is run this so what you are enabling someone to do is take this you know this is going to get deployed to your website um they can then go take this particular package and then go run it on any particular website the way around it if you uh don't want that to happen is under channels i don't know if we can do it on the web bot itself um if you go to add a direct line channel one of the settings on here is enhanced authentication options and you can add a trusted origin so you're still going to have to"
    },
    {
        "speaker": "",
        "title": "Kyle Mitofsky: Project Reflections 3 months after writing our first Chatbot to help with COVID",
        "videoId": "YNBwSuICVac",
        "description": "This is a recording of the July 16, 2020 virtual meetingProject Reflections - 3 months after writing our first Chatbot to help with COVIDWhen COVID-19 started increasing in the US, our dial-in line at the Vermont Department of Health went from being staffed by 1-3 temp people, to a full call center of dozens of internal staff, working in shifts and rotations to help address the large influx of public concern and questions. This was good, but also we knew it wasn't scalable or sustainable. Also, there were difficulties maintaining a public facing FAQ on our website as well as an internal set of answers to common questions.To help alleviate some of that burden, we stood up a chatbot using QnA Maker and MS Bot Builder, with QnA Maker serving as our canonical Knowledge Base. We then also set up a Static Site Generator to pull from the Knowledge Base APIs and publish a public facing FAQ page to syndicate the same content.The project is all open source ( https://github.com/VermontDepartmentOfHealth/covid-bot ), but let's explore it together. This talk will briefly cover the technologies in play, how they're being applied, and some of the gotchas we've faced along the way. If there's time and interest, we can do a 15-minute demo of standing up your very own bot from scratch.QnA Maker and cognitive services got some nice refreshes at Build 2020 a couple months ago, so there's never been a better time to start thinking about how you can build up a single source of truth for common questions, and then syndicate it almost anywhere (chatbots, text, phone, ms teams, static content).Slides are here: https://docgov.dev/slides/chat-bot/SPEAKER BIOKyle MitofskyKyle Mitofsky is the Principal Software Developer at Vermont Department of Health. He's been writing software for the last eight years professionally for the Agency of Digital Services, and recreationally at code camps, meetups, and online. He's primarily focused on web development, using ASP.NET at work by day, and anything JavaScript-y for fun by night.",
        "start": "01:46:06",
        "seconds": 6366,
        "text": "do it on the web bot itself um if you go to add a direct line channel one of the settings on here is enhanced authentication options and you can add a trusted origin so you're still going to have to publish that key because it's all happening on the client uh that client has to reach out and make the handshake appropriately but you can say only allow it to run on vermont.gov or whatever your website is and that'll the only re uh in my case i don't care if somebody takes this iframe and puts it anywhere i want people to have the knowledge uh if it runs up us us up a transaction bill and it gets out of hand we can like look at it and investigate but the secret's only allowing them to run their put this bot framework anywhere it's not granting them access to the knowledge base or anything like that um so if you do configure the direct line then you can put in trusted origins to you know vermont.gov and now this will only run over that trusted origin uh oh it has to be like a hdp or something but uh yeah good question though um other questions from folks uh uh while i have the the window i just want to re-acknowledge a bunch of folks who worked on this um especially if it gets recorded they watch it later then i'll get we had a lot of folks on our team uh who put this together and a lot of folks who uh have really uh you know uh devs who have other priorities and uh we've been doing uh the same team that's been meeting for scrum on this also has other projects that are releasing at the same time right now that have been helping with covet or existing work uh and they've all done a bunch of like uh triage which is like uh normally well outside the scope of their work it's been really interesting it's definitely been all hands on deck uh at the health department people pitching in where they can in ways that they can and so i felt like this was a way we could help out so this is something that you know uh the team agreed uh on but you know i had suggested we uh take and uh focus some of our time doing that um so uh kudos to them kudos to our communication team for just tirelessly making edits on this thing and trying to get it up to speed and correct and accurate um it's a lot of updates even just you know as policies change and our response to this changes uh any other questions from folks am i audible kyle uh yeah you are hi yeah hi folks this is bill wilder um well uh uh folks please uh feel free to add any uh final questions for kyle i'll wrap up with a couple of uh quick announcements first a huge thank you for kyle and it's really great to see this you know we we we get together every couple of weeks and we nerd out on some technology uh it's great to see how this is being aimed at a real global problem we have in the world and using technology for uh all of all the the highest purposes so that that's really uh gratifying to see and congratulations to you and your team on um uh you know putting it to use in in uh in such a productive way uh a couple of quick announcements on the boston azure side uh we um just a fun fact uh boston azure has been around uh for more than 10 years about 10 and a half years and we just passed our 3000th member on meetup and in this new coronavirus world we the the 3000th person is actually somebody named chandelao who's who joined from dallas texas so we didn't have a lot of uh out of town members before uh before you know recently and it's really i guess a valuable side effect of this as we get to benefit from out of town speakers like kyle and most other folks who have joined us in our virtual mode we are working on other speakers and topics i believe this will be the last one in july but we have a couple of topics we're working on in august so please stay tuned at the usual places you go to boston boston azure.org that has links to both the north boston azure and boston azure meetup sites so that could be a single point of entry um it looks like there are no final questions so kyle let's um we'll call it there i'll thank you on behalf of boston azure once again on behalf of veronica and jason who are both in the background at the moment the three of us put these uh sessions together more than me i must admit uh and uh thanks again and thanks everybody for for joining us we'll uh see you next time stay safe out there yeah thanks for having me "
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:00:06",
        "seconds": 6,
        "text": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question. This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.. give me a second um yeah when i started this i was on the very early azure sales team and um so that's how bill and i came because he was a customer um i was just figuring out what this thing was about literally that year when they hired us there were four of us and they said go figure out how to sell this thing so um then they decided they knew better how to sell it so things are a little weird right now which is why i'm still doing the same slide deck well i should it's not the same slide deck some of these pictures if you've seen this before you'll recognize it um [Music] um you know i've some of it i've had for for quite a while but and the weird thing is after 10 years in that it still seems to be relevant um which yeah we just got two sides to it as well normally in our industry if something hasn't really kind of grabbed the big value proposition within a few years we rebrand it and we go on we keep calling we call it something different and we keep going cloud has actually been quite tenacious i mean it's it's a 15 year old conversation and we're still talking about it we've just wrapped a bunch of other stuff around it so um slides are showing okay okay thanks all right um so the um yeah also the kind of so i do work for microsoft still i'm in what's called i was called an application development manager until a few months ago i'm an account manager who manages uh developer support contracts and the developer world um wound up eating the whole you know in the cloud space wound up not being just about application architecture and code it wound up um you know we have infrastructure as code which i'll talk about that in a few minutes we have devops you know so there's dev involved in that and that's really dev tooling being applied to ops problems um among other things and it's just a whole language that we in the development community speak that the traditional microsoft infrastructure space they just really don't know anything about it um so i've gleaned a lot of these lessons starting with opinions and now kind of validated in the field in front of customers you will hear me say things that are not in alignment with messaging you'll hear from microsoft um i think microsoft's you know mistaken in in some of the ways that we're putting this forward and it has to do with what our customers want to hear versus what the actual cloud value proposition is so um the big picture i have a mission statement for myself uh and this came about because you if you walk in and you talk about like rip and replace and everything's got to go to the cloud or you got to think about doing things in a completely different way people get scared and they say we can't do that particularly in the enterprise space startups of course can do it so i came up with this idea that the key is to develop a revolutionary vision up front and then build an evolutionary path to get there and uh and that lands much more gently um people the the particularly in the enterprise they'd like to do things better than they do but they're saddled with decades of um of techniques and technology and you name it and you need to show them like i said an evolutionary path to get out of the uh the space that they're in um this is another theme and it seems so obvious right there is no change without change but if you get involved you know in in the enterprise space in particular they want to be better but they want to quote reuse their existing skills those two things are counter to each other and so i i figure out how to boil it down to a very simple statement which is if you want to change you need to change it's that simple and one of the things you have to do is start with yes uh in in this space uh generally i'll bring up an idea continuous delivery is a fun one to bring up you bring that up and immediate you won't get to say another word for like half an hour as the room fills up with all the reasons why you can't do it i think we should start with yes and move forward from there and then another concept is that it's really important to treat the things that we're building as products rather than as projects i'm sorry about the delayed clicking there that was weird um particularly the space that i'm in and where the big vendors come from everything's a project the thing with the project is it has a beginning a middle and an end and everybody moves on but really if you think about the way application software uh what the total life cycle is is it does live in perpetuity and that really impacts how you um how you architect it how you deploy it almost every aspect of of it if you is radically different when you consider it as a product instead of a project so this is kind of the mission that i'm on right now with my customers and sharing with you all tonight"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:05:12",
        "seconds": 312,
        "text": "how you deploy it almost every aspect of of it if you is radically different when you consider it as a product instead of a project so this is kind of the mission that i'm on right now with my customers and sharing with you all tonight and hoping that you're going to join in and this is the statement that made me put this slide deck together in january of 2010 which i believe when i showed it to bill he wanted me to come in and show it to the group um this was customer facing i've been on the team for about two months when i went to training in november at what was called pdc at the time now called build we sat down with the product group and they got up in front of us and they very wisely you know they you know they said in a very sage way everyone has their definition of the cloud and like an idiot i went okay and then i started to think about how i wanted to talk about this new cloud thing in front of customers and this thing went through my head and i went wait a minute this makes no sense so i broke it down so this is the definition of a definition which is basically it's a meaning of a particular word or phrase that we all agree means that everyone that's all of us so if you think about oh right and when i bring this up people go oh yeah that's just semantics so i'm like so i threw this in here too that it's the meaning of a word phrase or text so i'm like yeah it is semantics so if you look at the statement everyone has their definition of the cloud or devops or microservices or whatever it's semantic nonsense and it's when you sit and you're trying to have a conversation particularly with large legacy type of companies and they think it's okay for them to have their own definition of cloud computing as i used to say you know if you think cars are for moving on roads and i think they're for moving on water we're not talking about cars we're not having the same conversation so this is a an origin point uh for for this entire talk um it's i've become somewhat more shall we say strident about definitions and first articles the world is full of people who think they understand what a thing is and then they operate on that they don't a lot of while like with the cloud they you know they it was deemed okay for everyone to have their own definition of what it is that's not acceptable and then what i'm seeing now 10 years in on all of this is that things that had tremendous value like cloud devops and microservices have become so mangled that i think a key part of the conversation is to go back to the first articles where we all started and you can do that with cloud computing and we'll go through that definition tonight devops i'll touch on that and i'll give you i'll share a link with you an excellent blog post that goes through the whole history of it um microservices i'm gonna do a little on tonight because it happens to me my my total passion um [Music] sadly i'm spending more time talking to people about what cloud computing is and what devops are that i don't really get into microservice conversation as much as i would like to and then because i didn't have any place else to put it i threw this term technical dead in here which i learned recently was not what i thought it was we tend to view it as the idea of when something we take a piece of code for instance and we work on it for years and we keep doing this that and the other thing like running it on windows xp while xp is going end of life and we consider that technical debt that's actually not what the definition is when we came up with it originally the idea was we all make decisions in order to be able to ship software where we make a compromise and the idea is we make this compromise with the idea that we're going to undo that compromise somewhere down the road and that's why we drew this analogy with debt we take on the debt debt needs to be retired well we skipped the retirement part and then you go 20 years on with taking on technical debt voluntarily and now you have a mess so since we were talking about definitions i tossed this one in here kind of as intellectual interest for people because you will hear the term before we get into technology or any of this kind of stuff we need to understand what business problems we're trying to solve and it's pretty straightforward okay um i boil it down in a nutshell to better faster cheaper but i'll break it down in a little more detail business people want to get things done in a time frame that's meaningful in the market there's no point responding to a competitive thread after the competitor is stolen your market from you you need to get things done quickly there's no point in having software that you need to deploy so for instance take the uh take the super bowl if if you need to be ready on a particular date you need to be ready on that date and if your engineering practices don't allow you to respond to that then you're not an agile organization and it's going to hurt you in the market complexity is an interesting"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:10:16",
        "seconds": 616,
        "text": "particular date you need to be ready on that date and if your engineering practices don't allow you to respond to that then you're not an agile organization and it's going to hurt you in the market complexity is an interesting thing because companies like my employer like to talk about easy and seamless or simple we want to make things simple if the problem that we're solving is complex we can go to irreducible complexity but we can't actually make it simple that's a false target but we do need to manage the complexity of the business processes that we're automating because fundamentally that's what we do is automate business processes in the big companies in particular governance and compliance are facts of life there's nothing we can do about it we need to deal with it which means we need to build it into the architecture up front and use capabilities that the cloud brings to us that um that make it a little easier lots of things turned out to be relatively easy if you just think about them up front rather than nailing them on after the house is already built uh and then i hear a lot about cost it's too expensive relative to what that's the response to that um you know it's you can take something as simple as an email server it's expensive to run an email server or to use office 365 or whatever but what's the cost if you don't run an email server and you're trying to do business in in the 21st century without it so it has to be cost has to be relative to something it can't be in a vacuum most of the conversations we get into with business executives wind up being like it costs too much and they want it to be lower and that's not really a goal that you can target but it is a big business problem that we need to handle so there are challenges to solving these problems so excessively complex solutions that look like this which ultimately lead to this problem they wind up the older a piece of software against no surprise the more brittle it becomes and when it fails it tends to fail catastrophically um so this is kind of a and i have a few of these things where they're just lists of like almost stream of consciousness ideas that i've come up with over the years a lot of how things are implemented today are done in ways that when we had uh you know not much ram for instance or hard drives that were small and slow and things like this and so we develop software techniques to handle resource constraints it's generally accepted that certainly the the resource constraints that we had in the 60s 70s and 80s are long gone um and yet we're stuck with these legacy techniques that we developed to my mind literally in the 60s um that are still dogging us and um become business challenges um same idea here there are a lot of things that um that they made sense at the time when we were resource constrained or computers weren't very fast or whatever or they weren't networked but there comes a point when you need to revisit the kind of the principles that you built up your um your architecture on and then of course there's just human nature um i get into a lot of these kind of conversations and it's very very difficult the info security world now is replete with we have to do it this way i have a friend who's at a large company here in town he has i think he said he's managing over 300 non-functional requirements in the security space every single one of them tied to a particular tool that they're currently using to enforce that security policy and that's just not a good way to get after it and and it requires that all of us who are involved in these conversations um you know become well versed in these in in uh in these talking points and and how to push back on this legacy thinking uh legacy thinking was fine 20 years ago but we need to bring it forward so fundamentally when when i look at cloud computing um andrew you're saying legacy thinking what do you mean anyway go ahead and say i'll i'll come back to it in a second um legacy thinking to my mind is anything that was appropriate in the past but is no longer appropriate and we need to bring it forward right to rather than continuing to think about problems in the old way ah got it um so fundamentally what cloud was really really good at was solving problems of scale it turns out it's if you're not addressing a problem with scale it's a relatively expensive way to solve problems but that's a different kind that's an economics conversation so i break it down into three types of scaling problems uh and i put this slide that together by the way so that i can explain these concepts to people who don't care"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:15:18",
        "seconds": 918,
        "text": "problems but that's a different kind that's an economics conversation so i break it down into three types of scaling problems uh and i put this slide that together by the way so that i can explain these concepts to people who don't care about technology so you won't see really any tech slides in here uh in this next set um so this is an example of what you know a retail establishment looks like at the holidays you can probably guess from the color scheme which retail establishment it is okay um and it turns out and this slide by the way goes back to 2010. um it basically manifests these com what we would call compute scale issues manifest in in four different ways one of them is what we call the on off pattern or the batch mode so where you need a lot of compute and then you don't need a lot of compute and then you need a lot of compute and then you don't need it it's very expensive again in the legacy way of doing things to have to stand up that full amount of capacity for when you have those workloads running and it just sits there providing no value and consuming electricity in space so this is one pattern there's the pattern where your company is growing very quickly this tends to impact startups more than it does enterprises but still you need to be able to build up uh your capacity quickly uh in response to growing market conditions there are many situations where if you can't keep up with the market you're gonna a gap had this in the early days with their website they could not they would run sales and then not be able to handle the traffic and um and and people would just not come back again you would lose those customers if you weren't able to to solve it unpredictable bursting is a model like if you think about weather forecasting um you're going to need a lot of capacity during a major winter storm and you don't but you don't know exactly when you're going to need it you can't predict it as opposed to things like retail at the holidays or accounting during tax season and things like this um funny story on the predictable bursting we're having trouble convincing or educating our accounting people on why the big four accounting firm's consumption consistently drops um in may and that that was just very shocking to them we also have it with uh insurance companies who do open enrollment in the last couple of months of the year and then they're processing it in january and then in february their numbers roll off and the accounting people get all upset because they don't understand these models so it's very important to be able to have these conversations with business people so the cloud solution is just have a lot of capacity available um kind of the model here with the cash registers is yeah the cash registers are all sitting there but they don't have cashiers in them and you can scale up and down as your capacity goes up and down so that's the analogy there for cloud compute then you have geographic scale that you need to deal with accuweather was one of my early customers and when they tried to expand internationally they were having to back haul all of the mobile phone traffic and all of the web-based traffic from europe to state college pennsylvania because that's where their data center was so you can imagine the user experience in the other parts of the world what was not that good and that's what this is representing and then eventually with cloud computing because it's relatively easy to just distribute your compute as long as you make the architectural concessions and then you now have a much better user experience and you can handle the geographic scale and then the last one is storage so i've come up with a cute way of showing you increasing storage requirements and then the solution is to just do it at massive scale multi-tenant storage and leverage this and this has actually been particularly in the enterprise um storage has been one of the most uh successful parts of the story at this point it's not a great business model for us on the vendor side but the customers get a lot of value out of this and you can see how companies like emc are struggling with the old way of doing things and now they're more in a commodity game because of cloud computing than they ever were in the past so if you remember i started this with everybody has their definition of the cloud to make the case why that can't be and then it turns out that there actually is a definition of cloud computing um there are two flavors of it one is from the us government and one is from iso uh in the international space they're roughly the same i put these slides together to talk about the miss definition the us definition it's not substantively different than the other ones so i did not try to genericize the slides so then this definition has five essential characteristics of cloud computing if it doesn't have these five essential characteristics it's not a cloud it's probably something else useful but it's not a cloud so it needs to be on demand and"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:20:21",
        "seconds": 1221,
        "text": "so then this definition has five essential characteristics of cloud computing if it doesn't have these five essential characteristics it's not a cloud it's probably something else useful but it's not a cloud so it needs to be on demand and self-service uh these are these are key characteristics of it you need to in order to get agility you can't have to go through a procurement process for instance or any kind of manual process i will share with you that many many large enterprises they did this first with virtualization in fact bill's former employer they had a 204 day process from the time somebody said i need a server until they had the server most of that was process accounting requisition all this kind of stuff and when they went to virtualization because this was going to speed them up and make them more efficient they saved about 10 business days out of the 240 because they saved the part where they had to rack and stack a physical server everything else about the process was the same for cloud computing this automation is critical it's key and it also gets into how you do scaling and things like that through apis it all has to be automated by the way vmware's original vision for vm for uh virtualization was exactly the same just nobody bought nobody bothered to do it when i make a statement like that i mean so close to no one that it's effectively no one it needs to be elastic i never really came up with good pictures for this but this shows an example of a truck that can get bigger when the load gets bigger or we've all seen meeting space where you can move the walls around and get larger rooms when you need them okay multi-tenancy so the example here is back in the day i assume it's still this way the new york taxi cab system the cabs were shared by multiple drivers um and they came out of a common pool metered services this is a key and it's one of the ways that you work the cost model of cloud computing is you need to be able to meter your consumption in small increments um one of the things that's missed in a standard cloud deployment model is to deploy a vm and turn it on 24 7. um that's a very coarse kind of metering at that point and it turns out it's very expensive and then broad network access so it is considered to be a distributed computing paradigm and therefore massive network scale is required so those are the five characteristics you hear a lot of companies say well we have a private cloud because we have a fully virtualized data center typically in that situation they don't have metered service for instance um so they're missing one of the characteristics at least one and it's simply not a cloud at that point so there are four deployment models everyone's probably heard these at this point there's the public cloud where all the noise is there's the private cloud which is completely bastardized as a fully virtualized data center the only difference architecturally between a private cloud and a public cloud is who owns it and typically the scale of it this message is only now after 10 years starting to be felt in the enterprise where they're actually starting to deploy homogeneous um infrastructure that can be leveraged and we use in cloud techniques hybrid cloud to my mind is a nonsensical term but it is part of the nist definition and it's the idea of public cloud and either private cloud or on-prem infrastructure um collaborating together we used to call this service-oriented architecture but people like this hybrid cloud tour and the marketing people these days love it it's it's really to me it's it's a completely abstract concept that doesn't mean anything but if you read all three cloud vendors and what their is driving their success you'll see there they we all insist that it's hybrid computing that's making it making the cloud real in the enterprise and then community cloud is really more of a government idea where you would have like an intelligence community with a shared cloud or the defense uh community some of you are probably snickering because of the jedi news at this point but that's the idea behind a community cloud to me these are kind of distinctions without a difference but they are part of the definition so i do bring it to the people i also want to point out and i've alluded to this a couple of times this is the nist definition of cloud computing there are essential characteristics they're deployment models and they're service models it is not this there are not different essential characteristics for private clouds in public clouds and this is a huge mistake that is or misperception that has been in place for over a decade i'm still railing about it like i said people are finally starting to catch on to it but it's led to a lot"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:25:23",
        "seconds": 1523,
        "text": "this is a huge mistake that is or misperception that has been in place for over a decade i'm still railing about it like i said people are finally starting to catch on to it but it's led to a lot of churn in the enterprise world around um what they think they're implementing and it hasn't really helped move the state of the art forward and there are three service models you've all heard of these software as a service platform as a service and infrastructure as a service and you may i know here the bottom two are really building block layers whereas the software is a service you're there's more of a um a corolla or a correlation with the old model of you know license based software on a per-user basis we tend to call them seats it tends to be a higher level of abstraction and then a lot of times you take a look at something like software um salesforce.com they sell it as you know on a per user basis but they also have apis on it and you can leverage it as a platform we of course have similar things as well but for examples i tend to go with the best known ones excuse me so now we're gonna get into what i call key themes these are ideas that are part of the overall conversation because that was cloud and cloud's an interesting conversation and a lot of the computer science behind cloud computing which is basically distributed computing has been around since the 70s um we just didn't have the hardware to support it uh so things so we couldn't leverage it in cloud computing with moore's law and the economics and all that type of economies of scale have allowed those ideas to be practical now sadly most of what we spend our time doing with cloud computing is the old legacy stuff that has nothing to do with distributed computing and we'll talk about some of that in a few minutes i i have a couple of uh slides on that so services we just talked about you know the software as a service platform service whatever so it's a good idea and it's actually back in the day this took me a long time to come up with a concise model of what a service is so it's code and a contract is really what differentiates a service from any other type of of application code okay the contract will tell you what the service does tell you how you can access it so the uri for instance or actually where the service can be accessed is the uri the how it's accessed is basically the api definition i still find it kind of amusing that soho was sneered at because it was so over engineered and it was um but when they we did rest we went to rest apis we said we don't need all that fancy whistle stuff and and the contract you know definitions and all that up front until they decided that actually we do and then we had to reverse engineer all of that with um with what was called um swagger which is now open api and loose coupling i used to say this is a it was more of a cloud idea but it's really a service idea and it's really really critical if you want to stay out of dependency hell if you want to avoid technical debt if you want to maintain your agility over time your services that you're building excuse me need to be loosely coupled and that's excuse me a second sorry about that little lack of preparation on my part um so the key we have to avoid hard dependencies and what what makes a an application become a monolith is hard dependencies and boy i'm ahead of myself here um and this is the only way that i have seen in all of the work that i'm doing in a customer-facing way is the only way to avoid creating a monolith over time there is the idea of a well-architected monolith by the way where you can minimize the dependencies but this is the real world we live in and the people who conceived of the original architecture and by the way this is a flaw in sam newman's second book that's called for monolith and uh to microservices it assumes a well-architected monolith and i don't know about you guys but in the work that i'm doing i don't find very many of those i spent six months working with one of my clients trying to decompose their monolith and one day i finally said team not only is your monolith made out of granite it is also set in concrete um and i said that and start the the work of getting them to consider rebuilding it from scratch which is not an easy sell by the way nobody wants to hear that um and this is another key thing for loose coupling and we we violate this constantly"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:30:27",
        "seconds": 1827,
        "text": "of getting them to consider rebuilding it from scratch which is not an easy sell by the way nobody wants to hear that um and this is another key thing for loose coupling and we we violate this constantly the internal state of a service cannot be exposed outside the service the reason that is so key is if the internal state is understood if you need to change the internal structure of the state you will break everything that no that needs to know about that structure and the only way to avoid this type tighter coupling is to have the api and the internal state that comes through the um through that api is is completely abstracted um it's interesting if you look at something like um [Music] what's it called the open data standard i'm drawing a blank um you actually do queries against internal data structures within the service so you're pretty explicitly exposing exposing the internal state so this is a technology that shouldn't even exist because you're almost guaranteed to be creating monoliths with it and then for those of you who've taken any time to study hypermedia it's very interesting it's intriguing um but it's a complete rewiring of your head to be able to think in the way that hypermedia requires so i think we need to walk before we run and and what i've taken away from the hyper media ideas is that you basically have three forms of state instead of just two one inside the producer one inside the consumer and then the representation of the state across the wire and you map at the apis and again yes oops sorry i was trying to find a theme uh you want to finish your thought then i have a question on the side no go ahead on the um hard dependencies of course if you're building cloud native applications you have the option of taking dependencies on cloud services of anything you know in the azure platform for example you can you can use um storage queues or service bus or event grid or um a sql db uh new you know cosmos anything you pick your pick your uh pick your thing just curious what your thoughts are about about that sort of coupling uh because you're taking a dependency on it certainly you're not compiling um you know uh event grid into your application right because it's an external service but um i'm just curious how you think about the the dependency uh aspects of taking a dependency on cloud services and can we be sure for example that those are stable over time uh so i'll answer the second one second part first and the answer is no and you shouldn't um because you can't um i believe so the database here is very um is much easier for me to answer that on i believe the data tiers should be abstracted um by the application architecture completely um when we if you look at the original three-tier architectures you know from the 80s there was this idea that you had these three tiers and that you in principle could swap any of them out particularly the data tier but once the middle tier takes hard dependencies on the data tier you're just hosed so the way we get around that right is to abstract that interface between the two um now with service oriented architectures we would create a service layer in front of the data tier and everything is abstracted through that and at that point you're now free to swap out your different cloud services at that point does that make sense it does so basically you're you're uh insulating yourself correct you have to and there's a very interesting uh i meant i have a reference to this book at the end i don't know if any of you have heard of yavaloi and he has a book that he's written called writing software his company i think is called i design um and let's just say he's extremely self-confident um he has come up with an architecture technique which he refers to as the method um but i saw my own techniques in it i just hadn't formalized it and and he it's an architecture technique where you you try to anticipate where the what he calls the areas of volatility are for instance i mean i designed uh actually the first thing that i implemented on azure i had actually implemented on a linux host previously and i very very deliberately abstracted the data tier and so when i went from my sql on the linux host to azure db at the top or sql db at the time that layer of code was was very um tightly held and it was relatively easy to to transfer it over and this is critical with any application"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:35:28",
        "seconds": 2128,
        "text": "linux host to azure db at the top or sql db at the time that layer of code was was very um tightly held and it was relatively easy to to transfer it over and this is critical with any application any big application you need to anticipate that it's going to live for years if not decades and if we've got enough history now we know that things are going to change and build to the point you were asking about taking a dependency on a cloud service we don't promise to never change them we don't promise to never do breaking changes to my mind the rest api um approach that we take that microsoft takes and i'm assuming everybody else does too is actually not particularly friendly to versioning and keeping track of different versions and how you do that and so it's it falls to us on the app side to to abstract that properly interesting side note on the uh on the rest apis i i've i've noticed uh some folks so the sdks are much easier to consume than the apis so if you're dealing with storage for example there's a nice clean sdk that adds a lot of value but then right yeah and i was going to say some people avoid using it and they go directly to the rest apis just because it's too hard to uh you know in their in their model of the world it's too hard to keep up with changes to the sdks the sdks have had a lot more churn over the years than the uh rest apis correct right because as we all know when we write you know there's that old adage you should write your code once then throw it away and do it again and i heard recently you actually it takes three times um so yeah sure we took a stab at it when it was just you know the simple blob storage table storage and queues um and that wound up being insufficient so i we've probably changed it twice if i remember correctly which you know that impacts your code now in theory you could even abstract away our sdks um at some point we have to make the trade-off over how much work we want to do to keep ourselves insulated and interestingly there is this fantasy about um no vendor lock-in or what are we calling it now multi-cloud and i actually don't have anything in here i consider that to be a nonsensical idea but everybody loves it um you know if you want to do multi-cloud if you want to have cloud independence you actually have to do all of this abstraction stuff i just think there are better reasons to do this abstraction and then you also need to decide you know if you're dated to your changes is that such a major impact on your application that you'll live with the recoding effort that has to go into it so lots of trade-offs to be made in this phase i'm just trying to i know that this coupling thing is what leads to monoliths which leads to a lack of agility in the code which leads to a lack of business agility for the organization and it's going to kill companies now because i've written in the past about it takes a certain amount of time to respond to a competitive threat and because of the accelerating pace of change there's less and less time to actually respond to a competitive threat and these companies are going to die when they can't do it so these concepts are key um no i'm so michael i see your comment there um yeah that's a big topic what you have to distinguish between the fact is that in the application domain you are going to have coupling that you can't get away with all right if the rules of accounting say x y and z or you have three dimensions of space that's a essential piece of coupling that you'll never be able to do away with would it be but would that fall into the coupling between services well it depends for example if let's say the um let's say you had a service that checked the financial the to make sure that your audit was in compliance with the generally accepted accounting principles and you had a separate service that just for the sake of argument came up with the audit that's it if the general principles of accounting change you can't you can't remove that dependency and that that's an external impact isn't that an external dependency then well when you look at the classic literature on loose versus tight coupling that's distinction that you made and then to go back to your original point yes you could say that but now we're quibbling over definitions right what i'm trying to well you and i would never do that come on right never but the point i'm trying to make is that very often when people start to think about we have to make everything"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:40:31",
        "seconds": 2431,
        "text": "right what i'm trying to well you and i would never do that come on right never but the point i'm trying to make is that very often when people start to think about we have to make everything loosely coupled and they try to loosely couple things that are intrinsically covered by the application domain yeah no that's fair and and in a sense we could we could leverage by analogy the things need to be as simple as possible and no simpler correct yes but they need to be as loosely coupled as possible and no and no more if we if it didn't have coupling we wouldn't have applications yes so yes philosophically i i agree with that i'm to me this is this is about monolith avoidance when i when i'm harping on this particular concept in this place but your point is well taken okay that's what i like feedback so um i really wasn't going to get much no that's right i forgot this line's broken um i don't want to spend too much time on microservices even though it's like i actually think microservices have the ability to really revolutionize how we're doing things however there's a mental block that kicks in really hard and really fast on them so i'm not going to spend a lot of time on it why the reason i wanted to touch on it this idea of definitions and stuff um people will say things to me like ah the micro really doesn't matter yeah it does it really does they try to make out like microservices are really no different than service oriented architecture type of services which to my my most service oriented architecture services wound up looking like a collection of monoliths rather than actual microservices so the microservices by function need to be small um and they are small not only in the scope of the work that they do um but also this the the size of the teams that um that actually support them and no it doesn't mean that you need a separate team for every single microservice a single team can manage multiple microservices but that microservice is only managed by that team all right and then there can be no sharing of state [Music] by which i mean there can't be a shared data tier between two different microservices of course to have an application you need to be able to exchange state information but that goes back to the hypermedia discussion about bringing that state across the wire um you know in an abstract form and that piece of state has to be managed by only one microservice and any other entity that needs access to that information has to ask that microservice for it so those are kind of the general principles around this um it's interesting in how it's evolved just in the last five or six years since it started there was a time when we looked at having a distributed data tier now i think the performance of the data tier is is improved to a point that you can actually have a shape shared data tier but particularly with respect to right access that has to be delegated to a single microservice so that's a key concept um so this diagram and if you look if you can read the url at the bottom comes from the microsoft document site this is actually an ancient diagram that used to just have web apis on it and before that it had web services um this i do not consider to be a micro service architecture i consider this to be a traditional web service architecture with the word microservice liberally sprinkled onto it so this is a very common way that people view it this isn't correct um the prop sorry there we go the proper way to think about microservices in this kind of a model and this is actually a diagram that came from red hat uh showing their um their service mesh idea of how they communicate so you really want to think of a a sea of small microservices all communicating together now this is where people get messed up excuse me um because if you try to do this manually it's really complex which is where the idea of service meshes came from i'm not getting into that tonight but there are techniques to manage the complexity of the communication between all of these microservices and that's really all i want to say about it tonight so i didn't get my little thing at the beginning that goes into cloud computing is interesting i started down this path i didn't finish it cloud computing is interesting but in and of itself it doesn't actually solve all of the problems that we've discussed at the beginning you do need devops which is"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:45:34",
        "seconds": 2734,
        "text": "interesting i started down this path i didn't finish it cloud computing is interesting but in and of itself it doesn't actually solve all of the problems that we've discussed at the beginning you do need devops which is your way of actually taking code from a developer's desktop and getting it into production in a reliable way as part of devops we'll talk briefly about continuous integration and continuous delivery these are techniques that tend to impact the developer world more than um than the ops world you have um security the security life cycle that needs to be part of this automated scheme as well and then you have microservices which i was just talking about those are how you take something that starts with cloud computing and then ultimately becomes a modern architecture for a business agile piece of functionality so we'll talk about devops here as a key theme and you hear a lot of talk about devops and culture and this is where i had another one of my epiphanies not all that long ago um culture follows devops you can't you can't change the culture in order to establish devops devops fundamentally comes down to two things for me and i'm not hung up on the order i'm just happy to be showing them to you in this order it's automation historically the tooling that we have would be used to automate a human process we need to change that because in devops we need to invert that where the tooling is there you well i'll show you in a second um the processes that you're automating need to be designed to be automated they're not manual processes that you were then automating and that is the culture change that you get okay and this is a quote uh from a google engineer back in the days and he basically says if we are engineering processes and solutions that are not automatable we continue having to staff humans to maintain the system automation by definition is designed to not have humans involved otherwise there's no point to it and the second aspect of collaboration and we'll see how many people i can offend with this slide um it is a collaboration between development and operations i have another friend who slapped me because originally this slide said development with operations which nominally imply development in the in the uh in the top position so we modified the words because words matter and there is this historic wall between development and operations we talk about throwing things over the wall and devops is about stopping that so again this is a culture change if you tear down the wall and you start to collaborate between the two teams you will then have affected a culture change so someone detailed no more throwing it over the wall for my entire career we've talked about how we on the dev side would build the code and then we throw it over the wall and then the ops guys would figure out how to make it performant and secure so we need to stop that and by the way it turns out in the current world the throwing is going in both directions because the ops guys decide what infrastructure we can have and they throw that back over the wall with the dev side and that is also flawed and i'll talk on that briefly later on mark yes yes uh so is another version of this you you you mention it as dev and ops working hand in hand harmoniously no throwing over the wall um some teams want to eliminate basically a separate ops function and have devs manage the ops side of their uh you know they they they own the dev team owns the service um you know cradle to grave so i yeah i came up i have an amusing line on that there are three constituencies involved here the business dev and ops and each of them thinks the other two are idiots okay so i think one of the things that we have to do we have to start doing in this new world order is we need to respect the subject matter expertise of the other teams so i would balk at the idea of dev doing ops in my understanding of history there were some startups where there was no ops so the devs wind up doing ops and you'll see in a minute that i actually thought at one time that was the origin of devops but it turns out it wasn't um but i myself would not i wouldn't i wouldn't necessarily go that way and by the way site reliability engineering which is how google does devops [Music] is staffed all by developers all of their sres are developers but they're like developers plus they're developers"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:50:37",
        "seconds": 3037,
        "text": "i wouldn't i wouldn't necessarily go that way and by the way site reliability engineering which is how google does devops [Music] is staffed all by developers all of their sres are developers but they're like developers plus they're developers with ops knowledge so if that's what you're referring to that is uh that is a very possible outcome practically speaking in the enterprise which is my focus for obvious reasons um the ops guys aren't going away they do create separate devops teams which it was actually one of my clients who pointed out that that is considered an anti-pattern and now i fully understand why so that needs to go away in fact this particular client showed me a venn diagram one day that had dev on one side it had ops over here it had devops here and then this big elongated thing that was labeled sre and um so they were going up in complexity things were not getting better that way and i'm just actually still working with them and trying to help dial that down so no separate devops teams and this is a key one this is a big change application architecture needs to lead infrastructure architecture from a theoretical slash academic perspective i would have said this was always the case practically speaking though you can't stand up an on-prem data center that can support any architecture that we can dream up on the app side but with cloud computing with its building blocks we actually now have the ability to figure out the optimal application architecture and then drive the infrastructure implementation with that and then the infrastructure's code techniques that we have make that even more practical to do that um so that's devops in a nutshell i mean it wasn't much but that's because i boiled it all down to automation and collaboration and all the rest of it are our ideas that are concocted by what i call the devops industrial complex because between the analysts and the consultants they need something new to sell every year so they keep coming up with new ideas and you can drive cultural transformation you know forever um in fact we came up with digital transformation so we have something else to talk about that doesn't exist so uh yes netflix definitely has that method i agree so first articles like i said definitions of first articles matter i mentioned this is where i thought this i heard this through the lore that these were practices developed by developers who had to do ops i'm not saying that that wasn't out there i think netflix actually did and many companies like netflix actually did come up and this is another thing and i don't have this word in the definition list but to my mind and i think i've successfully won all the arguments i've had on it so far there is a difference between the enterprise and companies like netflix they're both large so they have that attribute in common but if we look at particularly those of us that have done both they function very very differently and um and so my world is helping to transform the enterprise um and and i'm not i think the other side the netflix is in the and you know all the born in the cloud companies that we talk about those guys are pretty good taking care of themselves i hear a lot of them still like to do things in the old way because that's what they were taught in college but they figure out really quickly um that those techniques don't uh don't hold on um was somebody bill was somebody on our team here was it carbonite at one time i can't remember yeah that was george okay um carbonite learned the hard way of what happens when you take traditional scaling methods that you use um you know that you're taught in college and then try to apply them in the cloud because they had a massive surge in business when google lost a bunch of inboxes about 150 000 inboxes and the experts told everybody you need to be backing up your google inbox and carbonite had a solution for that but they could not handle the workload but they figured it out real fast and they survived and it was all good um so in reality and this is the blog post i referenced this tom garrity piece which goes into a lot of um history of devops but the where the term came from it evolved in 2008 2009 where a developer and an ops guy got together and the ops guy was the one who was frustrated with the friction between the two teams and also saw the benefit of the tooling that the dev side had available and how that could be applied to operations problems okay and um and so that's where it all came from that's where it started and we need it it's important particularly when you're conversing with an enterprise team that you have this history available"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "00:55:40",
        "seconds": 3340,
        "text": "that could be applied to operations problems okay and um and so that's where it all came from that's where it started and we need it it's important particularly when you're conversing with an enterprise team that you have this history available to you because it's much less threatening to the ops guys if they think it was their idea all right here's another idea automated testing is not a nice to have um i had a conversation with a customer a few weeks ago we were talking about devops i was explaining all these ideas in fact i used more or less a version of slide deck and they interrupted me at one point said well we're doing all of those things but they're not automated trying to make the case that they were doing devops and so i said are you doing unit testing well no so they weren't even doing automated testing and automated testing you have to do it there's just no two ways about it and it's really really hard and it's really hard to reverse engineer into existing code um but if you're going to say that you're doing devops you have to have automated testing um and then this this is a comment i've had in here for a long time i just changed the tense of it today as a matter of fact the tooling that we use can be imperative or declarative a lot of people are more comfortable with imperative techniques however you if you're thinking about automating infrastructure you get into all the same kind of bug problems that you get with um with imperative programming on the application side also imperative can get really unwieldy at scale so there are these declarative techniques now i've met many developers who just it takes them a long time to get comfortable with the declarative way of thinking but it's worth the journey microsoft because of the scale that we work out is doing a workout is doing almost everything declaratively we provide a lot of imperative capabilities through the azure cli and the like but the way we will recommend that you do things is either with something like an arm template or with terraform templates um and just using those automated declarative techniques so um i break it into three pipelines so there's what i call devops for applications and i'm not going to read these slides to you but i'll try to go slow enough that you have time to read them the continuous integration idea which is the idea of keeping your code always buildable okay and part of doing that is to check in your code frequently to not do a lot of branching and to have automatic build automated build processes including your unit testing framework so that each time you do a check-in you know whether the code can be built at that point and there are organizations that actually you're not supposed to go home if you've checked in code and broke and broken the build continue continuous delivery is the idea that the application is always deployable not that it will be deployed but that it always must be in a state where it is deployable there are organizations particularly the born in the cloud organizations um trying to remember if the amazon number and i mean amazon on aws the amazon number was something about 1100 deployments a day i think if if somebody knows that a bigger number than that feel free to put it in the chat but it's it's something of that magnitude the techniques you use to do that are things like feature flags where you deploy the code but you don't enable new functionality and then you enable it for a subset of users and things like that this model works really well in the web world it can work really well in a properly architected microservice architecture uh or application sorry um but it takes a lot more commitment uh to do that kind of thing but the capabilities are all there to to deploy to production there are many organizations now that have dumped their test environments they you know you check it in it builds if it goes down the pipeline then it goes into prod with the functionality disabled and then you enable it um at the appropriate time this also allows you to roll functionality back very quickly it's also the way you handle changing apis between services because as much as like we would like to say that the the apis are immutable that's not the real world question yeah you in the continuous integration part you mentioned uh not using very many branches once you're thinking there about the the impact of branching uh so and this goes back to jazz humble's original book on the subject which is actually on continuous delivery there's an uh integration books on it as well the idea is you when you branch a lot you introduce complexity the idea is not to not branch you can branch but they need to be short-lived you know if you need to to go outside the mainstream of the code and work privately for a little bit it's fine but you need"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:00:43",
        "seconds": 3643,
        "text": "complexity the idea is not to not branch you can branch but they need to be short-lived you know if you need to to go outside the mainstream of the code and work privately for a little bit it's fine but you need to minimize that and the intent is that the bulk of your work is actually going to be done um on the main branch thanks i i buy uh short-lived branches as a good proxy for a few branches right the the but the reality and i learned that there was a friend of mine he was um he became a big-time project manager and i remember talking to him one saturday morning because they had everybody had a feature branch and then they had this big integration phase back into the trunk and it just blew up and just completely melted down i have a client today that they're getting better but for a long time it was like they were maybe 50 50 with whether they could do a merge and deploy and they were i think on a bi-weekly cycle um so these are the techniques that people smarter than me have come up with for avoiding that kind of integration hell that so many organizations were going through there's also another factor that we're trying to get here too is that we would like to have better than a quarterly release cycle and most organizations have a lot of difficulty and i'm one of my clients is doing a semi-annual release cycle and it is not enough to keep up with the pace of the changes that their customers are demanding all right and then the last bullet here is about observability which is basically meaning how these applications behave needs to be observable when it's in pride and we as developers need to basically build that in so that's what this aspect is in devops for applications i'll touch on this in a little more detail in a minute then there's the infrastructure pipeline so the so-called so-called infrastructure is code um site reliability engineering can fall into this as i said sre is how google does devops i've seen that it's written down somewhere infrastructure as code is key and when you get into organizations that are used to traditional ways of deploying infrastructure the whole pets versus cattle conversation and how you patch for instance um it's just a total mind twist um bill i'm not going to use your expression um but the um but infrastructure as code is a really really key part of implementing devops because not only does your application need to be able to be deployed um tested and deployed quickly your infrastructure does as well that world from a tooling perspective is less well developed but it's coming along and then we hear about monitoring and observability so it occurred to me monitoring is a verb it's something you do and observability is an attribute of the system which basically things that are exposed so that you can monitor them and that's you know that's a code thing and then these are the three categories of things that need to be exposed tracing in a distributed system is pretty mandatory and non-trivial so um i find it to be an interesting topic i've got an application i need to wire up with it at this point um but it's definitely non-trivial but really really important so that those sre guys can actually figure out why things aren't working in prod and then there are containers which are going to save the world right we're going to containerize everything and all of our legacy apps will become wonderful in the cloud and all that kind of stuff and all that snark is completely intentional and i'll talk about containers in a few minutes but they are a fundamental part of how you deploy the applications you do need to containerize them and then the infrastructure side manages the containers and then there's the devops for security you'll hear terms like devsecops which is talking about how devenops will take on the responsibility for security as well those of you who've heard me talk in the past you will know that you know you will have heard me say that security is not a cloud problem um i'm fascinated by all of the big financial services companies that we do business with who insist we have to do security exactly the way they do it and all of them have been hacked multiple times so um but security is a very interesting and important topic we do need to shift left which is this intention that the developers need to be part of designing secure code um there is still a tremendous amount of conversation in this industry about making it simple for developers so they don't have to worry they're pretty little heads about all of this as a developer and an architect i'm like i'm calling nonsense on that and this is something that we need to take on first and foremost you have to design for security and you have to test for security and these tools are coming along nicely in terms of doing um even simple ideas like all the libraries that include the nuget libraries and stuff they have to be scanned because they're finding"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:05:46",
        "seconds": 3946,
        "text": "have to test for security and these tools are coming along nicely in terms of doing um even simple ideas like all the libraries that include the nuget libraries and stuff they have to be scanned because they're finding vulnerabilities in those all the time and somebody needs to throw a flag on the play if an insecure library is rolling out into production operating system patches all this type of stuff need to be accounted for and this is a really key idea it's definitely important in security i find it kind of generically uh applicable we need to focus on what needs to be done what the what requirement is not the how requirement and i mentioned you know my friend with the 300 non-functional requirements to basically defined in terms of how to do something rather than what it is that needs to be done and leaving the flexibility for say the native capabilities of a cloud to handle that functionality rather than forcing legacy tools and techniques into the uh into the cloud so you want me to talk about shift left or did i make it clear actually that threat appeared before the shift left showed up on your slide jason may have more to mention oh okay all right all right well that's good synchronization jason you can unmute instead of typing we're recording um um so i'm not going to spend much time on containers i actually i should have linked to this book that i read on it um it's fundamentally os virtualization which means it's if you get down and you study containers it's a linux process it's an os process is all it is um i read a book on actually kubernetes security but the first few chap it was by somebody a woman named liz rice she writes very well first few chapters were about how containers are built using the linux capabilities we should all bow down to docker because the morass of stuff that you need to do to build a container that they automated is really kind of brilliant um no it wasn't you know we needed orchestration too but that does not take away from the brilliance of what docker accomplished with containerization and by the way containers go back to sun's efforts to do virtual pcs in the solaris world back in the 90s those that's when the original hooks got put into the to the to the unix kernel at the time um it's a portable unit of deployment and that is very key um there is a principle and i think it's a humble cd book i've read it elsewhere too you're not supposed to store binary artifacts over time you're supposed to store all the information so that you can rebuild a binary artifact which is really tricky because that includes the tool versions that were in place at the time with containerization you can actually pack everything together into a single docker definition so that and it's very interesting how it's done you you include the tools in the docker image when you load it in the tools run and build your code and then there's a layer where you then strip the tools back out of it to shrink the size of the container and leave you only with the application bits so now you have your binary output it can go into a repository it can be rebuilt it will and and exactly the same bits we'll run in dev we'll run and test we'll run in pride um i almost pulled this bullet because this is kind of part of the marketing around virtualization without the need for a full virtual machine it's not really um particularly with hypervisors virtual machines are much more secure they're much more isolated than a container will ever be we're finally getting things locked down it was actually not hard for application code to escape from a container and get into the into the rest of the system we're tightening things up the practices are known now but the fact of the matter is containers do not provide you the isolation that a virtual machine does typically you would put one service per container and then you can while in the kubernetes world you have pods so you can take the container and its communication container running side by side and that can become a unit of deployment so there are a lot of handy things you can do architecturally but it all comes down to this ability to just package up your bits in it and it really comes down to a packaging technique so i'm going to talk briefly about something called system containers and application containers if you read the original app uh container work the word lightweight appears a lot but then the ops guys got hold of these containers which were going to save"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:10:49",
        "seconds": 4249,
        "text": "something called system containers and application containers if you read the original app uh container work the word lightweight appears a lot but then the ops guys got hold of these containers which were going to save the world and they decided that they needed to put everything inside the container so the windows server core without asp.net loaded without iis um across the wire it's 1.3 gig and it expands i believe to about five gig this doesn't mean any definition of lightweight that i'm familiar with but it did allow ops guys to get in on this what is fundamentally an application streamlining technology so we renamed it now we have system containers which are huge and application containers uh which are the original lightweight containers the security book that i mentioned she explicitly in the preface says we're only talking about application containers here another comment mark on your fourth bullet i i would add a on the i this is about uh versus virtual machines i would add that another really valuable facet of the container is the density of deployment so it may be less secure in the in certain sense than a via than a cm but but one of the one of the plus sides is uh you can fit more of them in the same amount of uh resource and save money that's a big deal that is correct um and i would be fine and i'm fine with that from an application architecture perspective the problem is that that same argument is being used with system containers and it's not valid so it works great you're 100 right with application containers that is absolutely a value for you get much better packing density and utilization of your physical nodes than you can with a vm in fact those of us have been around the azure world for a long time we know that one of the problems with the original cloud services is that the um the granularity was too coarse for scaling you know you had to go buy a one a one core vm was the smallest you could scale by and that was too much for a lot of functionality so yes that's a that's a great point though so what problems do they solve i've sort of touched on these um and i'm actually not sure why i wonder if that question mark is even mine because i did borrow these bullets from somebody else but it does provide portability better than any technique that we've had in the past you can build up a vm image and use that as a unit of deployment as well and it'll be consistent but it's a little coarse all right um but by having the same bits in each environment you do eliminate this works on my machine problem um however as with all things there's work to be done you have to inject the environment specific information into the container and there are techniques for doing that hard coding is not not really a good idea for that kind of thing but lots of people do that uh there is an improvement in productivity it typically takes less time to set up environments um [Music] and i'm not actually sure what eliminates debugging environment specific issues would be so i'm going to move on from that again i borrowed these these particular bullets um it is definitely a smaller footprint than vm so to bill's point it does increase um server consolidation for application containers i find that to be a fairly false statement when it comes to system containers and there is isolation but like i said it's pretty much process isolation linux the linux kernel provides you with all of the capabilities that isolate your processes from each other so in that sense it's nothing new it's just a very uh convenient way to handle this functionality um and here again for applications containers they are very performant and they start up quickly which if you have a highly scalable application is a really important capability using the aforementioned example of the windows server core container a 1.3 gig container is not going to be started up in any quick quick manner at all um so a bunch of so i had tipped my friend michael stiefel who's out there these are he actually did a presentation for the dot net architecture group about a month month or two ago where he went into it he used as a proxy for his explanation the the challenges that the massachusetts vaccine website had when it came up and these"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:15:52",
        "seconds": 4552,
        "text": "dot net architecture group about a month month or two ago where he went into it he used as a proxy for his explanation the the challenges that the massachusetts vaccine website had when it came up and these seven principles and i'm going to recommend that you go listen to the recording of his presentation but i wanted to touch on each of these ideas tonight in terms of things you need to do to build a scalable architecture if you remember back in the beginning i said that um the cloud solves problems of scale so you need to be able to build scalable architectures one thing that i do with a lot of customers where i'm trying to bring them around on proper cloud thinking is i ask the following question would it surprise you to know that cloud hardware is fundamentally unreliable and they have all so far answered the question exactly the same way which is yes that would surprise me it says a lot about the marketing doesn't it um so you need to design uh for failure and you need to assume failure michael and i actually wrestled with this term for a long time i think netflix actually may have used this one first but it's considered a negative term um so um but the point of the from an architecture perspective is the underlying infrastructure is not reliable and cannot guarantee availability our architectures have to take that into account failures cascade um particularly this is kind of a distributed computing concept um and again where the dependencies can get tricky um and to michael's point about um [Music] what was it intrinsic um essential coupling um where you have coupling if you get a failure in the middle of it it's going to cascade and you have to figure out how to get yourself out of it i like this one that there's no such thing as a transient failure um i think my first example with this is actually with an old scuzzy drive uh back in the mid 90s and somebody decided that a two minute timeout was appropriate so when you were trying to troubleshoot this system get this system working and you had to wait 120 seconds to see if it was going to fail out um you learned quickly that these timeouts are completely inappropriate and the point that michael makes here is that you need to detect the failure quickly and treat it as a as a resource failure and so the whole idea of retrying is kind of flawed because the you know if it's if it's a system failure there's nothing to say that retrying it is going to um is going to fix it and you need to get it back into a place where usually a human manages to uh to deal with it all right objection your honor yeah sure on point three uh i uh i i'm i'm uh trying to grapple with the recommendation to not if i'm understanding it correctly are we saying that retries should not be part of your strategy no no not at all it's the you just don't want to do it for too long oh okay no problem michael there are some people um i forget the name of the book i think it's um it's i'm staring at my bookshelf oh it's release it very interesting book uh called release it i think he would argue completely against retries on the grounds that if you have any you know you you have resources that are scarce they're just so many database connections ports um buffers that you're using and when you're retrying and this is part of the reason why failures cascade is that you're taking resources away from the rest of the system when you retry so for example if the credit card system this is a good example of essential coupling and retry let's say you're an argument against even human intervention let's say you are netflix and you want to charge the person's credit card they let's have a pick a movie or you're selling something better yet you're amazon and you're selling something and you can't get to the credit card system to make the charge so what do you do you don't recharge but you use a policy method saying how big is the purchase how reliable is the customer and you just decide automatically to let it go through and maybe you'll put it on a stack and try it later okay so i mean there are people who argue that say and people who have done significant development says don't retry at all interesting so my experience there are a lot of scenarios where retry so that that's a big like application level policy that you're describing there's a much more micro kind of view here say"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:20:56",
        "seconds": 4856,
        "text": "development says don't retry at all interesting so my experience there are a lot of scenarios where retry so that that's a big like application level policy that you're describing there's a much more micro kind of view here say if you're trying to push a message on a queue or you know something like that or access a database um it often is as you know i i think it uh you know it's pretty helpful to be able to try it a couple of times maybe with an exponential back off not forever like mark said you don't want to you know hang around for 30 seconds while you're in the middle of some uh you know uh you know red-hot part of your system but the uh the these the small quick retry um saves uh saves the even if your application can handle the cascade of failures um sometimes it has consequences that you are better to avoid if you know for lack of a of a retry all right i mean it's fair enough i mean look ultimately it comes down to people using their engineering architectural common sense all right you you can you can list all the principles you want in the world these are not biblical imperatives they're they're more than rules of thumb because designing for failure will even take design for failure you can say in your opinion that certain failures are acceptable if you want to i mean i can't think of any good examples on the top of my head but again to go to back mark's point what you need to do is look at the business case and judge everything against the business case and if we can do this and satisfy the business case then fine it's just that it's as your system gets more complicated your retries that look so innocuous at one time can be deadly at another time so i mean that's you just have to think about those things yeah agree 100 right there's there's no um what i was more reacting to was a rule that said don't retry uh that's all i was reacting to uh nuance is uh uh important oh yes and but i would agree that in the applica as you said in the application layer more overwhelmingly more likely than not you should fail fast and not retry and the system layer i mean sure if you're putting something on a queue and you're in a background process who really cares yeah because user experience is also a huge part of this yes absolutely that's a good point actually it's an excellent point because the you that when you retry especially in scale let's say you are working with a write process so something you can't put on a cdn or something that you that's a right process that's going to a database well as mark mentioned before with geographic scaling then the speed of light comes into play and the more you retry the longer it takes to get back to the user so that's another factor that that you're right that you have to think about when you decide you're going to retry or not what's the user experience yeah and it occurred to me while i was listening to that that and i need to put this somewhere on one of the earlier slides we live in a world where people are like always or never and those two concepts don't generally apply in the real world but we insist on doing it so this was a great example of that as a rule don't retry but there are exceptions where it makes sense also empirically you can discover you can try retrying and then if you find out that it never goes through what's the point of retrying you may as well fail fast i i'll give you an exam i'll give you an example of how you use this i mean what it shows you how long i've been programming but when i first got started it was a great controversy over using go-to statements because you didn't produce structured programming right so what i did was i first established the rule that said i'll never use gotos and that instilled in me a discipline which i eventually learned when i could use go-to's but i didn't my experience was with a college professor who told us to never use go-to's i made the case that there might be places where you needed to his point was um there's always a different way and honestly to this day i've never had to use a go-to again oh yes but i accepted there were places where you needed it and i don't consider assembly language to count right but you're correct for a good reason but my point was by adopting a policy of never using it and reforming my habits i learned when it when you really had to use it because"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:25:59",
        "seconds": 5159,
        "text": "to count right but you're correct for a good reason but my point was by adopting a policy of never using it and reforming my habits i learned when it when you really had to use it because it's very easy to get sloppy when you say well i'll do this ninety percent of time and you're you're late the deadline's approaching you're tired on technical debt is what you're saying yes that's right so all right well let us let us continue um that was great conversation and then this reminded me bill of what it was like to be in person where we would just get a conversation erupting in the audience it was great um so use a margin of safety and again this is a thing where the cloud has made this much easier and much less expensive to do you know you can over provision resources reasonably without uh in order to build up your margin to safety without blowing out your cost model so so that's a key idea and then of course eliminating single points of failure got to get rid of the spots it's amazing how many people don't really get this and they do it anyway i like michael's comment here to admit you have to build a distributed application lots of people are still trying to deny that but that's what we're doing uh and then this is an early cloud idea to degrade gracefully and predictably rather than just failing out and we would see this in fact i think michael used to talk about this in his cap theorem um talk but also just in general if if you have an application that is becoming overloaded and you lose one of those resources you can stay on the air as just your performance is going to drop rather than just catastrophically failing and then my favorite assume the rare will occur because it's going to it will occur and the number of design decisions every day that i see which assume that that's never going to happen that's just a disaster waiting to happen in production in fact the ops guys should kind of mandate this from their side of things that this is not allowed to you know you're not allowed to assume something will never happen all right a question on that before you leave that slide if you don't mind and maybe this is as much for michael too as uh is there an underlying assumption that you have a horizontally scalable architecture no the assumption is that people are very and you can read about this in kahanamen or other places human beings are notoriously poor at estimating probabilities and when they think of consequence in other words we're all focused programmers have this bias that they focus on the case that works you know what's the path to success yeah the happy path and you'll notice how many i don't respond but i would like to address this the audience just as an as a honesty check how often people check for errors when they call an api and how many people have a actual strategy for dealing what happens when that error occurs well i'm assuming everyone does because we never see unhandled exceptions right right except for the great exception handler in the sky um so because people assume that things will work there's a intrinsic bias to say that will never happen the data center will never go down right redund you know and forget about the classic cases where the farmer with the backhoe runs over the power cable right or you know any one of a number of things such like this black spawns happen but so bill were you targeting specifically the last bullet or was there a more generic question you were asking it was it was more generic and maybe more tied to the first bullet where i don't know if you're you know if you're assuming that um the hardware on which your compute is running for example could vanish in a moment but you also want to not have uh you know meaningful downtime because of that and not have single points of failure and degrade gracefully and such you know more holistically yes yeah so like yeah so michael's answer is is i would say in theory correct it doesn't mandate it i think practically speaking that horizontal scaling is the solution to uh is the solution to all of these factors um also on the first one just to add the um you could say that we just give up or have a policy the point is not the horizontal scale necessarily the point is to have a policy based on the business case because as you always emphasize mark you have to always the the"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:31:03",
        "seconds": 5463,
        "text": "we just give up or have a policy the point is not the horizontal scale necessarily the point is to have a policy based on the business case because as you always emphasize mark you have to always the the arbiter of all these things is the business value and the business case because for example in the enterprise you can tell your employees well the system is down for three hours every night and they'll just have to deal with that in the consumer world you can't generally get away with that so you always help even in the enterprise space yeah and i've lived through this they will want a hundred percent uptime the only way you can guarantee that because of these reliability issues is to make everything redundant but then you find then they the decision makers find out that it's going to cost them twice as much to have hundred percent up time when ninety percent of time would be just fine yes or fifty times as much right right and i think one of the very first talks i gave for the azure user group i did a compar comparison of the reliability of the electric company compared with the reliability of what people demanded the electric company i don't think gives you four nines if i remember correctly it's been so long since i looked at it so you're in some sense when you demand 100 reliability you're asking more from this software world than you actually deal with with real life companies in the real world and one other thing i want to point out because i started this with the um unreliable hardware or unreliable infrastructure it's not just actual hardware failures which are possible and as it turned out empirically the hardware is more reliable than than we thought it would be but we still don't guarantee it but we do rebalance for instance one of the things that all clouds do is that we may need to rebalance and move a vm from one host to another and that vm is going to pause at that point and if your software is not designed to handle that which kind of falls into the failure category or you know we may need to patch the underlying host and that's going to cause a pause and things like that these things need to be you need to take these into account in your scalable architecture and certainly software failures fall into that the only reason i mentioned the the the infrastructures because that's where the illusion very often is fair enough anything else i'm sure we move on okay so uh recovery oriented uh computing which is uh kind of the nice phrase that we came up with i think he came out of stanford maybe um what did we have what was the other one we had designed for reliability in fact i may have that as a bullet here um stuff is going to break in the cloud i think we've just covered that ad nauseam um you need to design for that particular all of those failures at all levels you need to design for reliability which is where you get into your redundancy and things like see it's one thing to assume things are going to fail you also need to compensate for that to make the system actually reliable chaos engineering is a netflix idea where you basically bombard your system to have random component failures in it of all magnitudes um and then see how your system behaves essentially what they're doing is testing in production that's the important idea right yes and in the enterprise that's a they haven't even begun to wrap their heads around that um but we'll get them there um and then this concept of item potency i could have put this back on one of the services slides um but this idea because of these concepts where where you may have network failures and the like um and some and a process may execute more than once you need to get the same result um you know no matter how you do it and so this is a really key concept in distributed computing design is this idea of item potency um so real quickly there's this idea of the eight fallacies of distributed computing which started out as seven uh they came up with these at sun and then somebody else's son threw the eighth one on at the end we can decide if it's necessary these are really really important for developers to understand and it's why things like rpc remote procedure calls bother me because they're specifically designed to abstract away the vagaries of the network and that's a really dangerous place to go so uh so fallacy number one that the network is reliable it is not um fallacy number two that latency is zero michael referred to the speed of light before and in cloud public cloud computing for sure latency is a huge"
    },
    {
        "speaker": "",
        "title": "Mark Eisenberg The Essence of Cloud Computing a 2021 take on a 2010s question",
        "videoId": "yp_NK4lHjq0",
        "description": "This is a recording of the May 13, 2021 virtual meeting.The Essence of Cloud Computing: a 2021 take on a 2010s questionIn this online event, Mark Eisenberg of Microsoft will speak on \"The Essence of Cloud Computing: A 2021 take on a 2010s question.\"This session will make you think - or re-think - how you reason about cloud computing. Put on your thinking cap and bring an open mind and be prepared to leave with a fresh perspective.## SPEAKER BIOMark has over 30 years of technical sales and account management experience in the software and semiconductor industries. For the past decade, his entire focus has been on bringing the benefits of cloud computing to the enterprise. Most recently his cloud vision has expanded to include microservices and DevOps. He passionately believes that the current wave of technology innovation can significantly improve the state of the art in enterprise software application delivery.Prior to turning to the dark side Mark had 10 years of experience as an embedded software developer. He prides himself on having kept current on the technology front while still being able to find his way around a debugger.Mark holds a bachelor of science degree in electrical engineering from George Washington University.",
        "start": "01:36:06",
        "seconds": 5766,
        "text": "uh so fallacy number one that the network is reliable it is not um fallacy number two that latency is zero michael referred to the speed of light before and in cloud public cloud computing for sure latency is a huge issue and needs to be accounted for bandwidth is infinite practically speaking maybe we're getting there but it's not um the network is secure we all know that that is definitely not the case um although i am having more and more thoughts about are we spending too much time obsessing over bad bits getting to parts of the network when if we just design secure endpoints it would be irrelevant the denial of attack denial of service attacks are one exception to that where we do need to keep the network secure topology doesn't change that's not a fact there is one administrator and this is really critical because if you have multiple administrators that means you can get countervailing changes uh being made to the network and software needs to be able to deal with that transport cost is zero there is a cost every time you go out on the wire chatty applications we know are problematic and so we really need to you know this is another thing that the architects and developers need to keep track of it's also the another huge danger in thinking that the network is not there uh and the the latency is zero that you think you can be chatty when you can't um network is homogeneous um which really plays to the if you do repeated operations of the same type that you're always going to follow the same path if you put any kind of latency dependency uh dependent functionality and you're going to get bitten by this and that was the eighth one that was added way back for anybody who's interested here's the article in wikipedia it's got a lot of history on it too and we're pretty much done at this point these are the cloud documents the nist documents from the us government and iso from europe if you're interested in reading them it's fairly dry reading i don't really recommend it i just want you to know that it exists that there is actually a definition of cloud computing this is a bunch of articles that i've read over the years you'll notice that these 2010 netflix tech blogs are still really fundamental about they were actually talking about why they chose um amazon's cloud in the first place and honestly had our cloud been more mature it might have been more of a horse race but amazon was definitely ahead of us in those days and then what they learned in their first year of implementing it all this stuff still is valued um it still is valid and then here is the book i mentioned writing software uh by yovaloy and uh i i highly recommend this to anybody who's architecting code this is this is some really fundamental um good stuff to put a put it crudely this one's fun um i can't remember what steve's last name is but um he did yeah that's right and this was all if i remember this was all about how amazon came to be service oriented but he was at google at the time when he wrote it and i remember correctly that's what this is so anyway just some interesting reading for you and with that we're done wow well uh thank you so much mark let's open it up here for a couple minutes for any anybody um has final uh questions they want to pose to mark feel free to come off mute and let him have it we'll give that a few seconds to see if anybody's going to take take us up on that yeah uh well wait well we're giving that a minute uh michael it was uh great to have you uh colin haven't uh encountered you and maybe since pre-coveted uh are you uh in the uh continental uh escapes yeah are you you are okay i just came back from elsewhere where those of you who know me know where elsewhere is very good well we have some uh thanks for the presentation so it looks like we're not getting um uh uh any uh any tickers on further questions so uh huge thanks mark this was uh uh very energetic and you know like uh like i tried to allude to in the uh meeting uh uh posting and then the intro uh you always get us to think it was a good uh it was a good chat and i it was really great to have you uh so engaged as well michael yeah yeah exactly i had a good time thank you i appreciate your uh setting the stage and um yeah it's been a while since i did this one so it was fun to bring it back out and get it get it updated and i hope i did get some people thinking anybody who hopefully i might maybe even struck some painful chords and you should you know feel free to reach out to me and we can have a conversation about it um and i'll a lot of what i like is i kind of disclaimed at the beginning um i don't think my employer is doing a great job getting a lot of these messages out there and it's kind of my day-to-day life now working with my clients um i have said to one of my clients that with all due respect you don't have a cloud strategy and he didn't disagree with me so um you know this is these are these are messages that need to get out here even as bill's title alludes to over 10 years in and we're still having the same conversation mark what's your uh twitter handle i don't even use it that much it's out at cloud biz in tech i don't yeah i haven't been really "
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:00:00",
        "seconds": 0,
        "text": "Gregor Suttie - Super Charge Your Learning of Azure. This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.. okay okay so this should be going live soon Greg if you share your content let me stop sharing mine and if you share yours alright cool it should be going now the first times artists let me verify can people hear us we're learning sorry everyone awesome we're live okay I guess we're alive so let's start right so welcome everyone to our first virtual combined meet up with North Boston Azure and Boston as your user groups and finally we'll fix our issues so hopefully it will go smooth from now on you can post your questions and I will try to moderate it and Greg our speaker today I'll introduce him in a minute so I'll pass the questions to him and then he'll be making some pauses during his talk and he'll be answering questions you can also post your questions on slack even after the session so Greg will answer them later if you you want him to answer them and so let me actually introduce our first speaker first speaker for this four month it is Gregor study all the way from Glasgow that is super exciting now we can have international speakers in for our meetups so Greg he is an azure MVP he is really active in agile community he's doing lots of awesome things and he can tell you more about himself so I'll pass it to Greg okay thank you very much welcome everyone it's all about the technical difficulties I think it was probably my fault well that's no whatever that and semi isn't working well you can fix when you turn it off and turn it back on again so I'm super excited to be here super excited to be talking to you so get my name's Jo city also known as algebraic and welcome to my session on supercharge your agile moment I'll just have you but before we go any further I'm just gonna jump in here chief introduction to myself so I have 20 plus years experience as a mainly as a vb6 developer to begin with and then to donate so being a developer for 24 years Lucas as you can see in the bottom right hand corner was a little mark there of the Yuki and the starters I was just at east of Glasgow so you will recognize the Scottish accent so I'm hit currently head of development for sword IT in Glasgow so I have in charge of 17 developers all throughout the UK and we work on all sorts of different types of projects public sector private state more different types of donate mainly donate and as your projects also co-organized the Glasgow as your user group and I'm along with Cedar Lane it organized it and I just kind of help out so I kind of try and help it yes because to come along and speak it live in I run the house of global boot camp so this is their fourth year this year so out on the glass but if Nova and obviously this year that's going to be online so looking for speakers but we're always looking for speakers from over in the world just to sign grow their community personal blog as a courtesy don't call me my ball go and things like mojo are the devops don't like nothing and august 20 last year I became an MVP in Asia and I tend to help organize our community events when possible so quick qui tam committed to the larger community so as I said a lot of the Kosmos user lots of pictures looking so that's all that will introduction to me so the agenda for my talk today as I'm going to talk about a couple of things so I'm going to start off with my Johnny and but it took a little bit and my journey in hell and the huge subject pedia will hear from Scott and"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:05:04",
        "seconds": 304,
        "text": "so the agenda for my talk today as I'm going to talk about a couple of things so I'm going to start off with my Johnny and but it took a little bit and my journey in hell and the huge subject pedia will hear from Scott and next I'll cover some examined formations I had to get started with the hazard exams we had to thank useful links and info on dodging exams better move on look at learning resources so when the last two-and-a-half to now after three years of learning as you have gathered a lot of learning with you some good stuff I'll cover that later on and I went with some demos of that stuff so I'll show you the links talk a bit a links and then there I'm sure the resources are backed up as I go and if there's one thing I'm good I'm good at finding resources so if you're studying as your exams and hopefully someone else content will be useful to you and then telling the whole talk about particulars from a station and then block the optic questions as we go so if you have questions don't couple times through that's a cessation and then we'll funny for questions as well so my journey I'm 2073 soul journeys have to stop somewhere so when November 2017 I had literally zero as your knowledge I was working for JPMorgan and the big bank and the gospel office started wanting to look at new things I was kind of walking and what you would call a feature factory so I was working on one big project over three years and it was kind of doing to expense and just working on the same thing the endeared kind of get in voting kind of didn't a Dornier same sort of thing we can Rico and just wanted to stop looking at something different so I thought would be a kind of make yourself fanboy having a look at the cloud and kind of get interested in next time where they talk about failure which is not something many people talk about but it's also an important part of learning and what you can learn from failure and I said might have 400 few things from do now as it exams and tackling it from the start probably not the best way so I'll cover that and then I'm going to cover where I am today and my journey just to give you some context around my journey I'm landing agile and hopefully some of our isn't even affair the people on the call today so let's dive in the first part my funk my journey so start night so it was November 2017 as I said I was on one kind of big project I wanted it kept trying limbs from play development but internal EGP Morgan what kind of bone though to include and Oki Java do you have a place event really doing too much tornado but really doing any engine and I kind of might make you soft background I wanted a stabbing at landing housing so I started taking away all manager must be a team and as you can probably understand title and something like Ozzy was really very jointing and so yeah it's a very well subject beauty to end but when I put them into something like wall I'm not gonna say that I'm gonna go and do that and I started spinning t.rosile everything to Train well music so budget and I'll talk about how you can get started as well we've thrown him the best place to start so the one thing I was going to talk about feel and she suddenly may not hear much of misty and age but I kind of think it's an important thing because you can learn from your failures so I studied like crazy for a long time probably three or four months and one day when I was on Twitter I saw that they had they had started talking about you guys would exams and that kind of piqued my interest and then I saw a blog post talking about some new hazard and exams tonight so there I think that's the tippy-toe exams back then which was there as you as bonus to your exams I think this was in March might be 2018 so I've been lemon for a couple of months just too early which is quite long but I started looking at the easiest 100 by Kennedy which was the Microsoft Azure infrastructure and deployment exam and then I was also what cannot be easy at 101 know the problem I had was the b2 exams came out and had two weeks to study film so I kind of had to call down and look at it and if you know me I don't do things by half I can I like to jump right and so I kind of took two exams within two weeks both the two weeks I said beast I said to myself let's just go and get my show that's gonna not and start off high field the very first I was your exam I'd ever taken so I hadn't done any makeup exams for maybe four or five years since the MCS detour mcs TVs swaps and you an experienced field that exam by every four or five marks so it wasn't too bad and so that was I think that was a subdeacon in March and then I filled the second - exam which is like TVs latest Psalms to tend to feel so that wasn't great but I thought that is also these two examples I didn't really realize that I just not elephant so the point of me talking about fury is then what did I learn from failure doing these exams until you honest I kind of put four or five things I knew superb preparation I didn't really prepare for the exam I kind of was written blog posts and kind of looking at looking"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:10:07",
        "seconds": 607,
        "text": "about fury is then what did I learn from failure doing these exams until you honest I kind of put four or five things I knew superb preparation I didn't really prepare for the exam I kind of was written blog posts and kind of looking at looking at stuff I wasn't really doing hands-on so it all just he had fear of planning I kind of rushed onto the exams head Faust's I thought all I was repeating at PETA exams I'll have a show and also didn't study the night material I was kind of even make use of dork articles and we can belong forcing and the lessons that I learned I wasn't in time zone when I was reading the books and stuff like that and not actually opening up gonna I was like postal and building things that's kind of where I went wrong another reason why I wanted to maintain for you it was being a developer these two exams what kind of infrastructure and name okay to take things administration which I had no really feelings and so from what second most exams to sign off wasn't great but the one thing I did learn was I kind of came from though as you knowledge and I'm just gonna start until almost pass these exams which was interesting that one of his Leyland we start to sink and so that was good peaceful warm scene that I needed to learn hands-on lemon and take it all in and repeat that practice build a network both virtual machines and kind of do the hands-on and redo the process so that's I'm not gonna have a dual person and seeing things rather than just reading about things where I went wrong so that's kind of a lemon from feeling and since they enough exams in total one of a false a filter and I feel one Biagio their home twice pretty much doing the same thing again jumping jumping into just because it was a house you beat a exam made and it was gonna a quarter of the place so what one thing I would say is don't jump into the exams too quickly I'll cover some tips and some later on just to kind of talk a bit of things you should do and the things you shouldn't do but that's gonna and today let's talk about we learn to be so moving on in my journey meaning is not what it can be that hey how you can go on your own journey and WHAM something like Asia I don't recommend you try on all those good because it's obviously such a large topic so today I am an Izone MVP so that's pretty cool what was an identity within two years of not knowing any Asian and which I'm quite played off I think the main reason for becoming an idea MVP was basically giving back to the community so one of the things that I was constantly doing was setting the exams taking notes filling up my window reason below post ten times one leveling and then looking at the exam pages and looking at the content of it when he asked you on and coming up a fare study gates I think I study games were really grateful and I think that was kind of what kind of my glow of stats that study good blog post by quite but so I was getting back to people which felt good people would penguins he thanks for your study tips and kind of Sunday against passed my exams so I'm just gonna come in and that was pretty nice and the one thing I was learned from a long time ago and luckily it was always think of the Pearson Cohen behind you so they may be enough similar Johnny some people when they fall maybe I sell more Johnny and if you share with you and then maybe just one day and that helped you be able to help the same person on their journey which is always a good thing I think the good news is after filling the rest of two exams of no past their name exams or so I've learned my things not to do and there I wore the example at all Obama teeth and the other thing I wanted to talk about was just part of this journey people were seen that was certain exams and kind of and chasing that had blue eyes or knowledge and there was kind of pass these exams and being on part of the community I was getting people coming up to me and saying would you like to take a walk would you like to rate but on the exams and I'm like less often and that was quite so I ended up because technically my published algebra coin as your DevOps was really cool the other thing I wanted to talk was as part of that you can have opportunities and I'm not being asked to speak at conferences I'm kind of doing this talk today so that's quite another cool thing just giving back to the community I think it's pretty important so that's kind of weird as of today so the next thing I wanted to talk about what my goals for me goals are very important I set goals for myself every three months chemistry at schools not something simple things that I think would be really cool to have and do but I'm gonna be straightforward so these are the long-term goals I had when I started learning agent so the first one was I wanted to pass an argent exam then and the next thing was the pasteurizer architect exams of the architect exams probably the most difficult because they cover all of our you so from having no idea of knowledge to person my exam and I think just under two years was was quick played on myself for that and speaking of competencies obviously"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:15:12",
        "seconds": 912,
        "text": "probably the most difficult because they cover all of our you so from having no idea of knowledge to person my exam and I think just under two years was was quick played on myself for that and speaking of competencies obviously was one of my goals as well I always looked up to people who spoke at conferences and thought yeah that's kind of cool I'd really like they did can I do that I actually had a fourth cool in the back of my head but I didn't want to put up my slides as a as quickly it'll end up becoming an MVP was not something you should should be a cool becoming an MVP as a byproduct of giving back to the community so one of my biggest goals was becoming an MVP and I was NDP and pinned them on the wall above my monitor at home and I'm gonna struggle for motivation kind of the deepest darkest tears I think remain me of one of my goals so yeah that was kind of motivation and I always do have a calendar above a monitor I'm looking at right end of the things I want to do and win so it's kind of hard it's always good to have goals I'd recommend that people have goals because if you do it's quite easy to fall around and really know what game really want to be especially if you're starting to learn as you are you're gonna what are the best things about certain exams for me was gives you focus and that fills on gaps and your lemon so if I'm not liking a networked person but I learned a lot but as your networking which was something I wouldn't have went my way to do but in order to think I set these exams and pass these exams I still learn that that's kind of why I will say noses exams are quite an important part from when gives you a conical and 2-tone pass these exams so that's kind of my goal and so I've got time for some questions if you want it just is anyone get any questions at this moment so I can see sweater I didn't hear myself so I can stay only one question right now so Harish was ask him I'm preparing for easy 104 I was preparing for AC 103 I would like some guidance as I'm reading the exam reference book and going through videos on all Riley my goal is to become an azure architect and an azure everything so it would be great if you can share the best path towards achieving that yeah so if I said if you're studying for this as your e-zine 103 actually recommend you just go for the 104 and that's a PDF document online if you look at the example that will show you the differences between is ed 103 and they said 104 there's also a thing from the guy called Time Warner and Mike faithful and they're doing an online course on cloud skills and they say I guess been reduced in $97 or there's three days of training for the actual exam and I've done some of that training before and I would highly recommend you sign up to that it's can I have in the last month and their CDs have gone through courses and learning and but I can't guarantee you passed I think from previous courses and people certain exams that I pass rate from that is really high what forgets to be an imaginary P in general there's kind of no real fast and hard way tonight you just really need to give back to the community as much as you can some of the examples of stuff that I do is I organize events I can show you some songs and maybe later on in the talk organize events for community I take part in events I have run the user group which is a big thing and kind of stuff show you later on and I can I try to grow their humanity and so that was kind of good and if you want to do the architect exams start off small start off examine sushi I would take actually recommend you start off for these 1800 no inmates a lot of people look at that and think that's about basic but it's a really good example to start with if you've never done number four businesses actually truck equations in there you get used to the test that we have just given the main set do an exam and then we do these so yeah I would suggest that anything else any other questions over continue um yeah we have a couple of questions here so let's okay let me ask that one for prepping for adjourn I'm from an IT pro back round though moving to Azure cloud so wanted to get an idea of where I need to focus on so yeah I mean this is kind of how I started poor should have done as developer so I should have looked to the developer exams to begin with and then hain say oh I would start with the"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:20:18",
        "seconds": 1218,
        "text": "yeah I mean this is kind of how I started poor should have done as developer so I should have looked to the developer exams to begin with and then hain say oh I would start with the fundamentals exam so how what kind of fundamentals exam and you can I get a good idea of version and then if you're an IT office person then you make one a look at something like these at 1:04 the IT administrator exam look up what we suggest is you look up the exam information and frame the example it suits you best and I can show you some resources for that later on you can actually tie your skills to what exam you want to look up I always go on up in the exams but I really do think that'll be to me to fill in gaps and land things because they cover stuff which is good and bad but you will win souls yeah I think I'll show you some of some resources later they'll probably help with that question and of this awesome thank you Greg another question from Jim I've taken a couple a couple of other exams in the US and found the test itself to be terrible and nearly unpossible in my opinion what was your experience in Scotland I wonder if the same company prepares your exams yeah exams are run by one thing I would say is if you're doing exams I would suggest pourcel you can't do them though but if things had been different I just think it is just more comfortable to do that and then do them online you can do them proper notes recommend you do you're not a sailor yes the one good thing I would see is the labs labs or not so if you are thinking about an exam there are many labs which makes out well be easier I've set two exams mouth labs and tip you honest a lot of them doesn't even loads in the first example I certainly could take an exam and the labs didn't roll at all and then a set another exam where the whole phone crashed so here there's lots of reports of bad experiences but you coronavirus and usage of as you kind of removed all of the labs so I would suggest you never benefit to people because they're not great so I can experience not for me yes one more question I would like to take cp200 as a data engineer where do I start so depends first examiner but the best point out the factory resources on what we have to find and there's some really good level resources and things like taste creations and gives you and gives you an idea of what to expect I kind of yeah probably best to eat actually sometimes your sources rather and cover them just name that's okay I'm actually going to talk about exams next so I think we'll just pause with questions right now and I'll ask you more later okay okay so how's your exams let's talk about your exams so yeah due to the podalic one thing I did want to say was the labs are normal no longer which is which is good I think to be honest so let's talk about a lot more so I'll talk about some of the questions that people ask me so people always ask me what's the best way to take the exams online utkatasana I always suggest first quarter taste it and then do them from home obviously now you have to do the problem but there's many other exams coming like all the time those new ones popping up those new Peters coming up so yeah definitely do the example if you can is so another question is how much do the exams on the course so normally the 165 each unless you have a vote so some people can get photos or if you're certain I'd be tell exam now beta exams are slightly different there are more questions in the ether exam but are a quarter of the place and I think don't take this the wrong way but I think the exams are actually slightly easier and a lot of people seem to pass the B telegrams and the bit exams so that make us often cannot look at large number of questions you get asked excuse me was a good question and most know a good Christian based on feedback I also gas is quick and he big exams basically just a phrase to the exam fees and register from neon and it's fairly straightforward the one thing I would call it is if you're doing on a whole night you can I need to you need to sign in a little bit early because you get asked to take photographs of your ID"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:25:21",
        "seconds": 1521,
        "text": "exam fees and register from neon and it's fairly straightforward the one thing I would call it is if you're doing on a whole night you can I need to you need to sign in a little bit early because you get asked to take photographs of your ID on your phone and you'll have to take photographs of your only and they used to sometimes come on if I do and do that but it's now all on mobile so if it examines the start of one and the afternoon don't join 15 minutes they are doing half an hour early just so you're there and have your ID handy because you know you may need to take it forward and they thought my pictures and another tip is once you're doing an example in my home you need to stay within the camera because there's actually some some software that will run and if your face could move that picture face detection will crop up and you can actually get you can actually feel the exam if you do things like bending to pick up your moves or some like that or if you if you'll either if you cover your mouth is where you can you can feel so just be careful when you're doing the exams alone but that's this link at on this page you can see that's pixelated just a link to the kind of main exam so this is fundamental exams there's associate exams of those I expect exams so I always did you start the fundamental exams and then and then this will say next but that's kind of it's supposed to do you don't have to do them in that order you could start with like my associate and then go back and do fundamentals actually the last exam of that this fundamentals I didn't really think it was worthwhile doing and then I spoke to some people never say that the contents actually quite good so I kind of went back in the dark which is good at the diag night which is quite nice and then if we move on all over so about links here and what do they call it so the actual official blog for the exams is that link there and if you don't what that was a person called Liberty Munson so that's a good person to fall if you set up beat exams that person me cause i when they results are announced I'm gonna we can have blog about and you beat a exams coming up so that's all and I came to keep my I was also a really good website called build Fighting's it used to be about now as your company had to rename and the link and they'll talk about and I'm gonna I said if Azalea that website is really good and probably one of my favorite exam weeks is this official study gate so make yourself device a study aid where you click on that link and just put an easy - - or one for example then I will show you the official study gates that makers off typical and I'll show you that many better that's actually no I really well-known link and it's the first one that I say to people who are stepping new exams no nothing I put together was on I have an hour resources but I'll show you a little bit ago and I've been as many folders as I can for like easy at one or three two hundred three hundred four hundred five hundred nine hundred so of course some study gazes out and one of two people want to tell my friends if can add it the other than there so I'll show you summarize well which is pretty cool okay so we D start so if you start until they're larger and you kind of looking for resources I can out like to call these resources and make yourself limb no matter what level you are if you're beginner intermediate or an expert because of where none is just fantastic add a new content all the time you can learn the fundamentals about here you can land pretty much evident and some of these website links have labs you can spin up and kind of walk or I don't know if they're going to work today because of the violence but they made a lot in Taylor actually tried and fun I'll be well and then there's actually over review.com which is hasn't suggest an overview of a Yoshi find that is also see don't nobody service possibilities I hope you search for servers possible and I will give you some links to the official documentation and so on that's quite a handy that's kind of as it says an overview advisor one of the best places obviously the eyes of dogs so that allows your documentation from dope stop microsoft.com can't can't really be too um on that page quite record to be honest and the last one I want to call it was the clued adoption fee mark so if you come to my company and you're thinking about moving towards idea and I don't think the clade that's website is are absolutely blowing at all well I can show you it never even entered that will discuss how you go about moving to the cloud and think about things like governments so that you haven't even convey and resources and he just don't stop spending up stuff that's gonna cost you lots of money and you're gonna regret it there's lots of brilliant resources in there so that's kind of the best resources for when you're starting to learn larger from the nave or one so it's a really good st. call dad you're such a deal I will go through all these and I'll show you an almond I just said today becomes not really well known that's put together by the community and there's kind of links to all sorts of things like networking using the Parker and ansible"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:30:27",
        "seconds": 1827,
        "text": "such a deal I will go through all these and I'll show you an almond I just said today becomes not really well known that's put together by the community and there's kind of links to all sorts of things like networking using the Parker and ansible and all sorts of cool stuff you can search in there next we have our chance comm house of charms as a phenomenal website it's written by a guy here Watch from Microsoft and I'm going to it as well because it's so making things in there you can find it at any age of service you can find out about things like Haley which resources available and much country all sorts of really cool information is even a cousin there if you're not gonna use a good thing anyone I can work on that the next one's I have type some text written by and make up Crump so he has some urgent tips and tricks I covered on i-80 things networking basically and I think that so actually on hope so that's open for people to connect to and can I do pull request that covers all of our I think he's up totally 290 text a small man thing and if you look easy when it says all flame is actually on no one touches will just play cool and the water is also on here is just crack start templates so if you want an armed input so if you want a template that will help you spin up something that someone else is created or you want to do something like clear vm and you're not sure how to you can go in here and basically ouch just take the magic VM and come up with samples and templates affected what I do not so that's pretty cool as well that's kind of information if you're in the middle of the journey so the next one is experienced in Azure this phenomena place I'll check us calm so if you are experienced in as you and you'll ability to production oh I see kind of like a check for say you're doing how's your functions and you just about it to the enliven production you can go in there like gives you a checklist of all the things you may have not thought about and check off just to make sure that you've thought about security you thought about authorization and things like and that's really cool that's our community website as well next one is either an architectural saying that I says we have find a reference architecture on example what would include the based practices so the cloud based practices is really good if you're doing something like sequence you ever anyone know how to set up a replication a nice to see you go and then you can look up and I'll give you all sorts of background information and kind of reference architecture and how you want to operate it that's pretty good if you don't if you and as you know I could take that's a very good resource and a third one is Azure DevOps geraldine ethos really so if you're doing agile devops or do you want to learn how to use agile devops and the others labs there's all sorts of things I'll show you guys around you can learn ansible you can learn how to build pay planes release pay planes all sorts of really cool stuff in there and the last one is a Scott Hanselman I was afraid II so I'd be afraid of it at least two or three videos every week of things that he has phone talking to people who walk without it so that's some pretty cool stuff and there are things like how to improve performance in your website stuff like that so that's can ask your experience I won't show you a lot of these touring no I'm talking and really quickly but I'll be damned of most of these okay so let's talk about paid tuning so all those our resources are free these ones are not free so these are the training ones and I've came across in the past skyline's Academy really really good they've got really good coasters things like fundamentals of course on office365 10 and came out recently really really good play-doh site a few spool it was like for a long time the path or anything pass on that are excellent have no user code you do come to be honest I used udemy back in the day but I'm both school scholars trainings are fantastic in there and one thing that's really good if you feel really a rarity set an example and you're kind of looking for some questions that might be kind of somewhat on exams but they're not cheat sheets and in shape or form they're just gonna taste questions I suppose labs don't come I've used them a couple of times and they ask a question and you get an answer wrong and I don't give you a link to documentation on the website and you can go and read about it so that's really good and always mention measure up just because it's kind of make it off make yourself kind of thing in there from when you're signing up for exams I don't really use major don't comment him off to be honest I used to use it to begin with but I think there are a lot of resources I'm probably a little bit there so let's talk about communities also sold this one up to community resources the other are fantastic there's a lot of eyes of blogs that people have written blogs covering edge of things and there's lots of really good YouTube channels makers off to fantastic YouTube channel those user groups like that we"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:35:31",
        "seconds": 2131,
        "text": "are fantastic there's a lot of eyes of blogs that people have written blogs covering edge of things and there's lots of really good YouTube channels makers off to fantastic YouTube channel those user groups like that we can speak to people on aspirations and virtual conferences they need the support so they won't mind if you're on Twitter you can keep an eye out for things like that there's some really good resources some photos roses for I will show you in a minute I've put one together which covers all of my eyes you're learning and one thing once they call it was a thing called cloud family so myself and a couple lot of people have started any house youth community online and called played family but he's in white called cloud families we didn't want to put as you in the name because building build as your dorm I think renamed to those findings of a call it cloud family but that's a as far as like channel it's called website and I'll show you all in a minute and it basically the community is also they love growing so enough enough talk does anyone have any questions before I all that stuff for to want me just to keep good yeah yeah I still have a couple of questions okay I came here myself okay yeah it's better okay the question so someone was also going through similar paths as you did work and he has been using Linux Academy and was passing the practice exams with a hundred percent so what do you suggest to do to prepare to take it again also do you think I could take it as soon as possible or wait a couple of weeks I'm not sure why I have not I just just not something that I've come across that's it I said if you're doing exams and you cannot do the same questions over and over again so one of the things I did used major don't consider game month and I was kind of setting the same equations and getting obviously built schools because I knew the answers if you do not then look at something else but if you've been questions each thing definite answers then and you get 100% or how would actually they come in if you're getting over 80% then go for that I would just take take the exam and if you do feel examined again whatever it you can see we you get a report on end of it really we did well we didn't do so well so you'll you will to gauge your level and figure out what you need to learn the next thing I would see thank you another question here what do you suggest for an azure cloud DevOps as I'm currently working as a DevOps engineer but not not a measure I think is that kind of would be Russian do you want to answer I can talk so the age of DevOps exams an interesting zone because it's not just as your DevOps the product it's more a DevOps in general so it it talks about things like moving from Gallup to other DevOps moving moving off of TFS upgrading tier faced with a lot of questions about things like Jenkins so it's not just our DevOps which may come as a surprise to a lot of people but yeah if you look at the exam something with you you get them chasing idea but I actually feel that exam twice because I didn't know much about Jenkins actually again wasn't doing any hands-on things with Jenkins so I actually spun up a VM with Jenkins on it and that's the base we tell em for me so yeah I mean if you if you know demos person differently look into some of the content I will show you that we mullet because it's some interesting examples it's a little but some of the questions are not what I was expecting almost enough okay awesome um one more general question who was will this presentation be shared this is so I'll do is I'll put my slides and all the links and stuff on to my kelp and I well yeah so yes I'll show you real food on Israel sucking Frieda link as well so yeah all available at the end of it that's awesome I think we don't have any more questions right now okay like let me show you some of these resources there's all good Noelle's meeting their own resources but let me show you so let's just see if I support okay so these into collections so photographer dodging exams so okay that's like hey this is what"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:40:33",
        "seconds": 2433,
        "text": "of these resources there's all good Noelle's meeting their own resources but let me show you so let's just see if I support okay so these into collections so photographer dodging exams so okay that's like hey this is what I was talking about a month and so this is quite a good resource this is a personal rates that's blog so this is the actual official Microsoft blog and here's an example of what was talking light so that's person here this we to follow because if you didn't beat any exams or want to know when an examples coming out then they took quite a long but these comings was mostly tweets were they also resources that's a good time and one of the big scoop seats for women as for the exams of those five things that's weight like as fantastic I must admit though they've got whole but about why you want to get certified we have to go to get started popular training courses things like exam study gates for all the different exams so definitely check so if you want to do the liquid di engineering or the developer associate really good stuff one here there's actually also Zacks also study Gaiden here where you can put in the study gig notes and you can school yourself as you're going just to keep an eye on how you're getting on I'm trying to find out now second best wave so you feel a good boat finding zircon used to be both a joke on it's also really good blog by just like these desertification seen a free assessment so it's kind of like an Excel bougie and you can download a couple of them already you know here and if I just really screen again it kind of gives you the objectives by alien you can kind of fill in your confidence level on each area can I just keep an overview of hated lemmings going to I think if you like you'll play straightforward but quite nice and open up and that's all can open so you can join me on download easy ed will think you're the 104 and fellow the ear is confident master you're not confident with and then going so and once you're confident and then you'll know how about good resources are so this is my favorite link for finding exam information so this is basically the rights of training and you come in here and it automatically checks exam and then you just put an easy let's go for 500 then you get featuring any gum so these at 504 now when can you undo it's all working training content courses and stuff like that we can learn for the exam really really good website know more people know of it of those courses on all the things a good example so if you wanted it and want to have fun of tea yep one of three stuff you can come here have your stuff to go online flacco yes people always think yeah I always tell people and one other thing I would as my resources so if I talk on my go let me just click on the mean thing to the gun month so in here I've caught some community places of course some articles on DevOps but the one I wanted to show you for the exams exams folder so in here I've got folders for most of the exams not all of the exams but if you want to study the easy ed 104 this is where I put all my study gates of Kuwait it so if you want to go and you can find exams and I'll come food people links to training courses in a bit more and then there's quite a lot of links going on for things like babies ed one of these people have written some blog posts study gauge in here so definitely I look at these links and the last one was not sure he was just to make soft website because awful day on waves like this saw a fuel and placed it in rules so if you are a DevOps person you can bring him go to Portland in here and I will filter the information about the can exams for that rule which i think is very cool so you can go and learn about these at 400 exam the certification and the upcoming the exam for acp what woods so you can do by rules that's going in twisting to see you're doing and see your data scientist you can go in here a bit a data scientist but also you can line up at the products so if you have an interest in a certain as your product I wanna see you want to learn with cosmos DB that filters the results by cause don t be and I can go and find a war exam release it so that's make yourself alone but the song school that's the certification partner metric there's also these learning paths so that's this way"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:45:37",
        "seconds": 2737,
        "text": "cosmos DB that filters the results by cause don t be and I can go and find a war exam release it so that's make yourself alone but the song school that's the certification partner metric there's also these learning paths so that's this way I keep coming back to so I come in here and those things about how's your fundamentals I just fundamentals Learning Path can I take you through all these courses I mean you can away unmeasured one you can you can start off as beginner that will tell you about the exam tell you about the prerequisites and give you modules in this learning paths at least he's kind of learning fast of modules II can I go through and you kind of get pointed one it's kind of like you keep score as you're going but there's lots of different things in so you can do it by you do it by product you can do by rules you can do by levels so if you're big enough you can filter that you can do intermediate advanced and it helps to do a lemming path so if you see it'll begin on you want to do a whelming filter by that and there you go you can filter you can search for I don't know [Music] host our example yeah contributions and you can save lanlan parts of it virtual machines really really good website so the learning fast is really good they they keep up the Indy so keep coming back a lot of people use this and kind of never come back I always combine to make yourself well especially this is its edification apart and day for the lemming fun and I kind of think I'm a wave late there's something like 17 levels so those are walk acquaintance and yet and it's really good for all levels of people this content for beginners intermediate and the experience and I thought why they go in Landover containers what I really like about Microsoft lemmas it's kind of bait sighs lay on it so you can jump in and find it a bit some of it like but you don't need to do a whole course online and are you can come in here and thing they're warriors docker I just walk and then things up find another can i that's immediate course after that so that's kind of my links for housing exams next I'm going to show you holding resources askin across yes right okay so let's go into a little bit of um kind of talked about I say later on so if you are interested in something like event hubs you don't know why they're knobs as you can kind of come in here and search for things so that I can call event hubs and I'll tell you some information about when I come out you can click on the link and I will take you to the official event up documentation it's quite good to get started on and looking at the hood of your visor and what's come on in way and you can see what's generally available and what's probably preview I think that's websites on well Bo buddies I'll crack why don't show you the money on our website which is much better I think this one's really really good this is your charge card and I'm so this is a guy who wants to make it soft and this is just an amazing website so the kind of thing that covers all of the all of the different core things placing our phones what's been retired you can look at this kind of a better overview actually so this is all the services that you provide and click on I only one of them and I'll take you to the documentation I'll tell you how many of these there are all sorts of things what else is bit of an assist as a least you can get a Tilly's but protect ourselves if you want to know what the SLA is for these herbalux for example you can see the ACA is 99.5 and when it was updated you can go and see the status for things so if something's down and you want to figure out why it's down or is it down in fact you can go on going here and click on it and also shows you the number of regions available just play things again you can filter all these kind of things as well those regions so you can see the region scope of what's available we're so you can see like West Europe it'll go into like mine what's the North lip and the filters of depend on you can compare that to you see East Asia you can compare the kind of resources out of it over in the region and but one of the good ones is the solution Explorer so if you're looking for solutions or let's see other DevOps you can click on here and get was of 80 days of DevOps for container and I'll te telling us of example architecture and things online so you can learn all about kind of assault or something you can Brent and when the boo let's see you went to the learners are poor see it's gonna have you secured divorce from eks so there's lots of really good this website is really cool other thing I like is the landing customer story so you can run and find our customers who have put that these services and to play in and"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:50:40",
        "seconds": 3040,
        "text": "you secured divorce from eks so there's lots of really good this website is really cool other thing I like is the landing customer story so you can run and find our customers who have put that these services and to play in and to practice I've killed so see you want to land a bit who's done blocked in you can run in find a customer stories of a company's if that the practiced and how it saved them money and all I can I can good stuff blending exploder dear faculty I'll take you to links again same sort of stuff there's also quiz so yeah there's a lot of stuff in here and I don't really could spend on the really cool one thing I did want III was ACI labeled so I saw that's it small and the kubernetes SOA has just changed today and you can go in here you can get noticed get an autistic friend that was updated so that's canals your charge breaker website right by a guy here also make yourself to him yeah you can run in kind of track keys and do all sorts of stuff but they fire walking on wood next one is Michael Crump cuz he's Al Jarreau types and tricks I was talking about so he's got lots of trips and checks for all sorts of things with a Nigel so see you didn't front door how'd he get start to the front door I will talk about her there's so many things so many good ethical things like evil if you want to secure and remove as your secrets committed to get hub nothing was on here now this is all punch force as well so if you have a type of chuckling you like this year with someone you can you can go into life as well you can then he's got I did for many poor ones gonna add your code to that so that's that's plain earthly idea what was do you know walking in to show yes because this is one of my favorite resources so if they know much do now you're DevOps and you want to learn about I did a ROPS that's way of saying is really cool so this is me log gonna know the trick is equal to choose template and if you want to win so what this does is it say suck I will agile devops area for you like a whole project so that doesn't tapes of projects here there's a gentleman Joe Warren here says Java Java as you bleep up with my C coupe so what this will do is it will create a little project with an agile devops that will create peat wings build paint wings release bait wings Oh clipboards depending on what kind of scum board you want or an agile board the cord is also in here so it's called things like connects could commence and it basically shows you how to use all about your dev ops by example which is really cool the next thing next to that is DevOps labs so you can go to land a boat house Red Machine 11 you can learn a big dog you can learn about octopus deploy selenium and these are all kind of these all spent offense 810 Thanos and then sandbox is wonderful sandbox is you can go learn about ways to us ball and stuff like that so these are all these are all getting updated as well because this is playing near thing so keep an eye on that and that's also a lot of like spike to make software for so you can run my own their DevOps things this will take you to the basics of website based on DevOps and I asked what does it quite add option three mark which I would recommend everyone should kind of look out and download you can download the credit option free mark PDF and I will talk about how you go about moving to the cloud from from on-prem for example you can do a lot more than that but that's gonna have overlooked not sure folks we talked about as a fraidy I just feed is videos quite regularly was to see every 3d and again talking to nobody here I talk about how you speed up your application I'm not gonna short 20 minute 20 minute videos some things about the Scotsman talking to our guests just basically introducing a new project and topics and kind of talk about it's really really good stuff so I'm going to show you negative some community stuff that myself and I kept all our people put together so the Qantas thing called it clade family so basically is trying to grow the Azure community online all around the world so people have signed up for the quaint family and feed join it's not we've kind of got all the people who signed up just it can I show that feces and sort of total account got study guides in here as well so it's in large your study guides we have the people who are done let's get to show off the projects so those things like Ben Coleman has got around the template view we have Martin who has this really really cool diagram tool for drawing diagrams and are really fantastic Sam who can read who keeps resource management in foot toolkit for DevOps"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "00:55:43",
        "seconds": 3343,
        "text": "like Ben Coleman has got around the template view we have Martin who has this really really cool diagram tool for drawing diagrams and are really fantastic Sam who can read who keeps resource management in foot toolkit for DevOps the size of charge it's lots of good stuff in here and I've also got useful links so all of the links that I've can I show it and talk to it so people put extra links in here and pull requests and kind of sure that make it off layout obtaining this pd-nim it's free option fee marks or slack channels we've also got a slack channel that people can join and can I ask you a send and get help and kind of promote a little user groups first of a blog so everyone who comes and it was got a blog as your blog or whatever doesn't need to be nigelball but we're kind of just linked in the US this is all those your community blogs good to place they come and find useful information we've also got podcasts so if you've got an age of podcast you can put anymore so it's a quite skills 1 by M Mike faith or something yeah good one denies you lady and as you're late you around control all hazard publication Europe and that's really I've got some virtual events so we've got the class budget as you use a bit so user group events in the UK but looking for people to kind of join that the cloud family and contribute put these resources in here the idea being that it's just one place to come and playing finger resources rather than something for these guy things so we've got 100 odd people joined but please join please sign up if you're looking for details just ping me I can send you there like there's this slight channel get started from there and it's also that's website is actually oh and go up so people have contributed to to the site it's actually running on a thing called Google so far over 25 contributors it's just a static website we can pull requests and so please do have a look at that I know last one that was good I sure you talked about it as just my resources in general so I have my talk world one here so I'll put my slides in the talks Mulder well what do they show you they kind of useful links post-merger policies so if you have kind of keen on either policies so that's things like it stops people creating large as your images as cani naming conventions version so if you don't chase the major policies you can put somewhere near across the major government things I'm tagging just really good resources I've came across so that's the kind of why do I put my eyes you hide your resources in here community we've kind of just got some links probably most of this is actually going to end up on the close family website to be honest so that's that and the last thing I wanted to talk about I think that's just about me yeah that's just about me for kind of shiny older is also saw me just quickly switch back to the slides so does anyone have any questions on it I run through I can suggest one is the edge collections shareable yes and someone said that the slack channel link and the cloud family page is broken yes yeah few people so I bet Lee you have attained shortly you and I think it's time innate so I'll need to flex up yeah I'm solo so please do sign up and then hang me on these just ping down there if you want or lengthen I think I'm the only going up so thisis just pay me on the and and really the only other thing I was going to say is the key theories for the key theories for us Charles please to stop to be if you're not well advise you know how do you want to take me via clear negative direction then start whaling on something like how's your today and set yourself some goals definitely have goals if you don't have goals and I always sit at a moment so what I'm picking an exam or book it maybe I'm one thing knowing that that's when we have same focused you've sent me and start studying and stop watching therefore like some things on example failures will welcome you will probably feel an example to maybe you want but so it was good to kinda talk about furio's or what people don't know mention like you will learn alot new skills which is why I was a dude exam that will fill in the blanks and if you're done Wayne and you're talking to people and things like the clay family and you will get opportunities people aren't always in there - like channels in someone hammer that's"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "01:00:47",
        "seconds": 3647,
        "text": "the blanks and if you're done Wayne and you're talking to people and things like the clay family and you will get opportunities people aren't always in there - like channels in someone hammer that's good someone record a video on this but someone like this speak a nice event except rotator and last but not least Thursday trying get back to the community because it's good to pay something back and I always think it's always good to think of the person combined they may read a blog post even though you think obvious gonna read my blog post upon someone making that but the same problem here and then we read that read the solution so what and actually there's my contact details have been and he wants to get and tucked off me and that's the end of that I can see one my question here ah what's the best place to start if you're totally new to Azure so yeah that's what we cover use like so it depends on your background okay so I feel kind of developer then well was just I would start with fundamentals so you want to look at easy eight nine hundred so that's kind of an overview module so start we'll have a look at that the exam that will give you links to they kind of trainer and thus amazing thing added links and some of the stuff allows you weren't already and special and they get help as your resources and I will give you a good good foundation to start off with and I'll throw in some kind of blanks and hopefully you'll pick up but feel free the other thing is feel free to each other on Twitter so this hashtag as your family and hashtag clade family and there's quite a lot of people follow those hashtags so if you do have any questions always feel free just ask the question people are always rolling tail I would say definitely start with fundamentals ago awesome I don't think we'd have any more questions people are just super happy and super excited and we're all excited that you share it amazing presentation and now we learn along that we're all gonna go and take all that as your exams so thank you so much Greg we hope to see you again and for now I'm gonna pass words to Bill so he can talk about future meetups and what's going on with boss and Azure hello folks and am i audible hi Craig pleasure to meet you I caught much of your talk and my I'm completely embarrassed that I was late for this hi oh yeah I thought it was starting an hour later so you think I'd know better so welcome back everybody else to to Boston Asher it's been a while since we've had a meeting and you haven't heard from us until very recently I didn't think you needed to hear from Boston ah sure that we're we noticed that coronavirus is happening and we're doing all the obvious things so we just stayed quiet rather than bother you it's been a couple months we had meetings in February in both Burlington and Cambridge and now it's two months later the bootcamp is scheduled for the 25th which is a week from Saturday at my calendar mathas right and we're not actively participating in that but there is still energy bootcamp the global boot camp that you can tap into if you're interested our next Boston Azure specific event is two weeks from tonight and it's Kali who has spoken with us before and tab will be talking about sequel agent and not secret agent which would also be a cool talks but sequel agent and what you might think is a gap in the in the Microsoft Azure managed as a sequel database service because there is no sequel agent rather he'll explain why it's not a gap and how all the interesting things you can do with sequel agents there are more Azure cloud native ways of accomplishing the same things and so I'm looking forward to that that will be our second virtual session also you know again I I feel really bad I was late so I didn't get to hear how this was set up at the beginning but so let me just speak for just just a minute I the you know"
    },
    {
        "speaker": "",
        "title": "Gregor Suttie - Super Charge Your Learning of Azure",
        "videoId": "_dM5AqWlga8",
        "description": "This is a recording of the April 16, 2020 virtual meetingSupercharge your azure learning - in this talk I will cover my journey learning Azure, I'll cover how I got started, the azure exams and then focus and demo the top learning resources I have come across, which will cover all levels of Azure knowledge from beginner to expert with some community content thrown in for good measure - questions at the end are very welcome.SPEAKER BIOGregor Suttie wrote about himself:I am a passionate developer with 20+ years experience, mainly with Microsoft Technologies and background is a .NET developer since the start of .NET. – I was one of the first 50 people in the world to become an MCSD developer back in the day.I currently work for Sword as the Head of Development Services where I manage a team of full-time employees who are mostly remote workers all over the UK.My main passions are around Azure and DevOps, in my current role I am doing a lot of Azure and absolutely loving the hands-on time I get with Azure. In the past, I have used plain old MSBuild, TeamCity, Cake, and Octopus Deploy and now I focus primarily on Azure DevOps (formerly known as Visual Studio Team Services VSTS).DevOps and Azure are my focus of late and they are my main passion apart from learning new technologies. I went from no knowledge of Azure to an Azure MVP in under 2 years and along the journey passed 9 exams, I learn new skills quickly and I keep on top of a number of technologies and a life learner.",
        "start": "01:05:53",
        "seconds": 3953,
        "text": "also you know again I I feel really bad I was late so I didn't get to hear how this was set up at the beginning but so let me just speak for just just a minute I the you know this virtual meeting thing it's new to Veronica and Jason and myself and we've we've never done a Boston Asher event that was just purely a virtual one so we're all learning in part it's a an opportunity there's no travel overhead there's no painful room reservation process my goodness you would be surprised at how painful it can be to get a room at nerd the there's no pizza to buy so we'd have to figure out how to fund pizza and so forth so that there no costs really and one of the decisions that we took was to since it's a simpler process not only for us to organize but also for anybody who's attending to make it to the event but you don't have to travel to nerd or to the Burlington office you don't have to figure out how to have dinner and other kinds of things are simpler we've we're leaning on a we're going to try this out we're gonna try shorter meetings instead of having like one of the things we've worked real hard to do was have two talks every meeting to make it really worth a while to show up that was you know the most common pattern we're gonna try one talk one focused you know feature talk like we had tonight with Greg except we'll be more frequently so the the tail talk is two weeks of tonight for example and then we're going to try to get roughly on a two-week cadence oh you know virtual meetings as an opportunity we're also thinking about if we can capture the recording since it's already digital and post it to YouTube with speaker permission and our you know as long as things don't go wrong where we don't want to promise that we'll be doing this all time but it's something that we also want to try so that's another part of the opportunity and still another part of the opportunity is a really excellent one as it would have been essentially impossible for us to have Gregg as a speaker in person because he's in Glasgow and very late over there right now I'm sure is it half 12 hey yeah so thank you for sticking with us that's to be a general - oh good so so this is a fantastic opportunity and one of the things where we're gonna be able to do is you know fan out our speaker base so we should be able to pipe through folks who are you know have been out of reach essentially in the past which is fantastic will you'll still hear from local speakers you know Delp is a local MVP and you know we're excited to have him back we have a lot of quality speakers locally we still plan to have them enlighten us but you know we'll we'll widen our our net four four speakers that we can bring in and we we still want to you know have a sense of community we don't quite know how to do that yet honestly so we have the slack thing if you haven't joined the Boston as your slack that might be a good thing to plug into it's there's a bitly link I posted in the in the teams chat area but it's basically vit ly / all lowercase ba / short for Boston as your slack and you can self invite there it just takes a couple of minutes and there's a slack channel for today's meeting which of course if I had been here on time I would have told you all about before the meeting I don't know if others had the opportunity to do that but that's one way we're trying to stay you know in touch with the community and if you have feedback for us we would really love your feedback because we're you know genuinely you know we're trying to figure this out too and we want to we don't want to do this just for us either you know we want it's great if we get feedback and we get ideas from the community what's working what's not in terms of talk format are we using the right tools are we having it at the right times at the right frequencies anything you know in this world I don't know maybe we should have a meeting occasionally at noon who knows right it's because the rules are just different and we got to think a little bit outside of the constraints that we're accustomed to living within the in-person meeting world so that's my offer back to the community huge community let's let's talk on slack in the general channel that would probably a good place about if you have that kind of feedback you have a feedback or you want to discuss a particular meeting we're gonna at least experiment with creating a channel per meeting so that we have a you know plate a home base for any particular meeting and we're trying to balance that with the live event chat stream that we have here I don't know if they conflict or whatever we you know we're again admittedly where I'll do with this and was kind of figure it out so with that let me again thank our speaker from across the pond Greg was really great to catch most of your talk and thank you for your burning them in that oil to hang out with us and you know we're honored to have you as our first virtual speaker in a new era of community here for Boston house so thank you Greg oh thank you thanks for didn't think very much appreciated photoline joiner organized fantastic so I'll pause there and see if I don't think anybody else has the ability to speak with a with the way we do the meeting so Veronica or Jason if you have anything to add feel free to do so otherwise I'll just end the meeting I guess he'll in the meeting so thanks everybody I look forward to chatting more on slack again VI t ly bitly / VA slack all lowercase and we'll we'll look forward to talking to you in the future everybody stay safe out there and stay sane and we'll see ya next time take care thank you just you "
    }
]