{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Tie it all together\n",
    "\n",
    "In this lab, you use a combination of all the other Labs in order to have a RAG application that:\n",
    "\n",
    "* Uses the transcripts from all the Boston Azure Youtube videos\n",
    "* Uses the transcript version that is chunked in 5 minute increments\n",
    "* Uses Azure AI Search as the vector store\n",
    "* Creates citations with the Youtube video title and url to the 5 minute chunk\n",
    "\n",
    "> NOTE: Soon after the GAB I will be pulling the Azure AI Search indexes down that is used in this lab\n",
    "\n",
    "### Step 1:\n",
    "\n",
    "Look over the code and run the following to get ready for the lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "  openai_api_version=\"2023-05-15\",\n",
    "  azure_deployment= os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"{d.metadata['title']}~https://youtu.be/{d.metadata['videoId']}?t={d.metadata['seconds']}~{d.page_content}\" for d in docs])\n",
    "\n",
    "vectorstore_address = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "vectorstore_password = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "\n",
    "index_name: str = \"boston-azured-transcripts\"\n",
    "vectorstore: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vectorstore_address,\n",
    "    azure_search_key=vectorstore_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next there is a new prompt template in order to handle the video title and the Youtube url. \n",
    "\n",
    "Run the following to create it (you may find you want to modify it to get better results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_with_citations = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"Assistant helps people with their questions about the content of video transcripts. Be brief in your answers.\n",
    "        Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. \n",
    "        Do not generate answers that don't use the sources below.\n",
    "        Each source has this format: title~url~source\n",
    "        Always include the source title and url for each fact you use in the response.         \n",
    "         Place the title and url in square brackets after your answer, for example:\n",
    "            [Source Title: https://source.url]\n",
    "         Don't combine sources, list each source separately, for example:\n",
    "            [Source Title Video 1: https://source.url1]\n",
    "            [Source Title Video 2: https://source.url2]\n",
    "         \n",
    "            Context: {context}\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a retriever and the chain to call the vector store, format the results and call the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template_with_citations\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"What is azure container apps?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few different questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"How do you evaluate RAG applications?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What did Bill Wilder present?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"Who presented on SQL Server?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is it! You made it through to the end. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
