{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Build a RAG Application with LangChain, Part 3\n",
    "\n",
    "In this lab we continue to build on [Lab2](./2_rag.ipynb) and [Lab 3](./3_rag-with-chunking.ipynb)\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "* Learn how to use Azure AI Search for a Vector Store\n",
    "* Learn how to add citations to the response\n",
    "\n",
    "### Step 1: Setup what we covered in Lab 2 and Lab 3\n",
    "\n",
    "Run the following to get ready for this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "  openai_api_version=\"2023-05-15\",\n",
    "  azure_deployment= os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a helpful assistant that is very brief but polite in your answers. Answer questions in less than 50 words.\n",
    "            Answer the question based on the context below. If you can't \n",
    "            answer the question, reply \"I don't know\".\n",
    "\n",
    "            Context: {context}\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "DATASET_NAME = \"./prep/output/master.json\"\n",
    "transcripts_dataset = pd.read_json(DATASET_NAME)\n",
    "\n",
    "loader = DataFrameLoader(transcripts_dataset, page_content_column=\"text\")\n",
    "transcripts = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many documents we are working with in this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use Azure AI Search as the vector store\n",
    "\n",
    "**Please change the index name to include your initials or name so it won't have duplicate entries from another user in it**\n",
    "\n",
    "Run the below to configure the client used to interact with Azure Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "vectorstore_address = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "vectorstore_password = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "\n",
    "# Add your name to the index name to avoid conflicts with other users\n",
    "index_name = \"bos-gab-index-<yourname>\"\n",
    "vectorstore = AzureSearch(\n",
    "    azure_search_endpoint=vectorstore_address,\n",
    "    azure_search_key=vectorstore_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the documents loaded in Step 1 into the AzureSearch vector store.\n",
    "\n",
    "> NOTE: This will take a few minutes depending on the network speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are documents to use, try a similarity search to verify things are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search(\n",
    "    query=\"What is langchain?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems to be working. Now let's move toward the functionality we testing in Lab 3.\n",
    "\n",
    "Create a retriever to use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if it is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_docs = retriever.get_relevant_documents(query=\"What is langchain?\")\n",
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just like at the end of Lab 3, try out it out - just remember the vector store is not running in-memory this time, but in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add citations for identifying the source\n",
    "\n",
    "One of the important parts of a RAG application is to include citations - this helps verify the LLM is not making something up.\n",
    "\n",
    "> NOTE: Citations do not guarantee the LLM didn't make up the response, but it does help to verify to help you with a confidence level.\n",
    "\n",
    "In order to have the response include citations we need to do a couple of things:\n",
    "1. Modify the document listing used as the context to include the title of the video\n",
    "1. Modify the prompt with some instructions for how to use the title and how we want it returned\n",
    "\n",
    "The first thing we need is a utility function we'll use to modify the string returned from the retriever so the format will look like: \n",
    "```code\n",
    "\"<video title>:<transcript text>\"\n",
    "```\n",
    "\n",
    "Run the following to declare the utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([f\"{d.metadata['title']}:{d.page_content}\" for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify the prompt template to let the LLM know how the context is formatted and how to use the title and content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_with_citations = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"Assistant helps people with their questions about the content of video transcripts. Be brief in your answers.\n",
    "        Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. \n",
    "        Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
    "        Each source has a title followed by colon and the actual information, always include the source title for each fact you use in the response. \n",
    "         Use square brackets to reference the source, for example [Video title here]. Don't combine sources, list each source separately, for example [Video 1][Video 2].\n",
    "            Context: {context}\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template_with_citations\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is AKS?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Here are some good resources to learn more about using Azure AI Search with LangChain:\n",
    "* [Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-cognitive-search-and-langchain-a-seamless-integration-for/ba-p/3901448)\n",
    "* LangChain Docs [Azure AI Search](https://python.langchain.com/docs/integrations/vectorstores/azuresearch/)\n",
    "* [Azure AI Search client library for Python - version 11.4.0](https://learn.microsoft.com/en-us/python/api/overview/azure/search-documents-readme?view=azure-python)\n",
    "\n",
    "## [Go To Next Lab](./5_rag-final.ipynb.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
